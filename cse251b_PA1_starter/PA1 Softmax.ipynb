{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pca import PCA\n",
    "import argparse\n",
    "import network\n",
    "import os, random, sys\n",
    "from data import traffic_sign, generate_k_fold_set, onehot_encode, onehot_decode, z_score_normalize, append_bias\n",
    "from model.softmax import SoftmaxRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34799, 1024)\n",
      "(34799,)\n",
      "float32\n",
      "uint8\n"
     ]
    }
   ],
   "source": [
    "### Q6(a) - Evaluate Network on all 43 traffic signs (aligned dataset)\n",
    "\n",
    "# Load aligned data\n",
    "X, y = traffic_sign(True)\n",
    "X = X.astype(np.float32) # cast to float32 as float64 running out of memory\n",
    "X = z_score_normalize(X) \n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(X.dtype)\n",
    "print(y.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## (i) With PCA on aligned\n",
    "\n",
    "DEBUG = False\n",
    "\n",
    "# Softmax Regression Parameters\n",
    "lr = 0.5\n",
    "num_features = X.shape[1]\n",
    "num_classes = y.max() + 1\n",
    "\n",
    "train_loss_record = []\n",
    "\n",
    "train_accuracy_record = []\n",
    "\n",
    "holdout_loss_record = []\n",
    "\n",
    "holdout_accuracy_record = []\n",
    "\n",
    "test_accuracy_record = []\n",
    "\n",
    "# PCA number of principal components\n",
    "n_components = 300\n",
    "\n",
    "first_plot = True\n",
    "\n",
    "num_epochs = 300\n",
    "epochs_print = [50, 100, 150, 200, 250, 300]\n",
    "\n",
    "k = 10\n",
    "\n",
    "total_test_accuracy = 0.0\n",
    "total_test_loss = 0.0\n",
    "\n",
    "cur_fold = 0\n",
    "for train, valid, test in generate_k_fold_set((X, y), k):\n",
    "    print(f\"Current Fold: {cur_fold}\")\n",
    "    train_data, train_label = train\n",
    "    valid_data, valid_label = valid\n",
    "    test_data, test_label = test\n",
    "    \n",
    "    # Project data onto principal components\n",
    "    pca = PCA(n_components)\n",
    "    projected = pca.fit_transform(train_data) # len(train_data) x n_components\n",
    "    \n",
    "    # Plot principal components\n",
    "    if first_plot == True : \n",
    "        pca.plot_PC()\n",
    "        first_plot = False\n",
    "    train_d = append_bias(projected)     \n",
    "    valid_d = append_bias(pca.PCA_generate(valid_data))\n",
    "    test_d = append_bias(pca.PCA_generate(test_data))\n",
    "\n",
    "    softmax_model = SoftmaxRegression(lr, n_components, num_classes)\n",
    "    best_w = softmax_model.W\n",
    "\n",
    "    # Onehot encode labels\n",
    "    y_true = onehot_encode(train_label)\n",
    "    valid_label_onehot = onehot_encode(valid_label)\n",
    "    test_label_onehot = onehot_encode(test_label)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        y_hat = softmax_model.model(train_d)\n",
    "        \n",
    "        raw_train_loss = softmax_model.cross_entropy(y_true, y_hat)\n",
    "        train_loss_norm = raw_train_loss / len(train_d) / num_classes # train loss normalized by # examples and classes\n",
    "        \n",
    "        train_loss_record.append(train_loss_norm)\n",
    "        \n",
    "        train_accuracy = softmax_model.accuracy(y_true, y_hat)\n",
    "        train_accuracy_record.append(train_accuracy)\n",
    "        \n",
    "        holdout_y = softmax_model.model(valid_d)\n",
    "\n",
    "        holdout_loss = softmax_model.cross_entropy(holdout_y, valid_label_onehot)\n",
    "        holdout_loss_norm = holdout_loss / len(valid_d) / num_classes # holdout loss normalized by # examples and classes\n",
    "        holdout_loss_record.append(holdout_loss_norm)\n",
    "\n",
    "        holdout_accuracy = softmax_model.accuracy(holdout_y, valid_label_onehot)\n",
    "        holdout_accuracy_record.append(holdout_accuracy)\n",
    "\n",
    "        if holdout_accuracy >= max(holdout_accuracy_record[cur_fold * num_epochs:]):\n",
    "            best_w = softmax_model.W\n",
    "\n",
    "        # Update Weights\n",
    "        softmax_model.update_weights(train_d, y_true, y_hat)\n",
    "\n",
    "        if (epoch + 1) in epochs_print:\n",
    "            print(f' epoch: {epoch + 1}, train accuracy: {train_accuracy:.4f}, train_loss_norm:{train_loss_norm:.4f}, '\\\n",
    "                f'valid_acc: {holdout_accuracy:.4f}, valid_loss_norm: {holdout_loss_norm:.4f}')\n",
    "            if DEBUG:\n",
    "                test_y = softmax_model.model_w(test_d, best_w)\n",
    "                test_y_1 = softmax_model.model(test_d)\n",
    "\n",
    "                test_accuracy = softmax_model.accuracy(test_y, test_label_onehot)\n",
    "                test_accuracy_1 = softmax_model.accuracy(test_y_1, test_label_onehot)\n",
    "\n",
    "                raw_test_loss = softmax_model.cross_entropy(test_y, test_label_onehot)\n",
    "                test_loss_norm = raw_test_loss / len(test_d) / num_classes\n",
    "\n",
    "                print(f'MODEL_W: Test accuracy: {test_accuracy:.4f}', f'Test loss norm: {test_loss_norm:.4f}')\n",
    "                print(f'MODEL: Test accuracy: {test_accuracy_1:.4f}')\n",
    "\n",
    "    # Run on Test Dataset\n",
    "    test_y = softmax_model.model_w(test_d, best_w)\n",
    "\n",
    "    test_accuracy = softmax_model.accuracy(test_y, test_label_onehot)\n",
    "\n",
    "    print(f'Test accuracy: {test_accuracy:.4f}')\n",
    "\n",
    "    test_accuracy_record.append(test_accuracy)\n",
    "\n",
    "    raw_test_loss = softmax_model.cross_entropy(test_y, test_label_onehot)\n",
    "    test_loss_norm = raw_test_loss / len(test_d) / num_classes\n",
    "    total_test_loss += test_loss_norm\n",
    "    print(f\"Test loss norm: {test_loss_norm:.4f}\")\n",
    "\n",
    "    cur_fold += 1\n",
    "\n",
    "print(f'Average test accuracy over {k} folds: {np.mean(test_accuracy_record):.4f} (+/- {np.std(test_accuracy_record):.4f})')\n",
    "print(f'Average test loss per example and class over {k} folds: {total_test_loss / k:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_out_data_k(data, k=10):\n",
    "    total_count = len(data)\n",
    "    count_per_fold = total_count // k # Assumes cleanly divisble number\n",
    "    new_data = [0.0 for i in range(count_per_fold)]\n",
    "    for i in range(k):\n",
    "        for j in range(count_per_fold):\n",
    "            new_data[j] += data[i * count_per_fold + j]\n",
    "    new_data = [d / k for d in new_data]\n",
    "    return new_data\n",
    "\n",
    "def get_data_at_epoch_fold(data, epoch, total_num_folds=10):\n",
    "    # Returns a new list of data points at a specified epoch from all folds\n",
    "    # data = [fold1....fold10]\n",
    "    # epoch is 0-indexed\n",
    "    epoch_per_fold = len(data) // total_num_folds\n",
    "    new_data = [data[f * (epoch_per_fold) + epoch] for f in range(total_num_folds)]\n",
    "    return new_data # [epoch n from fold1, epoch n from fold2, ..., epoch n from fold10]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 1, constrained_layout=True)\n",
    "\n",
    "epochs_error_bar = [50, 100, 150, 200, 250, 300] # 1-indexed\n",
    "epochs_error_bar_0 = [epoch - 1 for epoch in epochs_error_bar] # 0-indexed\n",
    "\n",
    "# Plot Loss\n",
    "average_train_loss = average_out_data_k(train_loss_record)\n",
    "train_loss_error_bar_y = [average_train_loss[epoch] for epoch in epochs_error_bar_0]\n",
    "train_loss_error_bar_yerr = [np.std(get_data_at_epoch_fold(train_loss_record, epoch)) for epoch in epochs_error_bar_0]\n",
    "\n",
    "# For Q6b_ii comparison\n",
    "batch_average_train_loss = average_train_loss \n",
    "batch_average_train_loss_error_bar_y = train_loss_error_bar_y\n",
    "batch_average_train_loss_error_bar_yerr = train_loss_error_bar_yerr\n",
    "\n",
    "average_valid_loss = average_out_data_k(holdout_loss_record)\n",
    "valid_loss_error_bar_y = [average_valid_loss[epoch] for epoch in epochs_error_bar_0]\n",
    "valid_loss_error_bar_yerr = [np.std(get_data_at_epoch_fold(holdout_loss_record, epoch)) for epoch in epochs_error_bar_0]\n",
    "\n",
    "axs[0].plot(average_train_loss, '-b', label='Training loss')\n",
    "axs[0].errorbar(x=epochs_error_bar_0, y=train_loss_error_bar_y, yerr=train_loss_error_bar_yerr, label='Training loss error', fmt='-b')\n",
    "\n",
    "axs[0].plot(average_valid_loss, '--r', label='Validation loss')\n",
    "axs[0].errorbar(x=epochs_error_bar_0, y=valid_loss_error_bar_y, yerr=valid_loss_error_bar_yerr, label='Validation loss error', fmt='--r')\n",
    "\n",
    "axs[0].legend()\n",
    "axs[0].set_xlabel('Epochs')\n",
    "axs[0].set_ylabel('Normalized Loss')\n",
    "axs[0].set_title('Loss normalized per example and class vs. Epochs')\n",
    "\n",
    "# Plot Accuracy\n",
    "average_train_acc = average_out_data_k(train_accuracy_record)\n",
    "train_acc_error_bar_y = [average_train_acc[epoch] for epoch in epochs_error_bar_0]\n",
    "train_acc_error_bar_yerr = [np.std(get_data_at_epoch_fold(train_accuracy_record, epoch)) for epoch in epochs_error_bar_0]\n",
    "\n",
    "average_valid_acc = average_out_data_k(holdout_accuracy_record)\n",
    "valid_acc_error_bar_y = [average_valid_acc[epoch] for epoch in epochs_error_bar_0]\n",
    "valid_acc_error_bar_yerr = [np.std(get_data_at_epoch_fold(holdout_accuracy_record, epoch)) for epoch in epochs_error_bar_0]\n",
    "\n",
    "axs[1].plot(average_train_acc, '-b', label='Training accuracy')\n",
    "axs[1].errorbar(x=epochs_error_bar_0, y=train_acc_error_bar_y, yerr=train_acc_error_bar_yerr, label='Training accuracy error', fmt='-b')\n",
    "\n",
    "axs[1].plot(average_valid_acc, '--r', label='Validation accuracy')\n",
    "axs[1].errorbar(x=epochs_error_bar_0, y=valid_acc_error_bar_y, yerr=valid_acc_error_bar_yerr, label='Validation accuracy error', fmt='--r')\n",
    "\n",
    "axs[1].legend()\n",
    "axs[1].set_xlabel('Epochs')\n",
    "axs[1].set_ylabel('Accuracy')\n",
    "axs[1].set_title('Accuracy vs. Epochs')\n",
    "\n",
    "plt.savefig(\"plots/Q6a_i.png\")\n",
    "plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## (ii) Without PCA on aligned and with PCA on unaligned\n",
    "## 1. Without PCA on aligned\n",
    "\n",
    "print(\"(ii)\")\n",
    "print(\"Without PCA on aligned\")\n",
    "\n",
    "# Weights for Q6c (Weight Visualization on non PCA weights)\n",
    "weight_visualization_weights = None\n",
    "\n",
    "DEBUG = False\n",
    "\n",
    "# Softmax Regression Parameters\n",
    "lr = 0.01\n",
    "num_features = X.shape[1]\n",
    "num_classes = y.max() + 1\n",
    "\n",
    "train_loss_record = []\n",
    "\n",
    "train_accuracy_record = []\n",
    "\n",
    "holdout_loss_record = []\n",
    "\n",
    "holdout_accuracy_record = []\n",
    "\n",
    "test_accuracy_record = []\n",
    "\n",
    "num_epochs = 300\n",
    "epochs_print = [50, 100, 150, 200, 250, 300]\n",
    "\n",
    "k = 10\n",
    "\n",
    "total_test_accuracy = 0.0\n",
    "total_test_loss = 0.0\n",
    "\n",
    "cur_fold = 0\n",
    "for train, valid, test in generate_k_fold_set((X, y), k):\n",
    "    print(f\"Current Fold: {cur_fold}\")\n",
    "    train_data, train_label = train\n",
    "    valid_data, valid_label = valid\n",
    "    test_data, test_label = test\n",
    "    \n",
    "    train_d = append_bias(train_data)     \n",
    "    valid_d = append_bias(valid_data)\n",
    "    test_d = append_bias(test_data)\n",
    "\n",
    "    softmax_model = SoftmaxRegression(lr, num_features, num_classes)\n",
    "    best_w = softmax_model.W\n",
    "\n",
    "    # Onehot encode labels\n",
    "    y_true = onehot_encode(train_label)\n",
    "    valid_label_onehot = onehot_encode(valid_label)\n",
    "    test_label_onehot = onehot_encode(test_label)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        y_hat = softmax_model.model(train_d)\n",
    "        \n",
    "        raw_train_loss = softmax_model.cross_entropy(y_true, y_hat)\n",
    "\n",
    "        train_loss_norm = raw_train_loss / len(train_d) / num_classes # train loss normalized by # examples and classes\n",
    "        \n",
    "        train_loss_record.append(train_loss_norm)\n",
    "        \n",
    "        train_accuracy = softmax_model.accuracy(y_true, y_hat)\n",
    "        train_accuracy_record.append(train_accuracy)\n",
    "        \n",
    "        holdout_y = softmax_model.model(valid_d)\n",
    "\n",
    "        holdout_loss = softmax_model.cross_entropy(holdout_y, valid_label_onehot)\n",
    "        holdout_loss_norm = holdout_loss / len(valid_d) / num_classes # holdout loss normalized by # examples and classes\n",
    "        holdout_loss_record.append(holdout_loss_norm)\n",
    "\n",
    "        holdout_accuracy = softmax_model.accuracy(holdout_y, valid_label_onehot)\n",
    "        holdout_accuracy_record.append(holdout_accuracy)\n",
    "\n",
    "        # if holdout_accuracy >= max(holdout_accuracy_record):\n",
    "        if holdout_accuracy >= max(holdout_accuracy_record[cur_fold * num_epochs:]):\n",
    "            best_w = softmax_model.W\n",
    "            weight_visualization_weights = best_w[:-1]\n",
    "\n",
    "        # Update Weights\n",
    "        softmax_model.update_weights(train_d, y_true, y_hat)\n",
    "\n",
    "        if DEBUG:\n",
    "            print(f' epoch: {epoch + 1}, train accuracy: {train_accuracy:.4f}, train_loss_norm:{train_loss_norm:.4f}, '\\\n",
    "                f'valid_acc: {holdout_accuracy:.4f}, valid_loss_norm: {holdout_loss_norm:.4f}')\n",
    "        else:\n",
    "            if (epoch + 1) in epochs_print:\n",
    "                print(f' epoch: {epoch + 1}, train accuracy: {train_accuracy:.4f}, train_loss_norm:{train_loss_norm:.4f}, '\\\n",
    "                    f'valid_acc: {holdout_accuracy:.4f}, valid_loss_norm: {holdout_loss_norm:.4f}')\n",
    "\n",
    "    # Run on Test Dataset\n",
    "    test_y = softmax_model.model_w(test_d, best_w)\n",
    "\n",
    "    test_accuracy = softmax_model.accuracy(test_y, test_label_onehot)\n",
    "\n",
    "    print(f'Test accuracy: {test_accuracy:.4f}')\n",
    "\n",
    "    test_accuracy_record.append(test_accuracy)\n",
    "\n",
    "    raw_test_loss = softmax_model.cross_entropy(test_y, test_label_onehot)\n",
    "    test_loss_norm = raw_test_loss / len(test_d) / num_classes\n",
    "    total_test_loss += test_loss_norm\n",
    "    print(f\"Test loss norm: {test_loss_norm:.4f}\")\n",
    "\n",
    "    cur_fold += 1\n",
    "\n",
    "print(f'Average test accuracy over {k} folds: {np.mean(test_accuracy_record):.4f} (+/- {np.std(test_accuracy_record):.4f})')\n",
    "print(f'Average test loss per example and class over {k} folds: {total_test_loss / k}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 1, constrained_layout=True)\n",
    "\n",
    "epochs_error_bar = [50, 100, 150, 200, 250, 300] # 1-indexed\n",
    "epochs_error_bar_0 = [epoch - 1 for epoch in epochs_error_bar] # 0-indexed\n",
    "\n",
    "# Plot Loss\n",
    "average_train_loss = average_out_data_k(train_loss_record)\n",
    "train_loss_error_bar_y = [average_train_loss[epoch] for epoch in epochs_error_bar_0]\n",
    "train_loss_error_bar_yerr = [np.std(get_data_at_epoch_fold(train_loss_record, epoch)) for epoch in epochs_error_bar_0]\n",
    "\n",
    "average_valid_loss = average_out_data_k(holdout_loss_record)\n",
    "valid_loss_error_bar_y = [average_valid_loss[epoch] for epoch in epochs_error_bar_0]\n",
    "valid_loss_error_bar_yerr = [np.std(get_data_at_epoch_fold(holdout_loss_record, epoch)) for epoch in epochs_error_bar_0]\n",
    "\n",
    "axs[0].plot(average_train_loss, '-b', label='Training loss')\n",
    "axs[0].errorbar(x=epochs_error_bar_0, y=train_loss_error_bar_y, yerr=train_loss_error_bar_yerr, label='Training loss error', fmt='-b')\n",
    "\n",
    "axs[0].plot(average_valid_loss, '--r', label='Validation loss')\n",
    "axs[0].errorbar(x=epochs_error_bar_0, y=valid_loss_error_bar_y, yerr=valid_loss_error_bar_yerr, label='Validation loss error', fmt='--r')\n",
    "\n",
    "axs[0].legend()\n",
    "axs[0].set_xlabel('Epochs')\n",
    "axs[0].set_ylabel('Normalized Loss')\n",
    "axs[0].set_title('Loss normalized per example and class vs. Epochs')\n",
    "\n",
    "# Plot Accuracy\n",
    "average_train_acc = average_out_data_k(train_accuracy_record)\n",
    "train_acc_error_bar_y = [average_train_acc[epoch] for epoch in epochs_error_bar_0]\n",
    "train_acc_error_bar_yerr = [np.std(get_data_at_epoch_fold(train_accuracy_record, epoch)) for epoch in epochs_error_bar_0]\n",
    "\n",
    "average_valid_acc = average_out_data_k(holdout_accuracy_record)\n",
    "valid_acc_error_bar_y = [average_valid_acc[epoch] for epoch in epochs_error_bar_0]\n",
    "valid_acc_error_bar_yerr = [np.std(get_data_at_epoch_fold(holdout_accuracy_record, epoch)) for epoch in epochs_error_bar_0]\n",
    "\n",
    "axs[1].plot(average_train_acc, '-b', label='Training accuracy')\n",
    "axs[1].errorbar(x=epochs_error_bar_0, y=train_acc_error_bar_y, yerr=train_acc_error_bar_yerr, label='Training accuracy error', fmt='-b')\n",
    "\n",
    "axs[1].plot(average_valid_acc, '--r', label='Validation accuracy')\n",
    "axs[1].errorbar(x=epochs_error_bar_0, y=valid_acc_error_bar_y, yerr=valid_acc_error_bar_yerr, label='Validation accuracy error', fmt='--r')\n",
    "\n",
    "axs[1].legend()\n",
    "axs[1].set_xlabel('Epochs')\n",
    "axs[1].set_ylabel('Accuracy')\n",
    "axs[1].set_title('Accuracy vs. Epochs')\n",
    "\n",
    "plt.savefig(\"plots/Q6a_ii_1.png\")\n",
    "plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2. With PCA on unaligned\n",
    "\n",
    "print(\"With PCA on unaligned\")\n",
    "\n",
    "# Load unaligned data\n",
    "X, y = traffic_sign(False)\n",
    "X = X.astype(np.float32) # cast to float32 as float64 running out of memory\n",
    "X = z_score_normalize(X) \n",
    "\n",
    "DEBUG = False\n",
    "\n",
    "# Softmax Regression Parameters\n",
    "lr = 0.5\n",
    "num_features = X.shape[1]\n",
    "num_classes = y.max() + 1\n",
    "\n",
    "train_loss_record = []\n",
    "\n",
    "train_accuracy_record = []\n",
    "\n",
    "holdout_loss_record = []\n",
    "\n",
    "holdout_accuracy_record = []\n",
    "\n",
    "test_accuracy_record = []\n",
    "\n",
    "# PCA number of principal components\n",
    "n_components = 300\n",
    "\n",
    "first_plot = True\n",
    "\n",
    "num_epochs = 300\n",
    "epochs_print = [50, 100, 150, 200, 250, 300]\n",
    "\n",
    "k = 10\n",
    "\n",
    "total_test_accuracy = 0.0\n",
    "total_test_loss = 0.0\n",
    "\n",
    "cur_fold = 0\n",
    "for train, valid, test in generate_k_fold_set((X, y), k):\n",
    "    print(f\"Current Fold: {cur_fold}\")\n",
    "    train_data, train_label = train\n",
    "    valid_data, valid_label = valid\n",
    "    test_data, test_label = test\n",
    "    \n",
    "    # Project data onto principal components\n",
    "    pca = PCA(n_components)\n",
    "    projected = pca.fit_transform(train_data) # len(train_data) x n_components\n",
    "    \n",
    "    # Plot principal components\n",
    "    if first_plot == True : \n",
    "        pca.plot_PC()\n",
    "        first_plot = False\n",
    "    train_d = append_bias(projected)     \n",
    "    valid_d = append_bias(pca.PCA_generate(valid_data))\n",
    "    test_d = append_bias(pca.PCA_generate(test_data))\n",
    "\n",
    "    softmax_model = SoftmaxRegression(lr, n_components, num_classes)\n",
    "    best_w = softmax_model.W\n",
    "\n",
    "    # Onehot encode labels\n",
    "    y_true = onehot_encode(train_label)\n",
    "    valid_label_onehot = onehot_encode(valid_label)\n",
    "    test_label_onehot = onehot_encode(test_label)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        y_hat = softmax_model.model(train_d)\n",
    "        \n",
    "        raw_train_loss = softmax_model.cross_entropy(y_true, y_hat)\n",
    "        train_loss_norm = raw_train_loss / len(train_d) / num_classes # train loss normalized by # examples and classes\n",
    "        \n",
    "        train_loss_record.append(train_loss_norm)\n",
    "        \n",
    "        train_accuracy = softmax_model.accuracy(y_true, y_hat)\n",
    "        train_accuracy_record.append(train_accuracy)\n",
    "        \n",
    "        holdout_y = softmax_model.model(valid_d)\n",
    "\n",
    "        holdout_loss = softmax_model.cross_entropy(holdout_y, valid_label_onehot)\n",
    "        holdout_loss_norm = holdout_loss / len(valid_d) / num_classes # holdout loss normalized by # examples and classes\n",
    "        holdout_loss_record.append(holdout_loss_norm)\n",
    "\n",
    "        holdout_accuracy = softmax_model.accuracy(holdout_y, valid_label_onehot)\n",
    "        holdout_accuracy_record.append(holdout_accuracy)\n",
    "\n",
    "        if holdout_accuracy >= max(holdout_accuracy_record[cur_fold * num_epochs:]):\n",
    "            best_w = softmax_model.W\n",
    "\n",
    "        # Update Weights\n",
    "        softmax_model.update_weights(train_d, y_true, y_hat)\n",
    "\n",
    "        if (epoch + 1) in epochs_print:\n",
    "            print(f' epoch: {epoch + 1}, train accuracy: {train_accuracy:.4f}, train_loss_norm:{train_loss_norm:.4f}, '\\\n",
    "                f'valid_acc: {holdout_accuracy:.4f}, valid_loss_norm: {holdout_loss_norm:.4f}')\n",
    "\n",
    "    # Run on Test Dataset\n",
    "    test_y = softmax_model.model_w(test_d, best_w)\n",
    "\n",
    "    test_accuracy = softmax_model.accuracy(test_y, test_label_onehot)\n",
    "\n",
    "    print(f'Test accuracy: {test_accuracy:.4f}')\n",
    "\n",
    "    test_accuracy_record.append(test_accuracy)\n",
    "\n",
    "    raw_test_loss = softmax_model.cross_entropy(test_y, test_label_onehot)\n",
    "    test_loss_norm = raw_test_loss / len(test_d) / num_classes\n",
    "    total_test_loss += test_loss_norm\n",
    "    print(f\"Test loss norm: {test_loss_norm:.4f}\")\n",
    "\n",
    "    cur_fold += 1\n",
    "\n",
    "print(f'Average test accuracy over {k} folds: {np.mean(test_accuracy_record):.4f} (+/- {np.std(test_accuracy_record):.4f})')\n",
    "print(f'Average test loss per example and class over {k} folds: {total_test_loss / k}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 1, constrained_layout=True)\n",
    "\n",
    "epochs_error_bar = [50, 100, 150, 200, 250, 300] # 1-indexed\n",
    "epochs_error_bar_0 = [epoch - 1 for epoch in epochs_error_bar] # 0-indexed\n",
    "\n",
    "# Plot Loss\n",
    "average_train_loss = average_out_data_k(train_loss_record)\n",
    "train_loss_error_bar_y = [average_train_loss[epoch] for epoch in epochs_error_bar_0]\n",
    "train_loss_error_bar_yerr = [np.std(get_data_at_epoch_fold(train_loss_record, epoch)) for epoch in epochs_error_bar_0]\n",
    "\n",
    "average_valid_loss = average_out_data_k(holdout_loss_record)\n",
    "valid_loss_error_bar_y = [average_valid_loss[epoch] for epoch in epochs_error_bar_0]\n",
    "valid_loss_error_bar_yerr = [np.std(get_data_at_epoch_fold(holdout_loss_record, epoch)) for epoch in epochs_error_bar_0]\n",
    "\n",
    "axs[0].plot(average_train_loss, '-b', label='Training loss')\n",
    "axs[0].errorbar(x=epochs_error_bar_0, y=train_loss_error_bar_y, yerr=train_loss_error_bar_yerr, label='Training loss error', fmt='-b')\n",
    "\n",
    "axs[0].plot(average_valid_loss, '--r', label='Validation loss')\n",
    "axs[0].errorbar(x=epochs_error_bar_0, y=valid_loss_error_bar_y, yerr=valid_loss_error_bar_yerr, label='Validation loss error', fmt='--r')\n",
    "\n",
    "axs[0].legend()\n",
    "axs[0].set_xlabel('Epochs')\n",
    "axs[0].set_ylabel('Normalized Loss')\n",
    "axs[0].set_title('Loss normalized per example and class vs. Epochs')\n",
    "\n",
    "# Plot Accuracy\n",
    "average_train_acc = average_out_data_k(train_accuracy_record)\n",
    "train_acc_error_bar_y = [average_train_acc[epoch] for epoch in epochs_error_bar_0]\n",
    "train_acc_error_bar_yerr = [np.std(get_data_at_epoch_fold(train_accuracy_record, epoch)) for epoch in epochs_error_bar_0]\n",
    "\n",
    "average_valid_acc = average_out_data_k(holdout_accuracy_record)\n",
    "valid_acc_error_bar_y = [average_valid_acc[epoch] for epoch in epochs_error_bar_0]\n",
    "valid_acc_error_bar_yerr = [np.std(get_data_at_epoch_fold(holdout_accuracy_record, epoch)) for epoch in epochs_error_bar_0]\n",
    "\n",
    "axs[1].plot(average_train_acc, '-b', label='Training accuracy')\n",
    "axs[1].errorbar(x=epochs_error_bar_0, y=train_acc_error_bar_y, yerr=train_acc_error_bar_yerr, label='Training accuracy error', fmt='-b')\n",
    "\n",
    "axs[1].plot(average_valid_acc, '--r', label='Validation accuracy')\n",
    "axs[1].errorbar(x=epochs_error_bar_0, y=valid_acc_error_bar_y, yerr=valid_acc_error_bar_yerr, label='Validation accuracy error', fmt='--r')\n",
    "\n",
    "axs[1].legend()\n",
    "axs[1].set_xlabel('Epochs')\n",
    "axs[1].set_ylabel('Accuracy')\n",
    "axs[1].set_title('Accuracy vs. Epochs')\n",
    "\n",
    "plt.savefig(\"plots/Q6a_ii_2.png\")\n",
    "plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## (iii) Confusion Matrix on Test Set results\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q6(b) - Stochastic Gradient Descent\n",
      "Cur fold: 0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x800 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27841, 300)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'PCA' object has no attribute 'PCA_generate'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/wt/l4n6hhns3dz9d7ljspfyxvd40000gn/T/ipykernel_24121/1349694922.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mfirst_plot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mtrain_d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mappend_bias\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprojected\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0mvalid_d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mappend_bias\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPCA_generate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m     \u001b[0mtest_d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mappend_bias\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPCA_generate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'PCA' object has no attribute 'PCA_generate'"
     ]
    }
   ],
   "source": [
    "### Q6(b) - Stochastic Gradient Descent\n",
    "\n",
    "print(\"Q6(b) - Stochastic Gradient Descent\")\n",
    "\n",
    "# (i)\n",
    "# Load aligned data\n",
    "X, y = traffic_sign(True)\n",
    "X = X.astype(np.float32) # cast to float32 as float64 running out of memory\n",
    "X = z_score_normalize(X) \n",
    "\n",
    "# Softmax Regression Parameters\n",
    "lr = 0.01\n",
    "num_features = X.shape[1]\n",
    "num_classes = y.max() + 1\n",
    "\n",
    "train_loss_record = []\n",
    "train_accuracy_record = []\n",
    "holdout_loss_record = []\n",
    "holdout_accuracy_record = []\n",
    "test_accuracy_record = []\n",
    "\n",
    "\n",
    "# PCA number of principal components\n",
    "n_components = 300\n",
    "\n",
    "first_plot = True\n",
    "\n",
    "num_epochs = 300\n",
    "epochs_print = [50, 100, 150, 200, 250, 300]\n",
    "\n",
    "cur_fold = 0\n",
    "\n",
    "for train, valid, test in generate_k_fold_set((X, y), k = 10):\n",
    "    print(\"Cur fold:\", cur_fold)\n",
    "    train_data, train_label = train\n",
    "    valid_data, valid_label = valid\n",
    "    test_data, test_label = test\n",
    "    \n",
    "    # Project data onto principal components\n",
    "    pca = PCA(n_components)\n",
    "    projected = pca.fit_transform(train_data)\n",
    "    \n",
    "    # Plot principal components\n",
    "    if first_plot == True : \n",
    "        pca.plot_PC()\n",
    "        first_plot = False\n",
    "    train_d = append_bias(projected)     \n",
    "    valid_d = append_bias(pca.PCA_generate(valid_data))\n",
    "    test_d = append_bias(pca.PCA_generate(test_data))\n",
    "\n",
    "    softmax_model = SoftmaxRegression(lr, n_components, num_classes)\n",
    "\n",
    "    valid_label_onehot = onehot_encode(valid_label)\n",
    "\n",
    "    # SGD\n",
    "    for epoch in range(num_epochs):\n",
    "        # Shuffle indices\n",
    "        indices = np.arange(len(train_d))\n",
    "        indices = np.random.shuffle(indices)\n",
    "\n",
    "        train_d = train_d[indices].squeeze(0)\n",
    "        train_label = train_label[indices].squeeze(0)\n",
    "        \n",
    "        # Onehot encode labels\n",
    "        y_true = onehot_encode(train_label)\n",
    "            \n",
    "        # Iterate over each example\n",
    "        for i in range(len(train_d)):\n",
    "            cur_ex = train_d[i][np.newaxis, :]\n",
    "            cur_label = y_true[i][np.newaxis, :]\n",
    "            y_hat = softmax_model.model(cur_ex)\n",
    "\n",
    "            # Update Weights\n",
    "            softmax_model.update_weights(cur_ex, cur_label, y_hat)\n",
    "\n",
    "        # Training Loss\n",
    "        y_hat = softmax_model.model(train_d)\n",
    "\n",
    "        raw_train_loss = softmax_model.cross_entropy(y_true, y_hat)\n",
    "        train_loss_norm = raw_train_loss / len(train_d) / num_classes\n",
    "\n",
    "        train_loss_record.append(raw_train_loss)\n",
    "\n",
    "        train_accuracy = softmax_model.accuracy(y_true, y_hat)\n",
    "        train_accuracy_record.append(train_accuracy)\n",
    "\n",
    "        # Validation Loss\n",
    "        holdout_y = softmax_model.model(valid_d)\n",
    "\n",
    "        holdout_loss = softmax_model.cross_entropy(holdout_y, valid_label_onehot)\n",
    "        holdout_loss_norm = holdout_loss / len(valid_d) / num_classes # holdout loss normalized by # examples and classes\n",
    "        holdout_loss_record.append(holdout_loss_norm)\n",
    "\n",
    "        holdout_accuracy = softmax_model.accuracy(holdout_y, valid_label_onehot)\n",
    "        holdout_accuracy_record.append(holdout_accuracy)\n",
    "\n",
    "        if holdout_accuracy >= max(holdout_accuracy_record[cur_fold * num_epochs:]):\n",
    "            best_w = softmax_model.W\n",
    "\n",
    "        \n",
    "        # if (epoch + 1) in epochs_print:\n",
    "        print(f' epoch: {epoch + 1}, train accuracy: {train_accuracy:.4f}, train_loss_norm:{train_loss_norm:.4f}, '\\\n",
    "            f'valid_acc: {holdout_accuracy:.4f}, valid_loss_norm: {holdout_loss_norm:.4f}')\n",
    "\n",
    "    # Run on Test Dataset\n",
    "    test_y = softmax_model.model_w(test_d, best_w)\n",
    "\n",
    "    test_label_onehot = onehot_encode(test_label)\n",
    "    test_accuracy = softmax_model.accuracy(test_y, test_label_onehot)\n",
    "\n",
    "    print(f'Test accuracy: {test_accuracy:.4f}')\n",
    "\n",
    "    test_accuracy_record.append(test_accuracy)\n",
    "\n",
    "    raw_test_loss = softmax_model.cross_entropy(test_y, test_label_onehot)\n",
    "    test_loss_norm = raw_test_loss / len(test_d) / num_classes\n",
    "    total_test_loss += test_loss_norm\n",
    "    print(f\"Test loss norm: {test_loss_norm:.4f}\")\n",
    "\n",
    "    cur_fold += 1\n",
    "\n",
    "print(f'Average test accuracy over {k} folds: {np.mean(test_accuracy_record):.4f} (+/- {np.std(test_accuracy_record):.4f})')\n",
    "print(f'Average test loss per example and class over {k} folds: {total_test_loss / k}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 1, constrained_layout=True)\n",
    "\n",
    "epochs_error_bar = [50, 100, 150, 200, 250, 300] # 1-indexed\n",
    "epochs_error_bar_0 = [epoch - 1 for epoch in epochs_error_bar] # 0-indexed\n",
    "\n",
    "# Plot Loss\n",
    "average_train_loss = average_out_data_k(train_loss_record)\n",
    "train_loss_error_bar_y = [average_train_loss[epoch] for epoch in epochs_error_bar_0]\n",
    "train_loss_error_bar_yerr = [np.std(get_data_at_epoch_fold(train_loss_record, epoch)) for epoch in epochs_error_bar_0]\n",
    "\n",
    "average_valid_loss = average_out_data_k(holdout_loss_record)\n",
    "valid_loss_error_bar_y = [average_valid_loss[epoch] for epoch in epochs_error_bar_0]\n",
    "valid_loss_error_bar_yerr = [np.std(get_data_at_epoch_fold(holdout_loss_record, epoch)) for epoch in epochs_error_bar_0]\n",
    "\n",
    "axs[0].plot(average_train_loss, '-b', label='Training loss')\n",
    "axs[0].errorbar(x=epochs_error_bar_0, y=train_loss_error_bar_y, yerr=train_loss_error_bar_yerr, label='Training loss error', fmt='-b')\n",
    "\n",
    "axs[0].plot(average_valid_loss, '--r', label='Validation loss')\n",
    "axs[0].errorbar(x=epochs_error_bar_0, y=valid_loss_error_bar_y, yerr=valid_loss_error_bar_yerr, label='Validation loss error', fmt='--r')\n",
    "\n",
    "axs[0].legend()\n",
    "axs[0].set_xlabel('Epochs')\n",
    "axs[0].set_ylabel('Normalized Loss')\n",
    "axs[0].set_title('Loss normalized per example and class vs. Epochs')\n",
    "\n",
    "# Plot Accuracy\n",
    "average_train_acc = average_out_data_k(train_accuracy_record)\n",
    "train_acc_error_bar_y = [average_train_acc[epoch] for epoch in epochs_error_bar_0]\n",
    "train_acc_error_bar_yerr = [np.std(get_data_at_epoch_fold(train_accuracy_record, epoch)) for epoch in epochs_error_bar_0]\n",
    "\n",
    "average_valid_acc = average_out_data_k(holdout_accuracy_record)\n",
    "valid_acc_error_bar_y = [average_valid_acc[epoch] for epoch in epochs_error_bar_0]\n",
    "valid_acc_error_bar_yerr = [np.std(get_data_at_epoch_fold(holdout_accuracy_record, epoch)) for epoch in epochs_error_bar_0]\n",
    "\n",
    "axs[1].plot(average_train_acc, '-b', label='Training accuracy')\n",
    "axs[1].errorbar(x=epochs_error_bar_0, y=train_acc_error_bar_y, yerr=train_acc_error_bar_yerr, label='Training accuracy error', fmt='-b')\n",
    "\n",
    "axs[1].plot(average_valid_acc, '--r', label='Validation accuracy')\n",
    "axs[1].errorbar(x=epochs_error_bar_0, y=valid_acc_error_bar_y, yerr=valid_acc_error_bar_yerr, label='Validation accuracy error', fmt='--r')\n",
    "\n",
    "axs[1].legend()\n",
    "axs[1].set_xlabel('Epochs')\n",
    "axs[1].set_ylabel('Accuracy')\n",
    "axs[1].set_title('Accuracy vs. Epochs')\n",
    "\n",
    "plt.savefig(\"plots/Q6b_i.png\")\n",
    "plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (ii) Plot Batch vs. Stochastic Gradient Descent\n",
    "\n",
    "fig, axs = plt.subplots(2, 1, constrained_layout=True)\n",
    "\n",
    "epochs_error_bar = [50, 100, 150, 200, 250, 300] # 1-indexed\n",
    "epochs_error_bar_0 = [epoch - 1 for epoch in epochs_error_bar] # 0-indexed\n",
    "\n",
    "# Plot Loss\n",
    "average_train_loss = average_out_data_k(train_loss_record)\n",
    "train_loss_error_bar_y = [average_train_loss[epoch] for epoch in epochs_error_bar_0]\n",
    "train_loss_error_bar_yerr = [np.std(get_data_at_epoch_fold(train_loss_record, epoch)) for epoch in epochs_error_bar_0]\n",
    "\n",
    "axs[0].plot(average_train_loss, '-b', label='Stochastic')\n",
    "axs[0].errorbar(x=epochs_error_bar_0, y=train_loss_error_bar_y, yerr=train_loss_error_bar_yerr, label='Stochastic error', fmt='-b')\n",
    "\n",
    "axs[0].plot(batch_average_train_loss, '--r', label='Batch')\n",
    "axs[0].errorbar(x=epochs_error_bar_0, y=batch_average_train_loss_error_bar_y, yerr=batch_average_train_loss_error_bar_yerr, label='Batch error', fmt='--r')\n",
    "\n",
    "axs[0].legend()\n",
    "axs[0].set_xlabel('Epochs')\n",
    "axs[0].set_ylabel('Normalized Loss')\n",
    "axs[0].set_title('Batch vs. Stochastic Normalized Training Loss')\n",
    "\n",
    "plt.savefig(\"plots/Q6b_ii.png\")\n",
    "plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### (c) Visualize the weights\n",
    "\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "def weights2range(w, min=0, max=256):\n",
    "    # Scales weights to be between min and max\n",
    "    w /= np.max(w)\n",
    "    w *= (max)\n",
    "    w += min\n",
    "    return w\n",
    "\n",
    "# Plot image\n",
    "\n",
    "weight_visualization_weights = best_w[:-1]\n",
    "\n",
    "# Traffic sign classes to be plotted\n",
    "ts_classes = [7, 11, 21, 25]\n",
    "\n",
    "fig, axs = plt.subplots(4,1) \n",
    "fig.set_size_inches(10, 6)\n",
    "\n",
    "for i, ts_class in enumerate(ts_classes):\n",
    "    # Get weights for each class\n",
    "    class_weights = weight_visualization_weights[:,ts_class].reshape((32, 32))\n",
    "    # Scale to [0, 256]\n",
    "    img_weights = weights2range(class_weights)\n",
    "    # Plot image\n",
    "    axs[i].set_title(f'Class {ts_class}')\n",
    "    axs[i].imshow(img_weights)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/Q6c_weights.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "005f4ed24810181fa8b2266ec303702d6575bedfaa41c7848d327e7f780b3129"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
