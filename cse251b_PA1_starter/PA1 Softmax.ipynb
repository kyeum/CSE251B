{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pca import PCA\n",
    "import argparse\n",
    "import network\n",
    "import os, random, sys\n",
    "from data import traffic_sign, generate_k_fold_set, onehot_encode, onehot_decode, z_score_normalize\n",
    "from model.softmax import SoftmaxRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34799, 1024)\n",
      "(34799,)\n",
      "float32\n",
      "uint8\n"
     ]
    }
   ],
   "source": [
    "#Q6(a) - Evaluate Network on all 43 traffic signs (aligned dataset)\n",
    "\n",
    "# Load aligned data\n",
    "X, y = traffic_sign(True)\n",
    "X = X.astype(np.float32) # cast to float32 as float64 running out of memory\n",
    "X = z_score_normalize(X) \n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(X.dtype)\n",
    "print(y.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********\n",
      "(27841, 1024)\n",
      "[1023 1022 1021 ...    2    1    0]\n",
      "bruh1: (1024,)\n",
      "bruh (27841, 1024)\n",
      "bruh3 (27841, 1024)\n",
      "(27841, 100)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x800 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " epoch: 1, train accuracy: 0.004956718508674258,               train_loss_ex:3.761200115693563, train_loss_class: 2435.245870256383\n",
      " epoch: 2, train accuracy: 0.6597464171545562,               train_loss_ex:3.7366346096321252, train_loss_class: 2419.3405620178605\n",
      " epoch: 3, train accuracy: 0.6597464171545562,               train_loss_ex:3.7121857755491887, train_loss_class: 2403.510794815464\n",
      " epoch: 4, train accuracy: 0.6597464171545562,               train_loss_ex:3.6878566285390493, train_loss_class: 2387.7585208175738\n",
      " epoch: 5, train accuracy: 0.6597464171545562,               train_loss_ex:3.663650394793163, train_loss_class: 2372.085828870615\n",
      " epoch: 6, train accuracy: 0.6597464171545562,               train_loss_ex:3.639570519115105, train_loss_class: 2356.494949364736\n",
      " epoch: 7, train accuracy: 0.6597464171545562,               train_loss_ex:3.615620671391707, train_loss_class: 2340.9882584236398\n",
      " epoch: 8, train accuracy: 0.6597823354046191,               train_loss_ex:3.591804751648413, train_loss_class: 2325.568281177755\n",
      " epoch: 9, train accuracy: 0.6597823354046191,               train_loss_ex:3.5681268932609562, train_loss_class: 2310.237693843681\n",
      " epoch: 10, train accuracy: 0.6597464171545562,               train_loss_ex:3.5445914638420963, train_loss_class: 2294.999324298321\n",
      " epoch: 11, train accuracy: 0.6598900901548077,               train_loss_ex:3.521203063276409, train_loss_class: 2279.8561508064768\n",
      " epoch: 12, train accuracy: 0.6598541719047448,               train_loss_ex:3.4979665183439344, train_loss_class: 2264.811298539848\n",
      " epoch: 13, train accuracy: 0.6598900901548077,               train_loss_ex:3.47488687336266, train_loss_class: 2249.868033518368\n",
      " epoch: 14, train accuracy: 0.6599619266549334,               train_loss_ex:3.4519693762987265, train_loss_class: 2235.029753617043\n",
      " epoch: 15, train accuracy: 0.6599978449049962,               train_loss_ex:3.429219459850855, train_loss_class: 2220.2999763187827\n",
      " epoch: 16, train accuracy: 0.6601415179052477,               train_loss_ex:3.406642717119635, train_loss_class: 2205.682322961111\n",
      " epoch: 17, train accuracy: 0.6602492726554362,               train_loss_ex:3.384244871628742, train_loss_class: 2191.180499325949\n",
      " epoch: 18, train accuracy: 0.6602851909054991,               train_loss_ex:3.3620317416749983, train_loss_class: 2176.798272557526\n",
      " epoch: 19, train accuracy: 0.6602851909054991,               train_loss_ex:3.3400091992429064, train_loss_class: 2162.5394445609713\n",
      " epoch: 20, train accuracy: 0.6603570274056249,               train_loss_ex:3.318183124014473, train_loss_class: 2148.407822225278\n",
      " epoch: 21, train accuracy: 0.6604647821558134,               train_loss_ex:3.2965593533166118, train_loss_class: 2134.4071850159953\n",
      " epoch: 22, train accuracy: 0.6606443734061277,               train_loss_ex:3.27514362914913, train_loss_class: 2120.541250677696\n",
      " epoch: 23, train accuracy: 0.6606443734061277,               train_loss_ex:3.253941543694682, train_loss_class: 2106.813639953573\n",
      " epoch: 24, train accuracy: 0.6606802916561905,               train_loss_ex:3.2329584848970505, train_loss_class: 2093.227841349274\n",
      " epoch: 25, train accuracy: 0.6607521281563162,               train_loss_ex:3.2121995837795234, train_loss_class: 2079.7871770233887\n",
      " epoch: 26, train accuracy: 0.6607521281563162,               train_loss_ex:3.1916696651454677, train_loss_class: 2066.49477086779\n",
      " epoch: 27, train accuracy: 0.6608239646564419,               train_loss_ex:3.171373203156486, train_loss_class: 2053.35351974604\n",
      " epoch: 28, train accuracy: 0.6609317194066305,               train_loss_ex:3.151314283032924, train_loss_class: 2040.3660686958056\n",
      " epoch: 29, train accuracy: 0.6611831471570705,               train_loss_ex:3.1314965697928727, train_loss_class: 2027.5347906884506\n",
      " epoch: 30, train accuracy: 0.6612549836571963,               train_loss_ex:3.111923284573846, train_loss_class: 2014.8617712981497\n",
      " epoch: 31, train accuracy: 0.6613986566574477,               train_loss_ex:3.09259718870323, train_loss_class: 2002.348798388061\n",
      " epoch: 32, train accuracy: 0.661578247907762,               train_loss_ex:3.0735205753337986, train_loss_class: 1989.9973566946114\n",
      " epoch: 33, train accuracy: 0.661578247907762,               train_loss_ex:3.054695268165432, train_loss_class: 1977.8086269998555\n",
      " epoch: 34, train accuracy: 0.6617219209080134,               train_loss_ex:3.0361226265502923, train_loss_class: 1965.7834894368998\n",
      " epoch: 35, train accuracy: 0.6620092669085162,               train_loss_ex:3.017803556131755, train_loss_class: 1953.922530378237\n",
      " epoch: 36, train accuracy: 0.6620092669085162,               train_loss_ex:2.9997385240941323, train_loss_class: 1942.2260523094126\n",
      " epoch: 37, train accuracy: 0.6622247764088933,               train_loss_ex:2.9819275780908083, train_loss_class: 1930.6940860843301\n",
      " epoch: 38, train accuracy: 0.6621888581588306,               train_loss_ex:2.9643703679591735, train_loss_class: 1919.3264049849151\n",
      " epoch: 39, train accuracy: 0.6624762041593334,               train_loss_ex:2.947066169406869, train_loss_class: 1908.1225400571311\n",
      " epoch: 40, train accuracy: 0.6626917136597105,               train_loss_ex:2.9300139089515094, train_loss_class: 1897.0817962585807\n",
      " epoch: 41, train accuracy: 0.6628353866599619,               train_loss_ex:2.9132121895032115, train_loss_class: 1886.2032690223002\n",
      " epoch: 42, train accuracy: 0.6629790596602133,               train_loss_ex:2.896659316086866, train_loss_class: 1875.4858609110336\n",
      " epoch: 43, train accuracy: 0.663302323910779,               train_loss_ex:2.8803533213025245, train_loss_class: 1864.928298101944\n",
      " epoch: 44, train accuracy: 0.6634459969110305,               train_loss_ex:2.8642919902135797, train_loss_class: 1854.5291465008436\n",
      " epoch: 45, train accuracy: 0.6635896699112819,               train_loss_ex:2.8484728844315192, train_loss_class: 1844.286827336231\n",
      " epoch: 46, train accuracy: 0.6639847706619734,               train_loss_ex:2.8328933652323482, train_loss_class: 1834.1996321263675\n",
      " epoch: 47, train accuracy: 0.6642361984124133,               train_loss_ex:2.8175506155938477, train_loss_class: 1824.265736947635\n",
      " epoch: 48, train accuracy: 0.6642721166624762,               train_loss_ex:2.8024416610857554, train_loss_class: 1814.483215960198\n",
      " epoch: 49, train accuracy: 0.6644157896627276,               train_loss_ex:2.7875633895781466, train_loss_class: 1804.8500541684925\n",
      " epoch: 50, train accuracy: 0.664559462662979,               train_loss_ex:2.7729125697584, train_loss_class: 1795.3641594103165\n",
      " epoch: 51, train accuracy: 0.6647749721633562,               train_loss_ex:2.7584858684655607, train_loss_class: 1786.023373580225\n",
      " epoch: 52, train accuracy: 0.6653496641643619,               train_loss_ex:2.744279866864157, train_loss_class: 1776.8254831015115\n",
      " epoch: 53, train accuracy: 0.6655292554146762,               train_loss_ex:2.7302910754886884, train_loss_class: 1767.7682286669901\n",
      " epoch: 54, train accuracy: 0.6658884379153047,               train_loss_ex:2.716515948196174, train_loss_class: 1758.849314272783\n",
      " epoch: 55, train accuracy: 0.6664272116662476,               train_loss_ex:2.7029508950680734, train_loss_class: 1750.066415571866\n",
      " epoch: 56, train accuracy: 0.6668582306670019,               train_loss_ex:2.6895922943052626, train_loss_class: 1741.4171875756467\n",
      " epoch: 57, train accuracy: 0.6671814949175676,               train_loss_ex:2.676436503160974, train_loss_class: 1732.8992717326669\n",
      " epoch: 58, train accuracy: 0.6675406774181962,               train_loss_ex:2.6634798679571454, train_loss_class: 1724.5103024138348\n",
      " epoch: 59, train accuracy: 0.6679357781688876,               train_loss_ex:2.650718733229611, train_loss_class: 1716.2479128336188\n",
      " epoch: 60, train accuracy: 0.6682590424194533,               train_loss_ex:2.6381494500472584, train_loss_class: 1708.109740436412\n",
      " epoch: 61, train accuracy: 0.6686900614202076,               train_loss_ex:2.625768383549744, train_loss_class: 1700.0934317769402\n",
      " epoch: 62, train accuracy: 0.668833734420459,               train_loss_ex:2.6135719197476646, train_loss_class: 1692.1966469231334\n",
      " epoch: 63, train accuracy: 0.6691569986710247,               train_loss_ex:2.601556471628292, train_loss_class: 1684.4170634093787\n",
      " epoch: 64, train accuracy: 0.6694443446715276,               train_loss_ex:2.5897184846090884, train_loss_class: 1676.7523797674796\n",
      " epoch: 65, train accuracy: 0.669588017671779,               train_loss_ex:2.5780544413802193, train_loss_class: 1669.200318662016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " epoch: 66, train accuracy: 0.6698394454222191,               train_loss_ex:2.566560866176244, train_loss_class: 1661.758629656112\n",
      " epoch: 67, train accuracy: 0.6699831184224705,               train_loss_ex:2.5552343285159775, train_loss_class: 1654.4250916328683\n",
      " epoch: 68, train accuracy: 0.6703063826730362,               train_loss_ex:2.544071446448308, train_loss_class: 1647.197514896915\n",
      " epoch: 69, train accuracy: 0.6704500556732876,               train_loss_ex:2.533068889340411, train_loss_class: 1640.0737429796834\n",
      " epoch: 70, train accuracy: 0.6707374016737905,               train_loss_ex:2.522223380243432, train_loss_class: 1633.0516541711022\n",
      " epoch: 71, train accuracy: 0.6710606659243562,               train_loss_ex:2.5115316978692275, train_loss_class: 1626.1291627994688\n",
      " epoch: 72, train accuracy: 0.6712402571746704,               train_loss_ex:2.500990678210245, train_loss_class: 1619.3042202802658\n",
      " epoch: 73, train accuracy: 0.6715635214252361,               train_loss_ex:2.490597215833072, train_loss_class: 1612.5748159536874\n",
      " epoch: 74, train accuracy: 0.6718867856758018,               train_loss_ex:2.480348264874577, train_loss_class: 1605.938977729607\n",
      " epoch: 75, train accuracy: 0.672102295176179,               train_loss_ex:2.470240839767969, train_loss_class: 1599.394772557675\n",
      " epoch: 76, train accuracy: 0.6725333141769333,               train_loss_ex:2.460272015724493, train_loss_class: 1592.9403067392004\n",
      " epoch: 77, train accuracy: 0.6728924966775619,               train_loss_ex:2.4504389289948727, train_loss_class: 1586.5737260964243\n",
      " epoch: 78, train accuracy: 0.673359433928379,               train_loss_ex:2.440738776933037, train_loss_class: 1580.2932160137834\n",
      " epoch: 79, train accuracy: 0.6737545346790704,               train_loss_ex:2.431168817883128, train_loss_class: 1574.097001364748\n",
      " epoch: 80, train accuracy: 0.673862289429259,               train_loss_ex:2.4217263709092736, train_loss_class: 1567.9833463368623\n",
      " epoch: 81, train accuracy: 0.6741855536798247,               train_loss_ex:2.4124088153861662, train_loss_class: 1561.9505541666572\n",
      " epoch: 82, train accuracy: 0.6743292266800761,               train_loss_ex:2.4032135904670935, train_loss_class: 1555.9969667952175\n",
      " epoch: 83, train accuracy: 0.674616572680579,               train_loss_ex:2.394138194444722, train_loss_class: 1550.120964454314\n",
      " epoch: 84, train accuracy: 0.6750835099313961,               train_loss_ex:2.3851801840186795, train_loss_class: 1544.3209651921873\n",
      " epoch: 85, train accuracy: 0.6753349376818362,               train_loss_ex:2.376337173482781, train_loss_class: 1538.5954243473047\n",
      " epoch: 86, train accuracy: 0.6755863654322761,               train_loss_ex:2.3676068338435967, train_loss_class: 1532.9428339776643\n",
      " epoch: 87, train accuracy: 0.6758377931827161,               train_loss_ex:2.3589868918810177, train_loss_class: 1527.3617222525445\n",
      " epoch: 88, train accuracy: 0.6759096296828419,               train_loss_ex:2.3504751291604715, train_loss_class: 1521.8506528129462\n",
      " epoch: 89, train accuracy: 0.6762328939334076,               train_loss_ex:2.342069381005516, train_loss_class: 1516.4082241063854\n",
      " epoch: 90, train accuracy: 0.6765561581839733,               train_loss_ex:2.3337675354386813, train_loss_class: 1511.0330687011237\n",
      " epoch: 91, train accuracy: 0.6766998311842247,               train_loss_ex:2.32556753209764, train_loss_class: 1505.723852584428\n",
      " epoch: 92, train accuracy: 0.6769153406846018,               train_loss_ex:2.3174673611330334, train_loss_class: 1500.4792744489484\n",
      " epoch: 93, train accuracy: 0.6772386049351675,               train_loss_ex:2.309465062093634, train_loss_class: 1495.2980649709039\n",
      " epoch: 94, train accuracy: 0.6773822779354189,               train_loss_ex:2.30155872280387, train_loss_class: 1490.178986083315\n",
      " epoch: 95, train accuracy: 0.6776696239359219,               train_loss_ex:2.293746478238196, train_loss_class: 1485.1208302472005\n",
      " epoch: 96, train accuracy: 0.6781365611867389,               train_loss_ex:2.2860265093962653, train_loss_class: 1480.1224197232887\n",
      " epoch: 97, train accuracy: 0.678387988937179,               train_loss_ex:2.2783970421823674, train_loss_class: 1475.182605846495\n",
      " epoch: 98, train accuracy: 0.6787112531877447,               train_loss_ex:2.2708563462922, train_loss_class: 1470.3002683051427\n",
      " epoch: 99, train accuracy: 0.6788549261879961,               train_loss_ex:2.2634027341096092, train_loss_class: 1465.4743144266426\n",
      " epoch: 100, train accuracy: 0.6791063539384361,               train_loss_ex:2.256034559615618, train_loss_class: 1460.703678471126\n",
      " epoch: 101, train accuracy: 0.6792500269386875,               train_loss_ex:2.2487502173117013, train_loss_class: 1455.9873209343043\n",
      " epoch: 102, train accuracy: 0.6795373729391904,               train_loss_ex:2.2415481411590177, train_loss_class: 1451.324227860656\n",
      " epoch: 103, train accuracy: 0.6800043101900075,               train_loss_ex:2.2344268035350026, train_loss_class: 1446.7134101678605\n",
      " epoch: 104, train accuracy: 0.6802916561905104,               train_loss_ex:2.227384714208541, train_loss_class: 1442.1539029832556\n",
      " epoch: 105, train accuracy: 0.6807945116913904,               train_loss_ex:2.220420419334677, train_loss_class: 1437.6447649929476\n",
      " epoch: 106, train accuracy: 0.6812973671922704,               train_loss_ex:2.213532500469672, train_loss_class: 1433.1850778040962\n",
      " epoch: 107, train accuracy: 0.6818002226931504,               train_loss_ex:2.2067195736070273, train_loss_class: 1428.773945320773\n",
      " epoch: 108, train accuracy: 0.6819798139434646,               train_loss_ex:2.1999802882349537, train_loss_class: 1424.4104931337058\n",
      " epoch: 109, train accuracy: 0.6824467511942818,               train_loss_ex:2.193313326415622, train_loss_class: 1420.093867924124\n",
      " epoch: 110, train accuracy: 0.6827700154448475,               train_loss_ex:2.1867174018864315, train_loss_class: 1415.8232368818637\n",
      " epoch: 111, train accuracy: 0.6829855249452247,               train_loss_ex:2.180191259183403, train_loss_class: 1411.5977871377934\n",
      " epoch: 112, train accuracy: 0.6834883804461047,               train_loss_ex:2.173733672786735, train_loss_class: 1407.4167252105929\n",
      " epoch: 113, train accuracy: 0.6840271541970475,               train_loss_ex:2.167343446288475, train_loss_class: 1403.2792764678472\n",
      " epoch: 114, train accuracy: 0.6844581731978018,               train_loss_ex:2.1610194115821724, train_loss_class: 1399.1846846013782\n",
      " epoch: 115, train accuracy: 0.6848173556984304,               train_loss_ex:2.1547604280743404, train_loss_class: 1395.132211116691\n",
      " epoch: 116, train accuracy: 0.6849251104486189,               train_loss_ex:2.1485653819174955, train_loss_class: 1391.1211348363952\n",
      " epoch: 117, train accuracy: 0.6851047016989332,               train_loss_ex:2.1424331852644816, train_loss_class: 1387.1507514174052\n",
      " epoch: 118, train accuracy: 0.6855357206996875,               train_loss_ex:2.1363627755437786, train_loss_class: 1383.2203728817287\n",
      " epoch: 119, train accuracy: 0.6860385762005675,               train_loss_ex:2.130353114755428, train_loss_class: 1379.329327160602\n",
      " epoch: 120, train accuracy: 0.6861463309507561,               train_loss_ex:2.124403188787215, train_loss_class: 1375.4769576517406\n",
      " epoch: 121, train accuracy: 0.6864695952013218,               train_loss_ex:2.1185120067506884, train_loss_class: 1371.6626227894399\n",
      " epoch: 122, train accuracy: 0.6863977587011961,               train_loss_ex:2.1126786003366242, train_loss_class: 1367.8856956272546\n",
      " epoch: 123, train accuracy: 0.6866491864516361,               train_loss_ex:2.1069020231894804, train_loss_class: 1364.145563432984\n",
      " epoch: 124, train accuracy: 0.6870802054523903,               train_loss_ex:2.1011813503004126, train_loss_class: 1360.4416272956696\n",
      " epoch: 125, train accuracy: 0.6874034697029561,               train_loss_ex:2.095515677418398, train_loss_class: 1356.7733017443168\n",
      " epoch: 126, train accuracy: 0.6879781617039618,               train_loss_ex:2.0899041204790128, train_loss_class: 1353.140014378051\n",
      " epoch: 127, train accuracy: 0.6883014259545275,               train_loss_ex:2.0843458150504004, train_loss_class: 1349.5412055073998\n",
      " epoch: 128, train accuracy: 0.6886606084551561,               train_loss_ex:2.0788399157959856, train_loss_class: 1345.9763278064192\n",
      " epoch: 129, train accuracy: 0.6889838727057218,               train_loss_ex:2.0733855959534555, train_loss_class: 1342.4448459753526\n",
      " epoch: 130, train accuracy: 0.6895585647067275,               train_loss_ex:2.0679820468295773, train_loss_class: 1338.946236413541\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " epoch: 131, train accuracy: 0.6898459107072303,               train_loss_ex:2.0626284773103807, train_loss_class: 1335.4799869022863\n",
      " epoch: 132, train accuracy: 0.6902410114579217,               train_loss_ex:2.05732411338627, train_loss_class: 1332.0455962973756\n",
      " epoch: 133, train accuracy: 0.6907438669588017,               train_loss_ex:2.0520681976916237, train_loss_class: 1328.6425742309884\n",
      " epoch: 134, train accuracy: 0.6908516217089904,               train_loss_ex:2.0468599890584533, train_loss_class: 1325.270440822707\n",
      " epoch: 135, train accuracy: 0.6910671312093675,               train_loss_ex:2.041698762083681, train_loss_class: 1321.928726399343\n",
      " epoch: 136, train accuracy: 0.6914981502101217,               train_loss_ex:2.0365838067096393, train_loss_class: 1318.6169712233273\n",
      " epoch: 137, train accuracy: 0.6918573327107503,               train_loss_ex:2.031514427817372, train_loss_class: 1315.3347252293827\n",
      " epoch: 138, train accuracy: 0.6922524334614417,               train_loss_ex:2.026489944832334, train_loss_class: 1312.0815477692327\n",
      " epoch: 139, train accuracy: 0.692432024711756,               train_loss_ex:2.021509691342112, train_loss_class: 1308.8570073640872\n",
      " epoch: 140, train accuracy: 0.6926834524621961,               train_loss_ex:2.0165730147257768, train_loss_class: 1305.6606814646593\n",
      " epoch: 141, train accuracy: 0.6930785532128875,               train_loss_ex:2.011679275794497, train_loss_class: 1302.4921562184788\n",
      " epoch: 142, train accuracy: 0.6932940627132647,               train_loss_ex:2.006827848443054, train_loss_class: 1299.3510262442574\n",
      " epoch: 143, train accuracy: 0.6934736539635789,               train_loss_ex:2.002018119311912, train_loss_class: 1296.2368944130917\n",
      " epoch: 144, train accuracy: 0.693689163463956,               train_loss_ex:1.9972494874594966, train_loss_class: 1293.1493716362754\n",
      " epoch: 145, train accuracy: 0.6938328364642075,               train_loss_ex:1.9925213640443467, train_loss_class: 1290.0880766595037\n",
      " epoch: 146, train accuracy: 0.6940483459645846,               train_loss_ex:1.98783317201683, train_loss_class: 1287.052635863269\n",
      " epoch: 147, train accuracy: 0.6944075284652131,               train_loss_ex:1.9831843458201026, train_loss_class: 1284.0426830692436\n",
      " epoch: 148, train accuracy: 0.6948026292159046,               train_loss_ex:1.9785743311000061, train_loss_class: 1281.057859352448\n",
      " epoch: 149, train accuracy: 0.6949822204662189,               train_loss_ex:1.974002584423622, train_loss_class: 1278.0978128590245\n",
      " epoch: 150, train accuracy: 0.6952695664667218,               train_loss_ex:1.9694685730061854, train_loss_class: 1275.1621986294235\n",
      " epoch: 151, train accuracy: 0.6952695664667218,               train_loss_ex:1.9649717744460982, train_loss_class: 1272.250678426833\n",
      " epoch: 152, train accuracy: 0.6954850759670989,               train_loss_ex:1.960511676467761, train_loss_class: 1269.362920570673\n",
      " epoch: 153, train accuracy: 0.6957365037175389,               train_loss_ex:1.9560877766719793, train_loss_class: 1266.4985997749902\n",
      " epoch: 154, train accuracy: 0.6961316044682303,               train_loss_ex:1.9516995822936882, train_loss_class: 1263.6573969915946\n",
      " epoch: 155, train accuracy: 0.696454868718796,               train_loss_ex:1.947346609966758, train_loss_class: 1260.8389992577793\n",
      " epoch: 156, train accuracy: 0.6965985417190474,               train_loss_ex:1.943028385495651, train_loss_class: 1258.0430995484749\n",
      " epoch: 157, train accuracy: 0.6968140512194246,               train_loss_ex:1.9387444436336958, train_loss_class: 1255.2693966326913\n",
      " epoch: 158, train accuracy: 0.697209151970116,               train_loss_ex:1.9344943278677786, train_loss_class: 1252.5175949341121\n",
      " epoch: 159, train accuracy: 0.6975324162206817,               train_loss_ex:1.9302775902092242, train_loss_class: 1249.7874043956979\n",
      " epoch: 160, train accuracy: 0.697712007470996,               train_loss_ex:1.9260937909906783, train_loss_class: 1247.0785403481739\n",
      " epoch: 161, train accuracy: 0.6979993534714989,               train_loss_ex:1.9219424986687894, train_loss_class: 1244.3907233822736\n",
      " epoch: 162, train accuracy: 0.6982866994720017,               train_loss_ex:1.9178232896325023, train_loss_class: 1241.7236792246163\n",
      " epoch: 163, train accuracy: 0.6986099637225675,               train_loss_ex:1.9137357480167856, train_loss_class: 1239.0771386171007\n",
      " epoch: 164, train accuracy: 0.6989332279731332,               train_loss_ex:1.90967946552161, train_loss_class: 1236.450837199701\n",
      " epoch: 165, train accuracy: 0.6990769009733846,               train_loss_ex:1.9056540412360181, train_loss_class: 1233.8445153965577\n",
      " epoch: 166, train accuracy: 0.6994001652239503,               train_loss_ex:1.9016590814671108, train_loss_class: 1231.257918305252\n",
      " epoch: 167, train accuracy: 0.6995797564742646,               train_loss_ex:1.8976941995738006, train_loss_class: 1228.690795589167\n",
      " epoch: 168, train accuracy: 0.6996875112244532,               train_loss_ex:1.8937590158051805, train_loss_class: 1226.142901372838\n",
      " epoch: 169, train accuracy: 0.6999389389748931,               train_loss_ex:1.8898531571433508, train_loss_class: 1223.6139941401868\n",
      " epoch: 170, train accuracy: 0.700226284975396,               train_loss_ex:1.8859762571505767, train_loss_class: 1221.1038366355629\n",
      " epoch: 171, train accuracy: 0.700477712725836,               train_loss_ex:1.8821279558206254, train_loss_class: 1218.612195767489\n",
      " epoch: 172, train accuracy: 0.7008368952264645,               train_loss_ex:1.8783078994341633, train_loss_class: 1216.138842515036\n",
      " epoch: 173, train accuracy: 0.7010164864767788,               train_loss_ex:1.8745157404180763, train_loss_class: 1213.6835518367363\n",
      " epoch: 174, train accuracy: 0.7013397507273446,               train_loss_ex:1.8707511372085934, train_loss_class: 1211.246102581964\n",
      " epoch: 175, train accuracy: 0.7015911784777845,               train_loss_ex:1.8670137541180982, train_loss_class: 1208.826277404697\n",
      " epoch: 176, train accuracy: 0.7017348514780359,               train_loss_ex:1.8633032612055058, train_loss_class: 1206.4238626795927\n",
      " epoch: 177, train accuracy: 0.7023454617291045,               train_loss_ex:1.8596193341501026, train_loss_class: 1204.0386484203025\n",
      " epoch: 178, train accuracy: 0.7025968894795446,               train_loss_ex:1.8559616541287371, train_loss_class: 1201.6704281999575\n",
      " epoch: 179, train accuracy: 0.7027764807298589,               train_loss_ex:1.8523299076962594, train_loss_class: 1199.3189990737571\n",
      " epoch: 180, train accuracy: 0.7030279084802988,               train_loss_ex:1.8487237866691084, train_loss_class: 1196.9841615035964\n",
      " epoch: 181, train accuracy: 0.7033152544808017,               train_loss_ex:1.845142988011958, train_loss_class: 1194.6657192846726\n",
      " epoch: 182, train accuracy: 0.7035307639811789,               train_loss_ex:1.841587213727316, train_loss_class: 1192.3634794740049\n",
      " epoch: 183, train accuracy: 0.7037821917316188,               train_loss_ex:1.838056170747998, train_loss_class: 1190.0772523208143\n",
      " epoch: 184, train accuracy: 0.7040695377321217,               train_loss_ex:1.834549570832385, train_loss_class: 1187.8068511987076\n",
      " epoch: 185, train accuracy: 0.7042132107323731,               train_loss_ex:1.831067130462376, train_loss_class: 1185.552092539605\n",
      " epoch: 186, train accuracy: 0.7046801479831902,               train_loss_ex:1.827608570743969, train_loss_class: 1183.3127957693684\n",
      " epoch: 187, train accuracy: 0.7051111669839445,               train_loss_ex:1.8241736173103709, train_loss_class: 1181.0887832450705\n",
      " epoch: 188, train accuracy: 0.7053625947343846,               train_loss_ex:1.8207620002275833, train_loss_class: 1178.879880193864\n",
      " epoch: 189, train accuracy: 0.7053625947343846,               train_loss_ex:1.817373453902373, train_loss_class: 1176.6859146533945\n",
      " epoch: 190, train accuracy: 0.7059732049854531,               train_loss_ex:1.8140077169925672, train_loss_class: 1174.5067174137223\n",
      " epoch: 191, train accuracy: 0.7061527962357674,               train_loss_ex:1.810664532319603, train_loss_class: 1172.3421219606992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " epoch: 192, train accuracy: 0.7064401422362703,               train_loss_ex:1.807343646783259, train_loss_class: 1170.1919644207608\n",
      " epoch: 193, train accuracy: 0.706763406486836,               train_loss_ex:1.8040448112785201, train_loss_class: 1168.0560835070994\n",
      " epoch: 194, train accuracy: 0.7069429977371502,               train_loss_ex:1.8007677806144908, train_loss_class: 1165.9343204671636\n",
      " epoch: 195, train accuracy: 0.7073380984878417,               train_loss_ex:1.7975123134353237, train_loss_class: 1163.8265190314617\n",
      " epoch: 196, train accuracy: 0.7073380984878417,               train_loss_ex:1.7942781721430834, train_loss_class: 1161.7325253636184\n",
      " epoch: 197, train accuracy: 0.7074099349879673,               train_loss_ex:1.7910651228225036, train_loss_class: 1159.6521880116586\n",
      " epoch: 198, train accuracy: 0.7075536079882189,               train_loss_ex:1.7878729351675762, train_loss_class: 1157.5853578604765\n",
      " epoch: 199, train accuracy: 0.7076613627384074,               train_loss_ex:1.7847013824099247, train_loss_class: 1155.5318880854584\n",
      " epoch: 200, train accuracy: 0.7080564634890988,               train_loss_ex:1.7815502412489064, train_loss_class: 1153.491634107228\n",
      " epoch: 201, train accuracy: 0.7083797277396645,               train_loss_ex:1.7784192917834034, train_loss_class: 1151.4644535474822\n",
      " epoch: 202, train accuracy: 0.7086311554901045,               train_loss_ex:1.7753083174452402, train_loss_class: 1149.450206185882\n",
      " epoch: 203, train accuracy: 0.7089903379907331,               train_loss_ex:1.7722171049341982, train_loss_class: 1147.448753917977\n",
      " epoch: 204, train accuracy: 0.7091340109909845,               train_loss_ex:1.7691454441545715, train_loss_class: 1145.4599607141263\n",
      " epoch: 205, train accuracy: 0.7093136022412988,               train_loss_ex:1.7660931281532273, train_loss_class: 1143.4836925793954\n",
      " epoch: 206, train accuracy: 0.7095650299917388,               train_loss_ex:1.7630599530591227, train_loss_class: 1141.5198175143962\n",
      " epoch: 207, train accuracy: 0.7099242124923674,               train_loss_ex:1.7600457180242464, train_loss_class: 1139.5682054770475\n",
      " epoch: 208, train accuracy: 0.7100678854926188,               train_loss_ex:1.7570502251659361, train_loss_class: 1137.6287283452286\n",
      " epoch: 209, train accuracy: 0.7101397219927446,               train_loss_ex:1.7540732795105463, train_loss_class: 1135.701259880305\n",
      " epoch: 210, train accuracy: 0.7105707409934988,               train_loss_ex:1.7511146889384142, train_loss_class: 1133.7856756914973\n",
      " epoch: 211, train accuracy: 0.7108940052440645,               train_loss_ex:1.7481742641301012, train_loss_class: 1131.8818532010732\n",
      " epoch: 212, train accuracy: 0.7109299234941273,               train_loss_ex:1.7452518185138735, train_loss_class: 1129.989671610343\n",
      " epoch: 213, train accuracy: 0.7111095147444416,               train_loss_ex:1.7423471682143765, train_loss_class: 1128.1090118664292\n",
      " epoch: 214, train accuracy: 0.7113609424948817,               train_loss_ex:1.7394601320024916, train_loss_class: 1126.2397566297993\n",
      " epoch: 215, train accuracy: 0.7116842067454474,               train_loss_ex:1.7365905312463226, train_loss_class: 1124.381790242532\n",
      " epoch: 216, train accuracy: 0.7121511439962646,               train_loss_ex:1.7337381898632958, train_loss_class: 1122.5349986973026\n",
      " epoch: 217, train accuracy: 0.7124025717467045,               train_loss_ex:1.73090293427334, train_loss_class: 1120.699269607071\n",
      " epoch: 218, train accuracy: 0.7129413454976473,               train_loss_ex:1.7280845933531137, train_loss_class: 1118.8744921754428\n",
      " epoch: 219, train accuracy: 0.7133005279982759,               train_loss_ex:1.7252829983912599, train_loss_class: 1117.0605571676992\n",
      " epoch: 220, train accuracy: 0.7134082827484645,               train_loss_ex:1.7224979830446518, train_loss_class: 1115.2573568824687\n",
      " epoch: 221, train accuracy: 0.7136597104989045,               train_loss_ex:1.7197293832956135, train_loss_class: 1113.4647851240275\n",
      " epoch: 222, train accuracy: 0.7139470564994074,               train_loss_ex:1.716977037410083, train_loss_class: 1111.6827371752122\n",
      " epoch: 223, train accuracy: 0.7141984842498473,               train_loss_ex:1.7142407858966953, train_loss_class: 1109.9111097709276\n",
      " epoch: 224, train accuracy: 0.7145217485004131,               train_loss_ex:1.7115204714667613, train_loss_class: 1108.149801072235\n",
      " epoch: 225, train accuracy: 0.7150246040012931,               train_loss_ex:1.7088159389951219, train_loss_class: 1106.3987106410043\n",
      " epoch: 226, train accuracy: 0.7151323587514816,               train_loss_ex:1.7061270354818503, train_loss_class: 1104.657739415121\n",
      " epoch: 227, train accuracy: 0.715276031751733,               train_loss_ex:1.7034536100147857, train_loss_class: 1102.9267896842243\n",
      " epoch: 228, train accuracy: 0.7153478682518588,               train_loss_ex:1.7007955137328712, train_loss_class: 1101.2057650659735\n",
      " epoch: 229, train accuracy: 0.7154915412521102,               train_loss_ex:1.6981525997902838, train_loss_class: 1099.4945704828208\n",
      " epoch: 230, train accuracy: 0.715527459502173,               train_loss_ex:1.6955247233213255, train_loss_class: 1097.7931121392796\n",
      " epoch: 231, train accuracy: 0.7157429690025502,               train_loss_ex:1.6929117414060688, train_loss_class: 1096.101297499683\n",
      " epoch: 232, train accuracy: 0.7161021515031788,               train_loss_ex:1.6903135130367242, train_loss_class: 1094.4190352664054\n",
      " epoch: 233, train accuracy: 0.7163894975036816,               train_loss_ex:1.687729899084725, train_loss_class: 1092.7462353585543\n",
      " epoch: 234, train accuracy: 0.7165331705039331,               train_loss_ex:1.6851607622685008, train_loss_class: 1091.0828088911005\n",
      " epoch: 235, train accuracy: 0.7170719442548759,               train_loss_ex:1.6826059671219284, train_loss_class: 1089.428668154456\n",
      " epoch: 236, train accuracy: 0.7172156172551273,               train_loss_ex:1.68006537996344, train_loss_class: 1087.7837265944681\n",
      " epoch: 237, train accuracy: 0.7175747997557559,               train_loss_ex:1.6775388688657773, train_loss_class: 1086.1478987928397\n",
      " epoch: 238, train accuracy: 0.7176825545059444,               train_loss_ex:1.6750263036263688, train_loss_class: 1084.5211004479474\n",
      " epoch: 239, train accuracy: 0.7179339822563845,               train_loss_ex:1.6725275557383201, train_loss_class: 1082.9032483560597\n",
      " epoch: 240, train accuracy: 0.7182213282568873,               train_loss_ex:1.6700424983620035, train_loss_class: 1081.2942603929428\n",
      " epoch: 241, train accuracy: 0.7184009195072016,               train_loss_ex:1.6675710062972222, train_loss_class: 1079.6940554958362\n",
      " epoch: 242, train accuracy: 0.7186164290075787,               train_loss_ex:1.6651129559559519, train_loss_class: 1078.102553645806\n",
      " epoch: 243, train accuracy: 0.718580510757516,               train_loss_ex:1.6626682253356284, train_loss_class: 1076.5196758504471\n",
      " epoch: 244, train accuracy: 0.7189037750080816,               train_loss_ex:1.6602366939929811, train_loss_class: 1074.9453441269438\n",
      " epoch: 245, train accuracy: 0.719047448008333,               train_loss_ex:1.6578182430183923, train_loss_class: 1073.3794814854664\n",
      " epoch: 246, train accuracy: 0.7193707122588987,               train_loss_ex:1.6554127550107707, train_loss_class: 1071.822011912904\n",
      " epoch: 247, train accuracy: 0.719550303509213,               train_loss_ex:1.653020114052932, train_loss_class: 1070.2728603569228\n",
      " epoch: 248, train accuracy: 0.7198735677597787,               train_loss_ex:1.650640205687465, train_loss_class: 1068.731952710342\n",
      " epoch: 249, train accuracy: 0.7200890772601559,               train_loss_ex:1.6482729168930803, train_loss_class: 1067.1992157958198\n",
      " epoch: 250, train accuracy: 0.7204482597607844,               train_loss_ex:1.6459181360614275, train_loss_class: 1065.674577350842\n",
      " epoch: 251, train accuracy: 0.7209151970116016,               train_loss_ex:1.6435757529743686, train_loss_class: 1064.1579660130092\n",
      " epoch: 252, train accuracy: 0.721058870011853,               train_loss_ex:1.6412456587816975, train_loss_class: 1062.6493113056101\n",
      " epoch: 253, train accuracy: 0.7212384612621673,               train_loss_ex:1.6389277459792952, train_loss_class: 1061.1485436234782\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " epoch: 254, train accuracy: 0.7213462160123558,               train_loss_ex:1.636621908387712, train_loss_class: 1059.655594219123\n",
      " epoch: 255, train accuracy: 0.7219209080133616,               train_loss_ex:1.6343280411311665, train_loss_class: 1058.170395189135\n",
      " epoch: 256, train accuracy: 0.7222082540138645,               train_loss_ex:1.6320460406169484, train_loss_class: 1056.692879460848\n",
      " epoch: 257, train accuracy: 0.722316008764053,               train_loss_ex:1.6297758045152217, train_loss_class: 1055.2229807792626\n",
      " epoch: 258, train accuracy: 0.7224237635142415,               train_loss_ex:1.6275172317392124, train_loss_class: 1053.7606336942188\n",
      " epoch: 259, train accuracy: 0.7227111095147445,               train_loss_ex:1.6252702224257782, train_loss_class: 1052.305773547816\n",
      " epoch: 260, train accuracy: 0.7228907007650587,               train_loss_ex:1.6230346779163485, train_loss_class: 1050.858336462071\n",
      " epoch: 261, train accuracy: 0.7229984555152473,               train_loss_ex:1.620810500738225, train_loss_class: 1049.4182593268122\n",
      " epoch: 262, train accuracy: 0.7231780467655616,               train_loss_ex:1.6185975945862374, train_loss_class: 1047.9854797878008\n",
      " epoch: 263, train accuracy: 0.7232498832656873,               train_loss_ex:1.6163958643047476, train_loss_class: 1046.5599362350808\n",
      " epoch: 264, train accuracy: 0.7234653927660645,               train_loss_ex:1.6142052158699856, train_loss_class: 1045.141567791541\n",
      " epoch: 265, train accuracy: 0.7237527387665673,               train_loss_ex:1.612025556372724, train_loss_class: 1043.7303143016977\n",
      " epoch: 266, train accuracy: 0.723824575266693,               train_loss_ex:1.6098567940012722, train_loss_class: 1042.3261163206842\n",
      " epoch: 267, train accuracy: 0.723824575266693,               train_loss_ex:1.607698838024786, train_loss_class: 1040.9289151034434\n",
      " epoch: 268, train accuracy: 0.7240041665170073,               train_loss_ex:1.6055515987768882, train_loss_class: 1039.5386525941242\n",
      " epoch: 269, train accuracy: 0.7242915125175101,               train_loss_ex:1.603414987639591, train_loss_class: 1038.155271415671\n",
      " epoch: 270, train accuracy: 0.724327430767573,               train_loss_ex:1.601288917027516, train_loss_class: 1036.7787148596065\n",
      " epoch: 271, train accuracy: 0.7245429402679502,               train_loss_ex:1.5991733003724018, train_loss_class: 1035.4089268760008\n",
      " epoch: 272, train accuracy: 0.7247225315182644,               train_loss_ex:1.5970680521078946, train_loss_class: 1034.0458520636255\n",
      " epoch: 273, train accuracy: 0.7251535505190188,               train_loss_ex:1.5949730876546173, train_loss_class: 1032.6894356602838\n",
      " epoch: 274, train accuracy: 0.7254768147695845,               train_loss_ex:1.5928883234055098, train_loss_class: 1031.339623533321\n",
      " epoch: 275, train accuracy: 0.725584569519773,               train_loss_ex:1.590813676711432, train_loss_class: 1029.9963621703018\n",
      " epoch: 276, train accuracy: 0.7257641607700873,               train_loss_ex:1.5887490658670294, train_loss_class: 1028.6595986698596\n",
      " epoch: 277, train accuracy: 0.7260515067705902,               train_loss_ex:1.5866944100968519, train_loss_class: 1027.3292807327082\n",
      " epoch: 278, train accuracy: 0.7264106892712187,               train_loss_ex:1.58464962954172, train_loss_class: 1026.0053566528147\n",
      " epoch: 279, train accuracy: 0.7266980352717216,               train_loss_ex:1.582614645245336, train_loss_class: 1024.6877753087304\n",
      " epoch: 280, train accuracy: 0.7269494630221616,               train_loss_ex:1.5805893791411312, train_loss_class: 1023.3764861550752\n",
      " epoch: 281, train accuracy: 0.7271290542724759,               train_loss_ex:1.5785737540393503, train_loss_class: 1022.0714392141756\n",
      " epoch: 282, train accuracy: 0.7272727272727273,               train_loss_ex:1.5765676936143602, train_loss_class: 1020.7725850678466\n",
      " epoch: 283, train accuracy: 0.727344563772853,               train_loss_ex:1.574571122392183, train_loss_class: 1019.4798748493201\n",
      " epoch: 284, train accuracy: 0.7277755827736073,               train_loss_ex:1.5725839657382505, train_loss_class: 1018.193260235317\n",
      " epoch: 285, train accuracy: 0.7279551740239215,               train_loss_ex:1.570606149845371, train_loss_class: 1016.9126934382552\n",
      " epoch: 286, train accuracy: 0.7282784382744872,               train_loss_ex:1.5686376017219057, train_loss_class: 1015.6381271985948\n",
      " epoch: 287, train accuracy: 0.7284221112747387,               train_loss_ex:1.5666782491801514, train_loss_class: 1014.3695147773161\n",
      " epoch: 288, train accuracy: 0.7284939477748644,               train_loss_ex:1.5647280208249266, train_loss_class: 1013.1068099485298\n",
      " epoch: 289, train accuracy: 0.7287094572752415,               train_loss_ex:1.5627868460423497, train_loss_class: 1011.8499669922107\n",
      " epoch: 290, train accuracy: 0.7287812937753673,               train_loss_ex:1.5608546549888171, train_loss_class: 1010.5989406870618\n",
      " epoch: 291, train accuracy: 0.728853130275493,               train_loss_ex:1.5589313785801648, train_loss_class: 1009.3536863034969\n",
      " epoch: 292, train accuracy: 0.7289249667756187,               train_loss_ex:1.5570169484810192, train_loss_class: 1008.1141595967455\n",
      " epoch: 293, train accuracy: 0.7289968032757445,               train_loss_ex:1.5551112970943282, train_loss_class: 1006.8803168000742\n",
      " epoch: 294, train accuracy: 0.7290686397758701,               train_loss_ex:1.5532143575510715, train_loss_class: 1005.6521146181251\n",
      " epoch: 295, train accuracy: 0.729355985776373,               train_loss_ex:1.5513260637001425, train_loss_class: 1004.4295102203643\n",
      " epoch: 296, train accuracy: 0.7294637405265616,               train_loss_ex:1.5494463500984061, train_loss_class: 1003.2124612346448\n",
      " epoch: 297, train accuracy: 0.7294996587766244,               train_loss_ex:1.5475751520009202, train_loss_class: 1002.0009257408748\n",
      " epoch: 298, train accuracy: 0.7295714952767501,               train_loss_ex:1.5457124053513223, train_loss_class: 1000.7948622647946\n",
      " epoch: 299, train accuracy: 0.7300025142775044,               train_loss_ex:1.5438580467723788, train_loss_class: 999.5942297718558\n",
      " epoch: 300, train accuracy: 0.7303257785280701,               train_loss_ex:1.542012013556691, train_loss_class: 998.3989876612055\n",
      "**********\n",
      "(38278, 1024)\n",
      "[1023 1022 1021 ...    2    1    0]\n",
      "bruh1: (1024,)\n",
      "bruh (38278, 1024)\n",
      "bruh3 (38278, 1024)\n",
      "(38278, 100)\n",
      " epoch: 1, train accuracy: 0.005172684048278384,               train_loss_ex:3.761200115693563, train_loss_class: 3348.16786112833\n",
      " epoch: 2, train accuracy: 0.6603793301635404,               train_loss_ex:3.7366188436080066, train_loss_class: 3326.285955712262\n",
      " epoch: 3, train accuracy: 0.6603793301635404,               train_loss_ex:3.712154309139877, train_loss_class: 3304.5079684943307\n",
      " epoch: 4, train accuracy: 0.6603793301635404,               train_loss_ex:3.6878095168236245, train_loss_class: 3282.836574069179\n",
      " epoch: 5, train accuracy: 0.6604054548304509,               train_loss_ex:3.663587682350125, train_loss_class: 3261.274634999955\n",
      " epoch: 6, train accuracy: 0.6604054548304509,               train_loss_ex:3.6394922401619128, train_loss_class: 3239.825208579481\n",
      " epoch: 7, train accuracy: 0.6604054548304509,               train_loss_ex:3.615526850002655, train_loss_class: 3218.491552660503\n",
      " epoch: 8, train accuracy: 0.6603793301635404,               train_loss_ex:3.591695402042869, train_loss_class: 3197.2771302185333\n",
      " epoch: 9, train accuracy: 0.6604054548304509,               train_loss_ex:3.5680020201463605, train_loss_class: 3176.1856122595905\n",
      " epoch: 10, train accuracy: 0.6604577041642719,               train_loss_ex:3.5444510627869854, train_loss_class: 3155.2208786362844\n",
      " epoch: 11, train accuracy: 0.6603793301635404,               train_loss_ex:3.521047121078219, train_loss_class: 3134.3870162937687\n",
      " epoch: 12, train accuracy: 0.6604577041642719,               train_loss_ex:3.4977950133450078, train_loss_class: 3113.6883144376793\n",
      " epoch: 13, train accuracy: 0.6604838288311824,               train_loss_ex:3.4746997756565565, train_loss_class: 3093.12925610655\n",
      " epoch: 14, train accuracy: 0.6605099534980929,               train_loss_ex:3.451766647758727, train_loss_class: 3072.7145056490363\n",
      " epoch: 15, train accuracy: 0.6606144521657349,               train_loss_ex:3.429001053905098, train_loss_class: 3052.448891659985\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " epoch: 16, train accuracy: 0.6606405768326454,               train_loss_ex:3.4064085781944087, train_loss_class: 3032.3373850261764\n",
      " epoch: 17, train accuracy: 0.6606667014995559,               train_loss_ex:3.3839949341850706, train_loss_class: 3012.3850718775843\n",
      " epoch: 18, train accuracy: 0.6607189508333768,               train_loss_ex:3.36176592877558, train_loss_class: 2992.597121434225\n",
      " epoch: 19, train accuracy: 0.6608234495010189,               train_loss_ex:3.3397274206079515, train_loss_class: 2972.978748977469\n",
      " epoch: 20, train accuracy: 0.6610063221693924,               train_loss_ex:3.3178852735562203, train_loss_class: 2953.5351744461627\n",
      " epoch: 21, train accuracy: 0.6611630701708553,               train_loss_ex:3.2962453061823247, train_loss_class: 2934.2715774429544\n",
      " epoch: 22, train accuracy: 0.6612675688384974,               train_loss_ex:3.2748132383482, train_loss_class: 2915.1930497091253\n",
      " epoch: 23, train accuracy: 0.6612675688384974,               train_loss_ex:3.2535946364330415, train_loss_class: 2896.304546357767\n",
      " epoch: 24, train accuracy: 0.6613459428392288,               train_loss_ex:3.232594858785668, train_loss_class: 2877.610837316228\n",
      " epoch: 25, train accuracy: 0.6613981921730498,               train_loss_ex:3.2118190031175824, train_loss_class: 2859.1164604961587\n",
      " epoch: 26, train accuracy: 0.6615549401745128,               train_loss_ex:3.191271857497471, train_loss_class: 2840.825678169493\n",
      " epoch: 27, train accuracy: 0.6617900621767072,               train_loss_ex:3.170957856442355, train_loss_class: 2822.742437881406\n",
      " epoch: 28, train accuracy: 0.6618684361774387,               train_loss_ex:3.150881043329977, train_loss_class: 2804.8703389903458\n",
      " epoch: 29, train accuracy: 0.6620251841789018,               train_loss_ex:3.1310450400100005, train_loss_class: 2787.2126056163443\n",
      " epoch: 30, train accuracy: 0.6621296828465437,               train_loss_ex:3.1114530241055096, train_loss_class: 2769.7720664351323\n",
      " epoch: 31, train accuracy: 0.6623909295156487,               train_loss_ex:3.0921077141102304, train_loss_class: 2752.5511414118932\n",
      " epoch: 32, train accuracy: 0.6624431788494697,               train_loss_ex:3.0730113620358477, train_loss_class: 2735.551835256004\n",
      " epoch: 33, train accuracy: 0.6625738021840222,               train_loss_ex:3.0541657530739506, train_loss_class: 2718.775737120109\n",
      " epoch: 34, train accuracy: 0.6626260515178432,               train_loss_ex:3.0355722115235, train_loss_class: 2702.2240258766637\n",
      " epoch: 35, train accuracy: 0.6627305501854851,               train_loss_ex:3.0172316121011575, train_loss_class: 2685.897480186235\n",
      " epoch: 36, train accuracy: 0.6629395475207691,               train_loss_ex:2.9991443956930666, train_loss_class: 2669.7964925195165\n",
      " epoch: 37, train accuracy: 0.6629917968545901,               train_loss_ex:2.9813105886109788, train_loss_class: 2653.9210862988616\n",
      " epoch: 38, train accuracy: 0.6632530435236951,               train_loss_ex:2.9637298244680843, train_loss_class: 2638.270935371845\n",
      " epoch: 39, train accuracy: 0.6634620408589791,               train_loss_ex:2.946401367874974, train_loss_class: 2622.845385105076\n",
      " epoch: 40, train accuracy: 0.6636971628611735,               train_loss_ex:2.9293241392596374, train_loss_class: 2607.643474478614\n",
      " epoch: 41, train accuracy: 0.6639061601964575,               train_loss_ex:2.9124967402256514, train_loss_class: 2592.6639586594765\n",
      " epoch: 42, train accuracy: 0.66403678353101,               train_loss_ex:2.8959174789708846, train_loss_class: 2577.905331629012\n",
      " epoch: 43, train accuracy: 0.664193531532473,               train_loss_ex:2.879584395389283, train_loss_class: 2563.3658485281626\n",
      " epoch: 44, train accuracy: 0.6644809028684884,               train_loss_ex:2.863495285567112, train_loss_class: 2549.0435474636724\n",
      " epoch: 45, train accuracy: 0.6647160248706829,               train_loss_ex:2.8476477254608787, train_loss_class: 2534.9362705858493\n",
      " epoch: 46, train accuracy: 0.6650295208736089,               train_loss_ex:2.832039093606998, train_loss_class: 2521.0416843043877\n",
      " epoch: 47, train accuracy: 0.6653691415434453,               train_loss_ex:2.816666592763816, train_loss_class: 2507.357298553799\n",
      " epoch: 48, train accuracy: 0.6656042635456398,               train_loss_ex:2.801527270426321, train_loss_class: 2493.8804850553192\n",
      " epoch: 49, train accuracy: 0.6659700088823868,               train_loss_ex:2.7866180381842764, train_loss_class: 2480.6084945492494\n",
      " epoch: 50, train accuracy: 0.6663096295522232,               train_loss_ex:2.7719356899172056, train_loss_class: 2467.538472991879\n",
      " epoch: 51, train accuracy: 0.6667798735566122,               train_loss_ex:2.7574769188363155, train_loss_class: 2454.667476725965\n",
      " epoch: 52, train accuracy: 0.6669366215580751,               train_loss_ex:2.7432383333952055, train_loss_class: 2441.9924866442248\n",
      " epoch: 53, train accuracy: 0.6671717435602696,               train_loss_ex:2.729216472099416, train_loss_class: 2429.510421372592\n",
      " epoch: 54, train accuracy: 0.6674329902293745,               train_loss_ex:2.715407817250381, train_loss_class: 2417.218149504886\n",
      " epoch: 55, train accuracy: 0.6677987355661216,               train_loss_ex:2.7018088076628883, train_loss_class: 2405.112500923722\n",
      " epoch: 56, train accuracy: 0.668086106902137,               train_loss_ex:2.6884158503974005, train_loss_class: 2393.1902772444582\n",
      " epoch: 57, train accuracy: 0.6684518522388839,               train_loss_ex:2.6752253315497976, train_loss_class: 2381.4482614200733\n",
      " epoch: 58, train accuracy: 0.668608600240347,               train_loss_ex:2.6622336261417767, train_loss_class: 2369.8832265454635\n",
      " epoch: 59, train accuracy: 0.6687914729087204,               train_loss_ex:2.6494371071553364, train_loss_class: 2358.491943899813\n",
      " epoch: 60, train accuracy: 0.6689743455770939,               train_loss_ex:2.63683215375467, train_loss_class: 2347.2711902656106\n",
      " epoch: 61, train accuracy: 0.6692617169131093,               train_loss_ex:2.624415158738516, train_loss_class: 2336.217754562626\n",
      " epoch: 62, train accuracy: 0.6696797115836773,               train_loss_ex:2.6121825352655716, train_loss_class: 2325.32844383478\n",
      " epoch: 63, train accuracy: 0.6700715815873347,               train_loss_ex:2.6001307228949604, train_loss_class: 2314.600088627286\n",
      " epoch: 64, train accuracy: 0.6704895762579027,               train_loss_ex:2.5882561929830907, train_loss_class: 2304.0295477908544\n",
      " epoch: 65, train accuracy: 0.6708814462615602,               train_loss_ex:2.5765554534773663, train_loss_class: 2293.6137127489915\n",
      " epoch: 66, train accuracy: 0.6710643189299337,               train_loss_ex:2.565025053146321, train_loss_class: 2283.3495112636015\n",
      " epoch: 67, train accuracy: 0.6715868122681435,               train_loss_ex:2.55366158528465, train_loss_class: 2273.233910733159\n",
      " epoch: 68, train accuracy: 0.6717958096034276,               train_loss_ex:2.542461690930497, train_loss_class: 2263.2639210566876\n",
      " epoch: 69, train accuracy: 0.6722660536078165,               train_loss_ex:2.531422061631029, train_loss_class: 2253.43659709564\n",
      " epoch: 70, train accuracy: 0.6724750509431004,               train_loss_ex:2.520539441791025, train_loss_class: 2243.749040764578\n",
      " epoch: 71, train accuracy: 0.6729191702805789,               train_loss_ex:2.509810630637731, train_loss_class: 2234.198402780257\n",
      " epoch: 72, train accuracy: 0.6731804169496839,               train_loss_ex:2.4992324838337194, train_loss_class: 2224.7818840973746\n",
      " epoch: 73, train accuracy: 0.6735722869533414,               train_loss_ex:2.488801914767971, train_loss_class: 2215.4967370578697\n",
      " epoch: 74, train accuracy: 0.6736767856209833,               train_loss_ex:2.478515895553747, train_loss_class: 2206.340266279217\n",
      " epoch: 75, train accuracy: 0.6740425309577303,               train_loss_ex:2.468371457760266, train_loss_class: 2197.309829305755\n",
      " epoch: 76, train accuracy: 0.6742776529599248,               train_loss_ex:2.4583656929035365, train_loss_class: 2188.402837045618\n",
      " epoch: 77, train accuracy: 0.6745650242959402,               train_loss_ex:2.448495752720129, train_loss_class: 2179.6167540144443\n",
      " epoch: 78, train accuracy: 0.6748001462981347,               train_loss_ex:2.4387588492460783, train_loss_class: 2170.9490984056138\n",
      " epoch: 79, train accuracy: 0.6751136423010606,               train_loss_ex:2.429152254721562, train_loss_class: 2162.397442005394\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " epoch: 80, train accuracy: 0.6752965149694341,               train_loss_ex:2.419673301340508, train_loss_class: 2153.9594099700457\n",
      " epoch: 81, train accuracy: 0.6756100109723601,               train_loss_ex:2.4103193808628616, train_loss_class: 2145.6326804806654\n",
      " epoch: 82, train accuracy: 0.6758190083076441,               train_loss_ex:2.401087944105813, train_loss_class: 2137.414984290286\n",
      " epoch: 83, train accuracy: 0.6761586289774806,               train_loss_ex:2.3919765003290197, train_loss_class: 2129.3041041766096\n",
      " epoch: 84, train accuracy: 0.676498249647317,               train_loss_ex:2.3829826165275705, train_loss_class: 2121.2978743126127\n",
      " epoch: 85, train accuracy: 0.676707246982601,               train_loss_ex:2.3741039166452786, train_loss_class: 2113.394179566232\n",
      " epoch: 86, train accuracy: 0.6771513663200794,               train_loss_ex:2.3653380807197615, train_loss_class: 2105.590954739326\n",
      " epoch: 87, train accuracy: 0.6773342389884529,               train_loss_ex:2.3566828439697445, train_loss_class: 2097.8861837552063\n",
      " epoch: 88, train accuracy: 0.6775693609906474,               train_loss_ex:2.348135995834033, train_loss_class: 2090.2778988031423\n",
      " epoch: 89, train accuracy: 0.6778044829928418,               train_loss_ex:2.3396953789707267, train_loss_class: 2082.764179447476\n",
      " epoch: 90, train accuracy: 0.6780918543288573,               train_loss_ex:2.3313588882243526, train_loss_class: 2075.3431517081804\n",
      " epoch: 91, train accuracy: 0.6784837243325148,               train_loss_ex:2.323124469567901, train_loss_class: 2068.0129871190725\n",
      " epoch: 92, train accuracy: 0.6786404723339777,               train_loss_ex:2.31499011902595, train_loss_class: 2060.7719017691934\n",
      " epoch: 93, train accuracy: 0.6790584670045456,               train_loss_ex:2.306953881584468, train_loss_class: 2053.6181553323318\n",
      " epoch: 94, train accuracy: 0.6796070850096662,               train_loss_ex:2.299013850092244, train_loss_class: 2046.5500500890912\n",
      " epoch: 95, train accuracy: 0.6799205810125921,               train_loss_ex:2.2911681641583637, train_loss_class: 2039.5659299454383\n",
      " epoch: 96, train accuracy: 0.6803647003500706,               train_loss_ex:2.2834150090496257, train_loss_class: 2032.6641794511995\n",
      " epoch: 97, train accuracy: 0.68086106902137,               train_loss_ex:2.2757526145913496, train_loss_class: 2025.843222821574\n",
      " epoch: 98, train accuracy: 0.6812006896912064,               train_loss_ex:2.2681792540745906, train_loss_class: 2019.1015229643529\n",
      " epoch: 99, train accuracy: 0.6816709336955954,               train_loss_ex:2.2606932431724047, train_loss_class: 2012.4375805151933\n",
      " epoch: 100, train accuracy: 0.6818015570301479,               train_loss_ex:2.253292938867463, train_loss_class: 2005.849932882994\n",
      " epoch: 101, train accuracy: 0.6819583050316108,               train_loss_ex:2.245976738392985, train_loss_class: 1999.3371533071322\n",
      " epoch: 102, train accuracy: 0.6821934270338054,               train_loss_ex:2.23874307818871, train_loss_class: 1992.89784992808\n",
      " epoch: 103, train accuracy: 0.6825330477036418,               train_loss_ex:2.231590432873325, train_loss_class: 1986.5306648726776\n",
      " epoch: 104, train accuracy: 0.6828726683734783,               train_loss_ex:2.2245173142345798, train_loss_class: 1980.2342733551452\n",
      " epoch: 105, train accuracy: 0.6832645383771357,               train_loss_ex:2.2175222702380903, train_loss_class: 1974.0073827947353\n",
      " epoch: 106, train accuracy: 0.6837086577146141,               train_loss_ex:2.210603884055649, train_loss_class: 1967.8487319507474\n",
      " epoch: 107, train accuracy: 0.6838654057160771,               train_loss_ex:2.2037607731137046, train_loss_class: 1961.7570900754972\n",
      " epoch: 108, train accuracy: 0.6844401483881081,               train_loss_ex:2.1969915881625055, train_loss_class: 1955.7312560856835\n",
      " epoch: 109, train accuracy: 0.6847275197241235,               train_loss_ex:2.1902950123663003, train_loss_class: 1949.770057752494\n",
      " epoch: 110, train accuracy: 0.68506714039396,               train_loss_ex:2.183669760414838, train_loss_class: 1943.8723509106783\n",
      " epoch: 111, train accuracy: 0.685276137729244,               train_loss_ex:2.177114577656331, train_loss_class: 1938.037018686722\n",
      " epoch: 112, train accuracy: 0.6856941323998119,               train_loss_ex:2.170628239251944, train_loss_class: 1932.2629707461838\n",
      " epoch: 113, train accuracy: 0.6859292544020064,               train_loss_ex:2.1642095493517863, train_loss_class: 1926.5491425601786\n",
      " epoch: 114, train accuracy: 0.6864517477402163,               train_loss_ex:2.1578573402923276, train_loss_class: 1920.8944946909235\n",
      " epoch: 115, train accuracy: 0.6866868697424108,               train_loss_ex:2.1515704718150763, train_loss_class: 1915.2980120962206\n",
      " epoch: 116, train accuracy: 0.6867913684100527,               train_loss_ex:2.145347830306338, train_loss_class: 1909.7587034526978\n",
      " epoch: 117, train accuracy: 0.6870003657453367,               train_loss_ex:2.139188328057775, train_loss_class: 1904.27560049757\n",
      " epoch: 118, train accuracy: 0.6872877370813523,               train_loss_ex:2.133090902547507, train_loss_class: 1898.8477573886853\n",
      " epoch: 119, train accuracy: 0.6875228590835467,               train_loss_ex:2.1270545157414205, train_loss_class: 1893.47425008256\n",
      " epoch: 120, train accuracy: 0.6877318564188306,               train_loss_ex:2.121078153414324, train_loss_class: 1888.1541757300813\n",
      " epoch: 121, train accuracy: 0.6880976017555777,               train_loss_ex:2.115160824490604, train_loss_class: 1882.886652089566\n",
      " epoch: 122, train accuracy: 0.688489471759235,               train_loss_ex:2.1093015604039564, train_loss_class: 1877.6708169568058\n",
      " epoch: 123, train accuracy: 0.688802967762161,               train_loss_ex:2.1034994144758126, train_loss_class: 1872.505827611748\n",
      " epoch: 124, train accuracy: 0.689064214431266,               train_loss_ex:2.0977534613120237, train_loss_class: 1867.3908602814336\n",
      " epoch: 125, train accuracy: 0.6893777104341919,               train_loss_ex:2.0920627962173763, train_loss_class: 1862.3251096188076\n",
      " epoch: 126, train accuracy: 0.6896912064371179,               train_loss_ex:2.0864265346275155, train_loss_class: 1857.3077881970241\n",
      " epoch: 127, train accuracy: 0.6899524531062229,               train_loss_ex:2.0808438115578194, train_loss_class: 1852.338126018842\n",
      " epoch: 128, train accuracy: 0.6903443231098804,               train_loss_ex:2.0753137810687936, train_loss_class: 1847.4153700407276\n",
      " epoch: 129, train accuracy: 0.6906316944458958,               train_loss_ex:2.0698356157475475, train_loss_class: 1842.5387837112703\n",
      " epoch: 130, train accuracy: 0.6908668164480903,               train_loss_ex:2.064408506204902, train_loss_class: 1837.707646523517\n",
      " epoch: 131, train accuracy: 0.6913893097863002,               train_loss_ex:2.059031660587701, train_loss_class: 1832.9212535808376\n",
      " epoch: 132, train accuracy: 0.6916766811223157,               train_loss_ex:2.053704304105895, train_loss_class: 1828.1789151759406\n",
      " epoch: 133, train accuracy: 0.6919901771252417,               train_loss_ex:2.048425678573958, train_loss_class: 1823.47995638265\n",
      " epoch: 134, train accuracy: 0.6924865457965411,               train_loss_ex:2.0431950419662317, train_loss_class: 1818.8237166600795\n",
      " epoch: 135, train accuracy: 0.6928261664663775,               train_loss_ex:2.0380116679857743, train_loss_class: 1814.209549468825\n",
      " epoch: 136, train accuracy: 0.6930612884685721,               train_loss_ex:2.0328748456463037, train_loss_class: 1809.6368218988189\n",
      " epoch: 137, train accuracy: 0.6931396624693035,               train_loss_ex:2.027783878866845, train_loss_class: 1805.1049143084904\n",
      " epoch: 138, train accuracy: 0.6933225351376769,               train_loss_ex:2.0227380860786854, train_loss_class: 1800.613219974882\n",
      " epoch: 139, train accuracy: 0.69347928313914,               train_loss_ex:2.0177367998442612, train_loss_class: 1796.1611447543867\n",
      " epoch: 140, train accuracy: 0.6939495271435289,               train_loss_ex:2.0127793664875884, train_loss_class: 1791.7481067537653\n",
      " epoch: 141, train accuracy: 0.6941846491457234,               train_loss_ex:2.0078651457358996, train_loss_class: 1787.373536011134\n",
      " epoch: 142, train accuracy: 0.6943936464810073,               train_loss_ex:2.0029935103721055, train_loss_class: 1783.036874186592\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " epoch: 143, train accuracy: 0.6948638904853963,               train_loss_ex:1.9981638458977535, train_loss_class: 1778.737574262191\n",
      " epoch: 144, train accuracy: 0.6951773864883223,               train_loss_ex:1.993375550206143, train_loss_class: 1774.4751002509474\n",
      " epoch: 145, train accuracy: 0.6954125084905167,               train_loss_ex:1.9886280332652695, train_loss_class: 1770.2489269146042\n",
      " epoch: 146, train accuracy: 0.6957782538272637,               train_loss_ex:1.9839207168102826, train_loss_class: 1766.0585394898606\n",
      " epoch: 147, train accuracy: 0.6961178744971002,               train_loss_ex:1.9792530340451504, train_loss_class: 1761.903433422797\n",
      " epoch: 148, train accuracy: 0.6964313705000261,               train_loss_ex:1.974624429353235, train_loss_class: 1757.7831141112354\n",
      " epoch: 149, train accuracy: 0.6966926171691311,               train_loss_ex:1.9700343580164787, train_loss_class: 1753.6970966547622\n",
      " epoch: 150, train accuracy: 0.697058362505878,               train_loss_ex:1.9654822859429415, train_loss_class: 1749.644905612184\n",
      " epoch: 151, train accuracy: 0.697424107842625,               train_loss_ex:1.9609676894023937, train_loss_class: 1745.6260747661588\n",
      " epoch: 152, train accuracy: 0.697633105177909,               train_loss_ex:1.9564900547697226, train_loss_class: 1741.6401468947777\n",
      " epoch: 153, train accuracy: 0.6979204765139244,               train_loss_ex:1.9520488782758836, train_loss_class: 1737.6866735498668\n",
      " epoch: 154, train accuracy: 0.6982339725168504,               train_loss_ex:1.9476436657661593, train_loss_class: 1733.765214841792\n",
      " epoch: 155, train accuracy: 0.6985735931866869,               train_loss_ex:1.943273932465485, train_loss_class: 1729.8753392305543\n",
      " epoch: 156, train accuracy: 0.6988870891896128,               train_loss_ex:1.9389392027506083, train_loss_class: 1726.0166233229718\n",
      " epoch: 157, train accuracy: 0.6990438371910758,               train_loss_ex:1.9346390099288628, train_loss_class: 1722.1886516757445\n",
      " epoch: 158, train accuracy: 0.6993050838601808,               train_loss_ex:1.9303728960233448, train_loss_class: 1718.391016604223\n",
      " epoch: 159, train accuracy: 0.6995663305292857,               train_loss_ex:1.9261404115642744, train_loss_class: 1714.6233179966812\n",
      " epoch: 160, train accuracy: 0.6998275771983907,               train_loss_ex:1.921941115386353, train_loss_class: 1710.885163133926\n",
      " epoch: 161, train accuracy: 0.7001410732013167,               train_loss_ex:1.917774574431911, train_loss_class: 1707.1761665140627\n",
      " epoch: 162, train accuracy: 0.7004023198704217,               train_loss_ex:1.9136403635596695, train_loss_class: 1703.4959496822564\n",
      " epoch: 163, train accuracy: 0.7005590678718846,               train_loss_ex:1.9095380653589282, train_loss_class: 1699.8441410653268\n",
      " epoch: 164, train accuracy: 0.7007419405402581,               train_loss_ex:1.905467269969002, train_loss_class: 1696.2203758110109\n",
      " epoch: 165, train accuracy: 0.701055436543184,               train_loss_ex:1.9014275749037488, train_loss_class: 1692.6242956317603\n",
      " epoch: 166, train accuracy: 0.701473431213752,               train_loss_ex:1.8974185848810126, train_loss_class: 1689.0555486529163\n",
      " epoch: 167, train accuracy: 0.7017085532159465,               train_loss_ex:1.8934399116568337, train_loss_class: 1685.5137892651228\n",
      " epoch: 168, train accuracy: 0.7018653012174095,               train_loss_ex:1.8894911738642677, train_loss_class: 1681.9986779808476\n",
      " epoch: 169, train accuracy: 0.7021265478865144,               train_loss_ex:1.8855719968566744, train_loss_class: 1678.5098812948786\n",
      " epoch: 170, train accuracy: 0.7022310465541565,               train_loss_ex:1.8816820125553235, train_loss_class: 1675.0470715486667\n",
      " epoch: 171, train accuracy: 0.702361669888709,               train_loss_ex:1.8778208593011898, train_loss_class: 1671.609926798394\n",
      " epoch: 172, train accuracy: 0.7026229165578138,               train_loss_ex:1.8739881817108066, train_loss_class: 1668.1981306866571\n",
      " epoch: 173, train accuracy: 0.7028580385600084,               train_loss_ex:1.8701836305360384, train_loss_class: 1664.811372317639\n",
      " epoch: 174, train accuracy: 0.7030409112283819,               train_loss_ex:1.8664068625276644, train_loss_class: 1661.449346135673\n",
      " epoch: 175, train accuracy: 0.7033282825643973,               train_loss_ex:1.8626575403026395, train_loss_class: 1658.11175180708\n",
      " epoch: 176, train accuracy: 0.7036679032342338,               train_loss_ex:1.858935332214934, train_loss_class: 1654.7982941051916\n",
      " epoch: 177, train accuracy: 0.7040336485709807,               train_loss_ex:1.8552399122298255, train_loss_class: 1651.508682798448\n",
      " epoch: 178, train accuracy: 0.7043471445739067,               train_loss_ex:1.8515709598015446, train_loss_class: 1648.2426325414772\n",
      " epoch: 179, train accuracy: 0.7044255185746382,               train_loss_ex:1.8479281597541695, train_loss_class: 1644.999862769072\n",
      " epoch: 180, train accuracy: 0.7045561419091907,               train_loss_ex:1.8443112021656722, train_loss_class: 1641.7800975929676\n",
      " epoch: 181, train accuracy: 0.7047912639113851,               train_loss_ex:1.8407197822550114, train_loss_class: 1638.5830657013332\n",
      " epoch: 182, train accuracy: 0.7050525105804901,               train_loss_ex:1.8371536002721864, train_loss_class: 1635.4085002609013\n",
      " epoch: 183, train accuracy: 0.7053137572495951,               train_loss_ex:1.833612361391164, train_loss_class: 1632.2561388216507\n",
      " epoch: 184, train accuracy: 0.7055488792517896,               train_loss_ex:1.8300957756055816, train_loss_class: 1629.125723223964\n",
      " epoch: 185, train accuracy: 0.7059146245885365,               train_loss_ex:1.82660355762715, train_loss_class: 1626.0169995081872\n",
      " epoch: 186, train accuracy: 0.70609749725691,               train_loss_ex:1.8231354267866757, train_loss_class: 1622.9297178265203\n",
      " epoch: 187, train accuracy: 0.7061758712576415,               train_loss_ex:1.8196911069376174, train_loss_class: 1619.8636323571657\n",
      " epoch: 188, train accuracy: 0.7064109932598359,               train_loss_ex:1.8162703263621074, train_loss_class: 1616.8185012206684\n",
      " epoch: 189, train accuracy: 0.7067244892627619,               train_loss_ex:1.8128728176793594, train_loss_class: 1613.7940863983843\n",
      " epoch: 190, train accuracy: 0.7070118605987774,               train_loss_ex:1.8094983177563995, train_loss_class: 1610.7901536530107\n",
      " epoch: 191, train accuracy: 0.7072992319347928,               train_loss_ex:1.8061465676210389, train_loss_class: 1607.8064724511191\n",
      " epoch: 192, train accuracy: 0.7075866032708082,               train_loss_ex:1.8028173123770381, train_loss_class: 1604.842815887634\n",
      " epoch: 193, train accuracy: 0.7077433512722713,               train_loss_ex:1.799510301121384, train_loss_class: 1601.8989606121938\n",
      " epoch: 194, train accuracy: 0.7079000992737342,               train_loss_ex:1.7962252868636275, train_loss_class: 1598.9746867573474\n",
      " epoch: 195, train accuracy: 0.7084225926119442,               train_loss_ex:1.792962026447219, train_loss_class: 1596.0697778685267\n",
      " epoch: 196, train accuracy: 0.7086838392810492,               train_loss_ex:1.7897202804727799, train_loss_class: 1593.184020835746\n",
      " epoch: 197, train accuracy: 0.7088667119494226,               train_loss_ex:1.7864998132232623, train_loss_class: 1590.3172058269777\n",
      " epoch: 198, train accuracy: 0.7091018339516171,               train_loss_ex:1.7833003925909308, train_loss_class: 1587.4691262231547\n",
      " epoch: 199, train accuracy: 0.7092063326192591,               train_loss_ex:1.7801217900061301, train_loss_class: 1584.6395785547593\n",
      " epoch: 200, train accuracy: 0.7093630806207221,               train_loss_ex:1.7769637803677691, train_loss_class: 1581.8283624399412\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_29300/3334929375.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m         \u001b[0my_hat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoftmax_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_d\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[0mraw_train_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoftmax_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_hat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Documents\\UCSD\\0CSE251B\\hw1\\CSE251B\\cse251b_PA1_starter\\model\\softmax.py\u001b[0m in \u001b[0;36mmodel\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     34\u001b[0m         '''\n\u001b[0;32m     35\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcross_entropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_hat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Documents\\UCSD\\0CSE251B\\hw1\\CSE251B\\cse251b_PA1_starter\\model\\softmax.py\u001b[0m in \u001b[0;36msoftmax\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[1;31m# [:, np.newaxis] is necessary for broadcasting to work properly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0mpartition\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# sum of each row\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0meX\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mpartition\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Softmax Regression Parameters\n",
    "lr = 0.1\n",
    "num_features = X.shape[1]\n",
    "num_classes = y.max() + 1\n",
    "\n",
    "train_loss_record = []\n",
    "train_accuracy_record = []\n",
    "holdout_loss_record = []\n",
    "holdout_accuracy_record = []\n",
    "test_accuracy_record = []\n",
    "\n",
    "\n",
    "# PCA number of principal components\n",
    "n_components = 100\n",
    "\n",
    "first_plot = True\n",
    "\n",
    "num_epochs = 300\n",
    "epochs_print = [50, 100, 150, 200, 250, 300]\n",
    "\n",
    "for train, valid, test in generate_k_fold_set((X, y), 10):\n",
    "    print(\"**********\")\n",
    "    train_data, train_label = train\n",
    "    valid_data, valid_label = valid\n",
    "    test_data, test_label = test\n",
    "    \n",
    "    print(train_data.shape)\n",
    "    # Project data onto principal components\n",
    "    pca = PCA(n_components)\n",
    "    projected = pca.fit_transform(train_data)\n",
    "    print(projected.shape)\n",
    "    \n",
    "    # Plot principal components\n",
    "    if first_plot == True : \n",
    "        pca.plot_PC()\n",
    "        first_plot = False\n",
    "    train_d = projected     \n",
    "    valid_d = pca.PCA_generate(valid_data)\n",
    "    test_d = pca.PCA_generate(test_data)\n",
    "\n",
    "    softmax_model = SoftmaxRegression(lr, n_components, num_classes)\n",
    "    \n",
    "    # Onehot encode labels\n",
    "    y_true = onehot_encode(train_label)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        y_hat = softmax_model.model(train_d)\n",
    "        \n",
    "        raw_train_loss = softmax_model.cross_entropy(y_true, y_hat)\n",
    "        train_loss_ex = raw_train_loss / len(train_d) # train loss per example\n",
    "        train_loss_class = raw_train_loss / num_classes # train loss per class\n",
    "        \n",
    "        train_loss_record.append(raw_train_loss)\n",
    "        \n",
    "        train_accuracy = softmax_model.accuracy(y_true, y_hat)\n",
    "        train_accuracy_record.append(train_accuracy)\n",
    "        \n",
    "        # Update Weights\n",
    "        softmax_model.update_weights(train_d, y_true, y_hat)\n",
    "        \n",
    "        if (epoch + 1) in epochs_print:\n",
    "            print(f' epoch: {epoch + 1}, train accuracy: {train_accuracy}, \\\n",
    "                  train_loss_ex:{train_loss_ex}, train_loss_class: {train_loss_class}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
