{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from neuralnet_update_PC import *\n",
    "# from neuralnet_works_FC import *\n",
    "from neuralnet import *\n",
    "from random import shuffle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "config_c = {}\n",
    "config_c['layer_specs'] = [3072, 64, 64, 10]\n",
    "config_c['activation'] = 'tanh'\n",
    "config_c['learning_rate'] = 0.005\n",
    "config_c['batch_size'] = 128\n",
    "config_c['epochs'] = 100  \n",
    "config_c['early_stop'] = True \n",
    "config_c['early_stop_epoch'] = 5\n",
    "config_c['L2_penalty'] = 0  \n",
    "config_c['momentum'] = True  \n",
    "config_c['momentum_gamma'] = 0.9  \n",
    "# Create the model\n",
    "\n",
    "#TODO\n",
    "#momentum, early stop , expect accuracy around 37%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "inp: (50000, 32, 32, 3)\n",
      "num_mini-batches 351.5625\n",
      "d_w: 2.220446049250313e-14\n",
      "d_b: -6.661338147750939e-16\n",
      "pre_d_w: 0.0\n",
      "pre_d_b: 0.0\n",
      "d_w: 8.543056850616104\n",
      "d_b: 8.731248782971136\n",
      "pre_d_w: 0.0\n",
      "pre_d_b: 0.0\n",
      "d_w: -6917.993034387071\n",
      "d_b: 1.1677161207092877\n",
      "pre_d_w: 0.0\n",
      "pre_d_b: 0.0\n",
      " epoch: 1, train accuracy: 0.1138, train_loss_norm:10.1753, valid_acc: 0.1060, valid_loss_norm: 10.3014\n",
      "\n",
      "d_w: 0.0\n",
      "d_b: 5.575401251789458e-15\n",
      "pre_d_w: 2.220446049250313e-14\n",
      "pre_d_b: -6.661338147750939e-16\n",
      "d_w: 0.0\n",
      "d_b: 0.0\n",
      "pre_d_w: 8.543056850616104\n",
      "pre_d_b: 8.731248782971136\n",
      "d_w: 0.0\n",
      "d_b: 0.0\n",
      "pre_d_w: -6917.993034387071\n",
      "pre_d_b: 1.1677161207092877\n",
      " epoch: 2, train accuracy: 0.1406, train_loss_norm:2.2970, valid_acc: 0.1440, valid_loss_norm: 2.2975\n",
      "\n",
      "d_w: 6.689093723366568e-15\n",
      "d_b: -7.355227538141662e-16\n",
      "pre_d_w: 0.0\n",
      "pre_d_b: 5.575401251789458e-15\n",
      "d_w: -7.815672953389912\n",
      "d_b: 0.10718037041087011\n",
      "pre_d_w: 0.0\n",
      "pre_d_b: 0.0\n",
      "d_w: 93.69447867015944\n",
      "d_b: 0.014897932811446751\n",
      "pre_d_w: 0.0\n",
      "pre_d_b: 0.0\n",
      " epoch: 3, train accuracy: 0.1427, train_loss_norm:2.2819, valid_acc: 0.1436, valid_loss_norm: 2.2827\n",
      "\n",
      "d_w: -8.659739592076221e-15\n",
      "d_b: -1.3877787807814457e-16\n",
      "pre_d_w: 6.689093723366568e-15\n",
      "pre_d_b: -7.355227538141662e-16\n",
      "d_w: -6.623277152139762\n",
      "d_b: 0.06805230713812682\n",
      "pre_d_w: -7.815672953389912\n",
      "pre_d_b: 0.10718037041087011\n",
      "d_w: -13.460360518648947\n",
      "d_b: 0.07622835933168572\n",
      "pre_d_w: 93.69447867015944\n",
      "pre_d_b: 0.014897932811446751\n",
      " epoch: 4, train accuracy: 0.1417, train_loss_norm:2.2548, valid_acc: 0.1408, valid_loss_norm: 2.2563\n",
      "\n",
      "d_w: -8.215650382226158e-15\n",
      "d_b: 6.661338147750939e-16\n",
      "pre_d_w: -8.659739592076221e-15\n",
      "pre_d_b: -1.3877787807814457e-16\n",
      "d_w: -4.061640945032423\n",
      "d_b: 0.10221562506255981\n",
      "pre_d_w: -6.623277152139762\n",
      "pre_d_b: 0.06805230713812682\n",
      "d_w: 56.1188940335589\n",
      "d_b: 0.2000233603444476\n",
      "pre_d_w: -13.460360518648947\n",
      "pre_d_b: 0.07622835933168572\n",
      " epoch: 5, train accuracy: 0.1562, train_loss_norm:2.2215, valid_acc: 0.1562, valid_loss_norm: 2.2242\n",
      "\n",
      "d_w: -9.103828801926284e-15\n",
      "d_b: 4.440892098500626e-16\n",
      "pre_d_w: -8.215650382226158e-15\n",
      "pre_d_b: 6.661338147750939e-16\n",
      "d_w: -2.040655257585039\n",
      "d_b: 0.22134060527611266\n",
      "pre_d_w: -4.061640945032423\n",
      "pre_d_b: 0.10221562506255981\n",
      "d_w: 491.2128688852593\n",
      "d_b: 0.33091860308003107\n",
      "pre_d_w: 56.1188940335589\n",
      "pre_d_b: 0.2000233603444476\n",
      " epoch: 6, train accuracy: 0.1689, train_loss_norm:2.1730, valid_acc: 0.1684, valid_loss_norm: 2.1773\n",
      "\n",
      "d_w: -6.5503158452884236e-15\n",
      "d_b: 1.4432899320127035e-15\n",
      "pre_d_w: -9.103828801926284e-15\n",
      "pre_d_b: 4.440892098500626e-16\n",
      "d_w: -4.774811452631344\n",
      "d_b: -0.1765895394746119\n",
      "pre_d_w: -2.040655257585039\n",
      "pre_d_b: 0.22134060527611266\n",
      "d_w: 698.3957812764332\n",
      "d_b: 0.2749807824942604\n",
      "pre_d_w: 491.2128688852593\n",
      "pre_d_b: 0.33091860308003107\n",
      " epoch: 7, train accuracy: 0.2016, train_loss_norm:2.1307, valid_acc: 0.2004, valid_loss_norm: 2.1365\n",
      "\n",
      "d_w: 6.439293542825908e-15\n",
      "d_b: -8.881784197001252e-16\n",
      "pre_d_w: -6.5503158452884236e-15\n",
      "pre_d_b: 1.4432899320127035e-15\n",
      "d_w: -14.337403761428423\n",
      "d_b: -1.0245154609507692\n",
      "pre_d_w: -4.774811452631344\n",
      "pre_d_b: -0.1765895394746119\n",
      "d_w: -601.5640852748438\n",
      "d_b: 0.05711880138190263\n",
      "pre_d_w: 698.3957812764332\n",
      "pre_d_b: 0.2749807824942604\n",
      " epoch: 8, train accuracy: 0.1872, train_loss_norm:2.0977, valid_acc: 0.1852, valid_loss_norm: 2.1045\n",
      "\n",
      "d_w: -1.3322676295501878e-15\n",
      "d_b: 2.886579864025407e-15\n",
      "pre_d_w: 6.439293542825908e-15\n",
      "pre_d_b: -8.881784197001252e-16\n",
      "d_w: 0.7440483164287723\n",
      "d_b: -0.8334429810599686\n",
      "pre_d_w: -14.337403761428423\n",
      "pre_d_b: -1.0245154609507692\n",
      "d_w: 728.8458689923491\n",
      "d_b: 0.2898060236889839\n",
      "pre_d_w: -601.5640852748438\n",
      "pre_d_b: 0.05711880138190263\n",
      " epoch: 9, train accuracy: 0.2035, train_loss_norm:2.0678, valid_acc: 0.1944, valid_loss_norm: 2.0753\n",
      "\n",
      "d_w: 6.439293542825908e-15\n",
      "d_b: 6.661338147750939e-16\n",
      "pre_d_w: -1.3322676295501878e-15\n",
      "pre_d_b: 2.886579864025407e-15\n",
      "d_w: -5.851168776864162\n",
      "d_b: -1.3183873178114822\n",
      "pre_d_w: 0.7440483164287723\n",
      "pre_d_b: -0.8334429810599686\n",
      "d_w: 623.9415122531635\n",
      "d_b: -0.22194927548150933\n",
      "pre_d_w: 728.8458689923491\n",
      "pre_d_b: 0.2898060236889839\n",
      " epoch: 10, train accuracy: 0.1907, train_loss_norm:2.1722, valid_acc: 0.1888, valid_loss_norm: 2.1781\n",
      "\n",
      "d_w: -1.3100631690576847e-14\n",
      "d_b: 8.881784197001252e-16\n",
      "pre_d_w: 6.439293542825908e-15\n",
      "pre_d_b: 6.661338147750939e-16\n",
      "d_w: -43.937049816010244\n",
      "d_b: -1.672617542289649\n",
      "pre_d_w: -5.851168776864162\n",
      "pre_d_b: -1.3183873178114822\n",
      "d_w: -5032.545983980071\n",
      "d_b: -0.5269782818957431\n",
      "pre_d_w: 623.9415122531635\n",
      "pre_d_b: -0.22194927548150933\n",
      " epoch: 11, train accuracy: 0.1895, train_loss_norm:2.1850, valid_acc: 0.1836, valid_loss_norm: 2.1824\n",
      "\n",
      "d_w: 1.9761969838327786e-14\n",
      "d_b: 1.2212453270876722e-15\n",
      "pre_d_w: -1.3100631690576847e-14\n",
      "pre_d_b: 8.881784197001252e-16\n",
      "d_w: 23.2939295682693\n",
      "d_b: 1.8361425100384403\n",
      "pre_d_w: -43.937049816010244\n",
      "pre_d_b: -1.672617542289649\n",
      "d_w: 2581.025584077894\n",
      "d_b: 1.0035769006368644\n",
      "pre_d_w: -5032.545983980071\n",
      "pre_d_b: -0.5269782818957431\n",
      " epoch: 12, train accuracy: 0.2290, train_loss_norm:2.1484, valid_acc: 0.2312, valid_loss_norm: 2.1453\n",
      "\n",
      "d_w: -1.0380585280245214e-14\n",
      "d_b: -2.220446049250313e-15\n",
      "pre_d_w: 1.9761969838327786e-14\n",
      "pre_d_b: 1.2212453270876722e-15\n",
      "d_w: -1.624989469856065\n",
      "d_b: 0.6919891834830003\n",
      "pre_d_w: 23.2939295682693\n",
      "pre_d_b: 1.8361425100384403\n",
      "d_w: 2462.6282576139192\n",
      "d_b: 0.8492434242511099\n",
      "pre_d_w: 2581.025584077894\n",
      "pre_d_b: 1.0035769006368644\n",
      " epoch: 13, train accuracy: 0.2333, train_loss_norm:2.1270, valid_acc: 0.2286, valid_loss_norm: 2.1283\n",
      "\n",
      "d_w: 4.440892098500626e-15\n",
      "d_b: 1.3322676295501878e-15\n",
      "pre_d_w: -1.0380585280245214e-14\n",
      "pre_d_b: -2.220446049250313e-15\n",
      "d_w: -5.899806535998349\n",
      "d_b: -0.5693908165334862\n",
      "pre_d_w: -1.624989469856065\n",
      "pre_d_b: 0.6919891834830003\n",
      "d_w: -556.9266031055596\n",
      "d_b: 0.3184498910747208\n",
      "pre_d_w: 2462.6282576139192\n",
      "pre_d_b: 0.8492434242511099\n",
      " epoch: 14, train accuracy: 0.2351, train_loss_norm:2.0859, valid_acc: 0.2306, valid_loss_norm: 2.0893\n",
      "\n",
      "d_w: -2.3314683517128287e-14\n",
      "d_b: 2.6645352591003757e-15\n",
      "pre_d_w: 4.440892098500626e-15\n",
      "pre_d_b: 1.3322676295501878e-15\n",
      "d_w: 0.7312467753371126\n",
      "d_b: -0.8283738847136723\n",
      "pre_d_w: -5.899806535998349\n",
      "pre_d_b: -0.5693908165334862\n",
      "d_w: -1047.0688139398667\n",
      "d_b: 0.2336392656843366\n",
      "pre_d_w: -556.9266031055596\n",
      "pre_d_b: 0.3184498910747208\n",
      " epoch: 15, train accuracy: 0.2553, train_loss_norm:2.0251, valid_acc: 0.2510, valid_loss_norm: 2.0312\n",
      "\n",
      "d_w: -1.9984014443252818e-15\n",
      "d_b: 1.3322676295501878e-15\n",
      "pre_d_w: -2.3314683517128287e-14\n",
      "pre_d_b: 2.6645352591003757e-15\n",
      "d_w: 3.9875593500827673\n",
      "d_b: -0.4516822724898507\n",
      "pre_d_w: 0.7312467753371126\n",
      "pre_d_b: -0.8283738847136723\n",
      "d_w: 1260.2602267976367\n",
      "d_b: 0.4398504324334386\n",
      "pre_d_w: -1047.0688139398667\n",
      "pre_d_b: 0.2336392656843366\n",
      " epoch: 16, train accuracy: 0.2647, train_loss_norm:1.9917, valid_acc: 0.2572, valid_loss_norm: 2.0015\n",
      "\n",
      "d_w: 4.440892098500626e-15\n",
      "d_b: -1.9984014443252818e-15\n",
      "pre_d_w: -1.9984014443252818e-15\n",
      "pre_d_b: 1.3322676295501878e-15\n",
      "d_w: -1.2008035688383243\n",
      "d_b: -0.7369940010466771\n",
      "pre_d_w: 3.9875593500827673\n",
      "pre_d_b: -0.4516822724898507\n",
      "d_w: 785.3512706742708\n",
      "d_b: 0.27265920046335346\n",
      "pre_d_w: 1260.2602267976367\n",
      "pre_d_b: 0.4398504324334386\n",
      " epoch: 17, train accuracy: 0.2516, train_loss_norm:2.0353, valid_acc: 0.2444, valid_loss_norm: 2.0478\n",
      "\n",
      "d_w: -2.886579864025407e-15\n",
      "d_b: 1.6653345369377348e-15\n",
      "pre_d_w: 4.440892098500626e-15\n",
      "pre_d_b: -1.9984014443252818e-15\n",
      "d_w: -5.927244969432425\n",
      "d_b: -1.3836419336538595\n",
      "pre_d_w: -1.2008035688383243\n",
      "pre_d_b: -0.7369940010466771\n",
      "d_w: -3527.4143278881893\n",
      "d_b: -0.22609488539029693\n",
      "pre_d_w: 785.3512706742708\n",
      "pre_d_b: 0.27265920046335346\n",
      " epoch: 18, train accuracy: 0.2785, train_loss_norm:1.9774, valid_acc: 0.2672, valid_loss_norm: 1.9884\n",
      "\n",
      "d_w: 1.7763568394002505e-15\n",
      "d_b: 2.220446049250313e-16\n",
      "pre_d_w: -2.886579864025407e-15\n",
      "pre_d_b: 1.6653345369377348e-15\n",
      "d_w: -6.5288946419963185\n",
      "d_b: -0.1494380890182525\n",
      "pre_d_w: -5.927244969432425\n",
      "pre_d_b: -1.3836419336538595\n",
      "d_w: 1238.7352702744427\n",
      "d_b: 0.18859114791525944\n",
      "pre_d_w: -3527.4143278881893\n",
      "pre_d_b: -0.22609488539029693\n",
      " epoch: 19, train accuracy: 0.2635, train_loss_norm:2.0218, valid_acc: 0.2526, valid_loss_norm: 2.0309\n",
      "\n",
      "d_w: -1.0880185641326534e-14\n",
      "d_b: 2.886579864025407e-15\n",
      "pre_d_w: 1.7763568394002505e-15\n",
      "pre_d_b: 2.220446049250313e-16\n",
      "d_w: -0.6810451236660184\n",
      "d_b: 0.11988643825571277\n",
      "pre_d_w: -6.5288946419963185\n",
      "pre_d_b: -0.1494380890182525\n",
      "d_w: 2228.518600600768\n",
      "d_b: 0.3564899989879392\n",
      "pre_d_w: 1238.7352702744427\n",
      "pre_d_b: 0.18859114791525944\n",
      " epoch: 20, train accuracy: 0.2607, train_loss_norm:2.0055, valid_acc: 0.2566, valid_loss_norm: 2.0221\n",
      "\n",
      "d_w: 8.992806499463768e-15\n",
      "d_b: -2.220446049250313e-16\n",
      "pre_d_w: -1.0880185641326534e-14\n",
      "pre_d_b: 2.886579864025407e-15\n",
      "d_w: 5.625680831147473\n",
      "d_b: -0.5120479178227493\n",
      "pre_d_w: -0.6810451236660184\n",
      "pre_d_b: 0.11988643825571277\n",
      "d_w: -1687.9357285491606\n",
      "d_b: 0.5007914680062165\n",
      "pre_d_w: 2228.518600600768\n",
      "pre_d_b: 0.3564899989879392\n",
      " epoch: 21, train accuracy: 0.2713, train_loss_norm:1.9943, valid_acc: 0.2698, valid_loss_norm: 2.0077\n",
      "\n",
      "d_w: 4.107825191113079e-15\n",
      "d_b: -2.220446049250313e-15\n",
      "pre_d_w: 8.992806499463768e-15\n",
      "pre_d_b: -2.220446049250313e-16\n",
      "d_w: -7.3376106086121125\n",
      "d_b: -0.8627540378908973\n",
      "pre_d_w: 5.625680831147473\n",
      "pre_d_b: -0.5120479178227493\n",
      "d_w: -435.5844147791477\n",
      "d_b: 0.04441729557392793\n",
      "pre_d_w: -1687.9357285491606\n",
      "pre_d_b: 0.5007914680062165\n",
      " epoch: 22, train accuracy: 0.2673, train_loss_norm:2.0122, valid_acc: 0.2614, valid_loss_norm: 2.0201\n",
      "\n",
      "d_w: 6.8833827526759706e-15\n",
      "d_b: -3.3306690738754696e-15\n",
      "pre_d_w: 4.107825191113079e-15\n",
      "pre_d_b: -2.220446049250313e-15\n",
      "d_w: -13.303173300507172\n",
      "d_b: -0.335857368670178\n",
      "pre_d_w: -7.3376106086121125\n",
      "pre_d_b: -0.8627540378908973\n",
      "d_w: 2277.071681942984\n",
      "d_b: 0.4276678332368925\n",
      "pre_d_w: -435.5844147791477\n",
      "pre_d_b: 0.04441729557392793\n",
      " epoch: 23, train accuracy: 0.2515, train_loss_norm:2.0722, valid_acc: 0.2464, valid_loss_norm: 2.0881\n",
      "\n",
      "d_w: -4.884981308350689e-15\n",
      "d_b: -8.881784197001252e-16\n",
      "pre_d_w: 6.8833827526759706e-15\n",
      "pre_d_b: -3.3306690738754696e-15\n",
      "d_w: -2.469069310177714\n",
      "d_b: 1.2575828029745868\n",
      "pre_d_w: -13.303173300507172\n",
      "pre_d_b: -0.335857368670178\n",
      "d_w: 2085.7803770887253\n",
      "d_b: 1.4539035248730827\n",
      "pre_d_w: 2277.071681942984\n",
      "pre_d_b: 0.4276678332368925\n",
      " epoch: 24, train accuracy: 0.2662, train_loss_norm:2.0083, valid_acc: 0.2618, valid_loss_norm: 2.0216\n",
      "\n",
      "d_w: -1.021405182655144e-14\n",
      "d_b: 0.0\n",
      "pre_d_w: -4.884981308350689e-15\n",
      "pre_d_b: -8.881784197001252e-16\n",
      "d_w: 6.257578640682347\n",
      "d_b: -0.3401273298879904\n",
      "pre_d_w: -2.469069310177714\n",
      "pre_d_b: 1.2575828029745868\n",
      "d_w: -1750.52813255524\n",
      "d_b: -0.08058443937217147\n",
      "pre_d_w: 2085.7803770887253\n",
      "pre_d_b: 1.4539035248730827\n",
      " epoch: 25, train accuracy: 0.2158, train_loss_norm:2.0696, valid_acc: 0.2138, valid_loss_norm: 2.0789\n",
      "\n",
      "d_w: 1.2212453270876722e-14\n",
      "d_b: 3.552713678800501e-15\n",
      "pre_d_w: -1.021405182655144e-14\n",
      "pre_d_b: 0.0\n",
      "d_w: -0.02464882831346049\n",
      "d_b: 0.18941216204665745\n",
      "pre_d_w: 6.257578640682347\n",
      "pre_d_b: -0.3401273298879904\n",
      "d_w: -1081.6789147223897\n",
      "d_b: -0.3508014141750958\n",
      "pre_d_w: -1750.52813255524\n",
      "pre_d_b: -0.08058443937217147\n",
      " epoch: 26, train accuracy: 0.2891, train_loss_norm:1.9669, valid_acc: 0.2810, valid_loss_norm: 1.9801\n",
      "\n",
      "d_w: -1.4432899320127035e-14\n",
      "d_b: 1.887379141862766e-15\n",
      "pre_d_w: 1.2212453270876722e-14\n",
      "pre_d_b: 3.552713678800501e-15\n",
      "d_w: -19.108638658722416\n",
      "d_b: -0.04405381885959503\n",
      "pre_d_w: -0.02464882831346049\n",
      "pre_d_b: 0.18941216204665745\n",
      "d_w: 896.0689465975472\n",
      "d_b: 0.030025332594020515\n",
      "pre_d_w: -1081.6789147223897\n",
      "pre_d_b: -0.3508014141750958\n",
      " epoch: 27, train accuracy: 0.2700, train_loss_norm:1.9981, valid_acc: 0.2626, valid_loss_norm: 2.0185\n",
      "\n",
      "d_w: -5.5067062021407764e-14\n",
      "d_b: 0.0\n",
      "pre_d_w: -1.4432899320127035e-14\n",
      "pre_d_b: 1.887379141862766e-15\n",
      "d_w: 5.393015771856293\n",
      "d_b: -0.009067778649363228\n",
      "pre_d_w: -19.108638658722416\n",
      "pre_d_b: -0.04405381885959503\n",
      "d_w: -260.17501602167084\n",
      "d_b: 0.03237705049436854\n",
      "pre_d_w: 896.0689465975472\n",
      "pre_d_b: 0.030025332594020515\n",
      " epoch: 28, train accuracy: 0.2924, train_loss_norm:1.9528, valid_acc: 0.2936, valid_loss_norm: 1.9695\n",
      "\n",
      "d_w: 1.176836406102666e-14\n",
      "d_b: 8.881784197001252e-16\n",
      "pre_d_w: -5.5067062021407764e-14\n",
      "pre_d_b: 0.0\n",
      "d_w: 4.818023259249702\n",
      "d_b: -0.03459698584909088\n",
      "pre_d_w: 5.393015771856293\n",
      "pre_d_b: -0.009067778649363228\n",
      "d_w: -927.1911700889347\n",
      "d_b: -0.01383153961673788\n",
      "pre_d_w: -260.17501602167084\n",
      "pre_d_b: 0.03237705049436854\n",
      " epoch: 29, train accuracy: 0.2811, train_loss_norm:1.9695, valid_acc: 0.2804, valid_loss_norm: 1.9821\n",
      "\n",
      "d_w: -9.992007221626409e-15\n",
      "d_b: 0.0\n",
      "pre_d_w: 1.176836406102666e-14\n",
      "pre_d_b: 8.881784197001252e-16\n",
      "d_w: -18.506965477725238\n",
      "d_b: 0.12767198516618694\n",
      "pre_d_w: 4.818023259249702\n",
      "pre_d_b: -0.03459698584909088\n",
      "d_w: 1008.9266644523203\n",
      "d_b: 0.1413036835189329\n",
      "pre_d_w: -927.1911700889347\n",
      "pre_d_b: -0.01383153961673788\n",
      " epoch: 30, train accuracy: 0.3184, train_loss_norm:1.9265, valid_acc: 0.3018, valid_loss_norm: 1.9430\n",
      "\n",
      "d_w: -8.881784197001252e-16\n",
      "d_b: 1.3322676295501878e-15\n",
      "pre_d_w: -9.992007221626409e-15\n",
      "pre_d_b: 0.0\n",
      "d_w: -11.34130271201733\n",
      "d_b: 0.04080816437679635\n",
      "pre_d_w: -18.506965477725238\n",
      "pre_d_b: 0.12767198516618694\n",
      "d_w: 1324.4284671861224\n",
      "d_b: 0.2598938329854431\n",
      "pre_d_w: 1008.9266644523203\n",
      "pre_d_b: 0.1413036835189329\n",
      " epoch: 31, train accuracy: 0.2759, train_loss_norm:1.9771, valid_acc: 0.2728, valid_loss_norm: 2.0003\n",
      "\n",
      "d_w: -1.3766765505351941e-14\n",
      "d_b: -1.7763568394002505e-15\n",
      "pre_d_w: -8.881784197001252e-16\n",
      "pre_d_b: 1.3322676295501878e-15\n",
      "d_w: 10.082924656867556\n",
      "d_b: -0.41768121112024803\n",
      "pre_d_w: -11.34130271201733\n",
      "pre_d_b: 0.04080816437679635\n",
      "d_w: -994.4390983770472\n",
      "d_b: 0.21021102677976516\n",
      "pre_d_w: 1324.4284671861224\n",
      "pre_d_b: 0.2598938329854431\n",
      " epoch: 32, train accuracy: 0.3192, train_loss_norm:1.9060, valid_acc: 0.3100, valid_loss_norm: 1.9270\n",
      "\n",
      "d_w: -9.769962616701378e-15\n",
      "d_b: -1.4432899320127035e-15\n",
      "pre_d_w: -1.3766765505351941e-14\n",
      "pre_d_b: -1.7763568394002505e-15\n",
      "d_w: 0.4409498679895023\n",
      "d_b: 1.1119225044438807\n",
      "pre_d_w: 10.082924656867556\n",
      "pre_d_b: -0.41768121112024803\n",
      "d_w: -1353.6192285762268\n",
      "d_b: 0.2511298575095836\n",
      "pre_d_w: -994.4390983770472\n",
      "pre_d_b: 0.21021102677976516\n",
      " epoch: 33, train accuracy: 0.2792, train_loss_norm:1.9738, valid_acc: 0.2744, valid_loss_norm: 1.9874\n",
      "\n",
      "d_w: 4.6629367034256575e-15\n",
      "d_b: 2.220446049250313e-16\n",
      "pre_d_w: -9.769962616701378e-15\n",
      "pre_d_b: -1.4432899320127035e-15\n",
      "d_w: -27.912390923970882\n",
      "d_b: 1.094536627668594\n",
      "pre_d_w: 0.4409498679895023\n",
      "pre_d_b: 1.1119225044438807\n",
      "d_w: -545.7259816224938\n",
      "d_b: 0.532696591215617\n",
      "pre_d_w: -1353.6192285762268\n",
      "pre_d_b: 0.2511298575095836\n",
      " epoch: 34, train accuracy: 0.3055, train_loss_norm:1.9189, valid_acc: 0.3042, valid_loss_norm: 1.9387\n",
      "\n",
      "d_w: -2.220446049250313e-15\n",
      "d_b: 8.881784197001252e-16\n",
      "pre_d_w: 4.6629367034256575e-15\n",
      "pre_d_b: 2.220446049250313e-16\n",
      "d_w: 21.669962803878725\n",
      "d_b: -0.7656777417417548\n",
      "pre_d_w: -27.912390923970882\n",
      "pre_d_b: 1.094536627668594\n",
      "d_w: 1458.4029152129738\n",
      "d_b: -0.49901243242379\n",
      "pre_d_w: -545.7259816224938\n",
      "pre_d_b: 0.532696591215617\n",
      " epoch: 35, train accuracy: 0.2732, train_loss_norm:1.9802, valid_acc: 0.2698, valid_loss_norm: 2.0047\n",
      "\n",
      "d_w: -3.1086244689504383e-15\n",
      "d_b: 5.273559366969494e-16\n",
      "pre_d_w: -2.220446049250313e-15\n",
      "pre_d_b: 8.881784197001252e-16\n",
      "d_w: 12.613697111400512\n",
      "d_b: -0.004236427831899481\n",
      "pre_d_w: 21.669962803878725\n",
      "pre_d_b: -0.7656777417417548\n",
      "d_w: 351.8470924035962\n",
      "d_b: -0.15049175755459016\n",
      "pre_d_w: 1458.4029152129738\n",
      "pre_d_b: -0.49901243242379\n",
      " epoch: 36, train accuracy: 0.2829, train_loss_norm:1.9232, valid_acc: 0.2676, valid_loss_norm: 1.9475\n",
      "\n",
      "d_w: 1.2878587085651816e-14\n",
      "d_b: -3.3306690738754696e-15\n",
      "pre_d_w: -3.1086244689504383e-15\n",
      "pre_d_b: 5.273559366969494e-16\n",
      "d_w: -15.860496435768503\n",
      "d_b: 3.1337673173207956\n",
      "pre_d_w: 12.613697111400512\n",
      "pre_d_b: -0.004236427831899481\n",
      "d_w: -1288.381331767529\n",
      "d_b: 0.5479175198341673\n",
      "pre_d_w: 351.8470924035962\n",
      "pre_d_b: -0.15049175755459016\n",
      " epoch: 37, train accuracy: 0.3013, train_loss_norm:1.9490, valid_acc: 0.2924, valid_loss_norm: 1.9670\n",
      "\n",
      "d_w: 1.0658141036401503e-14\n",
      "d_b: -2.6645352591003757e-15\n",
      "pre_d_w: 1.2878587085651816e-14\n",
      "pre_d_b: -3.3306690738754696e-15\n",
      "d_w: -26.8237093096759\n",
      "d_b: -0.28730548707829173\n",
      "pre_d_w: -15.860496435768503\n",
      "pre_d_b: 3.1337673173207956\n",
      "d_w: 1661.7263076404292\n",
      "d_b: 0.48525034301621667\n",
      "pre_d_w: -1288.381331767529\n",
      "pre_d_b: 0.5479175198341673\n",
      " epoch: 38, train accuracy: 0.2949, train_loss_norm:1.9342, valid_acc: 0.2908, valid_loss_norm: 1.9579\n",
      "\n",
      "d_w: 2.220446049250313e-16\n",
      "d_b: 1.3322676295501878e-15\n",
      "pre_d_w: 1.0658141036401503e-14\n",
      "pre_d_b: -2.6645352591003757e-15\n",
      "d_w: 25.154617665956714\n",
      "d_b: -2.4301520343955003\n",
      "pre_d_w: -26.8237093096759\n",
      "pre_d_b: -0.28730548707829173\n",
      "d_w: 1480.5107661678123\n",
      "d_b: -0.7004531295012981\n",
      "pre_d_w: 1661.7263076404292\n",
      "pre_d_b: 0.48525034301621667\n",
      " epoch: 39, train accuracy: 0.3022, train_loss_norm:1.9372, valid_acc: 0.2964, valid_loss_norm: 1.9639\n",
      "\n",
      "d_w: -1.3322676295501878e-15\n",
      "d_b: -1.3322676295501878e-15\n",
      "pre_d_w: 2.220446049250313e-16\n",
      "pre_d_b: 1.3322676295501878e-15\n",
      "d_w: 5.828060072009528\n",
      "d_b: 1.4118216126016685\n",
      "pre_d_w: 25.154617665956714\n",
      "pre_d_b: -2.4301520343955003\n",
      "d_w: -858.4954605108348\n",
      "d_b: 0.2328621738256308\n",
      "pre_d_w: 1480.5107661678123\n",
      "pre_d_b: -0.7004531295012981\n",
      " epoch: 40, train accuracy: 0.2692, train_loss_norm:1.9359, valid_acc: 0.2544, valid_loss_norm: 1.9615\n",
      "\n",
      "d_w: -8.992806499463768e-15\n",
      "d_b: 4.440892098500626e-16\n",
      "pre_d_w: -1.3322676295501878e-15\n",
      "pre_d_b: -1.3322676295501878e-15\n",
      "d_w: -4.144075656495602\n",
      "d_b: 4.174290865349835\n",
      "pre_d_w: 5.828060072009528\n",
      "pre_d_b: 1.4118216126016685\n",
      "d_w: -1280.0529466479181\n",
      "d_b: 0.9100164447101053\n",
      "pre_d_w: -858.4954605108348\n",
      "pre_d_b: 0.2328621738256308\n",
      " epoch: 41, train accuracy: 0.3200, train_loss_norm:1.9126, valid_acc: 0.3096, valid_loss_norm: 1.9383\n",
      "\n",
      "d_w: 3.552713678800501e-15\n",
      "d_b: 3.219646771412954e-15\n",
      "pre_d_w: -8.992806499463768e-15\n",
      "pre_d_b: 4.440892098500626e-16\n",
      "d_w: -21.344395728243114\n",
      "d_b: -0.9327929124738363\n",
      "pre_d_w: -4.144075656495602\n",
      "pre_d_b: 4.174290865349835\n",
      "d_w: 1655.6188170195144\n",
      "d_b: 0.43201233223562746\n",
      "pre_d_w: -1280.0529466479181\n",
      "pre_d_b: 0.9100164447101053\n",
      " epoch: 42, train accuracy: 0.2979, train_loss_norm:1.9224, valid_acc: 0.2892, valid_loss_norm: 1.9494\n",
      "\n",
      "d_w: -2.6645352591003757e-15\n",
      "d_b: 0.0\n",
      "pre_d_w: 3.552713678800501e-15\n",
      "pre_d_b: 3.219646771412954e-15\n",
      "d_w: 12.943125116458006\n",
      "d_b: -3.3850009006513333\n",
      "pre_d_w: -21.344395728243114\n",
      "pre_d_b: -0.9327929124738363\n",
      "d_w: -31.508718832630926\n",
      "d_b: -0.4217039674048171\n",
      "pre_d_w: 1655.6188170195144\n",
      "pre_d_b: 0.43201233223562746\n",
      " epoch: 43, train accuracy: 0.3193, train_loss_norm:1.8982, valid_acc: 0.3092, valid_loss_norm: 1.9262\n",
      "\n",
      "d_w: -1.0658141036401503e-14\n",
      "d_b: -2.220446049250313e-16\n",
      "pre_d_w: -2.6645352591003757e-15\n",
      "pre_d_b: 0.0\n",
      "d_w: 6.887199402745754\n",
      "d_b: 0.8086375649578293\n",
      "pre_d_w: 12.943125116458006\n",
      "pre_d_b: -3.3850009006513333\n",
      "d_w: -2825.3514300331176\n",
      "d_b: 0.23774560114905283\n",
      "pre_d_w: -31.508718832630926\n",
      "pre_d_b: -0.4217039674048171\n",
      " epoch: 44, train accuracy: 0.3055, train_loss_norm:1.9046, valid_acc: 0.2944, valid_loss_norm: 1.9315\n",
      "\n",
      "d_w: 5.551115123125783e-16\n",
      "d_b: -5.315192730392937e-15\n",
      "pre_d_w: -1.0658141036401503e-14\n",
      "pre_d_b: -2.220446049250313e-16\n",
      "d_w: -27.290555889405898\n",
      "d_b: 4.090935952128791\n",
      "pre_d_w: 6.887199402745754\n",
      "pre_d_b: 0.8086375649578293\n",
      "d_w: 207.57171360790122\n",
      "d_b: 1.0725888793457632\n",
      "pre_d_w: -2825.3514300331176\n",
      "pre_d_b: 0.23774560114905283\n",
      " epoch: 45, train accuracy: 0.3369, train_loss_norm:1.8797, valid_acc: 0.3196, valid_loss_norm: 1.9094\n",
      "\n",
      "d_w: 8.881784197001252e-16\n",
      "d_b: 2.9976021664879227e-15\n",
      "pre_d_w: 5.551115123125783e-16\n",
      "pre_d_b: -5.315192730392937e-15\n",
      "d_w: -14.987567336525345\n",
      "d_b: 0.2913847284473323\n",
      "pre_d_w: -27.290555889405898\n",
      "pre_d_b: 4.090935952128791\n",
      "d_w: 1175.7352264998135\n",
      "d_b: 0.6061949161927542\n",
      "pre_d_w: 207.57171360790122\n",
      "pre_d_b: 1.0725888793457632\n",
      " epoch: 46, train accuracy: 0.3119, train_loss_norm:1.8931, valid_acc: 0.3004, valid_loss_norm: 1.9241\n",
      "\n",
      "d_w: -5.329070518200751e-15\n",
      "d_b: 4.440892098500626e-16\n",
      "pre_d_w: 8.881784197001252e-16\n",
      "pre_d_b: 2.9976021664879227e-15\n",
      "d_w: 12.961790166012662\n",
      "d_b: -2.621510465337636\n",
      "pre_d_w: -14.987567336525345\n",
      "pre_d_b: 0.2913847284473323\n",
      "d_w: -522.0810137616397\n",
      "d_b: -0.13212495307570352\n",
      "pre_d_w: 1175.7352264998135\n",
      "pre_d_b: 0.6061949161927542\n",
      " epoch: 47, train accuracy: 0.3351, train_loss_norm:1.8666, valid_acc: 0.3230, valid_loss_norm: 1.8957\n",
      "\n",
      "d_w: -7.327471962526033e-15\n",
      "d_b: 6.661338147750939e-16\n",
      "pre_d_w: -5.329070518200751e-15\n",
      "pre_d_b: 4.440892098500626e-16\n",
      "d_w: -2.936454253761976\n",
      "d_b: 1.1752297379429175\n",
      "pre_d_w: 12.961790166012662\n",
      "pre_d_b: -2.621510465337636\n",
      "d_w: -1584.9175592427055\n",
      "d_b: 0.33134799003080895\n",
      "pre_d_w: -522.0810137616397\n",
      "pre_d_b: -0.13212495307570352\n",
      " epoch: 48, train accuracy: 0.3234, train_loss_norm:1.8799, valid_acc: 0.3130, valid_loss_norm: 1.9092\n",
      "\n",
      "d_w: 1.9984014443252818e-15\n",
      "d_b: -3.219646771412954e-15\n",
      "pre_d_w: -7.327471962526033e-15\n",
      "pre_d_b: 6.661338147750939e-16\n",
      "d_w: -30.67649458455661\n",
      "d_b: 3.8894465686439537\n",
      "pre_d_w: -2.936454253761976\n",
      "pre_d_b: 1.1752297379429175\n",
      "d_w: 1130.3352464108407\n",
      "d_b: 1.1632567416186024\n",
      "pre_d_w: -1584.9175592427055\n",
      "pre_d_b: 0.33134799003080895\n",
      " epoch: 49, train accuracy: 0.3342, train_loss_norm:1.8705, valid_acc: 0.3136, valid_loss_norm: 1.9064\n",
      "\n",
      "d_w: -4.884981308350689e-15\n",
      "d_b: -1.4432899320127035e-15\n",
      "pre_d_w: 1.9984014443252818e-15\n",
      "pre_d_b: -3.219646771412954e-15\n",
      "d_w: -5.4354964548213225\n",
      "d_b: -0.30679674841616544\n",
      "pre_d_w: -30.67649458455661\n",
      "pre_d_b: 3.8894465686439537\n",
      "d_w: 1413.482466386378\n",
      "d_b: 0.43800305385232785\n",
      "pre_d_w: 1130.3352464108407\n",
      "pre_d_b: 1.1632567416186024\n",
      " epoch: 50, train accuracy: 0.3291, train_loss_norm:1.8707, valid_acc: 0.3142, valid_loss_norm: 1.9050\n",
      "\n",
      "d_w: -1.4210854715202004e-14\n",
      "d_b: -2.220446049250313e-15\n",
      "pre_d_w: -4.884981308350689e-15\n",
      "pre_d_b: -1.4432899320127035e-15\n",
      "d_w: 11.840846091664664\n",
      "d_b: -0.9062439921387535\n",
      "pre_d_w: -5.4354964548213225\n",
      "pre_d_b: -0.30679674841616544\n",
      "d_w: -1554.8579461422014\n",
      "d_b: 0.09033050784116123\n",
      "pre_d_w: 1413.482466386378\n",
      "pre_d_b: 0.43800305385232785\n",
      " epoch: 51, train accuracy: 0.3295, train_loss_norm:1.8682, valid_acc: 0.3122, valid_loss_norm: 1.9015\n",
      "\n",
      "d_w: -1.6708856520608606e-14\n",
      "d_b: -2.220446049250313e-16\n",
      "pre_d_w: -1.4210854715202004e-14\n",
      "pre_d_b: -2.220446049250313e-15\n",
      "d_w: -14.485456373966036\n",
      "d_b: 2.988544173541208\n",
      "pre_d_w: 11.840846091664664\n",
      "pre_d_b: -0.9062439921387535\n",
      "d_w: -1809.496515748124\n",
      "d_b: 0.5986132371487134\n",
      "pre_d_w: -1554.8579461422014\n",
      "pre_d_b: 0.09033050784116123\n",
      " epoch: 52, train accuracy: 0.3313, train_loss_norm:1.8711, valid_acc: 0.3180, valid_loss_norm: 1.9068\n",
      "\n",
      "d_w: -7.993605777301127e-15\n",
      "d_b: -2.6645352591003757e-15\n",
      "pre_d_w: -1.6708856520608606e-14\n",
      "pre_d_b: -2.220446049250313e-16\n",
      "d_w: -16.048537057767405\n",
      "d_b: 1.9894869032302824\n",
      "pre_d_w: -14.485456373966036\n",
      "pre_d_b: 2.988544173541208\n",
      "d_w: 1990.3409247933175\n",
      "d_b: 0.06043949449081362\n",
      "pre_d_w: -1809.496515748124\n",
      "pre_d_b: 0.5986132371487134\n",
      " epoch: 53, train accuracy: 0.3260, train_loss_norm:1.8664, valid_acc: 0.3076, valid_loss_norm: 1.9040\n",
      "\n",
      "d_w: -1.0880185641326534e-14\n",
      "d_b: -5.551115123125783e-15\n",
      "pre_d_w: -7.993605777301127e-15\n",
      "pre_d_b: -2.6645352591003757e-15\n",
      "d_w: 8.982655976576817\n",
      "d_b: -2.167399146387496\n",
      "pre_d_w: -16.048537057767405\n",
      "pre_d_b: 1.9894869032302824\n",
      "d_w: 1311.3190082805525\n",
      "d_b: -0.5019960338880323\n",
      "pre_d_w: 1990.3409247933175\n",
      "pre_d_b: 0.06043949449081362\n",
      " epoch: 54, train accuracy: 0.3253, train_loss_norm:1.8702, valid_acc: 0.3138, valid_loss_norm: 1.9072\n",
      "\n",
      "d_w: -2.1316282072803006e-14\n",
      "d_b: 0.0\n",
      "pre_d_w: -1.0880185641326534e-14\n",
      "pre_d_b: -5.551115123125783e-15\n",
      "d_w: 1.4199562253044125\n",
      "d_b: 1.012992872349534\n",
      "pre_d_w: 8.982655976576817\n",
      "pre_d_b: -2.167399146387496\n",
      "d_w: -844.3246454068026\n",
      "d_b: 0.6124086136354141\n",
      "pre_d_w: 1311.3190082805525\n",
      "pre_d_b: -0.5019960338880323\n",
      " epoch: 55, train accuracy: 0.3246, train_loss_norm:1.8621, valid_acc: 0.3014, valid_loss_norm: 1.9001\n",
      "\n",
      "d_w: -8.326672684688674e-16\n",
      "d_b: -3.608224830031759e-15\n",
      "pre_d_w: -2.1316282072803006e-14\n",
      "pre_d_b: 0.0\n",
      "d_w: -22.692628684376654\n",
      "d_b: 4.086519419293381\n",
      "pre_d_w: 1.4199562253044125\n",
      "pre_d_b: 1.012992872349534\n",
      "d_w: -313.10108805659775\n",
      "d_b: 1.0689622751641006\n",
      "pre_d_w: -844.3246454068026\n",
      "pre_d_b: 0.6124086136354141\n",
      " epoch: 56, train accuracy: 0.3364, train_loss_norm:1.8648, valid_acc: 0.3196, valid_loss_norm: 1.9038\n",
      "\n",
      "d_w: 8.881784197001252e-16\n",
      "d_b: -3.9968028886505635e-15\n",
      "pre_d_w: -8.326672684688674e-16\n",
      "pre_d_b: -3.608224830031759e-15\n",
      "d_w: -5.74797068397287\n",
      "d_b: -0.07168222552365733\n",
      "pre_d_w: -22.692628684376654\n",
      "pre_d_b: 4.086519419293381\n",
      "d_w: 941.7154420412035\n",
      "d_b: -0.5591321759049568\n",
      "pre_d_w: -313.10108805659775\n",
      "pre_d_b: 1.0689622751641006\n",
      " epoch: 57, train accuracy: 0.3385, train_loss_norm:1.8472, valid_acc: 0.3208, valid_loss_norm: 1.8849\n",
      "\n",
      "d_w: 6.439293542825908e-15\n",
      "d_b: 2.1094237467877974e-15\n",
      "pre_d_w: 8.881784197001252e-16\n",
      "pre_d_b: -3.9968028886505635e-15\n",
      "d_w: 16.518015828324874\n",
      "d_b: -3.921116956647948\n",
      "pre_d_w: -5.74797068397287\n",
      "pre_d_b: -0.07168222552365733\n",
      "d_w: 484.4076654730002\n",
      "d_b: -0.7494901178585364\n",
      "pre_d_w: 941.7154420412035\n",
      "pre_d_b: -0.5591321759049568\n",
      " epoch: 58, train accuracy: 0.3327, train_loss_norm:1.8608, valid_acc: 0.3210, valid_loss_norm: 1.8978\n",
      "\n",
      "d_w: -1.887379141862766e-14\n",
      "d_b: -3.552713678800501e-15\n",
      "pre_d_w: 6.439293542825908e-15\n",
      "pre_d_b: 2.1094237467877974e-15\n",
      "d_w: 2.8470793338509175\n",
      "d_b: 0.6012116638672813\n",
      "pre_d_w: 16.518015828324874\n",
      "pre_d_b: -3.921116956647948\n",
      "d_w: -1665.2473681747751\n",
      "d_b: 0.8384532921878682\n",
      "pre_d_w: 484.4076654730002\n",
      "pre_d_b: -0.7494901178585364\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Train your model here.\n",
    "Implement batch SGD to train the model.\n",
    "Implement Early Stopping.\n",
    "Use config to set parameters for training like learning rate, momentum, etc.\n",
    "\"\"\"\n",
    "def train_e(model, x_train, y_train, x_valid, y_valid, config, patience=5):\n",
    "    epochs = config_c['epochs']\n",
    "    batch_size = config['batch_size']\n",
    "    momentum =    config['momentum']\n",
    "    momentum_gamma = config['momentum_gamma']\n",
    "    L2_penalty = config['momentum_gamma']\n",
    "    patience = config['early_stop_epoch']\n",
    "\n",
    "    train_loss_record = []\n",
    "    train_accuracy_record = []\n",
    "    holdout_loss_record = []\n",
    "    holdout_accuracy_record = []\n",
    "\n",
    "    # How many times the validation loss has gone up in a row.\n",
    "    cur_loss_up_sequence = 0\n",
    "\n",
    "    print(\"num_mini-batches\", len(x_train) / batch_size)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        #model.zero_grad()\n",
    "        batch_loss = []\n",
    "        batch_accuracy = []\n",
    "        for x, y in generate_minibatches(x_train, y_train, batch_size):\n",
    "\n",
    "            # print(\"x:\", x.shape)\n",
    "            # print(\"y:\", y.shape)\n",
    "            # Forward Pass\n",
    "            train_y, loss = model.forward(x, y)\n",
    "            batch_loss.append(loss) \n",
    "            # Backward Pass\n",
    "            model.backward()\n",
    "\n",
    "            batch_accuracy.append(model.accuracy(x,y))\n",
    "\n",
    "        model.updateweight() # update weight for each layer.\n",
    "\n",
    "        model.zero_grad()\n",
    "\n",
    "        y_hat, loss = model.forward(x_train, y_train)\n",
    "        acc = model.accuracy(x_train, y_train)\n",
    "        \n",
    "        # train_loss = np.mean(np.array(batch_loss))\n",
    "        # train_accuracy = np.mean(np.array(batch_accuracy))\n",
    "\n",
    "        train_loss = np.mean(np.array(loss))\n",
    "        train_accuracy = np.mean(np.array(acc))\n",
    "        \n",
    "        holdout_loss = model.forward(x_valid, y_valid)[1]\n",
    "        holdout_accuracy = model.accuracy(x_valid, y_valid)\n",
    "\n",
    "        train_loss_record.append(train_loss)\n",
    "        train_accuracy_record.append(train_accuracy)\n",
    "\n",
    "        holdout_loss_record.append(holdout_loss)\n",
    "        holdout_accuracy_record.append(holdout_accuracy)\n",
    "\n",
    "        print(f' epoch: {epoch + 1}, train accuracy: {train_accuracy:.4f}, train_loss_norm:{train_loss:.4f}, '\\\n",
    "            f'valid_acc: {holdout_accuracy:.4f}, valid_loss_norm: {holdout_loss:.4f}')   \n",
    "        print()\n",
    "\n",
    "        # Save the best weights according to test set.\n",
    "        if holdout_loss > max(holdout_loss_record):\n",
    "            cur_loss_up_sequence += 1\n",
    "\n",
    "            if cur_loss_up_sequence >= patience:\n",
    "                model.save_load_weight(save=False)\n",
    "                print(\"earlystop\")\n",
    "                break\n",
    "        else:\n",
    "            cur_loss_up_sequence = 0\n",
    "            # Save the best weights.\n",
    "            model.save_load_weight(save=True)\n",
    "    \n",
    "    return train_loss_record, train_accuracy_record, holdout_loss_record, holdout_accuracy_record\n",
    "\n",
    "model_c  = Neuralnetwork(config_c)\n",
    "\n",
    "# Load the data\n",
    "x_train, y_train, stats = load_data(path=\"./data\",stats = None, mode=\"train\")\n",
    "x_test, y_test = load_data(path=\"./data\",stats = stats, mode=\"test\")\n",
    "\n",
    "x_train, y_train, x_valid, y_valid = split_data(x_train,y_train)\n",
    "\n",
    "train_loss_record, train_accuracy_record, holdout_loss_record, holdout_accuracy_record = train_e(model_c,x_train,y_train,x_valid,y_valid,config_c)\n",
    "\n",
    "# Recall parameters with minimum validation loss\n",
    "model_c.save_load_weight(save=False)\n",
    "test_accuracy = test(model_c, x_test, y_test) \n",
    "print(test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(1)\n",
    "plt.plot(np.arange(config_c['epochs']), train_loss_record, label='train')\n",
    "plt.plot(np.arange(config_c['epochs']), holdout_loss_record, label='valid')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and validation loss vs epochs')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure(2)\n",
    "plt.plot(np.arange(config_c['epochs']), train_accuracy_record, label='train')\n",
    "plt.plot(np.arange(config_c['epochs']), holdout_accuracy_record, label='valid')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and validation accuracy vs epochs')\n",
    "plt.legend()\n",
    "plt.savefig(\"plots/PA2_c_2.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "005f4ed24810181fa8b2266ec303702d6575bedfaa41c7848d327e7f780b3129"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
