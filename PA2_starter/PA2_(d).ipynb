{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification (d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from neuralnet_update_PC import *\n",
    "# from neuralnet_works_FC import *\n",
    "from neuralnet import *\n",
    "from random import shuffle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "config_d = {}\n",
    "config_d['layer_specs'] = [3072, 64, 64, 10]\n",
    "config_d['activation'] = 'tanh'\n",
    "config_d['learning_rate'] = 0.005\n",
    "config_d['batch_size'] = 128\n",
    "config_d['epochs'] = 110   # need to 10% more from configc\n",
    "config_d['early_stop'] = True \n",
    "config_d['early_stop_epoch'] = 10\n",
    "config_d['L2_penalty'] = 0  \n",
    "config_d['momentum'] = True  \n",
    "config_d['momentum_gamma'] = 0.9  \n",
    "# Create the model\n",
    "\n",
    "#TODO\n",
    "#momentum, early stop , expect accuracy around 37%\n",
    "\n",
    "\"\"\"\n",
    "Train your model here.\n",
    "Implement batch SGD to train the model.\n",
    "Implement Early Stopping.\n",
    "Use config to set parameters for training like learning rate, momentum, etc.\n",
    "\"\"\"\n",
    "def train_e(model, x_train, y_train, x_valid, y_valid, config):\n",
    "    epochs = config['epochs']\n",
    "    batch_size = config['batch_size']\n",
    "    momentum =    config['momentum']\n",
    "    momentum_gamma = config['momentum_gamma']\n",
    "    L2_penalty = config['momentum_gamma']\n",
    "    patience = config['early_stop_epoch']\n",
    "\n",
    "    train_loss_record = []\n",
    "    train_accuracy_record = []\n",
    "    holdout_loss_record = []\n",
    "    holdout_accuracy_record = []\n",
    "    \n",
    "    min_val_Loss = float('inf')\n",
    "    epoch_stop = 0\n",
    "\n",
    "    # How many times the validation loss has gone up in a row.\n",
    "    cur_loss_up_sequence = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        epoch_stop = epoch\n",
    "        batch_loss = []\n",
    "        batch_accuracy = []\n",
    "        for x, y in generate_minibatches(x_train, y_train, batch_size):\n",
    "            # Forward Pass\n",
    "            train_y, loss = model.forward(x, y)\n",
    "            batch_loss.append(loss) \n",
    "            # Backward Pass\n",
    "            model.backward()\n",
    "            model.updateweight() # update weight for each layer.\n",
    "            batch_accuracy.append(model.accuracy(x,y))\n",
    "\n",
    "\n",
    "        train_loss = np.mean(np.array(batch_loss))\n",
    "        train_accuracy = np.mean(np.array(batch_accuracy))\n",
    "        \n",
    "        #model.updateweight() # update weight for each layer.\n",
    "        #y_hat, loss = model.forward(x_train, y_train)\n",
    "        #acc = model.accuracy(x_train, y_train)\n",
    "        \n",
    "        #train_loss = np.mean(np.array(loss))\n",
    "        #train_accuracy = np.mean(np.array(acc))\n",
    "        \n",
    "        holdout_loss = model.forward(x_valid, y_valid)[1]\n",
    "        holdout_accuracy = model.accuracy(x_valid, y_valid)\n",
    "\n",
    "        train_loss_record.append(train_loss)\n",
    "        train_accuracy_record.append(train_accuracy)\n",
    "\n",
    "        holdout_loss_record.append(holdout_loss)\n",
    "        holdout_accuracy_record.append(holdout_accuracy)\n",
    "\n",
    "        print(f' epoch: {epoch + 1}, train accuracy: {train_accuracy:.4f}, train_loss_norm:{train_loss:.4f}, '\\\n",
    "            f'valid_acc: {holdout_accuracy:.4f}, valid_loss_norm: {holdout_loss:.4f}')   \n",
    "                \n",
    "        \n",
    "        # Save the best weights according to test set.\n",
    "        if holdout_loss > min_val_Loss:\n",
    "            cur_loss_up_sequence += 1\n",
    "            print(\"patience cnt\",cur_loss_up_sequence)\n",
    "\n",
    "            if cur_loss_up_sequence >= patience:\n",
    "                print(\"earlystop\")\n",
    "                break\n",
    "        else:\n",
    "            min_val_Loss = holdout_loss\n",
    "            cur_loss_up_sequence = 0\n",
    "            # Save the best weights.\n",
    "            model.save_load_weight(save=True)\n",
    "    \n",
    "    return epoch_stop, train_loss_record, train_accuracy_record, holdout_loss_record, holdout_accuracy_record\n",
    "\n",
    "L2 = [1e-2, 1e-3, 1e-4]\n",
    "\n",
    "\n",
    "# Load the data\n",
    "x_train, y_train, stats = load_data(path=\"./data\",stats = None, mode=\"train\")\n",
    "x_test, y_test = load_data(path=\"./data\",stats = stats, mode=\"test\")\n",
    "\n",
    "x_train, y_train, x_valid, y_valid = split_data(x_train,y_train)\n",
    "# model add\n",
    "\n",
    "epoch_all = []\n",
    "train_loss_record_all = []\n",
    "holdout_loss_record_all = []\n",
    "train_accuracy_record_all = []\n",
    "holdout_accuracy_record_all = []\n",
    "test_accuracy_all = []\n",
    "    \n",
    "for var in L2:\n",
    "    config_d['L2_penalty'] = var\n",
    "    model_d  = Neuralnetwork(config_d)\n",
    "    epoch, train_loss_record, train_accuracy_record, holdout_loss_record, holdout_accuracy_record = train_e(model_d,x_train,y_train,x_valid,y_valid,config_d)\n",
    "    \n",
    "    epoch_all.append(epoch)\n",
    "    train_loss_record_all.append(train_loss_record)\n",
    "    holdout_loss_record_all.append(holdout_loss_record)\n",
    "    train_accuracy_record_all.append(train_accuracy_record)\n",
    "    holdout_accuracy_record_all.append(holdout_accuracy_record)    \n",
    "    model_d.save_load_weight(save=False) # load data\n",
    "    test_accuracy = test(model_d, x_test, y_test) \n",
    "    test_accuracy_all.append(test_accuracy)                          \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "inp: (50000, 32, 32, 3)\n",
      " epoch: 1, train accuracy: 0.2169, train_loss_norm:5.5921, valid_acc: 0.1986, valid_loss_norm: 3.5988\n",
      " epoch: 2, train accuracy: 0.1066, train_loss_norm:2.3028, valid_acc: 0.0978, valid_loss_norm: 2.3027\n",
      " epoch: 3, train accuracy: 0.1677, train_loss_norm:2.1493, valid_acc: 0.1902, valid_loss_norm: 2.0303\n",
      " epoch: 4, train accuracy: 0.2542, train_loss_norm:1.9847, valid_acc: 0.2926, valid_loss_norm: 1.8960\n",
      " epoch: 5, train accuracy: 0.3735, train_loss_norm:1.8317, valid_acc: 0.3642, valid_loss_norm: 1.7827\n",
      " epoch: 6, train accuracy: 0.4258, train_loss_norm:1.7437, valid_acc: 0.3926, valid_loss_norm: 1.7182\n",
      " epoch: 7, train accuracy: 0.4675, train_loss_norm:1.6801, valid_acc: 0.4024, valid_loss_norm: 1.6858\n",
      " epoch: 8, train accuracy: 0.5049, train_loss_norm:1.6175, valid_acc: 0.4102, valid_loss_norm: 1.6873\n",
      " epoch: 9, train accuracy: 0.5325, train_loss_norm:1.5781, valid_acc: 0.4326, valid_loss_norm: 1.6375\n",
      " epoch: 10, train accuracy: 0.5518, train_loss_norm:1.5405, valid_acc: 0.4346, valid_loss_norm: 1.6293\n",
      " epoch: 11, train accuracy: 0.5667, train_loss_norm:1.5159, valid_acc: 0.4298, valid_loss_norm: 1.6606\n",
      " epoch: 12, train accuracy: 0.5804, train_loss_norm:1.4894, valid_acc: 0.4392, valid_loss_norm: 1.6259\n",
      " epoch: 13, train accuracy: 0.5927, train_loss_norm:1.4661, valid_acc: 0.4426, valid_loss_norm: 1.6038\n",
      " epoch: 14, train accuracy: 0.6032, train_loss_norm:1.4433, valid_acc: 0.4340, valid_loss_norm: 1.6357\n",
      " epoch: 15, train accuracy: 0.6145, train_loss_norm:1.4257, valid_acc: 0.4328, valid_loss_norm: 1.6438\n",
      " epoch: 16, train accuracy: 0.6214, train_loss_norm:1.4095, valid_acc: 0.4300, valid_loss_norm: 1.6341\n",
      " epoch: 17, train accuracy: 0.6314, train_loss_norm:1.3889, valid_acc: 0.4436, valid_loss_norm: 1.6162\n",
      " epoch: 18, train accuracy: 0.6412, train_loss_norm:1.3728, valid_acc: 0.4354, valid_loss_norm: 1.6298\n",
      " epoch: 19, train accuracy: 0.6473, train_loss_norm:1.3580, valid_acc: 0.4368, valid_loss_norm: 1.6400\n",
      " epoch: 20, train accuracy: 0.6556, train_loss_norm:1.3426, valid_acc: 0.4420, valid_loss_norm: 1.6352\n",
      " epoch: 21, train accuracy: 0.6633, train_loss_norm:1.3275, valid_acc: 0.4448, valid_loss_norm: 1.6175\n",
      " epoch: 22, train accuracy: 0.6679, train_loss_norm:1.3150, valid_acc: 0.4478, valid_loss_norm: 1.6434\n",
      " epoch: 23, train accuracy: 0.6756, train_loss_norm:1.2995, valid_acc: 0.4496, valid_loss_norm: 1.6323\n",
      " epoch: 24, train accuracy: 0.6837, train_loss_norm:1.2881, valid_acc: 0.4438, valid_loss_norm: 1.6290\n",
      " epoch: 25, train accuracy: 0.6873, train_loss_norm:1.2763, valid_acc: 0.4464, valid_loss_norm: 1.6491\n",
      " epoch: 26, train accuracy: 0.6936, train_loss_norm:1.2628, valid_acc: 0.4430, valid_loss_norm: 1.6446\n",
      " epoch: 27, train accuracy: 0.6989, train_loss_norm:1.2519, valid_acc: 0.4498, valid_loss_norm: 1.6317\n",
      " epoch: 28, train accuracy: 0.7045, train_loss_norm:1.2421, valid_acc: 0.4420, valid_loss_norm: 1.6554\n",
      " epoch: 29, train accuracy: 0.7086, train_loss_norm:1.2329, valid_acc: 0.4438, valid_loss_norm: 1.6560\n",
      " epoch: 30, train accuracy: 0.7116, train_loss_norm:1.2230, valid_acc: 0.4552, valid_loss_norm: 1.6322\n",
      " epoch: 31, train accuracy: 0.7173, train_loss_norm:1.2116, valid_acc: 0.4444, valid_loss_norm: 1.6495\n",
      " epoch: 32, train accuracy: 0.7213, train_loss_norm:1.2046, valid_acc: 0.4542, valid_loss_norm: 1.6297\n",
      " epoch: 33, train accuracy: 0.7248, train_loss_norm:1.1972, valid_acc: 0.4488, valid_loss_norm: 1.6348\n",
      " epoch: 34, train accuracy: 0.7290, train_loss_norm:1.1870, valid_acc: 0.4486, valid_loss_norm: 1.6649\n",
      " epoch: 35, train accuracy: 0.7320, train_loss_norm:1.1795, valid_acc: 0.4504, valid_loss_norm: 1.6354\n",
      " epoch: 36, train accuracy: 0.7374, train_loss_norm:1.1721, valid_acc: 0.4470, valid_loss_norm: 1.6702\n",
      " epoch: 37, train accuracy: 0.7388, train_loss_norm:1.1656, valid_acc: 0.4414, valid_loss_norm: 1.6801\n",
      " epoch: 38, train accuracy: 0.7433, train_loss_norm:1.1571, valid_acc: 0.4456, valid_loss_norm: 1.6847\n",
      " epoch: 39, train accuracy: 0.7464, train_loss_norm:1.1477, valid_acc: 0.4532, valid_loss_norm: 1.6622\n",
      " epoch: 40, train accuracy: 0.7483, train_loss_norm:1.1418, valid_acc: 0.4488, valid_loss_norm: 1.6737\n",
      " epoch: 41, train accuracy: 0.7509, train_loss_norm:1.1360, valid_acc: 0.4454, valid_loss_norm: 1.6779\n",
      " epoch: 42, train accuracy: 0.7532, train_loss_norm:1.1310, valid_acc: 0.4540, valid_loss_norm: 1.6582\n",
      " epoch: 43, train accuracy: 0.7579, train_loss_norm:1.1215, valid_acc: 0.4338, valid_loss_norm: 1.7341\n",
      " epoch: 44, train accuracy: 0.7586, train_loss_norm:1.1184, valid_acc: 0.4468, valid_loss_norm: 1.6926\n",
      " epoch: 45, train accuracy: 0.7611, train_loss_norm:1.1081, valid_acc: 0.4432, valid_loss_norm: 1.6977\n",
      " epoch: 46, train accuracy: 0.7645, train_loss_norm:1.1037, valid_acc: 0.4586, valid_loss_norm: 1.6601\n",
      " epoch: 47, train accuracy: 0.7677, train_loss_norm:1.1013, valid_acc: 0.4460, valid_loss_norm: 1.6933\n",
      " epoch: 48, train accuracy: 0.7700, train_loss_norm:1.0968, valid_acc: 0.4406, valid_loss_norm: 1.6928\n",
      " epoch: 49, train accuracy: 0.7712, train_loss_norm:1.0898, valid_acc: 0.4584, valid_loss_norm: 1.6952\n",
      " epoch: 50, train accuracy: 0.7749, train_loss_norm:1.0821, valid_acc: 0.4458, valid_loss_norm: 1.7013\n",
      " epoch: 51, train accuracy: 0.7742, train_loss_norm:1.0817, valid_acc: 0.4566, valid_loss_norm: 1.6790\n",
      " epoch: 52, train accuracy: 0.7772, train_loss_norm:1.0722, valid_acc: 0.4400, valid_loss_norm: 1.7320\n",
      " epoch: 53, train accuracy: 0.7804, train_loss_norm:1.0707, valid_acc: 0.4546, valid_loss_norm: 1.6832\n",
      " epoch: 54, train accuracy: 0.7823, train_loss_norm:1.0638, valid_acc: 0.4432, valid_loss_norm: 1.7275\n",
      " epoch: 55, train accuracy: 0.7835, train_loss_norm:1.0619, valid_acc: 0.4332, valid_loss_norm: 1.7567\n",
      " epoch: 56, train accuracy: 0.7865, train_loss_norm:1.0589, valid_acc: 0.4456, valid_loss_norm: 1.7086\n",
      " epoch: 57, train accuracy: 0.7894, train_loss_norm:1.0512, valid_acc: 0.4578, valid_loss_norm: 1.6960\n",
      " epoch: 58, train accuracy: 0.7885, train_loss_norm:1.0487, valid_acc: 0.4554, valid_loss_norm: 1.7017\n",
      " epoch: 59, train accuracy: 0.7915, train_loss_norm:1.0479, valid_acc: 0.4498, valid_loss_norm: 1.7223\n",
      " epoch: 60, train accuracy: 0.7914, train_loss_norm:1.0495, valid_acc: 0.4530, valid_loss_norm: 1.7204\n",
      " epoch: 61, train accuracy: 0.7950, train_loss_norm:1.0346, valid_acc: 0.4400, valid_loss_norm: 1.7438\n",
      " epoch: 62, train accuracy: 0.7960, train_loss_norm:1.0351, valid_acc: 0.4486, valid_loss_norm: 1.7161\n",
      " epoch: 63, train accuracy: 0.7956, train_loss_norm:1.0325, valid_acc: 0.4544, valid_loss_norm: 1.7101\n",
      " epoch: 64, train accuracy: 0.7994, train_loss_norm:1.0240, valid_acc: 0.4374, valid_loss_norm: 1.7812\n",
      " epoch: 65, train accuracy: 0.8001, train_loss_norm:1.0260, valid_acc: 0.4434, valid_loss_norm: 1.7196\n",
      " epoch: 66, train accuracy: 0.8032, train_loss_norm:1.0222, valid_acc: 0.4268, valid_loss_norm: 1.8075\n",
      " epoch: 67, train accuracy: 0.8032, train_loss_norm:1.0189, valid_acc: 0.4222, valid_loss_norm: 1.8222\n",
      " epoch: 68, train accuracy: 0.8018, train_loss_norm:1.0197, valid_acc: 0.4432, valid_loss_norm: 1.7296\n",
      " epoch: 69, train accuracy: 0.8049, train_loss_norm:1.0138, valid_acc: 0.4390, valid_loss_norm: 1.7510\n",
      " epoch: 70, train accuracy: 0.8071, train_loss_norm:1.0111, valid_acc: 0.4494, valid_loss_norm: 1.7451\n",
      " epoch: 71, train accuracy: 0.8069, train_loss_norm:1.0075, valid_acc: 0.4476, valid_loss_norm: 1.7350\n",
      " epoch: 72, train accuracy: 0.8110, train_loss_norm:1.0052, valid_acc: 0.4394, valid_loss_norm: 1.7971\n",
      " epoch: 73, train accuracy: 0.8093, train_loss_norm:1.0035, valid_acc: 0.4418, valid_loss_norm: 1.7620\n",
      " epoch: 74, train accuracy: 0.8129, train_loss_norm:0.9955, valid_acc: 0.4482, valid_loss_norm: 1.7428\n",
      " epoch: 75, train accuracy: 0.8134, train_loss_norm:0.9926, valid_acc: 0.4524, valid_loss_norm: 1.7279\n",
      " epoch: 76, train accuracy: 0.8126, train_loss_norm:0.9928, valid_acc: 0.4514, valid_loss_norm: 1.7387\n",
      " epoch: 77, train accuracy: 0.8125, train_loss_norm:0.9911, valid_acc: 0.4468, valid_loss_norm: 1.7434\n",
      " epoch: 78, train accuracy: 0.8153, train_loss_norm:0.9867, valid_acc: 0.4382, valid_loss_norm: 1.7910\n",
      " epoch: 79, train accuracy: 0.8183, train_loss_norm:0.9874, valid_acc: 0.4486, valid_loss_norm: 1.7421\n",
      " epoch: 80, train accuracy: 0.8173, train_loss_norm:0.9844, valid_acc: 0.4522, valid_loss_norm: 1.7317\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " epoch: 81, train accuracy: 0.8183, train_loss_norm:0.9869, valid_acc: 0.4008, valid_loss_norm: 1.9834\n",
      " epoch: 82, train accuracy: 0.8194, train_loss_norm:0.9780, valid_acc: 0.4434, valid_loss_norm: 1.8135\n",
      " epoch: 83, train accuracy: 0.8215, train_loss_norm:0.9765, valid_acc: 0.4490, valid_loss_norm: 1.7659\n",
      " epoch: 84, train accuracy: 0.8220, train_loss_norm:0.9782, valid_acc: 0.4484, valid_loss_norm: 1.7397\n",
      " epoch: 85, train accuracy: 0.8219, train_loss_norm:0.9711, valid_acc: 0.4392, valid_loss_norm: 1.7721\n",
      " epoch: 86, train accuracy: 0.8223, train_loss_norm:0.9729, valid_acc: 0.4466, valid_loss_norm: 1.7662\n",
      " epoch: 87, train accuracy: 0.8220, train_loss_norm:0.9709, valid_acc: 0.4446, valid_loss_norm: 1.7572\n",
      " epoch: 88, train accuracy: 0.8230, train_loss_norm:0.9719, valid_acc: 0.4454, valid_loss_norm: 1.8206\n",
      " epoch: 89, train accuracy: 0.8264, train_loss_norm:0.9641, valid_acc: 0.4444, valid_loss_norm: 1.7531\n",
      " epoch: 90, train accuracy: 0.8281, train_loss_norm:0.9658, valid_acc: 0.4206, valid_loss_norm: 1.8367\n",
      " epoch: 91, train accuracy: 0.8291, train_loss_norm:0.9633, valid_acc: 0.4522, valid_loss_norm: 1.7651\n",
      " epoch: 92, train accuracy: 0.8266, train_loss_norm:0.9631, valid_acc: 0.4454, valid_loss_norm: 1.7696\n",
      " epoch: 93, train accuracy: 0.8280, train_loss_norm:0.9606, valid_acc: 0.4520, valid_loss_norm: 1.7596\n",
      " epoch: 94, train accuracy: 0.8309, train_loss_norm:0.9543, valid_acc: 0.4396, valid_loss_norm: 1.8162\n",
      " epoch: 95, train accuracy: 0.8310, train_loss_norm:0.9554, valid_acc: 0.4516, valid_loss_norm: 1.7733\n",
      " epoch: 96, train accuracy: 0.8309, train_loss_norm:0.9555, valid_acc: 0.4458, valid_loss_norm: 1.7755\n",
      " epoch: 97, train accuracy: 0.8326, train_loss_norm:0.9541, valid_acc: 0.4462, valid_loss_norm: 1.7696\n",
      " epoch: 98, train accuracy: 0.8337, train_loss_norm:0.9466, valid_acc: 0.4376, valid_loss_norm: 1.8136\n",
      " epoch: 99, train accuracy: 0.8341, train_loss_norm:0.9440, valid_acc: 0.4430, valid_loss_norm: 1.8036\n",
      " epoch: 100, train accuracy: 0.8334, train_loss_norm:0.9490, valid_acc: 0.4516, valid_loss_norm: 1.7400\n",
      "0.4526\n"
     ]
    }
   ],
   "source": [
    "print('test set result : ' ,test_accuracy_all)\n",
    "\n",
    "plt.figure(1)\n",
    "plt.plot(np.arange(epoch_all[0]+1), train_loss_record_all[0], label='train')\n",
    "plt.plot(np.arange(epoch_all[0]+1), holdout_loss_record_all[0], label='valid')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and validation loss vs epochs')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(2)\n",
    "plt.plot(np.arange(epoch_all[0]+1), train_accuracy_record_all[0], label='train')\n",
    "plt.plot(np.arange(epoch_all[0]+1), holdout_accuracy_record_all[0], label='valid')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and validation accuracy vs epochs')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(3)\n",
    "plt.plot(np.arange(epoch_all[1]+1), train_loss_record_all[1], label='train')\n",
    "plt.plot(np.arange(epoch_all[1]+1), holdout_loss_record_all[1], label='valid')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and validation loss vs epochs')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(4)\n",
    "plt.plot(np.arange(epoch_all[1]+1), train_accuracy_record_all[1], label='train')\n",
    "plt.plot(np.arange(epoch_all[1]+1), holdout_accuracy_record_all[1], label='valid')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and validation accuracy vs epochs')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(5)\n",
    "plt.plot(np.arange(epoch_all[2]+1), train_loss_record_all[2], label='train')\n",
    "plt.plot(np.arange(epoch_all[2]+1), holdout_loss_record_all[2], label='valid')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and validation loss vs epochs')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(6)\n",
    "plt.plot(np.arange(epoch_all[2]+1), train_accuracy_record_all[2], label='train')\n",
    "plt.plot(np.arange(epoch_all[2]+1), holdout_accuracy_record_all[2], label='valid')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and validation accuracy vs epochs')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "005f4ed24810181fa8b2266ec303702d6575bedfaa41c7848d327e7f780b3129"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
