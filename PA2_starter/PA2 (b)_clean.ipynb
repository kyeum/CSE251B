{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "inp: (50000, 32, 32, 3)\n",
      "10 10\n",
      "in backward layer\n",
      "size: 10\n",
      "delta: (10, 10)\n",
      "change: 4.440892098500626e-16\n",
      "change: 4.163336342344337e-17\n",
      "*x.T_shape: (10, 10)\n",
      "*delta_shape: (10, 10)\n",
      "*d_w_shape: (10, 10)\n",
      "d_w :  -4.163336342344337e-17\n",
      "d_b :  -4.163336342344337e-17\n",
      "in backward layer\n",
      "size: 10\n",
      "delta: (10, 10)\n",
      "change: -3.7803481728656942\n",
      "change: -0.3780348172865692\n",
      "*x.T_shape: (10, 10)\n",
      "*delta_shape: (10, 10)\n",
      "*d_w_shape: (10, 10)\n",
      "d_w :  0.3780348172865692\n",
      "d_b :  0.3780348172865692\n",
      "in backward layer\n",
      "size: 10\n",
      "delta: (10, 10)\n",
      "change: 482.8810474192792\n",
      "change: 48.288104741927924\n",
      "*x.T_shape: (3072, 10)\n",
      "*delta_shape: (10, 10)\n",
      "*d_w_shape: (3072, 10)\n",
      "d_w :  -48.288104741927924\n",
      "d_b :  -48.288104741927924\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-1.32850882e-05,  1.45903488e-05, -2.32924336e-05, ...,\n",
       "        -2.46434433e-06, -1.10828988e-05,  1.08532447e-05],\n",
       "       [ 3.12593139e-03,  1.13898808e-04,  5.11964177e-03, ...,\n",
       "        -9.95171889e-04,  3.88315850e-03,  1.25684977e-03],\n",
       "       [ 1.50207731e-12,  5.95918566e-12, -2.63289052e-12, ...,\n",
       "        -3.17851575e-12,  6.89494773e-12,  6.17360722e-12],\n",
       "       ...,\n",
       "       [ 2.74560090e-11, -3.34223777e-11, -2.49502369e-11, ...,\n",
       "         4.62296638e-12, -1.82286031e-11, -1.87014343e-12],\n",
       "       [-2.16030976e-03, -8.57199430e-03,  3.78689084e-03, ...,\n",
       "         4.57200758e-03, -9.91783999e-03, -8.88010572e-03],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from neuralnet import *\n",
    "from random import shuffle\n",
    "import numpy as np\n",
    "\n",
    "# Load the configuration.\n",
    "config = load_config(\"./data\")\n",
    "\n",
    "# Create the model\n",
    "#model  = Neuralnetwork(config)\n",
    "# Load the data\n",
    "#x_train, y_train = load_data(path=\"./data\", mode=\"train\") # output normalized and one hot encoding\n",
    "#x_test, y_test = load_data(path=\"./data\", mode=\"test\")# output normalized and one hot encoding\n",
    "\n",
    "# Use 10 examples one from each category\n",
    "'''\n",
    "# Data loading and spliting\n",
    "X_b, y_b, X_stats = load_data(path=\"./data\", mode=\"train\")\n",
    "\n",
    "X_train = []\n",
    "y_train = []\n",
    "class_num = list(range(10))\n",
    "\n",
    "\n",
    "X_train, y_train = [], []\n",
    "for idx in range(y_b.shape[0]):\n",
    "    if len(class_num) == 0:\n",
    "        break\n",
    "    indice = onehot_decode(y_b[idx])\n",
    "    \n",
    "    if indice in class_num:\n",
    "        X_train.append(X_b[idx])\n",
    "        y_train.append(y_b[idx])\n",
    "        class_num.remove(indice)\n",
    "        \n",
    "        \n",
    "X_train = np.array(X_train)        \n",
    "y_train = np.array(y_train)       \n",
    "'''\n",
    "\n",
    "X_train, y_train, X_stats = load_data(path=\"./data\", stats=None, mode=\"train\")\n",
    "\n",
    "# Get 10 examples, 1 from each category.\n",
    "X_sub = []\n",
    "y_sub = []\n",
    "for k in range(10):\n",
    "    indices = y_train[:,k] == 1\n",
    "    X_sub.append(X_train[indices][0])\n",
    "    y_sub.append(y_train[indices][0])\n",
    "print(len(X_sub), len(y_sub))\n",
    "X_sub = np.array(X_sub)\n",
    "y_sub = np.array(y_sub)\n",
    "\n",
    "# Load model para\n",
    "config_prob_b = {}\n",
    "config_prob_b['layer_specs'] = [3072, 10, 10, 10]\n",
    "config_prob_b['activation'] = 'tanh'\n",
    "config_prob_b['learning_rate'] = 0.005\n",
    "config_prob_b['batch_size'] = 128 \n",
    "config_prob_b['epochs'] = 100  \n",
    "config_prob_b['early_stop'] = True \n",
    "config_prob_b['early_stop_epoch'] = 5  \n",
    "config_prob_b['L2_penalty'] = 0  \n",
    "config_prob_b['momentum'] = False  \n",
    "config_prob_b['momentum_gamma'] = 0.9  \n",
    "\n",
    "model_b = Neuralnetwork(config_prob_b)\n",
    "model_b.forward(X_sub, y_sub)\n",
    "model_b.backward()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layers: 5\n",
      "diff: -0.009038896391754037\n",
      "Output bias weight diff: 0.000050\n",
      "diff: 0.022823174643701982\n",
      "Hidden Layer 2 bias weight diff: 0.000205\n",
      "diff: -2.0126290360522603e-05\n",
      "Hidden Layer 1 bias weight diff: -0.000001\n",
      "diff: -0.022948392814019947\n",
      "Hidden to output weight diff 1: -0.000191\n",
      "diff: -0.011598303563825407\n",
      "Hidden to output weight diff 2: 0.000288\n",
      "diff: -1.3374003522415023e-06\n",
      "Input to hidden 1 weight diff 1: -0.000000\n",
      "diff: -0.006792612416164356\n",
      "Input to hidden 2 weight diff 2: -0.000310\n"
     ]
    }
   ],
   "source": [
    "# d_b d_w comparison\n",
    "\n",
    "## Part (b) Estimation of bias weight and weight\n",
    "def Num_Est_b(model, layer, eps, output_idx):\n",
    "    layer.b[0][output_idx] += eps # E(w+e)\n",
    "    loss_1 = model.forward(X_sub, y_sub)[1]\n",
    "    layer.b[0][output_idx] -= 2*eps # E(w-e)\n",
    "    loss_2 = model.forward(X_sub, y_sub)[1]\n",
    "    layer.b[0][output_idx] += eps # back to normal\n",
    "    print(\"diff:\", loss_1 - loss_2)\n",
    "    return (loss_1 - loss_2) / (2 * eps) # Numerical estimation for dEdW\n",
    "\n",
    "def Num_Est_w(model, layer, eps, input_idx, output_idx):\n",
    "    layer.w[input_idx][output_idx] += eps # E(w+e)\n",
    "    loss_1 = model.forward(X_sub, y_sub)[1]\n",
    "    layer.w[input_idx][output_idx] -= 2*eps # E(w-e)\n",
    "    loss_2 = model.forward(X_sub, y_sub)[1]\n",
    "    layer.w[input_idx][output_idx] += eps # back to normal\n",
    "    print(\"diff:\", loss_1 - loss_2)\n",
    "    return (loss_1 - loss_2) / (2 * eps) # Numerical estimation for dEdW\n",
    "\n",
    "print(\"Layers:\", len(model_b.layers))\n",
    "# Weights to modify:\n",
    "# 1 output bias weight\n",
    "# 1 hidden bias weight for each hidden layer\n",
    "# 2 hidden to output weights\n",
    "# 2 input to hidden weights\n",
    "# Show that the grad between is within O(eps^2) of backprop weights.\n",
    "db = []\n",
    "dw = []\n",
    "db_est = []\n",
    "dw_est = []\n",
    "\n",
    "eps = 10e-2\n",
    "# Hidden Layer 1\n",
    "hidden_layer_1 = model_b.layers[0]\n",
    "# Hidden Layer 2\n",
    "hidden_layer_2 = model_b.layers[2]\n",
    "# Output Layer\n",
    "output_layer = model_b.layers[4]\n",
    "\n",
    "# 1 output bias weight\n",
    "input_idx = 0\n",
    "output_idx = 1\n",
    "cur_layer = output_layer\n",
    "db_est.append(Num_Est_b(model_b, cur_layer, eps, output_idx))\n",
    "db.append(cur_layer.d_b[0][output_idx]) \n",
    "print(f\"Output bias weight diff: {db_est[-1] - db[-1]:.6f}\")\n",
    "\n",
    "# 1 hidden bias weight for hidden layer 2\n",
    "cur_layer = hidden_layer_2\n",
    "db_est.append(Num_Est_b(model_b, cur_layer, eps, output_idx))\n",
    "db.append(cur_layer.d_b[0][output_idx]) \n",
    "print(f\"Hidden Layer 2 bias weight diff: {db_est[-1] - db[-1]:.6f}\")\n",
    "\n",
    "# 1 hidden bias weight for hidden layer 1\n",
    "cur_layer = hidden_layer_1\n",
    "db_est.append(Num_Est_b(model_b, cur_layer, eps, output_idx))\n",
    "db.append(cur_layer.d_b[0][output_idx]) \n",
    "print(f\"Hidden Layer 1 bias weight diff: {db_est[-1] - db[-1]:.6f}\")\n",
    "\n",
    "# 2 hidden to output weights\n",
    "input_idx = 0\n",
    "output_idx = 1\n",
    "cur_layer = hidden_layer_2\n",
    "dw_est.append(Num_Est_w(model_b, cur_layer, eps, input_idx, output_idx))\n",
    "dw.append(cur_layer.d_w[input_idx][output_idx])\n",
    "print(f\"Hidden to output weight diff 1: {dw_est[-1] - dw[-1]:.6f}\")\n",
    "input_idx = 0\n",
    "output_idx = 2\n",
    "dw_est.append(Num_Est_w(model_b, cur_layer, eps, input_idx, output_idx))\n",
    "dw.append(cur_layer.d_w[input_idx][output_idx])\n",
    "print(f\"Hidden to output weight diff 2: {dw_est[-1] - dw[-1]:.6f}\")\n",
    "\n",
    "# 2 input to hidden weights\n",
    "input_idx = 0\n",
    "output_idx = 1\n",
    "cur_layer = hidden_layer_1\n",
    "dw_est.append(Num_Est_w(model_b, cur_layer, eps, input_idx, output_idx))\n",
    "dw.append(cur_layer.d_w[input_idx][output_idx])\n",
    "print(f\"Input to hidden 1 weight diff 1: {dw_est[-1] - dw[-1]:.6f}\")\n",
    "input_idx = 0\n",
    "output_idx = 2\n",
    "dw_est.append(Num_Est_w(model_b, cur_layer, eps, input_idx, output_idx))\n",
    "dw.append(cur_layer.d_w[input_idx][output_idx])\n",
    "print(f\"Input to hidden 2 weight diff 2: {dw_est[-1] - dw[-1]:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "005f4ed24810181fa8b2266ec303702d6575bedfaa41c7848d327e7f780b3129"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
