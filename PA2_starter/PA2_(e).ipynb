{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activations (e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with best param from b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from neuralnet import *\n",
    "from random import shuffle\n",
    "import numpy as np\n",
    "\n",
    "# Load the configuration.\n",
    "config = load_config(\"./data\")\n",
    "# Load model parameters\n",
    "# TODO: GET BEST PARAMS FROM (d) Regularization\n",
    "config = {}\n",
    "config['layer_specs'] = [3072, 64, 64, 10]\n",
    "config['learning_rate'] = 0.01\n",
    "config['batch_size'] = 256 \n",
    "config['epochs'] = 150\n",
    "config['early_stop'] = True \n",
    "config['early_stop_epoch'] = 5  \n",
    "config['L2_penalty'] = 0.001 \n",
    "config['momentum'] = True  \n",
    "config['momentum_gamma'] = 0.9  \n",
    "\n",
    "# Test different activations (not including tanh)\n",
    "activations = ['ReLU','leakyReLU', 'sigmoid']\n",
    "# Load the data\n",
    "X_train, y_train, X_stats = load_data(path=\"./data\", stats=None, mode=\"train\")\n",
    "X_test, y_test = load_data(path=\"./data\", stats=X_stats, mode=\"test\")\n",
    "X_train, y_train, X_valid, y_valid = split_data(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, train accuracy: 0.1014, train_loss_norm:1000.2854, valid_acc: 0.1052, valid_loss_norm: 1083.8226\n",
      "Valid loss going down!\n",
      "Epoch: 2, train accuracy: 0.1023, train_loss_norm:1065.0619, valid_acc: 0.0946, valid_loss_norm: 1046.3084\n",
      "Valid loss going down!\n",
      "Epoch: 3, train accuracy: 0.1002, train_loss_norm:1028.1975, valid_acc: 0.0984, valid_loss_norm: 1010.0933\n",
      "Valid loss going down!\n",
      "Epoch: 4, train accuracy: 0.1019, train_loss_norm:992.6092, valid_acc: 0.1056, valid_loss_norm: 975.1319\n",
      "Valid loss going down!\n",
      "Epoch: 5, train accuracy: 0.1035, train_loss_norm:958.2530, valid_acc: 0.0966, valid_loss_norm: 941.3807\n",
      "Valid loss going down!\n",
      "Epoch: 6, train accuracy: 0.1015, train_loss_norm:925.0863, valid_acc: 0.1000, valid_loss_norm: 908.7980\n",
      "Valid loss going down!\n",
      "Epoch: 7, train accuracy: 0.1036, train_loss_norm:893.0677, valid_acc: 0.0966, valid_loss_norm: 877.3435\n",
      "Valid loss going down!\n",
      "Epoch: 8, train accuracy: 0.1024, train_loss_norm:862.1577, valid_acc: 0.0984, valid_loss_norm: 846.9777\n",
      "Valid loss going down!\n",
      "Epoch: 9, train accuracy: 0.1036, train_loss_norm:832.3178, valid_acc: 0.0966, valid_loss_norm: 817.6634\n",
      "Valid loss going down!\n",
      "Epoch: 10, train accuracy: 0.1027, train_loss_norm:803.5108, valid_acc: 0.1052, valid_loss_norm: 789.3636\n",
      "Valid loss going down!\n",
      "Epoch: 11, train accuracy: 0.1021, train_loss_norm:775.7013, valid_acc: 0.0946, valid_loss_norm: 762.0439\n",
      "Valid loss going down!\n",
      "Epoch: 12, train accuracy: 0.1017, train_loss_norm:748.8544, valid_acc: 0.0946, valid_loss_norm: 735.6700\n",
      "Valid loss going down!\n",
      "Epoch: 13, train accuracy: 0.1033, train_loss_norm:722.9370, valid_acc: 0.0946, valid_loss_norm: 710.2091\n",
      "Valid loss going down!\n",
      "Epoch: 14, train accuracy: 0.1026, train_loss_norm:697.9170, valid_acc: 0.0986, valid_loss_norm: 685.6295\n",
      "Valid loss going down!\n",
      "Epoch: 15, train accuracy: 0.1013, train_loss_norm:673.7630, valid_acc: 0.0966, valid_loss_norm: 661.9009\n",
      "Valid loss going down!\n",
      "Epoch: 16, train accuracy: 0.1015, train_loss_norm:650.4453, valid_acc: 0.1052, valid_loss_norm: 638.9939\n",
      "Valid loss going down!\n",
      "Epoch: 17, train accuracy: 0.1030, train_loss_norm:627.9348, valid_acc: 0.1052, valid_loss_norm: 616.8799\n",
      "Valid loss going down!\n",
      "Epoch: 18, train accuracy: 0.1017, train_loss_norm:606.2037, valid_acc: 0.0984, valid_loss_norm: 595.5316\n",
      "Valid loss going down!\n",
      "Epoch: 19, train accuracy: 0.1028, train_loss_norm:585.2249, valid_acc: 0.0946, valid_loss_norm: 574.9225\n",
      "Valid loss going down!\n",
      "Epoch: 20, train accuracy: 0.1028, train_loss_norm:564.9724, valid_acc: 0.1052, valid_loss_norm: 555.0262\n",
      "Valid loss going down!\n",
      "Epoch: 21, train accuracy: 0.1026, train_loss_norm:545.4210, valid_acc: 0.0984, valid_loss_norm: 535.8193\n",
      "Valid loss going down!\n",
      "Epoch: 22, train accuracy: 0.1024, train_loss_norm:526.5465, valid_acc: 0.1000, valid_loss_norm: 517.2773\n",
      "Valid loss going down!\n",
      "Epoch: 23, train accuracy: 0.1028, train_loss_norm:508.3254, valid_acc: 0.0966, valid_loss_norm: 499.3769\n",
      "Valid loss going down!\n",
      "Epoch: 24, train accuracy: 0.1021, train_loss_norm:490.7351, valid_acc: 0.1052, valid_loss_norm: 482.0964\n",
      "Valid loss going down!\n",
      "Epoch: 25, train accuracy: 0.1025, train_loss_norm:473.7539, valid_acc: 0.0946, valid_loss_norm: 465.4145\n",
      "Valid loss going down!\n",
      "Epoch: 26, train accuracy: 0.1040, train_loss_norm:457.3604, valid_acc: 0.0984, valid_loss_norm: 449.3100\n",
      "Valid loss going down!\n",
      "Epoch: 27, train accuracy: 0.1033, train_loss_norm:441.5346, valid_acc: 0.0986, valid_loss_norm: 433.7625\n",
      "Valid loss going down!\n",
      "Epoch: 28, train accuracy: 0.1025, train_loss_norm:426.2567, valid_acc: 0.0966, valid_loss_norm: 418.7536\n",
      "Valid loss going down!\n",
      "Epoch: 29, train accuracy: 0.1019, train_loss_norm:411.5076, valid_acc: 0.0986, valid_loss_norm: 404.2643\n",
      "Valid loss going down!\n",
      "Epoch: 30, train accuracy: 0.1044, train_loss_norm:397.2692, valid_acc: 0.0984, valid_loss_norm: 390.2766\n",
      "Valid loss going down!\n",
      "Epoch: 31, train accuracy: 0.1009, train_loss_norm:383.5237, valid_acc: 0.0966, valid_loss_norm: 376.7731\n",
      "Valid loss going down!\n",
      "Epoch: 32, train accuracy: 0.1023, train_loss_norm:370.2541, valid_acc: 0.1056, valid_loss_norm: 363.7371\n",
      "Valid loss going down!\n",
      "Epoch: 33, train accuracy: 0.1016, train_loss_norm:357.4438, valid_acc: 0.1052, valid_loss_norm: 351.1526\n",
      "Valid loss going down!\n",
      "Epoch: 34, train accuracy: 0.1000, train_loss_norm:345.0771, valid_acc: 0.0966, valid_loss_norm: 339.0038\n",
      "Valid loss going down!\n",
      "Epoch: 35, train accuracy: 0.1036, train_loss_norm:333.1385, valid_acc: 0.1000, valid_loss_norm: 327.2754\n",
      "Valid loss going down!\n",
      "Epoch: 36, train accuracy: 0.1017, train_loss_norm:321.6132, valid_acc: 0.0986, valid_loss_norm: 315.9531\n",
      "Valid loss going down!\n",
      "Epoch: 37, train accuracy: 0.1016, train_loss_norm:310.4869, valid_acc: 0.1056, valid_loss_norm: 305.0228\n",
      "Valid loss going down!\n",
      "Epoch: 38, train accuracy: 0.1021, train_loss_norm:299.7459, valid_acc: 0.0946, valid_loss_norm: 294.4708\n",
      "Valid loss going down!\n",
      "Epoch: 39, train accuracy: 0.1021, train_loss_norm:289.3767, valid_acc: 0.0986, valid_loss_norm: 284.2842\n",
      "Valid loss going down!\n",
      "Epoch: 40, train accuracy: 0.1018, train_loss_norm:279.3664, valid_acc: 0.0966, valid_loss_norm: 274.4503\n",
      "Valid loss going down!\n",
      "Epoch: 41, train accuracy: 0.1010, train_loss_norm:269.7027, valid_acc: 0.0946, valid_loss_norm: 264.9570\n",
      "Valid loss going down!\n",
      "Epoch: 42, train accuracy: 0.1016, train_loss_norm:260.3735, valid_acc: 0.0966, valid_loss_norm: 255.7919\n",
      "Valid loss going down!\n",
      "Epoch: 43, train accuracy: 0.1021, train_loss_norm:251.3674, valid_acc: 0.0946, valid_loss_norm: 246.9444\n",
      "Valid loss going down!\n",
      "Epoch: 44, train accuracy: 0.1010, train_loss_norm:242.6730, valid_acc: 0.1034, valid_loss_norm: 238.4030\n",
      "Valid loss going down!\n",
      "Epoch: 45, train accuracy: 0.1027, train_loss_norm:234.2797, valid_acc: 0.0966, valid_loss_norm: 230.1576\n",
      "Valid loss going down!\n",
      "Epoch: 46, train accuracy: 0.1014, train_loss_norm:226.1769, valid_acc: 0.1010, valid_loss_norm: 222.1978\n",
      "Valid loss going down!\n",
      "Epoch: 47, train accuracy: 0.1018, train_loss_norm:218.3546, valid_acc: 0.1056, valid_loss_norm: 214.5129\n",
      "Valid loss going down!\n",
      "Epoch: 48, train accuracy: 0.1043, train_loss_norm:210.8031, valid_acc: 0.1056, valid_loss_norm: 207.0945\n",
      "Valid loss going down!\n",
      "Epoch: 49, train accuracy: 0.1017, train_loss_norm:203.5131, valid_acc: 0.0984, valid_loss_norm: 199.9329\n",
      "Valid loss going down!\n",
      "Epoch: 50, train accuracy: 0.1036, train_loss_norm:196.4754, valid_acc: 0.0966, valid_loss_norm: 193.0193\n",
      "Valid loss going down!\n",
      "Epoch: 51, train accuracy: 0.1023, train_loss_norm:189.6814, valid_acc: 0.0984, valid_loss_norm: 186.3449\n",
      "Valid loss going down!\n",
      "Epoch: 52, train accuracy: 0.1033, train_loss_norm:183.1226, valid_acc: 0.1034, valid_loss_norm: 179.9015\n",
      "Valid loss going down!\n",
      "Epoch: 53, train accuracy: 0.1016, train_loss_norm:176.7909, valid_acc: 0.1010, valid_loss_norm: 173.6814\n",
      "Valid loss going down!\n",
      "Epoch: 54, train accuracy: 0.1011, train_loss_norm:170.6784, valid_acc: 0.0966, valid_loss_norm: 167.6765\n",
      "Valid loss going down!\n",
      "Epoch: 55, train accuracy: 0.1013, train_loss_norm:164.7775, valid_acc: 0.1056, valid_loss_norm: 161.8795\n",
      "Valid loss going down!\n",
      "Epoch: 56, train accuracy: 0.1011, train_loss_norm:159.0809, valid_acc: 0.1056, valid_loss_norm: 156.2832\n",
      "Valid loss going down!\n",
      "Epoch: 57, train accuracy: 0.1006, train_loss_norm:153.5814, valid_acc: 0.1010, valid_loss_norm: 150.8807\n",
      "Valid loss going down!\n",
      "Epoch: 58, train accuracy: 0.1024, train_loss_norm:148.2725, valid_acc: 0.1010, valid_loss_norm: 145.6652\n",
      "Valid loss going down!\n",
      "Epoch: 59, train accuracy: 0.0993, train_loss_norm:143.1472, valid_acc: 0.0984, valid_loss_norm: 140.6300\n",
      "Valid loss going down!\n",
      "Epoch: 60, train accuracy: 0.1020, train_loss_norm:138.1994, valid_acc: 0.0966, valid_loss_norm: 135.7696\n",
      "Valid loss going down!\n",
      "Epoch: 61, train accuracy: 0.0988, train_loss_norm:133.4230, valid_acc: 0.0946, valid_loss_norm: 131.0772\n",
      "Valid loss going down!\n",
      "Epoch: 62, train accuracy: 0.1013, train_loss_norm:128.8119, valid_acc: 0.0966, valid_loss_norm: 126.5471\n",
      "Valid loss going down!\n",
      "Epoch: 63, train accuracy: 0.1019, train_loss_norm:124.3604, valid_acc: 0.0986, valid_loss_norm: 122.1741\n",
      "Valid loss going down!\n",
      "Epoch: 64, train accuracy: 0.1037, train_loss_norm:120.0629, valid_acc: 0.1000, valid_loss_norm: 117.9525\n",
      "Valid loss going down!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 65, train accuracy: 0.1022, train_loss_norm:115.9143, valid_acc: 0.0984, valid_loss_norm: 113.8768\n",
      "Valid loss going down!\n",
      "Epoch: 66, train accuracy: 0.1013, train_loss_norm:111.9094, valid_acc: 0.0966, valid_loss_norm: 109.9425\n",
      "Valid loss going down!\n",
      "Epoch: 67, train accuracy: 0.1006, train_loss_norm:108.0430, valid_acc: 0.0946, valid_loss_norm: 106.1441\n",
      "Valid loss going down!\n",
      "Epoch: 68, train accuracy: 0.0994, train_loss_norm:104.3106, valid_acc: 0.1034, valid_loss_norm: 102.4774\n",
      "Valid loss going down!\n",
      "Epoch: 69, train accuracy: 0.1006, train_loss_norm:100.7073, valid_acc: 0.0946, valid_loss_norm: 98.9378\n",
      "Valid loss going down!\n",
      "Epoch: 70, train accuracy: 0.1021, train_loss_norm:97.2288, valid_acc: 0.0966, valid_loss_norm: 95.5207\n",
      "Valid loss going down!\n",
      "Epoch: 71, train accuracy: 0.1042, train_loss_norm:93.8707, valid_acc: 0.1000, valid_loss_norm: 92.2216\n",
      "Valid loss going down!\n",
      "Epoch: 72, train accuracy: 0.1002, train_loss_norm:90.6289, valid_acc: 0.1056, valid_loss_norm: 89.0367\n",
      "Valid loss going down!\n",
      "Epoch: 73, train accuracy: 0.1016, train_loss_norm:87.4993, valid_acc: 0.1034, valid_loss_norm: 85.9623\n",
      "Valid loss going down!\n",
      "Epoch: 74, train accuracy: 0.1014, train_loss_norm:84.4780, valid_acc: 0.1000, valid_loss_norm: 82.9945\n",
      "Valid loss going down!\n",
      "Epoch: 75, train accuracy: 0.1052, train_loss_norm:81.5614, valid_acc: 0.1056, valid_loss_norm: 80.1292\n",
      "Valid loss going down!\n",
      "Epoch: 76, train accuracy: 0.1031, train_loss_norm:78.7457, valid_acc: 0.1010, valid_loss_norm: 77.3632\n",
      "Valid loss going down!\n",
      "Epoch: 77, train accuracy: 0.1027, train_loss_norm:76.0275, valid_acc: 0.1000, valid_loss_norm: 74.6924\n",
      "Valid loss going down!\n",
      "Epoch: 78, train accuracy: 0.1005, train_loss_norm:73.4034, valid_acc: 0.0986, valid_loss_norm: 72.1146\n",
      "Valid loss going down!\n",
      "Epoch: 79, train accuracy: 0.1022, train_loss_norm:70.8702, valid_acc: 0.0966, valid_loss_norm: 69.6260\n",
      "Valid loss going down!\n",
      "Epoch: 80, train accuracy: 0.1019, train_loss_norm:68.4247, valid_acc: 0.0946, valid_loss_norm: 67.2238\n",
      "Valid loss going down!\n",
      "Epoch: 81, train accuracy: 0.1016, train_loss_norm:66.0637, valid_acc: 0.0966, valid_loss_norm: 64.9041\n",
      "Valid loss going down!\n",
      "Epoch: 82, train accuracy: 0.1028, train_loss_norm:63.7846, valid_acc: 0.1052, valid_loss_norm: 62.6651\n",
      "Valid loss going down!\n",
      "Epoch: 83, train accuracy: 0.1044, train_loss_norm:61.5843, valid_acc: 0.0984, valid_loss_norm: 60.5039\n",
      "Valid loss going down!\n",
      "Epoch: 84, train accuracy: 0.1029, train_loss_norm:59.4603, valid_acc: 0.1034, valid_loss_norm: 58.4171\n",
      "Valid loss going down!\n",
      "Epoch: 85, train accuracy: 0.1019, train_loss_norm:57.4098, valid_acc: 0.0986, valid_loss_norm: 56.4027\n",
      "Valid loss going down!\n",
      "Epoch: 86, train accuracy: 0.1019, train_loss_norm:55.4302, valid_acc: 0.0946, valid_loss_norm: 54.4580\n",
      "Valid loss going down!\n",
      "Epoch: 87, train accuracy: 0.1024, train_loss_norm:53.5192, valid_acc: 0.1000, valid_loss_norm: 52.5807\n",
      "Valid loss going down!\n",
      "Epoch: 88, train accuracy: 0.1028, train_loss_norm:51.6743, valid_acc: 0.0966, valid_loss_norm: 50.7684\n",
      "Valid loss going down!\n",
      "Epoch: 89, train accuracy: 0.1001, train_loss_norm:49.8934, valid_acc: 0.1010, valid_loss_norm: 49.0187\n",
      "Valid loss going down!\n",
      "Epoch: 90, train accuracy: 0.1027, train_loss_norm:48.1740, valid_acc: 0.1000, valid_loss_norm: 47.3298\n",
      "Valid loss going down!\n",
      "Epoch: 91, train accuracy: 0.1012, train_loss_norm:46.5142, valid_acc: 0.0966, valid_loss_norm: 45.6990\n",
      "Valid loss going down!\n",
      "Epoch: 92, train accuracy: 0.1011, train_loss_norm:44.9119, valid_acc: 0.0946, valid_loss_norm: 44.1251\n",
      "Valid loss going down!\n",
      "Epoch: 93, train accuracy: 0.1015, train_loss_norm:43.3650, valid_acc: 0.1010, valid_loss_norm: 42.6054\n",
      "Valid loss going down!\n",
      "Epoch: 94, train accuracy: 0.1018, train_loss_norm:41.8717, valid_acc: 0.0984, valid_loss_norm: 41.1386\n",
      "Valid loss going down!\n",
      "Epoch: 95, train accuracy: 0.1003, train_loss_norm:40.4301, valid_acc: 0.0946, valid_loss_norm: 39.7220\n",
      "Valid loss going down!\n",
      "Epoch: 96, train accuracy: 0.1021, train_loss_norm:39.0384, valid_acc: 0.0966, valid_loss_norm: 38.3549\n",
      "Valid loss going down!\n",
      "Epoch: 97, train accuracy: 0.1031, train_loss_norm:37.6948, valid_acc: 0.0984, valid_loss_norm: 37.0349\n",
      "Valid loss going down!\n",
      "Epoch: 98, train accuracy: 0.1022, train_loss_norm:36.3978, valid_acc: 0.0966, valid_loss_norm: 35.7608\n",
      "Valid loss going down!\n",
      "Epoch: 99, train accuracy: 0.1023, train_loss_norm:35.1457, valid_acc: 0.1000, valid_loss_norm: 34.5306\n",
      "Valid loss going down!\n",
      "Epoch: 100, train accuracy: 0.1013, train_loss_norm:33.9369, valid_acc: 0.1034, valid_loss_norm: 33.3433\n",
      "Valid loss going down!\n",
      "Epoch: 101, train accuracy: 0.1016, train_loss_norm:32.7700, valid_acc: 0.1056, valid_loss_norm: 32.1970\n",
      "Valid loss going down!\n",
      "Epoch: 102, train accuracy: 0.1001, train_loss_norm:31.6435, valid_acc: 0.1034, valid_loss_norm: 31.0901\n",
      "Valid loss going down!\n",
      "Epoch: 103, train accuracy: 0.1023, train_loss_norm:30.5560, valid_acc: 0.0946, valid_loss_norm: 30.0220\n",
      "Valid loss going down!\n",
      "Epoch: 104, train accuracy: 0.1027, train_loss_norm:29.5061, valid_acc: 0.1000, valid_loss_norm: 28.9905\n",
      "Valid loss going down!\n",
      "Epoch: 105, train accuracy: 0.1008, train_loss_norm:28.4926, valid_acc: 0.0946, valid_loss_norm: 27.9947\n",
      "Valid loss going down!\n",
      "Epoch: 106, train accuracy: 0.1021, train_loss_norm:27.5141, valid_acc: 0.0966, valid_loss_norm: 27.0337\n",
      "Valid loss going down!\n",
      "Epoch: 107, train accuracy: 0.0983, train_loss_norm:26.5696, valid_acc: 0.1000, valid_loss_norm: 26.1056\n",
      "Valid loss going down!\n",
      "Epoch: 108, train accuracy: 0.1026, train_loss_norm:25.6577, valid_acc: 0.0966, valid_loss_norm: 25.2100\n",
      "Valid loss going down!\n",
      "Epoch: 109, train accuracy: 0.1026, train_loss_norm:24.7774, valid_acc: 0.0966, valid_loss_norm: 24.3451\n",
      "Valid loss going down!\n",
      "Epoch: 110, train accuracy: 0.1015, train_loss_norm:23.9276, valid_acc: 0.0984, valid_loss_norm: 23.5103\n",
      "Valid loss going down!\n",
      "Epoch: 111, train accuracy: 0.1015, train_loss_norm:23.1072, valid_acc: 0.0984, valid_loss_norm: 22.7044\n",
      "Valid loss going down!\n",
      "Epoch: 112, train accuracy: 0.1016, train_loss_norm:22.3152, valid_acc: 0.1000, valid_loss_norm: 21.9263\n",
      "Valid loss going down!\n",
      "Epoch: 113, train accuracy: 0.1017, train_loss_norm:21.5507, valid_acc: 0.1034, valid_loss_norm: 21.1750\n",
      "Valid loss going down!\n",
      "Epoch: 114, train accuracy: 0.0999, train_loss_norm:20.8126, valid_acc: 0.0984, valid_loss_norm: 20.4502\n",
      "Valid loss going down!\n",
      "Epoch: 115, train accuracy: 0.1014, train_loss_norm:20.1000, valid_acc: 0.0986, valid_loss_norm: 19.7503\n",
      "Valid loss going down!\n",
      "Epoch: 116, train accuracy: 0.1008, train_loss_norm:19.4121, valid_acc: 0.1000, valid_loss_norm: 19.0742\n",
      "Valid loss going down!\n",
      "Epoch: 117, train accuracy: 0.0987, train_loss_norm:18.7481, valid_acc: 0.0966, valid_loss_norm: 18.4219\n",
      "Valid loss going down!\n",
      "Epoch: 118, train accuracy: 0.1014, train_loss_norm:18.1070, valid_acc: 0.1056, valid_loss_norm: 17.7919\n",
      "Valid loss going down!\n",
      "Epoch: 119, train accuracy: 0.1034, train_loss_norm:17.4881, valid_acc: 0.1000, valid_loss_norm: 17.1840\n",
      "Valid loss going down!\n",
      "Epoch: 120, train accuracy: 0.1037, train_loss_norm:16.8906, valid_acc: 0.1034, valid_loss_norm: 16.5970\n",
      "Valid loss going down!\n",
      "Epoch: 121, train accuracy: 0.1008, train_loss_norm:16.3138, valid_acc: 0.0966, valid_loss_norm: 16.0305\n",
      "Valid loss going down!\n",
      "Epoch: 122, train accuracy: 0.1023, train_loss_norm:15.7570, valid_acc: 0.1052, valid_loss_norm: 15.4834\n",
      "Valid loss going down!\n",
      "Epoch: 123, train accuracy: 0.1021, train_loss_norm:15.2195, valid_acc: 0.1000, valid_loss_norm: 14.9556\n",
      "Valid loss going down!\n",
      "Epoch: 124, train accuracy: 0.1012, train_loss_norm:14.7006, valid_acc: 0.1034, valid_loss_norm: 14.4456\n",
      "Valid loss going down!\n",
      "Epoch: 125, train accuracy: 0.1019, train_loss_norm:14.1996, valid_acc: 0.0946, valid_loss_norm: 13.9535\n",
      "Valid loss going down!\n",
      "Epoch: 126, train accuracy: 0.1014, train_loss_norm:13.7160, valid_acc: 0.0986, valid_loss_norm: 13.4786\n",
      "Valid loss going down!\n",
      "Epoch: 127, train accuracy: 0.1024, train_loss_norm:13.2492, valid_acc: 0.1034, valid_loss_norm: 13.0197\n",
      "Valid loss going down!\n",
      "Epoch: 128, train accuracy: 0.1015, train_loss_norm:12.7984, valid_acc: 0.1010, valid_loss_norm: 12.5772\n",
      "Valid loss going down!\n",
      "Epoch: 129, train accuracy: 0.1006, train_loss_norm:12.3633, valid_acc: 0.0966, valid_loss_norm: 12.1496\n",
      "Valid loss going down!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 130, train accuracy: 0.1029, train_loss_norm:11.9433, valid_acc: 0.1056, valid_loss_norm: 11.7371\n",
      "Valid loss going down!\n",
      "Epoch: 131, train accuracy: 0.1007, train_loss_norm:11.5378, valid_acc: 0.1010, valid_loss_norm: 11.3385\n",
      "Valid loss going down!\n",
      "Epoch: 132, train accuracy: 0.1010, train_loss_norm:11.1463, valid_acc: 0.1034, valid_loss_norm: 10.9540\n",
      "Valid loss going down!\n",
      "Epoch: 133, train accuracy: 0.1035, train_loss_norm:10.7685, valid_acc: 0.0986, valid_loss_norm: 10.5828\n",
      "Valid loss going down!\n",
      "Epoch: 134, train accuracy: 0.1022, train_loss_norm:10.4036, valid_acc: 0.1056, valid_loss_norm: 10.2244\n",
      "Valid loss going down!\n",
      "Epoch: 135, train accuracy: 0.1006, train_loss_norm:10.0514, valid_acc: 0.1010, valid_loss_norm: 9.8784\n",
      "Valid loss going down!\n",
      "Epoch: 136, train accuracy: 0.1021, train_loss_norm:9.7114, valid_acc: 0.0946, valid_loss_norm: 9.5447\n",
      "Valid loss going down!\n",
      "Epoch: 137, train accuracy: 0.1011, train_loss_norm:9.3832, valid_acc: 0.0946, valid_loss_norm: 9.2220\n",
      "Valid loss going down!\n",
      "Epoch: 138, train accuracy: 0.1035, train_loss_norm:9.0664, valid_acc: 0.0946, valid_loss_norm: 8.9108\n",
      "Valid loss going down!\n",
      "Epoch: 139, train accuracy: 0.1026, train_loss_norm:8.7604, valid_acc: 0.0946, valid_loss_norm: 8.6101\n",
      "Valid loss going down!\n",
      "Epoch: 140, train accuracy: 0.1005, train_loss_norm:8.4651, valid_acc: 0.0984, valid_loss_norm: 8.3206\n",
      "Valid loss going down!\n",
      "Epoch: 141, train accuracy: 0.1020, train_loss_norm:8.1800, valid_acc: 0.1010, valid_loss_norm: 8.0399\n",
      "Valid loss going down!\n",
      "Epoch: 142, train accuracy: 0.1021, train_loss_norm:7.9048, valid_acc: 0.1000, valid_loss_norm: 7.7698\n",
      "Valid loss going down!\n",
      "Epoch: 143, train accuracy: 0.1014, train_loss_norm:7.6391, valid_acc: 0.0946, valid_loss_norm: 7.5087\n",
      "Valid loss going down!\n",
      "Epoch: 144, train accuracy: 0.1009, train_loss_norm:7.3827, valid_acc: 0.1056, valid_loss_norm: 7.2566\n",
      "Valid loss going down!\n",
      "Epoch: 145, train accuracy: 0.1006, train_loss_norm:7.1351, valid_acc: 0.0984, valid_loss_norm: 7.0137\n",
      "Valid loss going down!\n",
      "Epoch: 146, train accuracy: 0.1012, train_loss_norm:6.8960, valid_acc: 0.0984, valid_loss_norm: 6.7785\n",
      "Valid loss going down!\n",
      "Epoch: 147, train accuracy: 0.1024, train_loss_norm:6.6653, valid_acc: 0.1052, valid_loss_norm: 6.5519\n",
      "Valid loss going down!\n",
      "Epoch: 148, train accuracy: 0.1027, train_loss_norm:6.4425, valid_acc: 0.1000, valid_loss_norm: 6.3333\n",
      "Valid loss going down!\n",
      "Epoch: 149, train accuracy: 0.1044, train_loss_norm:6.2275, valid_acc: 0.0946, valid_loss_norm: 6.1219\n",
      "Valid loss going down!\n",
      "Epoch: 150, train accuracy: 0.1014, train_loss_norm:6.0198, valid_acc: 0.1010, valid_loss_norm: 5.9179\n",
      "Valid loss going down!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emmet.y/Desktop/CSE251B/PA2_starter/neuralnet.py:430: RuntimeWarning: overflow encountered in square\n",
      "  loss += (np.mean(layer.w ** 2)) * self.l2_penalty / 2.\n",
      "/Users/emmet.y/Desktop/CSE251B/PA2_starter/neuralnet.py:266: RuntimeWarning: invalid value encountered in greater\n",
      "  return np.where(self.x > 0, 1, 0.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, train accuracy: 0.0998, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 2, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 3, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 4, train accuracy: 0.0998, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 5, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 6, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 7, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 8, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 9, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 10, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 11, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 12, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 13, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 14, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 15, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 16, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 17, train accuracy: 0.0998, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 18, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 19, train accuracy: 0.0998, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 20, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 21, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 22, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 23, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 24, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 25, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 26, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 27, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 28, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 29, train accuracy: 0.0998, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 30, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 31, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 32, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 33, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 34, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 35, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 36, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 37, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 38, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 39, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 40, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 41, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 42, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 43, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 44, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 45, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 46, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 47, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 48, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 49, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 50, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 51, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 52, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 53, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 54, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 55, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 56, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 57, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 58, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 59, train accuracy: 0.0998, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 60, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 61, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 62, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 63, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 64, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 65, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 66, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 67, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 68, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 69, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 70, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 71, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 72, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 73, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 74, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 75, train accuracy: 0.0998, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 76, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 77, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 78, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 79, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 80, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 81, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 82, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 83, train accuracy: 0.0998, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 84, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 85, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 86, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 87, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 88, train accuracy: 0.0998, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 89, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 90, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 91, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 92, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 93, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 94, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 95, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 96, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 97, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 98, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 99, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 100, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 101, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 102, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 103, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 104, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 105, train accuracy: 0.1000, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 106, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 107, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 108, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 109, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 110, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 111, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 112, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 113, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 114, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 115, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 116, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 117, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 118, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 119, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 120, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 121, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 122, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 123, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 124, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 125, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 126, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 127, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 128, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 129, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 130, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 131, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 132, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 133, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 134, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 135, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 136, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 137, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 138, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 139, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 140, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 141, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 142, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 143, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 144, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 145, train accuracy: 0.0998, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 146, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 147, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 148, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 149, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 150, train accuracy: 0.0999, train_loss_norm:nan, valid_acc: 0.1010, valid_loss_norm: nan\n",
      "Valid loss going down!\n",
      "Epoch: 1, train accuracy: 0.2520, train_loss_norm:0.2389, valid_acc: 0.2834, valid_loss_norm: 0.1985\n",
      "Valid loss going down!\n",
      "Epoch: 2, train accuracy: 0.3164, train_loss_norm:0.1945, valid_acc: 0.3020, valid_loss_norm: 0.1939\n",
      "Valid loss going down!\n",
      "Epoch: 3, train accuracy: 0.3348, train_loss_norm:0.1899, valid_acc: 0.3292, valid_loss_norm: 0.1883\n",
      "Valid loss going down!\n",
      "Epoch: 4, train accuracy: 0.3497, train_loss_norm:0.1846, valid_acc: 0.3428, valid_loss_norm: 0.1838\n",
      "Valid loss going down!\n",
      "Epoch: 5, train accuracy: 0.3634, train_loss_norm:0.1810, valid_acc: 0.3364, valid_loss_norm: 0.1853\n",
      "Valid loss go up!\n",
      "Current patience count: 1\n",
      "Epoch: 6, train accuracy: 0.3745, train_loss_norm:0.1784, valid_acc: 0.3376, valid_loss_norm: 0.1830\n",
      "Valid loss going down!\n",
      "Epoch: 7, train accuracy: 0.3825, train_loss_norm:0.1758, valid_acc: 0.3560, valid_loss_norm: 0.1794\n",
      "Valid loss going down!\n",
      "Epoch: 8, train accuracy: 0.3955, train_loss_norm:0.1723, valid_acc: 0.3532, valid_loss_norm: 0.1800\n",
      "Valid loss go up!\n",
      "Current patience count: 1\n",
      "Epoch: 9, train accuracy: 0.3991, train_loss_norm:0.1714, valid_acc: 0.3716, valid_loss_norm: 0.1758\n",
      "Valid loss going down!\n",
      "Epoch: 10, train accuracy: 0.4036, train_loss_norm:0.1701, valid_acc: 0.3794, valid_loss_norm: 0.1755\n",
      "Valid loss going down!\n",
      "Epoch: 11, train accuracy: 0.4129, train_loss_norm:0.1679, valid_acc: 0.3716, valid_loss_norm: 0.1766\n",
      "Valid loss go up!\n",
      "Current patience count: 1\n",
      "Epoch: 12, train accuracy: 0.4142, train_loss_norm:0.1671, valid_acc: 0.3676, valid_loss_norm: 0.1757\n",
      "Valid loss going down!\n",
      "Epoch: 13, train accuracy: 0.4258, train_loss_norm:0.1647, valid_acc: 0.3746, valid_loss_norm: 0.1763\n",
      "Valid loss go up!\n",
      "Current patience count: 1\n",
      "Epoch: 14, train accuracy: 0.4296, train_loss_norm:0.1632, valid_acc: 0.3862, valid_loss_norm: 0.1748\n",
      "Valid loss going down!\n",
      "Epoch: 15, train accuracy: 0.4374, train_loss_norm:0.1608, valid_acc: 0.3922, valid_loss_norm: 0.1745\n",
      "Valid loss going down!\n",
      "Epoch: 16, train accuracy: 0.4437, train_loss_norm:0.1598, valid_acc: 0.3954, valid_loss_norm: 0.1707\n",
      "Valid loss going down!\n",
      "Epoch: 17, train accuracy: 0.4498, train_loss_norm:0.1576, valid_acc: 0.3860, valid_loss_norm: 0.1719\n",
      "Valid loss go up!\n",
      "Current patience count: 1\n",
      "Epoch: 18, train accuracy: 0.4561, train_loss_norm:0.1571, valid_acc: 0.3890, valid_loss_norm: 0.1723\n",
      "Valid loss go up!\n",
      "Current patience count: 2\n",
      "Epoch: 19, train accuracy: 0.4551, train_loss_norm:0.1566, valid_acc: 0.3964, valid_loss_norm: 0.1716\n",
      "Valid loss going down!\n",
      "Epoch: 20, train accuracy: 0.4613, train_loss_norm:0.1552, valid_acc: 0.3900, valid_loss_norm: 0.1724\n",
      "Valid loss go up!\n",
      "Current patience count: 1\n",
      "Epoch: 21, train accuracy: 0.4658, train_loss_norm:0.1536, valid_acc: 0.3876, valid_loss_norm: 0.1733\n",
      "Valid loss go up!\n",
      "Current patience count: 2\n",
      "Epoch: 22, train accuracy: 0.4744, train_loss_norm:0.1518, valid_acc: 0.3988, valid_loss_norm: 0.1703\n",
      "Valid loss going down!\n",
      "Epoch: 23, train accuracy: 0.4797, train_loss_norm:0.1503, valid_acc: 0.4072, valid_loss_norm: 0.1687\n",
      "Valid loss going down!\n",
      "Epoch: 24, train accuracy: 0.4793, train_loss_norm:0.1500, valid_acc: 0.4014, valid_loss_norm: 0.1698\n",
      "Valid loss go up!\n",
      "Current patience count: 1\n",
      "Epoch: 25, train accuracy: 0.4832, train_loss_norm:0.1492, valid_acc: 0.3932, valid_loss_norm: 0.1701\n",
      "Valid loss go up!\n",
      "Current patience count: 2\n",
      "Epoch: 26, train accuracy: 0.4889, train_loss_norm:0.1477, valid_acc: 0.4100, valid_loss_norm: 0.1682\n",
      "Valid loss going down!\n",
      "Epoch: 27, train accuracy: 0.4937, train_loss_norm:0.1466, valid_acc: 0.4104, valid_loss_norm: 0.1687\n",
      "Valid loss go up!\n",
      "Current patience count: 1\n",
      "Epoch: 28, train accuracy: 0.4980, train_loss_norm:0.1454, valid_acc: 0.3930, valid_loss_norm: 0.1732\n",
      "Valid loss go up!\n",
      "Current patience count: 2\n",
      "Epoch: 29, train accuracy: 0.4983, train_loss_norm:0.1454, valid_acc: 0.3870, valid_loss_norm: 0.1767\n",
      "Valid loss go up!\n",
      "Current patience count: 3\n",
      "Epoch: 30, train accuracy: 0.5009, train_loss_norm:0.1449, valid_acc: 0.3950, valid_loss_norm: 0.1713\n",
      "Valid loss going down!\n",
      "Epoch: 31, train accuracy: 0.5071, train_loss_norm:0.1434, valid_acc: 0.3998, valid_loss_norm: 0.1705\n",
      "Valid loss going down!\n",
      "Epoch: 32, train accuracy: 0.5100, train_loss_norm:0.1431, valid_acc: 0.4090, valid_loss_norm: 0.1684\n",
      "Valid loss going down!\n",
      "Epoch: 33, train accuracy: 0.5131, train_loss_norm:0.1414, valid_acc: 0.4026, valid_loss_norm: 0.1689\n",
      "Valid loss go up!\n",
      "Current patience count: 1\n",
      "Epoch: 34, train accuracy: 0.5165, train_loss_norm:0.1408, valid_acc: 0.4114, valid_loss_norm: 0.1696\n",
      "Valid loss go up!\n",
      "Current patience count: 2\n",
      "Epoch: 35, train accuracy: 0.5165, train_loss_norm:0.1411, valid_acc: 0.4040, valid_loss_norm: 0.1717\n",
      "Valid loss go up!\n",
      "Current patience count: 3\n",
      "Epoch: 36, train accuracy: 0.5234, train_loss_norm:0.1393, valid_acc: 0.4094, valid_loss_norm: 0.1684\n",
      "Valid loss going down!\n",
      "Epoch: 37, train accuracy: 0.5304, train_loss_norm:0.1372, valid_acc: 0.4128, valid_loss_norm: 0.1689\n",
      "Valid loss go up!\n",
      "Current patience count: 1\n",
      "Epoch: 38, train accuracy: 0.5283, train_loss_norm:0.1375, valid_acc: 0.4114, valid_loss_norm: 0.1710\n",
      "Valid loss go up!\n",
      "Current patience count: 2\n",
      "Epoch: 39, train accuracy: 0.5332, train_loss_norm:0.1368, valid_acc: 0.4178, valid_loss_norm: 0.1688\n",
      "Valid loss going down!\n",
      "Epoch: 40, train accuracy: 0.5322, train_loss_norm:0.1363, valid_acc: 0.4112, valid_loss_norm: 0.1703\n",
      "Valid loss go up!\n",
      "Current patience count: 1\n",
      "Epoch: 41, train accuracy: 0.5362, train_loss_norm:0.1350, valid_acc: 0.4162, valid_loss_norm: 0.1677\n",
      "Valid loss going down!\n",
      "Epoch: 42, train accuracy: 0.5369, train_loss_norm:0.1357, valid_acc: 0.4012, valid_loss_norm: 0.1709\n",
      "Valid loss go up!\n",
      "Current patience count: 1\n",
      "Epoch: 43, train accuracy: 0.5405, train_loss_norm:0.1353, valid_acc: 0.4168, valid_loss_norm: 0.1697\n",
      "Valid loss going down!\n",
      "Epoch: 44, train accuracy: 0.5399, train_loss_norm:0.1348, valid_acc: 0.4198, valid_loss_norm: 0.1692\n",
      "Valid loss going down!\n",
      "Epoch: 45, train accuracy: 0.5479, train_loss_norm:0.1330, valid_acc: 0.4204, valid_loss_norm: 0.1696\n",
      "Valid loss go up!\n",
      "Current patience count: 1\n",
      "Epoch: 46, train accuracy: 0.5489, train_loss_norm:0.1327, valid_acc: 0.4028, valid_loss_norm: 0.1729\n",
      "Valid loss go up!\n",
      "Current patience count: 2\n",
      "Epoch: 47, train accuracy: 0.5521, train_loss_norm:0.1318, valid_acc: 0.4220, valid_loss_norm: 0.1685\n",
      "Valid loss going down!\n",
      "Epoch: 48, train accuracy: 0.5541, train_loss_norm:0.1312, valid_acc: 0.4242, valid_loss_norm: 0.1691\n",
      "Valid loss go up!\n",
      "Current patience count: 1\n",
      "Epoch: 49, train accuracy: 0.5557, train_loss_norm:0.1308, valid_acc: 0.4114, valid_loss_norm: 0.1719\n",
      "Valid loss go up!\n",
      "Current patience count: 2\n",
      "Epoch: 50, train accuracy: 0.5569, train_loss_norm:0.1312, valid_acc: 0.4228, valid_loss_norm: 0.1670\n",
      "Valid loss going down!\n",
      "Epoch: 51, train accuracy: 0.5566, train_loss_norm:0.1302, valid_acc: 0.4154, valid_loss_norm: 0.1721\n",
      "Valid loss go up!\n",
      "Current patience count: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 52, train accuracy: 0.5592, train_loss_norm:0.1302, valid_acc: 0.4316, valid_loss_norm: 0.1671\n",
      "Valid loss going down!\n",
      "Epoch: 53, train accuracy: 0.5657, train_loss_norm:0.1287, valid_acc: 0.4226, valid_loss_norm: 0.1686\n",
      "Valid loss go up!\n",
      "Current patience count: 1\n",
      "Epoch: 54, train accuracy: 0.5672, train_loss_norm:0.1280, valid_acc: 0.4102, valid_loss_norm: 0.1702\n",
      "Valid loss go up!\n",
      "Current patience count: 2\n",
      "Epoch: 55, train accuracy: 0.5647, train_loss_norm:0.1291, valid_acc: 0.4188, valid_loss_norm: 0.1696\n",
      "Valid loss going down!\n",
      "Epoch: 56, train accuracy: 0.5724, train_loss_norm:0.1279, valid_acc: 0.4192, valid_loss_norm: 0.1691\n",
      "Valid loss going down!\n",
      "Epoch: 57, train accuracy: 0.5698, train_loss_norm:0.1278, valid_acc: 0.4280, valid_loss_norm: 0.1706\n",
      "Valid loss go up!\n",
      "Current patience count: 1\n",
      "Epoch: 58, train accuracy: 0.5711, train_loss_norm:0.1274, valid_acc: 0.4252, valid_loss_norm: 0.1743\n",
      "Valid loss go up!\n",
      "Current patience count: 2\n",
      "Epoch: 59, train accuracy: 0.5764, train_loss_norm:0.1258, valid_acc: 0.4280, valid_loss_norm: 0.1676\n",
      "Valid loss going down!\n",
      "Epoch: 60, train accuracy: 0.5759, train_loss_norm:0.1261, valid_acc: 0.4204, valid_loss_norm: 0.1770\n",
      "Valid loss go up!\n",
      "Current patience count: 1\n",
      "Epoch: 61, train accuracy: 0.5767, train_loss_norm:0.1263, valid_acc: 0.4246, valid_loss_norm: 0.1694\n",
      "Valid loss going down!\n",
      "Epoch: 62, train accuracy: 0.5829, train_loss_norm:0.1247, valid_acc: 0.4258, valid_loss_norm: 0.1679\n",
      "Valid loss going down!\n",
      "Epoch: 63, train accuracy: 0.5853, train_loss_norm:0.1246, valid_acc: 0.4204, valid_loss_norm: 0.1702\n",
      "Valid loss go up!\n",
      "Current patience count: 1\n",
      "Epoch: 64, train accuracy: 0.5808, train_loss_norm:0.1246, valid_acc: 0.4286, valid_loss_norm: 0.1684\n",
      "Valid loss going down!\n",
      "Epoch: 65, train accuracy: 0.5892, train_loss_norm:0.1229, valid_acc: 0.4350, valid_loss_norm: 0.1644\n",
      "Valid loss going down!\n",
      "Epoch: 66, train accuracy: 0.5874, train_loss_norm:0.1234, valid_acc: 0.4232, valid_loss_norm: 0.1704\n",
      "Valid loss go up!\n",
      "Current patience count: 1\n",
      "Epoch: 67, train accuracy: 0.5879, train_loss_norm:0.1231, valid_acc: 0.4336, valid_loss_norm: 0.1689\n",
      "Valid loss going down!\n",
      "Epoch: 68, train accuracy: 0.5878, train_loss_norm:0.1233, valid_acc: 0.4284, valid_loss_norm: 0.1678\n",
      "Valid loss going down!\n",
      "Epoch: 69, train accuracy: 0.5876, train_loss_norm:0.1233, valid_acc: 0.4308, valid_loss_norm: 0.1693\n",
      "Valid loss go up!\n",
      "Current patience count: 1\n",
      "Epoch: 70, train accuracy: 0.5961, train_loss_norm:0.1218, valid_acc: 0.4378, valid_loss_norm: 0.1674\n",
      "Valid loss going down!\n",
      "Epoch: 71, train accuracy: 0.5965, train_loss_norm:0.1206, valid_acc: 0.4288, valid_loss_norm: 0.1700\n",
      "Valid loss go up!\n",
      "Current patience count: 1\n",
      "Epoch: 72, train accuracy: 0.5986, train_loss_norm:0.1213, valid_acc: 0.4328, valid_loss_norm: 0.1691\n",
      "Valid loss going down!\n",
      "Epoch: 73, train accuracy: 0.5974, train_loss_norm:0.1214, valid_acc: 0.4354, valid_loss_norm: 0.1689\n",
      "Valid loss going down!\n",
      "Epoch: 74, train accuracy: 0.5985, train_loss_norm:0.1209, valid_acc: 0.4304, valid_loss_norm: 0.1692\n",
      "Valid loss go up!\n",
      "Current patience count: 1\n",
      "Epoch: 75, train accuracy: 0.5962, train_loss_norm:0.1215, valid_acc: 0.4262, valid_loss_norm: 0.1711\n",
      "Valid loss go up!\n",
      "Current patience count: 2\n",
      "Epoch: 76, train accuracy: 0.6002, train_loss_norm:0.1212, valid_acc: 0.4262, valid_loss_norm: 0.1709\n",
      "Valid loss going down!\n",
      "Epoch: 77, train accuracy: 0.6031, train_loss_norm:0.1202, valid_acc: 0.4344, valid_loss_norm: 0.1715\n",
      "Valid loss go up!\n",
      "Current patience count: 1\n",
      "Epoch: 78, train accuracy: 0.6088, train_loss_norm:0.1187, valid_acc: 0.4348, valid_loss_norm: 0.1717\n",
      "Valid loss go up!\n",
      "Current patience count: 2\n",
      "Epoch: 79, train accuracy: 0.6041, train_loss_norm:0.1188, valid_acc: 0.4406, valid_loss_norm: 0.1722\n",
      "Valid loss go up!\n",
      "Current patience count: 3\n",
      "Epoch: 80, train accuracy: 0.6054, train_loss_norm:0.1195, valid_acc: 0.4280, valid_loss_norm: 0.1710\n",
      "Valid loss going down!\n",
      "Epoch: 81, train accuracy: 0.5998, train_loss_norm:0.1209, valid_acc: 0.4342, valid_loss_norm: 0.1693\n",
      "Valid loss going down!\n",
      "Epoch: 82, train accuracy: 0.6110, train_loss_norm:0.1174, valid_acc: 0.4358, valid_loss_norm: 0.1700\n",
      "Valid loss go up!\n",
      "Current patience count: 1\n",
      "Epoch: 83, train accuracy: 0.6135, train_loss_norm:0.1175, valid_acc: 0.4392, valid_loss_norm: 0.1690\n",
      "Valid loss going down!\n",
      "Epoch: 84, train accuracy: 0.6123, train_loss_norm:0.1177, valid_acc: 0.4430, valid_loss_norm: 0.1685\n",
      "Valid loss going down!\n",
      "Epoch: 85, train accuracy: 0.6114, train_loss_norm:0.1179, valid_acc: 0.4240, valid_loss_norm: 0.1733\n",
      "Valid loss go up!\n",
      "Current patience count: 1\n",
      "Epoch: 86, train accuracy: 0.6129, train_loss_norm:0.1172, valid_acc: 0.4294, valid_loss_norm: 0.1709\n",
      "Valid loss going down!\n",
      "Epoch: 87, train accuracy: 0.6139, train_loss_norm:0.1169, valid_acc: 0.4266, valid_loss_norm: 0.1716\n",
      "Valid loss go up!\n",
      "Current patience count: 1\n",
      "Epoch: 88, train accuracy: 0.6182, train_loss_norm:0.1158, valid_acc: 0.4330, valid_loss_norm: 0.1710\n",
      "Valid loss going down!\n",
      "Epoch: 89, train accuracy: 0.6157, train_loss_norm:0.1162, valid_acc: 0.4262, valid_loss_norm: 0.1701\n",
      "Valid loss going down!\n",
      "Epoch: 90, train accuracy: 0.6154, train_loss_norm:0.1169, valid_acc: 0.4314, valid_loss_norm: 0.1682\n",
      "Valid loss going down!\n",
      "Epoch: 91, train accuracy: 0.6176, train_loss_norm:0.1157, valid_acc: 0.4394, valid_loss_norm: 0.1700\n",
      "Valid loss go up!\n",
      "Current patience count: 1\n",
      "Epoch: 92, train accuracy: 0.6236, train_loss_norm:0.1152, valid_acc: 0.4340, valid_loss_norm: 0.1699\n",
      "Valid loss going down!\n"
     ]
    }
   ],
   "source": [
    "all_train_loss_record = []\n",
    "all_train_acc_record = []\n",
    "\n",
    "all_valid_loss_record = []\n",
    "all_valid_acc_record = []\n",
    "\n",
    "all_test_acc_record = []\n",
    "epoch_record = []\n",
    "\n",
    "for activation in activations:\n",
    "    config['activation'] = activation\n",
    "    model = Neuralnetwork(config)    \n",
    "    epoch, train_loss_record, train_accuracy_record, valid_loss_record, valid_accuracy_record = train(model,X_train,y_train,X_valid,y_valid,config)\n",
    "    all_train_loss_record.append(train_loss_record)\n",
    "    all_train_acc_record.append(train_accuracy_record)\n",
    "    all_valid_loss_record.append(valid_loss_record)\n",
    "    all_valid_acc_record.append(valid_accuracy_record)\n",
    "\n",
    "    # Recall parameters with minimum validation loss\n",
    "    model.save_load_weight(save=False) # load best weights\n",
    "    test_accuracy = test(model, X_test, y_test) \n",
    "    all_test_acc_record.append(test_accuracy)\n",
    "    epoch_record.append(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot train and valid loss on one graph\n",
    "\n",
    "# Line type\n",
    "train_loss_lt = ['-b', '-r', '-g']\n",
    "valid_loss_lt = ['--b', '--r', '--g']\n",
    "\n",
    "for i, activation in enumerate(activations):\n",
    "    plt.plot(np.arange(epoch_record[i]+1), all_train_loss_record[i], train_loss_lt[i], label=f\"Train Loss: {activation}\")\n",
    "    plt.plot(np.arange(epoch_record[i]+1), all_valid_loss_record[i], valid_loss_lt[i], label=f\"Valid Loss: {activation}\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Normalized Loss')\n",
    "plt.title(\"Train and Validation Loss vs. Epochs\")\n",
    "plt.legend()\n",
    "plt.savefig('plots/(e)_act_loss.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot Train and valid acc on another\n",
    "\n",
    "# Line type\n",
    "train_acc_lt = ['-b', '-r', '-g']\n",
    "valid_acc_lt = ['--b', '--r', '--g']\n",
    "\n",
    "for i, activation in enumerate(activations):\n",
    "    plt.plot(np.arange(epoch_record[i]+1), all_train_acc_record[i], train_acc_lt[i], label=f\"Train Acc: {activation}\")\n",
    "    plt.plot(np.arange(epoch_record[i]+1), all_valid_acc_record[i], valid_acc_lt[i], label=f\"Valid Acc: {activation}\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(\"Train and Validation Accuracy vs. Epochs\")\n",
    "plt.legend()\n",
    "plt.savefig('plots/(e)_act_acc.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Update PAram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from neuralnet import *\n",
    "from random import shuffle\n",
    "import numpy as np\n",
    "\n",
    "# Load the configuration.\n",
    "config = load_config(\"./data\")\n",
    "# Load model parameters\n",
    "# TODO: GET BEST PARAMS FROM (d) Regularization\n",
    "config = {}\n",
    "config['layer_specs'] = [3072, 64, 64, 10]\n",
    "config['learning_rate'] = 0.005\n",
    "config['batch_size'] = 256 \n",
    "config['epochs'] = 150\n",
    "config['early_stop'] = True \n",
    "config['early_stop_epoch'] = 5  \n",
    "config['L2_penalty'] = 0.001 \n",
    "config['momentum'] = True  \n",
    "config['momentum_gamma'] = 0.9  \n",
    "\n",
    "# Test different activations (not including tanh)\n",
    "activations = ['ReLU','leakyReLU', 'sigmoid']\n",
    "# Load the data\n",
    "X_train, y_train, X_stats = load_data(path=\"./data\", stats=None, mode=\"train\")\n",
    "X_test, y_test = load_data(path=\"./data\", stats=X_stats, mode=\"test\")\n",
    "X_train, y_train, X_valid, y_valid = split_data(X_train,y_train)\n",
    "all_train_loss_record = []\n",
    "all_train_acc_record = []\n",
    "\n",
    "all_valid_loss_record = []\n",
    "all_valid_acc_record = []\n",
    "\n",
    "all_test_acc_record = []\n",
    "epoch_record = []\n",
    "\n",
    "for activation in activations:\n",
    "    config['activation'] = activation\n",
    "    model = Neuralnetwork(config)\n",
    "    model.scale_weights(0.05)\n",
    "    \n",
    "    epoch, train_loss_record, train_accuracy_record, valid_loss_record, valid_accuracy_record = train(model,X_train,y_train,X_valid,y_valid,config)\n",
    "    all_train_loss_record.append(train_loss_record)\n",
    "    all_train_acc_record.append(train_accuracy_record)\n",
    "    all_valid_loss_record.append(valid_loss_record)\n",
    "    all_valid_acc_record.append(valid_accuracy_record)\n",
    "\n",
    "    # Recall parameters with minimum validation loss\n",
    "    model.save_load_weight(save=False) # load best weights\n",
    "    test_accuracy = test(model, X_test, y_test) \n",
    "    all_test_acc_record.append(test_accuracy)\n",
    "    epoch_record.append(epoch)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot train and valid loss on one graph\n",
    "\n",
    "# Line type\n",
    "train_loss_lt = ['-b', '-r', '-g']\n",
    "valid_loss_lt = ['--b', '--r', '--g']\n",
    "\n",
    "for i, activation in enumerate(activations):\n",
    "    plt.plot(np.arange(epoch_record[i]+1), all_train_loss_record[i], train_loss_lt[i], label=f\"Train Loss: {activation}\")\n",
    "    plt.plot(np.arange(epoch_record[i]+1), all_valid_loss_record[i], valid_loss_lt[i], label=f\"Valid Loss: {activation}\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Normalized Loss')\n",
    "plt.title(\"Train and Validation Loss vs. Epochs\")\n",
    "plt.legend()\n",
    "plt.savefig('plots/(e)_act_loss.png')\n",
    "plt.show()\n",
    "\n",
    "## Plot Train and valid acc on another\n",
    "\n",
    "# Line type\n",
    "train_acc_lt = ['-b', '-r', '-g']\n",
    "valid_acc_lt = ['--b', '--r', '--g']\n",
    "\n",
    "for i, activation in enumerate(activations):\n",
    "    plt.plot(np.arange(epoch_record[i]+1), all_train_acc_record[i], train_acc_lt[i], label=f\"Train Acc: {activation}\")\n",
    "    plt.plot(np.arange(epoch_record[i]+1), all_valid_acc_record[i], valid_acc_lt[i], label=f\"Valid Acc: {activation}\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(\"Train and Validation Accuracy vs. Epochs\")\n",
    "plt.legend()\n",
    "plt.savefig('plots/(e)_act_acc.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "005f4ed24810181fa8b2266ec303702d6575bedfaa41c7848d327e7f780b3129"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
