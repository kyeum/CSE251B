{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "10 10\n"
     ]
    }
   ],
   "source": [
    "from neuralnet import *\n",
    "from random import shuffle\n",
    "import numpy as np\n",
    "\n",
    "# Load the configuration.\n",
    "config = load_config(\"./data\")\n",
    "\n",
    "X_train, y_train, X_stats = load_data(path=\"./data\", stats=None, mode=\"train\")\n",
    "\n",
    "# Get 10 examples, 1 from each category.\n",
    "X_sub = []\n",
    "y_sub = []\n",
    "for k in range(10):\n",
    "    indices = y_train[:,k] == 1\n",
    "    X_sub.append(X_train[indices][0])\n",
    "    y_sub.append(y_train[indices][0])\n",
    "print(len(X_sub), len(y_sub))\n",
    "X_sub = np.array(X_sub)\n",
    "y_sub = np.array(y_sub)\n",
    "\n",
    "# Load model para\n",
    "config_prob_b = {}\n",
    "config_prob_b['layer_specs'] = [3072, 64,64, 10]\n",
    "config_prob_b['activation'] = 'tanh'\n",
    "config_prob_b['learning_rate'] = 0.001\n",
    "config_prob_b['batch_size'] = 128 \n",
    "config_prob_b['epochs'] = 100  \n",
    "config_prob_b['early_stop'] = True \n",
    "config_prob_b['early_stop_epoch'] = 5  \n",
    "config_prob_b['L2_penalty'] = 0 \n",
    "config_prob_b['momentum'] = True\n",
    "config_prob_b['momentum_gamma'] = 0.9  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layers: 5\n",
      "epsilon used, expected diff: (0.01, 0.0001)\n",
      "(10,)\n",
      "actual: -0.03165755023252677\n",
      "est: -0.0032040621349538334\n",
      "Output bias weight diff: 0.0284534881\n",
      "actual: 7.325320419415491e-05\n",
      "est: 7.315655004003219e-06\n",
      "Hidden Layer 2 bias weight diff: -0.0000659375\n",
      "actual: -0.021807368175824994\n",
      "est: -0.002176287567512425\n",
      "Hidden Layer 1 bias weight diff: 0.0196310806\n",
      "actual: -0.16683971376113468\n",
      "est: -0.01664568843646741\n",
      "Hidden2 to output weight diff 1: 0.1501940253\n",
      "actual: 0.003184207354738211\n",
      "est: 0.00019100993028375868\n",
      "Hidden2 to output weight diff 2: -0.0029931974\n",
      "actual: -7.363770472256348e-05\n",
      "est: -7.354105180379378e-06\n",
      "Hidden1 to Hidden2 weight diff 1: 0.0000662836\n",
      "actual: -0.10628993898014337\n",
      "est: -0.010628584376004557\n",
      "Hidden1 to Hidden2 weight diff 2: 0.0956613546\n",
      "actual: 0.024485076445083118\n",
      "est: 0.002443754042669166\n",
      "Input to hidden 1 weight diff 1: -0.0220413224\n",
      "actual: 8.305234966487929e-11\n",
      "est: 8.304468224196171e-12\n",
      "Input to hidden 2 weight diff 2: -0.0000000001\n"
     ]
    }
   ],
   "source": [
    "# d_b d_w comparison\n",
    "\n",
    "## Part (b) Estimation of bias weight and weight\n",
    "def Num_Est_b(model, layer, eps, output_idx):\n",
    "    layer.b[0][output_idx] += eps # E(w+e)\n",
    "    loss_1 = model.forward(X_sub, y_sub)[1]\n",
    "    layer.b[0][output_idx] -= 2*eps # E(w-e)\n",
    "    loss_2 = model.forward(X_sub, y_sub)[1]\n",
    "    layer.b[0][output_idx] += eps # back to normal\n",
    "    #print(\"diff:\", loss_1 - loss_2)\n",
    "    #print(\"loss:\", (loss_1 - loss_2) / (2 * eps))\n",
    "    return (loss_1 - loss_2) / (2 * eps)  # Numerical estimation for dEdW\n",
    "\n",
    "def Num_Est_w(model, layer, eps, input_idx, output_idx):\n",
    "    layer.w[input_idx][output_idx] += eps # E(w+e)\n",
    "    loss_1 = model.forward(X_sub, y_sub)[1]\n",
    "    layer.w[input_idx][output_idx] -= 2*eps # E(w-e)\n",
    "    loss_2 = model.forward(X_sub, y_sub)[1]\n",
    "    layer.w[input_idx][output_idx] += eps # back to normal\n",
    "    #print(\"diff:\", loss_1 - loss_2)\n",
    "    #print(\"loss:\", (loss_1 - loss_2) / (2 * eps))\n",
    "    return (loss_1 - loss_2) / (2 * eps)  # Numerical estimation for dEdW\n",
    "\n",
    "model_b = Neuralnetwork(config_prob_b)\n",
    "\n",
    "loss_train = model_b.forward(X_sub, targets=y_sub)\n",
    "model_b.backward()\n",
    "\n",
    "print(\"Layers:\", len(model_b.layers))\n",
    "# Weights to modify:\n",
    "# 1 output bias weight\n",
    "# 1 hidden bias weight for each hidden layer\n",
    "# 2 hidden to output weights\n",
    "# 2 input to hidden weights\n",
    "# Show that the grad between is within O(eps^2) of backprop weights.\n",
    "db = []\n",
    "dw = []\n",
    "db_est = []\n",
    "dw_est = []\n",
    "\n",
    "eps = 0.01\n",
    "\n",
    "print(f\"epsilon used, expected diff: {eps , eps**2}\")\n",
    "\n",
    "\n",
    "# Hidden Layer 1\n",
    "hidden_layer_1 = model_b.layers[0]\n",
    "# Hidden Layer 2\n",
    "hidden_layer_2 = model_b.layers[2]\n",
    "# Output Layer\n",
    "output_layer = model_b.layers[4]\n",
    "\n",
    "## Bias\n",
    "# 1 output bias weight\n",
    "input_idx = 0\n",
    "output_idx = 1\n",
    "cur_layer = output_layer\n",
    "print(cur_layer.d_b.shape)\n",
    "\n",
    "db_est.append(Num_Est_b(model_b, cur_layer, eps, output_idx))\n",
    "db.append(cur_layer.d_b[output_idx]) \n",
    "print(\"actual:\", db[-1])\n",
    "print(\"est:\", db_est[-1])\n",
    "print(f\"Output bias weight diff: {db_est[-1] - db[-1]:.10f}\")\n",
    "\n",
    "# 1 hidden bias for hidden layer 2\n",
    "cur_layer = hidden_layer_2\n",
    "db_est.append(Num_Est_b(model_b, cur_layer, eps, output_idx))\n",
    "db.append(cur_layer.d_b[output_idx]) \n",
    "print(\"actual:\", db[-1])\n",
    "print(\"est:\", db_est[-1])\n",
    "print(f\"Hidden Layer 2 bias weight diff: {db_est[-1] - db[-1]:.10f}\")\n",
    "\n",
    "# 1 hidden bias for hidden layer 1\n",
    "cur_layer = hidden_layer_1\n",
    "db_est.append(Num_Est_b(model_b, cur_layer, eps, output_idx))\n",
    "db.append(cur_layer.d_b[output_idx]) \n",
    "print(\"actual:\", db[-1])\n",
    "print(\"est:\", db_est[-1])\n",
    "print(f\"Hidden Layer 1 bias weight diff: {db_est[-1] - db[-1]:.10f}\")\n",
    "\n",
    "\n",
    "## Weight\n",
    "\n",
    "# 2 hidden to output weights\n",
    "input_idx = 0\n",
    "output_idx = 1\n",
    "cur_layer = output_layer\n",
    "dw_est.append(Num_Est_w(model_b, cur_layer, eps, input_idx, output_idx))\n",
    "dw.append(cur_layer.d_w[input_idx][output_idx])\n",
    "print(\"actual:\", dw[-1])\n",
    "print(\"est:\", dw_est[-1])\n",
    "print(f\"Hidden2 to output weight diff 1: {dw_est[-1] - dw[-1]:.10f}\")\n",
    "input_idx = 0\n",
    "output_idx = 2\n",
    "dw_est.append(Num_Est_w(model_b, cur_layer, eps, input_idx, output_idx))\n",
    "dw.append(cur_layer.d_w[input_idx][output_idx])\n",
    "print(\"actual:\", dw[-1])\n",
    "print(\"est:\", dw_est[-1])\n",
    "print(f\"Hidden2 to output weight diff 2: {dw_est[-1] - dw[-1]:.10f}\")\n",
    "\n",
    "\n",
    "# 1 hidden to 2 hidden weights\n",
    "input_idx = 0\n",
    "output_idx = 1\n",
    "cur_layer = hidden_layer_2\n",
    "dw_est.append(Num_Est_w(model_b, cur_layer, eps, input_idx, output_idx))\n",
    "dw.append(cur_layer.d_w[input_idx][output_idx])\n",
    "print(\"actual:\", dw[-1])\n",
    "print(\"est:\", dw_est[-1])\n",
    "print(f\"Hidden1 to Hidden2 weight diff 1: {dw_est[-1] - dw[-1]:.10f}\")\n",
    "input_idx = 0\n",
    "output_idx = 2\n",
    "dw_est.append(Num_Est_w(model_b, cur_layer, eps, input_idx, output_idx))\n",
    "dw.append(cur_layer.d_w[input_idx][output_idx])\n",
    "print(\"actual:\", dw[-1])\n",
    "print(\"est:\", dw_est[-1])\n",
    "print(f\"Hidden1 to Hidden2 weight diff 2: {dw_est[-1] - dw[-1]:.10f}\")\n",
    "\n",
    "# 2 input to hidden weights\n",
    "input_idx = 0\n",
    "output_idx = 1\n",
    "cur_layer = hidden_layer_1\n",
    "dw_est.append(Num_Est_w(model_b, cur_layer, eps, input_idx, output_idx))\n",
    "dw.append(cur_layer.d_w[input_idx][output_idx])\n",
    "print(\"actual:\", dw[-1])\n",
    "print(\"est:\", dw_est[-1])\n",
    "print(f\"Input to hidden 1 weight diff 1: {dw_est[-1] - dw[-1]:.10f}\")\n",
    "input_idx = 0\n",
    "output_idx = 2\n",
    "dw_est.append(Num_Est_w(model_b, cur_layer, eps, input_idx, output_idx))\n",
    "dw.append(cur_layer.d_w[input_idx][output_idx])\n",
    "print(\"actual:\", dw[-1])\n",
    "print(\"est:\", dw_est[-1])\n",
    "print(f\"Input to hidden 2 weight diff 2: {dw_est[-1] - dw[-1]:.10f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'd_b' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/wt/l4n6hhns3dz9d7ljspfyxvd40000gn/T/ipykernel_12545/3141750882.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel_b\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0md_b\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md_b\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# multiply by the scaling factor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0md_w\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md_w\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md_w\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# multiply by the scaling factor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Real b: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'd_b' is not defined"
     ]
    }
   ],
   "source": [
    "for layer in model_b.layers:\n",
    "    if isinstance(layer, Layer):\n",
    "        d_b.append(layer.d_b[1] * 10) # multiply by the scaling factor\n",
    "        d_w.append([np.multiply(layer.d_w[0][1], 10) ,np.multiply(layer.d_w[0][2], 10)]) # multiply by the scaling factor\n",
    "print('Real b: {}'.format(d_b))\n",
    "print('Estimate b: {}'.format(d_b_estimate))\n",
    "print('Real w: {}'.format(d_w))\n",
    "print('Estimate w: {}'.format( d_w_estimate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "005f4ed24810181fa8b2266ec303702d6575bedfaa41c7848d327e7f780b3129"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
