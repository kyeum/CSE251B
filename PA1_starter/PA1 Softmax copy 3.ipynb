{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pca import PCA\n",
    "import argparse\n",
    "import network\n",
    "import os, random, sys\n",
    "from data import traffic_sign, generate_k_fold_set, onehot_encode, onehot_decode, z_score_normalize, append_bias\n",
    "from model.softmax import SoftmaxRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34799, 1024)\n",
      "(34799,)\n",
      "float32\n",
      "uint8\n"
     ]
    }
   ],
   "source": [
    "### Q6(a) - Evaluate Network on all 43 traffic signs (aligned dataset)\n",
    "\n",
    "# Load aligned data\n",
    "X, y = traffic_sign(True)\n",
    "X = X.astype(np.float32) # cast to float32 as float64 running out of memory\n",
    "X = z_score_normalize(X) \n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(X.dtype)\n",
    "print(y.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Fold: 0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27841, 300)\n",
      "(3479, 300)\n",
      "(3479, 300)\n",
      " epoch: 50, train accuracy: 0.8429, train_loss_norm:0.0295, valid_acc: 0.8307, valid_loss_norm: 0.0304\n",
      " epoch: 100, train accuracy: 0.8624, train_loss_norm:0.0216, valid_acc: 0.8425, valid_loss_norm: 0.0230\n",
      " epoch: 150, train accuracy: 0.8753, train_loss_norm:0.0182, valid_acc: 0.8531, valid_loss_norm: 0.0198\n",
      " epoch: 200, train accuracy: 0.8859, train_loss_norm:0.0161, valid_acc: 0.8569, valid_loss_norm: 0.0180\n",
      " epoch: 250, train accuracy: 0.8941, train_loss_norm:0.0147, valid_acc: 0.8626, valid_loss_norm: 0.0168\n",
      " epoch: 300, train accuracy: 0.9003, train_loss_norm:0.0137, valid_acc: 0.8663, valid_loss_norm: 0.0160\n",
      "Test accuracy: 0.8517\n",
      "Test loss norm: 0.0177\n",
      "Current Fold: 1\n",
      "(27841, 300)\n",
      "(3479, 300)\n",
      "(3479, 300)\n",
      " epoch: 50, train accuracy: 0.8444, train_loss_norm:0.0294, valid_acc: 0.8149, valid_loss_norm: 0.0319\n",
      " epoch: 100, train accuracy: 0.8645, train_loss_norm:0.0215, valid_acc: 0.8281, valid_loss_norm: 0.0246\n",
      " epoch: 150, train accuracy: 0.8773, train_loss_norm:0.0181, valid_acc: 0.8376, valid_loss_norm: 0.0215\n",
      " epoch: 200, train accuracy: 0.8874, train_loss_norm:0.0160, valid_acc: 0.8448, valid_loss_norm: 0.0198\n",
      " epoch: 250, train accuracy: 0.8953, train_loss_norm:0.0146, valid_acc: 0.8488, valid_loss_norm: 0.0186\n",
      " epoch: 300, train accuracy: 0.9022, train_loss_norm:0.0136, valid_acc: 0.8523, valid_loss_norm: 0.0177\n",
      "Test accuracy: 0.8615\n",
      "Test loss norm: 0.0169\n",
      "Current Fold: 2\n",
      "(27841, 300)\n",
      "(3479, 300)\n",
      "(3479, 300)\n",
      " epoch: 50, train accuracy: 0.8410, train_loss_norm:0.0296, valid_acc: 0.8137, valid_loss_norm: 0.0314\n",
      " epoch: 100, train accuracy: 0.8627, train_loss_norm:0.0217, valid_acc: 0.8304, valid_loss_norm: 0.0240\n",
      " epoch: 150, train accuracy: 0.8755, train_loss_norm:0.0182, valid_acc: 0.8422, valid_loss_norm: 0.0208\n",
      " epoch: 200, train accuracy: 0.8856, train_loss_norm:0.0162, valid_acc: 0.8537, valid_loss_norm: 0.0190\n",
      " epoch: 250, train accuracy: 0.8945, train_loss_norm:0.0148, valid_acc: 0.8600, valid_loss_norm: 0.0178\n",
      " epoch: 300, train accuracy: 0.9005, train_loss_norm:0.0137, valid_acc: 0.8638, valid_loss_norm: 0.0169\n",
      "Test accuracy: 0.8646\n",
      "Test loss norm: 0.0167\n",
      "Current Fold: 3\n",
      "(27841, 300)\n",
      "(3479, 300)\n",
      "(3479, 300)\n",
      " epoch: 50, train accuracy: 0.8397, train_loss_norm:0.0297, valid_acc: 0.8215, valid_loss_norm: 0.0313\n",
      " epoch: 100, train accuracy: 0.8612, train_loss_norm:0.0218, valid_acc: 0.8393, valid_loss_norm: 0.0238\n",
      " epoch: 150, train accuracy: 0.8743, train_loss_norm:0.0184, valid_acc: 0.8497, valid_loss_norm: 0.0206\n",
      " epoch: 200, train accuracy: 0.8848, train_loss_norm:0.0163, valid_acc: 0.8557, valid_loss_norm: 0.0188\n",
      " epoch: 250, train accuracy: 0.8928, train_loss_norm:0.0149, valid_acc: 0.8606, valid_loss_norm: 0.0177\n",
      " epoch: 300, train accuracy: 0.8989, train_loss_norm:0.0138, valid_acc: 0.8658, valid_loss_norm: 0.0168\n",
      "Test accuracy: 0.8686\n",
      "Test loss norm: 0.0160\n",
      "Current Fold: 4\n",
      "(27841, 300)\n",
      "(3479, 300)\n",
      "(3479, 300)\n",
      " epoch: 50, train accuracy: 0.8409, train_loss_norm:0.0298, valid_acc: 0.8275, valid_loss_norm: 0.0307\n",
      " epoch: 100, train accuracy: 0.8603, train_loss_norm:0.0219, valid_acc: 0.8425, valid_loss_norm: 0.0231\n",
      " epoch: 150, train accuracy: 0.8749, train_loss_norm:0.0184, valid_acc: 0.8531, valid_loss_norm: 0.0199\n",
      " epoch: 200, train accuracy: 0.8842, train_loss_norm:0.0163, valid_acc: 0.8583, valid_loss_norm: 0.0180\n",
      " epoch: 250, train accuracy: 0.8928, train_loss_norm:0.0149, valid_acc: 0.8617, valid_loss_norm: 0.0168\n",
      " epoch: 300, train accuracy: 0.8999, train_loss_norm:0.0139, valid_acc: 0.8672, valid_loss_norm: 0.0159\n",
      "Test accuracy: 0.8681\n",
      "Test loss norm: 0.0162\n",
      "Current Fold: 5\n",
      "(27841, 300)\n",
      "(3479, 300)\n",
      "(3479, 300)\n",
      " epoch: 50, train accuracy: 0.8420, train_loss_norm:0.0296, valid_acc: 0.8235, valid_loss_norm: 0.0306\n",
      " epoch: 100, train accuracy: 0.8623, train_loss_norm:0.0218, valid_acc: 0.8353, valid_loss_norm: 0.0232\n",
      " epoch: 150, train accuracy: 0.8758, train_loss_norm:0.0183, valid_acc: 0.8505, valid_loss_norm: 0.0201\n",
      " epoch: 200, train accuracy: 0.8857, train_loss_norm:0.0162, valid_acc: 0.8597, valid_loss_norm: 0.0183\n",
      " epoch: 250, train accuracy: 0.8934, train_loss_norm:0.0148, valid_acc: 0.8635, valid_loss_norm: 0.0171\n",
      " epoch: 300, train accuracy: 0.8998, train_loss_norm:0.0138, valid_acc: 0.8692, valid_loss_norm: 0.0162\n",
      "Test accuracy: 0.8589\n",
      "Test loss norm: 0.0168\n",
      "Current Fold: 6\n",
      "(27841, 300)\n",
      "(3479, 300)\n",
      "(3479, 300)\n",
      " epoch: 50, train accuracy: 0.8398, train_loss_norm:0.0296, valid_acc: 0.8120, valid_loss_norm: 0.0312\n",
      " epoch: 100, train accuracy: 0.8621, train_loss_norm:0.0218, valid_acc: 0.8293, valid_loss_norm: 0.0239\n",
      " epoch: 150, train accuracy: 0.8755, train_loss_norm:0.0183, valid_acc: 0.8385, valid_loss_norm: 0.0207\n",
      " epoch: 200, train accuracy: 0.8848, train_loss_norm:0.0162, valid_acc: 0.8465, valid_loss_norm: 0.0189\n",
      " epoch: 250, train accuracy: 0.8922, train_loss_norm:0.0148, valid_acc: 0.8511, valid_loss_norm: 0.0177\n",
      " epoch: 300, train accuracy: 0.8982, train_loss_norm:0.0138, valid_acc: 0.8557, valid_loss_norm: 0.0169\n",
      "Test accuracy: 0.8787\n",
      "Test loss norm: 0.0164\n",
      "Current Fold: 7\n",
      "(27841, 300)\n",
      "(3479, 300)\n",
      "(3479, 300)\n",
      " epoch: 50, train accuracy: 0.8391, train_loss_norm:0.0296, valid_acc: 0.8281, valid_loss_norm: 0.0311\n",
      " epoch: 100, train accuracy: 0.8601, train_loss_norm:0.0218, valid_acc: 0.8502, valid_loss_norm: 0.0235\n",
      " epoch: 150, train accuracy: 0.8737, train_loss_norm:0.0183, valid_acc: 0.8603, valid_loss_norm: 0.0203\n",
      " epoch: 200, train accuracy: 0.8848, train_loss_norm:0.0163, valid_acc: 0.8652, valid_loss_norm: 0.0184\n",
      " epoch: 250, train accuracy: 0.8924, train_loss_norm:0.0149, valid_acc: 0.8721, valid_loss_norm: 0.0172\n",
      " epoch: 300, train accuracy: 0.8986, train_loss_norm:0.0138, valid_acc: 0.8755, valid_loss_norm: 0.0163\n",
      "Test accuracy: 0.8669\n",
      "Test loss norm: 0.0164\n",
      "Current Fold: 8\n",
      "(27841, 300)\n",
      "(3479, 300)\n",
      "(3479, 300)\n",
      " epoch: 50, train accuracy: 0.8399, train_loss_norm:0.0296, valid_acc: 0.8275, valid_loss_norm: 0.0307\n",
      " epoch: 100, train accuracy: 0.8609, train_loss_norm:0.0217, valid_acc: 0.8431, valid_loss_norm: 0.0234\n",
      " epoch: 150, train accuracy: 0.8753, train_loss_norm:0.0182, valid_acc: 0.8505, valid_loss_norm: 0.0203\n",
      " epoch: 200, train accuracy: 0.8850, train_loss_norm:0.0162, valid_acc: 0.8554, valid_loss_norm: 0.0185\n",
      " epoch: 250, train accuracy: 0.8936, train_loss_norm:0.0148, valid_acc: 0.8626, valid_loss_norm: 0.0173\n",
      " epoch: 300, train accuracy: 0.9001, train_loss_norm:0.0137, valid_acc: 0.8658, valid_loss_norm: 0.0164\n",
      "Test accuracy: 0.8606\n",
      "Test loss norm: 0.0169\n",
      "1\n",
      "Current Fold: 9\n",
      "(27841, 300)\n",
      "(3479, 300)\n",
      "(3479, 300)\n",
      " epoch: 50, train accuracy: 0.8422, train_loss_norm:0.0296, valid_acc: 0.8204, valid_loss_norm: 0.0315\n",
      " epoch: 100, train accuracy: 0.8632, train_loss_norm:0.0218, valid_acc: 0.8367, valid_loss_norm: 0.0240\n",
      " epoch: 150, train accuracy: 0.8754, train_loss_norm:0.0183, valid_acc: 0.8428, valid_loss_norm: 0.0208\n",
      " epoch: 200, train accuracy: 0.8846, train_loss_norm:0.0162, valid_acc: 0.8494, valid_loss_norm: 0.0189\n",
      " epoch: 250, train accuracy: 0.8934, train_loss_norm:0.0148, valid_acc: 0.8546, valid_loss_norm: 0.0177\n",
      " epoch: 300, train accuracy: 0.9000, train_loss_norm:0.0138, valid_acc: 0.8574, valid_loss_norm: 0.0169\n",
      "Test accuracy: 0.8701\n",
      "Test loss norm: 0.0160\n",
      "Average test accuracy over 10 folds: 0.8650 (+/- 0.0070)\n",
      "Average test loss per example and class over 10 folds: 0.0166\n"
     ]
    }
   ],
   "source": [
    "## (i) With PCA on aligned\n",
    "\n",
    "DEBUG = False\n",
    "\n",
    "# Softmax Regression Parameters\n",
    "lr = 0.5\n",
    "num_features = X.shape[1]\n",
    "num_classes = y.max() + 1\n",
    "\n",
    "train_loss_record = []\n",
    "\n",
    "train_accuracy_record = []\n",
    "\n",
    "holdout_loss_record = []\n",
    "\n",
    "holdout_accuracy_record = []\n",
    "\n",
    "test_accuracy_record = []\n",
    "\n",
    "# PCA number of principal components\n",
    "n_components = 300\n",
    "\n",
    "first_plot = True\n",
    "\n",
    "num_epochs = 300\n",
    "epochs_print = [50, 100, 150, 200, 250, 300]\n",
    "\n",
    "k = 10\n",
    "\n",
    "total_test_loss = 0.0\n",
    "\n",
    "best_w = None\n",
    "\n",
    "cur_fold = 0\n",
    "for train, valid, test in generate_k_fold_set((X, y), k):\n",
    "    print(f\"Current Fold: {cur_fold}\")\n",
    "    train_data, train_label = train\n",
    "    valid_data, valid_label = valid\n",
    "    test_data, test_label = test\n",
    "    \n",
    "    # Project data onto principal components\n",
    "    pca = PCA(n_components)\n",
    "    projected = pca.fit_transform(train_data) # len(train_data) x n_components\n",
    "    \n",
    "    # Plot principal components\n",
    "    if first_plot == True : \n",
    "        pca.plot_PC()\n",
    "        first_plot = False\n",
    "    train_d = append_bias(projected)     \n",
    "    valid_d = append_bias(pca.PCA_generate(valid_data))\n",
    "    test_d = append_bias(pca.PCA_generate(test_data))\n",
    "\n",
    "    softmax_model = SoftmaxRegression(lr, n_components, num_classes)\n",
    "    best_w = softmax_model.W\n",
    "\n",
    "    # Onehot encode labels\n",
    "    y_true = onehot_encode(train_label)\n",
    "    valid_label_onehot = onehot_encode(valid_label)\n",
    "    test_label_onehot = onehot_encode(test_label)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        y_hat = softmax_model.model(train_d)\n",
    "        \n",
    "        raw_train_loss = softmax_model.cross_entropy(y_true, y_hat)\n",
    "        train_loss_norm = raw_train_loss / len(train_d) / num_classes # train loss normalized by # examples and classes\n",
    "        \n",
    "        train_loss_record.append(train_loss_norm)\n",
    "        \n",
    "        train_accuracy = softmax_model.accuracy(y_true, y_hat)\n",
    "        train_accuracy_record.append(train_accuracy)\n",
    "        \n",
    "        holdout_y = softmax_model.model(valid_d)\n",
    "\n",
    "        holdout_loss = softmax_model.cross_entropy(valid_label_onehot, holdout_y)\n",
    "        holdout_loss_norm = holdout_loss / len(valid_d) / num_classes # holdout loss normalized by # examples and classes\n",
    "        holdout_loss_record.append(holdout_loss_norm)\n",
    "\n",
    "        holdout_accuracy = softmax_model.accuracy(holdout_y, valid_label_onehot)\n",
    "        holdout_accuracy_record.append(holdout_accuracy)\n",
    "\n",
    "        if holdout_accuracy >= max(holdout_accuracy_record[cur_fold * num_epochs:]):\n",
    "            best_w = softmax_model.W\n",
    "\n",
    "        # Update Weights\n",
    "        softmax_model.update_weights(train_d, y_true, y_hat)\n",
    "\n",
    "        if (epoch + 1) in epochs_print:\n",
    "            print(f' epoch: {epoch + 1}, train accuracy: {train_accuracy:.4f}, train_loss_norm:{train_loss_norm:.4f}, '\\\n",
    "                f'valid_acc: {holdout_accuracy:.4f}, valid_loss_norm: {holdout_loss_norm:.4f}')\n",
    "            if DEBUG:\n",
    "                test_y = softmax_model.model_w(test_d, best_w)\n",
    "                test_y_1 = softmax_model.model(test_d)\n",
    "\n",
    "                test_accuracy = softmax_model.accuracy(test_y, test_label_onehot)\n",
    "                test_accuracy_1 = softmax_model.accuracy(test_y_1, test_label_onehot)\n",
    "\n",
    "                raw_test_loss = softmax_model.cross_entropy(test_y, test_label_onehot)\n",
    "                test_loss_norm = raw_test_loss / len(test_d) / num_classes\n",
    "\n",
    "                print(f'MODEL_W: Test accuracy: {test_accuracy:.4f}', f'Test loss norm: {test_loss_norm:.4f}')\n",
    "                print(f'MODEL: Test accuracy: {test_accuracy_1:.4f}')\n",
    "\n",
    "    # Run on Test Dataset\n",
    "    test_y = softmax_model.model_w(test_d, best_w)\n",
    "\n",
    "    test_accuracy = softmax_model.accuracy(test_y, test_label_onehot)\n",
    "\n",
    "    print(f'Test accuracy: {test_accuracy:.4f}')\n",
    "\n",
    "    test_accuracy_record.append(test_accuracy)\n",
    "\n",
    "    raw_test_loss = softmax_model.cross_entropy(test_label_onehot, test_y)\n",
    "    test_loss_norm = raw_test_loss / len(test_d) / num_classes\n",
    "    total_test_loss += test_loss_norm\n",
    "    print(f\"Test loss norm: {test_loss_norm:.4f}\")\n",
    "\n",
    "    cur_fold += 1\n",
    "\n",
    "print(f'Average test accuracy over {k} folds: {np.mean(test_accuracy_record):.4f} (+/- {np.std(test_accuracy_record):.4f})')\n",
    "print(f'Average test loss per example and class over {k} folds: {total_test_loss / k:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_out_data_k(data, k=10):\n",
    "    total_count = len(data)\n",
    "    count_per_fold = total_count // k # Assumes cleanly divisble number\n",
    "    new_data = [0.0 for i in range(count_per_fold)]\n",
    "    for i in range(k):\n",
    "        for j in range(count_per_fold):\n",
    "            new_data[j] += data[i * count_per_fold + j]\n",
    "    new_data = [d / k for d in new_data]\n",
    "    return new_data\n",
    "\n",
    "def get_data_at_epoch_fold(data, epoch, total_num_folds=10):\n",
    "    # Returns a new list of data points at a specified epoch from all folds\n",
    "    # data = [fold1....fold10]\n",
    "    # epoch is 0-indexed\n",
    "    epoch_per_fold = len(data) // total_num_folds\n",
    "    new_data = [data[f * (epoch_per_fold) + epoch] for f in range(total_num_folds)]\n",
    "    return new_data # [epoch n from fold1, epoch n from fold2, ..., epoch n from fold10]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q6(b) - Stochastic Gradient Descent\n",
      "Cur fold: 0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27841, 300)\n",
      "(3479, 300)\n",
      "(3479, 300)\n",
      " epoch: 1, train accuracy: 0.7912, train_loss_norm:0.0836, valid_acc: 0.7749, valid_loss_norm: 0.0837\n",
      " epoch: 2, train accuracy: 0.7914, train_loss_norm:0.0799, valid_acc: 0.7749, valid_loss_norm: 0.0800\n",
      " epoch: 3, train accuracy: 0.7917, train_loss_norm:0.0763, valid_acc: 0.7755, valid_loss_norm: 0.0764\n",
      " epoch: 4, train accuracy: 0.7925, train_loss_norm:0.0729, valid_acc: 0.7769, valid_loss_norm: 0.0731\n",
      " epoch: 5, train accuracy: 0.7930, train_loss_norm:0.0697, valid_acc: 0.7778, valid_loss_norm: 0.0699\n",
      " epoch: 6, train accuracy: 0.7940, train_loss_norm:0.0667, valid_acc: 0.7775, valid_loss_norm: 0.0669\n",
      " epoch: 7, train accuracy: 0.7952, train_loss_norm:0.0640, valid_acc: 0.7790, valid_loss_norm: 0.0642\n",
      " epoch: 8, train accuracy: 0.7965, train_loss_norm:0.0615, valid_acc: 0.7804, valid_loss_norm: 0.0617\n",
      " epoch: 9, train accuracy: 0.7977, train_loss_norm:0.0592, valid_acc: 0.7821, valid_loss_norm: 0.0595\n",
      " epoch: 10, train accuracy: 0.7991, train_loss_norm:0.0571, valid_acc: 0.7827, valid_loss_norm: 0.0574\n",
      " epoch: 11, train accuracy: 0.8010, train_loss_norm:0.0553, valid_acc: 0.7844, valid_loss_norm: 0.0556\n",
      " epoch: 12, train accuracy: 0.8024, train_loss_norm:0.0535, valid_acc: 0.7859, valid_loss_norm: 0.0539\n",
      " epoch: 13, train accuracy: 0.8037, train_loss_norm:0.0520, valid_acc: 0.7887, valid_loss_norm: 0.0523\n",
      " epoch: 14, train accuracy: 0.8054, train_loss_norm:0.0505, valid_acc: 0.7890, valid_loss_norm: 0.0509\n",
      " epoch: 15, train accuracy: 0.8070, train_loss_norm:0.0492, valid_acc: 0.7899, valid_loss_norm: 0.0495\n",
      " epoch: 16, train accuracy: 0.8088, train_loss_norm:0.0479, valid_acc: 0.7919, valid_loss_norm: 0.0483\n",
      " epoch: 17, train accuracy: 0.8106, train_loss_norm:0.0468, valid_acc: 0.7951, valid_loss_norm: 0.0472\n",
      " epoch: 18, train accuracy: 0.8122, train_loss_norm:0.0457, valid_acc: 0.7962, valid_loss_norm: 0.0461\n",
      " epoch: 19, train accuracy: 0.8134, train_loss_norm:0.0447, valid_acc: 0.8008, valid_loss_norm: 0.0452\n",
      " epoch: 20, train accuracy: 0.8147, train_loss_norm:0.0438, valid_acc: 0.8025, valid_loss_norm: 0.0442\n",
      " epoch: 21, train accuracy: 0.8162, train_loss_norm:0.0429, valid_acc: 0.8051, valid_loss_norm: 0.0434\n",
      " epoch: 22, train accuracy: 0.8175, train_loss_norm:0.0421, valid_acc: 0.8060, valid_loss_norm: 0.0426\n",
      " epoch: 23, train accuracy: 0.8193, train_loss_norm:0.0413, valid_acc: 0.8068, valid_loss_norm: 0.0418\n",
      " epoch: 24, train accuracy: 0.8203, train_loss_norm:0.0406, valid_acc: 0.8080, valid_loss_norm: 0.0411\n",
      " epoch: 25, train accuracy: 0.8213, train_loss_norm:0.0399, valid_acc: 0.8074, valid_loss_norm: 0.0404\n",
      " epoch: 26, train accuracy: 0.8221, train_loss_norm:0.0392, valid_acc: 0.8091, valid_loss_norm: 0.0397\n",
      " epoch: 27, train accuracy: 0.8232, train_loss_norm:0.0386, valid_acc: 0.8114, valid_loss_norm: 0.0391\n",
      " epoch: 28, train accuracy: 0.8240, train_loss_norm:0.0380, valid_acc: 0.8137, valid_loss_norm: 0.0385\n",
      " epoch: 29, train accuracy: 0.8249, train_loss_norm:0.0375, valid_acc: 0.8149, valid_loss_norm: 0.0380\n",
      " epoch: 30, train accuracy: 0.8260, train_loss_norm:0.0369, valid_acc: 0.8172, valid_loss_norm: 0.0374\n",
      " epoch: 31, train accuracy: 0.8270, train_loss_norm:0.0364, valid_acc: 0.8175, valid_loss_norm: 0.0369\n",
      " epoch: 32, train accuracy: 0.8278, train_loss_norm:0.0359, valid_acc: 0.8189, valid_loss_norm: 0.0364\n",
      " epoch: 33, train accuracy: 0.8286, train_loss_norm:0.0354, valid_acc: 0.8201, valid_loss_norm: 0.0360\n",
      " epoch: 34, train accuracy: 0.8298, train_loss_norm:0.0350, valid_acc: 0.8206, valid_loss_norm: 0.0355\n",
      " epoch: 35, train accuracy: 0.8309, train_loss_norm:0.0345, valid_acc: 0.8215, valid_loss_norm: 0.0351\n",
      " epoch: 36, train accuracy: 0.8317, train_loss_norm:0.0341, valid_acc: 0.8229, valid_loss_norm: 0.0347\n",
      " epoch: 37, train accuracy: 0.8327, train_loss_norm:0.0337, valid_acc: 0.8227, valid_loss_norm: 0.0343\n",
      " epoch: 38, train accuracy: 0.8336, train_loss_norm:0.0333, valid_acc: 0.8238, valid_loss_norm: 0.0339\n",
      " epoch: 39, train accuracy: 0.8341, train_loss_norm:0.0329, valid_acc: 0.8249, valid_loss_norm: 0.0335\n",
      " epoch: 40, train accuracy: 0.8346, train_loss_norm:0.0326, valid_acc: 0.8264, valid_loss_norm: 0.0332\n",
      " epoch: 41, train accuracy: 0.8351, train_loss_norm:0.0322, valid_acc: 0.8281, valid_loss_norm: 0.0328\n",
      " epoch: 42, train accuracy: 0.8355, train_loss_norm:0.0319, valid_acc: 0.8278, valid_loss_norm: 0.0325\n",
      " epoch: 43, train accuracy: 0.8368, train_loss_norm:0.0315, valid_acc: 0.8281, valid_loss_norm: 0.0322\n",
      " epoch: 44, train accuracy: 0.8374, train_loss_norm:0.0312, valid_acc: 0.8278, valid_loss_norm: 0.0318\n",
      " epoch: 45, train accuracy: 0.8380, train_loss_norm:0.0309, valid_acc: 0.8275, valid_loss_norm: 0.0315\n",
      " epoch: 46, train accuracy: 0.8386, train_loss_norm:0.0306, valid_acc: 0.8272, valid_loss_norm: 0.0312\n",
      " epoch: 47, train accuracy: 0.8388, train_loss_norm:0.0303, valid_acc: 0.8272, valid_loss_norm: 0.0310\n",
      " epoch: 48, train accuracy: 0.8393, train_loss_norm:0.0300, valid_acc: 0.8284, valid_loss_norm: 0.0307\n",
      " epoch: 49, train accuracy: 0.8397, train_loss_norm:0.0298, valid_acc: 0.8293, valid_loss_norm: 0.0304\n",
      " epoch: 50, train accuracy: 0.8400, train_loss_norm:0.0295, valid_acc: 0.8293, valid_loss_norm: 0.0302\n",
      " epoch: 51, train accuracy: 0.8407, train_loss_norm:0.0292, valid_acc: 0.8293, valid_loss_norm: 0.0299\n",
      " epoch: 52, train accuracy: 0.8411, train_loss_norm:0.0290, valid_acc: 0.8304, valid_loss_norm: 0.0297\n",
      " epoch: 53, train accuracy: 0.8412, train_loss_norm:0.0287, valid_acc: 0.8307, valid_loss_norm: 0.0294\n",
      " epoch: 54, train accuracy: 0.8417, train_loss_norm:0.0285, valid_acc: 0.8327, valid_loss_norm: 0.0292\n",
      " epoch: 55, train accuracy: 0.8422, train_loss_norm:0.0283, valid_acc: 0.8341, valid_loss_norm: 0.0290\n",
      " epoch: 56, train accuracy: 0.8424, train_loss_norm:0.0280, valid_acc: 0.8341, valid_loss_norm: 0.0288\n",
      " epoch: 57, train accuracy: 0.8427, train_loss_norm:0.0278, valid_acc: 0.8336, valid_loss_norm: 0.0286\n",
      " epoch: 58, train accuracy: 0.8433, train_loss_norm:0.0276, valid_acc: 0.8341, valid_loss_norm: 0.0283\n",
      " epoch: 59, train accuracy: 0.8438, train_loss_norm:0.0274, valid_acc: 0.8347, valid_loss_norm: 0.0281\n",
      " epoch: 60, train accuracy: 0.8440, train_loss_norm:0.0272, valid_acc: 0.8362, valid_loss_norm: 0.0280\n",
      " epoch: 61, train accuracy: 0.8447, train_loss_norm:0.0270, valid_acc: 0.8362, valid_loss_norm: 0.0278\n",
      " epoch: 62, train accuracy: 0.8452, train_loss_norm:0.0268, valid_acc: 0.8376, valid_loss_norm: 0.0276\n",
      " epoch: 63, train accuracy: 0.8457, train_loss_norm:0.0266, valid_acc: 0.8379, valid_loss_norm: 0.0274\n",
      " epoch: 64, train accuracy: 0.8464, train_loss_norm:0.0264, valid_acc: 0.8379, valid_loss_norm: 0.0272\n",
      " epoch: 65, train accuracy: 0.8470, train_loss_norm:0.0263, valid_acc: 0.8387, valid_loss_norm: 0.0270\n",
      " epoch: 66, train accuracy: 0.8473, train_loss_norm:0.0261, valid_acc: 0.8390, valid_loss_norm: 0.0269\n",
      " epoch: 67, train accuracy: 0.8476, train_loss_norm:0.0259, valid_acc: 0.8390, valid_loss_norm: 0.0267\n",
      " epoch: 68, train accuracy: 0.8481, train_loss_norm:0.0257, valid_acc: 0.8390, valid_loss_norm: 0.0265\n",
      " epoch: 69, train accuracy: 0.8485, train_loss_norm:0.0256, valid_acc: 0.8399, valid_loss_norm: 0.0264\n",
      " epoch: 70, train accuracy: 0.8491, train_loss_norm:0.0254, valid_acc: 0.8399, valid_loss_norm: 0.0262\n",
      " epoch: 71, train accuracy: 0.8495, train_loss_norm:0.0252, valid_acc: 0.8399, valid_loss_norm: 0.0261\n",
      " epoch: 72, train accuracy: 0.8499, train_loss_norm:0.0251, valid_acc: 0.8399, valid_loss_norm: 0.0259\n",
      " epoch: 73, train accuracy: 0.8504, train_loss_norm:0.0249, valid_acc: 0.8399, valid_loss_norm: 0.0258\n",
      " epoch: 74, train accuracy: 0.8509, train_loss_norm:0.0248, valid_acc: 0.8402, valid_loss_norm: 0.0256\n",
      " epoch: 75, train accuracy: 0.8514, train_loss_norm:0.0246, valid_acc: 0.8402, valid_loss_norm: 0.0255\n",
      " epoch: 76, train accuracy: 0.8519, train_loss_norm:0.0245, valid_acc: 0.8408, valid_loss_norm: 0.0254\n",
      " epoch: 77, train accuracy: 0.8526, train_loss_norm:0.0244, valid_acc: 0.8408, valid_loss_norm: 0.0252\n",
      " epoch: 78, train accuracy: 0.8528, train_loss_norm:0.0242, valid_acc: 0.8405, valid_loss_norm: 0.0251\n",
      " epoch: 79, train accuracy: 0.8536, train_loss_norm:0.0241, valid_acc: 0.8408, valid_loss_norm: 0.0250\n",
      " epoch: 80, train accuracy: 0.8540, train_loss_norm:0.0240, valid_acc: 0.8413, valid_loss_norm: 0.0249\n",
      " epoch: 81, train accuracy: 0.8541, train_loss_norm:0.0238, valid_acc: 0.8416, valid_loss_norm: 0.0247\n",
      " epoch: 82, train accuracy: 0.8544, train_loss_norm:0.0237, valid_acc: 0.8419, valid_loss_norm: 0.0246\n",
      " epoch: 83, train accuracy: 0.8547, train_loss_norm:0.0236, valid_acc: 0.8419, valid_loss_norm: 0.0245\n",
      " epoch: 84, train accuracy: 0.8551, train_loss_norm:0.0234, valid_acc: 0.8422, valid_loss_norm: 0.0244\n",
      " epoch: 85, train accuracy: 0.8554, train_loss_norm:0.0233, valid_acc: 0.8422, valid_loss_norm: 0.0243\n",
      " epoch: 86, train accuracy: 0.8559, train_loss_norm:0.0232, valid_acc: 0.8425, valid_loss_norm: 0.0242\n",
      " epoch: 87, train accuracy: 0.8561, train_loss_norm:0.0231, valid_acc: 0.8428, valid_loss_norm: 0.0240\n",
      " epoch: 88, train accuracy: 0.8565, train_loss_norm:0.0230, valid_acc: 0.8431, valid_loss_norm: 0.0239\n",
      " epoch: 89, train accuracy: 0.8569, train_loss_norm:0.0229, valid_acc: 0.8433, valid_loss_norm: 0.0238\n",
      " epoch: 90, train accuracy: 0.8572, train_loss_norm:0.0228, valid_acc: 0.8431, valid_loss_norm: 0.0237\n",
      " epoch: 91, train accuracy: 0.8575, train_loss_norm:0.0226, valid_acc: 0.8428, valid_loss_norm: 0.0236\n",
      " epoch: 92, train accuracy: 0.8579, train_loss_norm:0.0225, valid_acc: 0.8433, valid_loss_norm: 0.0235\n",
      " epoch: 93, train accuracy: 0.8584, train_loss_norm:0.0224, valid_acc: 0.8439, valid_loss_norm: 0.0234\n",
      " epoch: 94, train accuracy: 0.8585, train_loss_norm:0.0223, valid_acc: 0.8439, valid_loss_norm: 0.0233\n",
      " epoch: 95, train accuracy: 0.8588, train_loss_norm:0.0222, valid_acc: 0.8442, valid_loss_norm: 0.0232\n",
      " epoch: 96, train accuracy: 0.8588, train_loss_norm:0.0221, valid_acc: 0.8451, valid_loss_norm: 0.0231\n",
      " epoch: 97, train accuracy: 0.8590, train_loss_norm:0.0220, valid_acc: 0.8451, valid_loss_norm: 0.0230\n",
      " epoch: 98, train accuracy: 0.8595, train_loss_norm:0.0219, valid_acc: 0.8454, valid_loss_norm: 0.0230\n",
      " epoch: 99, train accuracy: 0.8598, train_loss_norm:0.0218, valid_acc: 0.8456, valid_loss_norm: 0.0229\n",
      " epoch: 100, train accuracy: 0.8598, train_loss_norm:0.0217, valid_acc: 0.8456, valid_loss_norm: 0.0228\n",
      " epoch: 101, train accuracy: 0.8600, train_loss_norm:0.0216, valid_acc: 0.8456, valid_loss_norm: 0.0227\n",
      " epoch: 102, train accuracy: 0.8603, train_loss_norm:0.0215, valid_acc: 0.8456, valid_loss_norm: 0.0226\n",
      " epoch: 103, train accuracy: 0.8606, train_loss_norm:0.0215, valid_acc: 0.8456, valid_loss_norm: 0.0225\n",
      " epoch: 104, train accuracy: 0.8610, train_loss_norm:0.0214, valid_acc: 0.8456, valid_loss_norm: 0.0224\n",
      " epoch: 105, train accuracy: 0.8615, train_loss_norm:0.0213, valid_acc: 0.8459, valid_loss_norm: 0.0224\n",
      " epoch: 106, train accuracy: 0.8620, train_loss_norm:0.0212, valid_acc: 0.8459, valid_loss_norm: 0.0223\n",
      " epoch: 107, train accuracy: 0.8622, train_loss_norm:0.0211, valid_acc: 0.8468, valid_loss_norm: 0.0222\n",
      " epoch: 108, train accuracy: 0.8624, train_loss_norm:0.0210, valid_acc: 0.8468, valid_loss_norm: 0.0221\n",
      " epoch: 109, train accuracy: 0.8625, train_loss_norm:0.0209, valid_acc: 0.8471, valid_loss_norm: 0.0220\n",
      " epoch: 110, train accuracy: 0.8629, train_loss_norm:0.0209, valid_acc: 0.8474, valid_loss_norm: 0.0220\n",
      " epoch: 111, train accuracy: 0.8632, train_loss_norm:0.0208, valid_acc: 0.8474, valid_loss_norm: 0.0219\n",
      " epoch: 112, train accuracy: 0.8635, train_loss_norm:0.0207, valid_acc: 0.8471, valid_loss_norm: 0.0218\n",
      " epoch: 113, train accuracy: 0.8639, train_loss_norm:0.0206, valid_acc: 0.8479, valid_loss_norm: 0.0218\n",
      " epoch: 114, train accuracy: 0.8640, train_loss_norm:0.0205, valid_acc: 0.8488, valid_loss_norm: 0.0217\n",
      " epoch: 115, train accuracy: 0.8643, train_loss_norm:0.0205, valid_acc: 0.8491, valid_loss_norm: 0.0216\n",
      " epoch: 116, train accuracy: 0.8645, train_loss_norm:0.0204, valid_acc: 0.8494, valid_loss_norm: 0.0215\n",
      " epoch: 117, train accuracy: 0.8649, train_loss_norm:0.0203, valid_acc: 0.8494, valid_loss_norm: 0.0215\n",
      " epoch: 118, train accuracy: 0.8653, train_loss_norm:0.0202, valid_acc: 0.8494, valid_loss_norm: 0.0214\n",
      " epoch: 119, train accuracy: 0.8658, train_loss_norm:0.0202, valid_acc: 0.8494, valid_loss_norm: 0.0213\n",
      " epoch: 120, train accuracy: 0.8661, train_loss_norm:0.0201, valid_acc: 0.8505, valid_loss_norm: 0.0213\n",
      " epoch: 121, train accuracy: 0.8663, train_loss_norm:0.0200, valid_acc: 0.8511, valid_loss_norm: 0.0212\n",
      " epoch: 122, train accuracy: 0.8666, train_loss_norm:0.0200, valid_acc: 0.8517, valid_loss_norm: 0.0211\n",
      " epoch: 123, train accuracy: 0.8669, train_loss_norm:0.0199, valid_acc: 0.8517, valid_loss_norm: 0.0211\n",
      " epoch: 124, train accuracy: 0.8671, train_loss_norm:0.0198, valid_acc: 0.8517, valid_loss_norm: 0.0210\n",
      " epoch: 125, train accuracy: 0.8675, train_loss_norm:0.0198, valid_acc: 0.8517, valid_loss_norm: 0.0210\n",
      " epoch: 126, train accuracy: 0.8676, train_loss_norm:0.0197, valid_acc: 0.8520, valid_loss_norm: 0.0209\n",
      " epoch: 127, train accuracy: 0.8679, train_loss_norm:0.0196, valid_acc: 0.8523, valid_loss_norm: 0.0208\n",
      " epoch: 128, train accuracy: 0.8681, train_loss_norm:0.0196, valid_acc: 0.8523, valid_loss_norm: 0.0208\n",
      " epoch: 129, train accuracy: 0.8685, train_loss_norm:0.0195, valid_acc: 0.8525, valid_loss_norm: 0.0207\n",
      " epoch: 130, train accuracy: 0.8687, train_loss_norm:0.0194, valid_acc: 0.8525, valid_loss_norm: 0.0207\n",
      " epoch: 131, train accuracy: 0.8689, train_loss_norm:0.0194, valid_acc: 0.8525, valid_loss_norm: 0.0206\n",
      " epoch: 132, train accuracy: 0.8691, train_loss_norm:0.0193, valid_acc: 0.8528, valid_loss_norm: 0.0206\n",
      " epoch: 133, train accuracy: 0.8693, train_loss_norm:0.0192, valid_acc: 0.8528, valid_loss_norm: 0.0205\n",
      " epoch: 134, train accuracy: 0.8695, train_loss_norm:0.0192, valid_acc: 0.8525, valid_loss_norm: 0.0204\n",
      " epoch: 135, train accuracy: 0.8695, train_loss_norm:0.0191, valid_acc: 0.8525, valid_loss_norm: 0.0204\n",
      " epoch: 136, train accuracy: 0.8697, train_loss_norm:0.0191, valid_acc: 0.8528, valid_loss_norm: 0.0203\n",
      " epoch: 137, train accuracy: 0.8700, train_loss_norm:0.0190, valid_acc: 0.8528, valid_loss_norm: 0.0203\n",
      " epoch: 138, train accuracy: 0.8702, train_loss_norm:0.0189, valid_acc: 0.8531, valid_loss_norm: 0.0202\n",
      " epoch: 139, train accuracy: 0.8704, train_loss_norm:0.0189, valid_acc: 0.8537, valid_loss_norm: 0.0202\n",
      " epoch: 140, train accuracy: 0.8707, train_loss_norm:0.0188, valid_acc: 0.8537, valid_loss_norm: 0.0201\n",
      " epoch: 141, train accuracy: 0.8710, train_loss_norm:0.0188, valid_acc: 0.8537, valid_loss_norm: 0.0201\n",
      " epoch: 142, train accuracy: 0.8712, train_loss_norm:0.0187, valid_acc: 0.8534, valid_loss_norm: 0.0200\n",
      " epoch: 143, train accuracy: 0.8717, train_loss_norm:0.0187, valid_acc: 0.8534, valid_loss_norm: 0.0200\n",
      " epoch: 144, train accuracy: 0.8721, train_loss_norm:0.0186, valid_acc: 0.8537, valid_loss_norm: 0.0199\n",
      " epoch: 145, train accuracy: 0.8722, train_loss_norm:0.0186, valid_acc: 0.8540, valid_loss_norm: 0.0199\n",
      " epoch: 146, train accuracy: 0.8725, train_loss_norm:0.0185, valid_acc: 0.8540, valid_loss_norm: 0.0198\n",
      " epoch: 147, train accuracy: 0.8726, train_loss_norm:0.0184, valid_acc: 0.8543, valid_loss_norm: 0.0198\n",
      " epoch: 148, train accuracy: 0.8728, train_loss_norm:0.0184, valid_acc: 0.8546, valid_loss_norm: 0.0197\n",
      " epoch: 149, train accuracy: 0.8729, train_loss_norm:0.0183, valid_acc: 0.8546, valid_loss_norm: 0.0197\n",
      " epoch: 150, train accuracy: 0.8732, train_loss_norm:0.0183, valid_acc: 0.8546, valid_loss_norm: 0.0197\n",
      " epoch: 151, train accuracy: 0.8735, train_loss_norm:0.0182, valid_acc: 0.8546, valid_loss_norm: 0.0196\n",
      " epoch: 152, train accuracy: 0.8739, train_loss_norm:0.0182, valid_acc: 0.8543, valid_loss_norm: 0.0196\n",
      " epoch: 153, train accuracy: 0.8741, train_loss_norm:0.0181, valid_acc: 0.8546, valid_loss_norm: 0.0195\n",
      " epoch: 154, train accuracy: 0.8743, train_loss_norm:0.0181, valid_acc: 0.8548, valid_loss_norm: 0.0195\n",
      " epoch: 155, train accuracy: 0.8745, train_loss_norm:0.0180, valid_acc: 0.8548, valid_loss_norm: 0.0194\n",
      " epoch: 156, train accuracy: 0.8749, train_loss_norm:0.0180, valid_acc: 0.8548, valid_loss_norm: 0.0194\n",
      " epoch: 157, train accuracy: 0.8751, train_loss_norm:0.0179, valid_acc: 0.8548, valid_loss_norm: 0.0193\n",
      " epoch: 158, train accuracy: 0.8752, train_loss_norm:0.0179, valid_acc: 0.8548, valid_loss_norm: 0.0193\n",
      " epoch: 159, train accuracy: 0.8755, train_loss_norm:0.0179, valid_acc: 0.8548, valid_loss_norm: 0.0193\n",
      " epoch: 160, train accuracy: 0.8757, train_loss_norm:0.0178, valid_acc: 0.8548, valid_loss_norm: 0.0192\n",
      " epoch: 161, train accuracy: 0.8760, train_loss_norm:0.0178, valid_acc: 0.8551, valid_loss_norm: 0.0192\n",
      " epoch: 162, train accuracy: 0.8763, train_loss_norm:0.0177, valid_acc: 0.8551, valid_loss_norm: 0.0191\n",
      " epoch: 163, train accuracy: 0.8766, train_loss_norm:0.0177, valid_acc: 0.8551, valid_loss_norm: 0.0191\n",
      " epoch: 164, train accuracy: 0.8768, train_loss_norm:0.0176, valid_acc: 0.8551, valid_loss_norm: 0.0191\n",
      " epoch: 165, train accuracy: 0.8769, train_loss_norm:0.0176, valid_acc: 0.8551, valid_loss_norm: 0.0190\n",
      " epoch: 166, train accuracy: 0.8771, train_loss_norm:0.0175, valid_acc: 0.8551, valid_loss_norm: 0.0190\n",
      " epoch: 167, train accuracy: 0.8773, train_loss_norm:0.0175, valid_acc: 0.8551, valid_loss_norm: 0.0189\n",
      " epoch: 168, train accuracy: 0.8775, train_loss_norm:0.0175, valid_acc: 0.8548, valid_loss_norm: 0.0189\n",
      " epoch: 169, train accuracy: 0.8778, train_loss_norm:0.0174, valid_acc: 0.8551, valid_loss_norm: 0.0189\n",
      " epoch: 170, train accuracy: 0.8781, train_loss_norm:0.0174, valid_acc: 0.8554, valid_loss_norm: 0.0188\n",
      " epoch: 171, train accuracy: 0.8782, train_loss_norm:0.0173, valid_acc: 0.8554, valid_loss_norm: 0.0188\n",
      " epoch: 172, train accuracy: 0.8783, train_loss_norm:0.0173, valid_acc: 0.8560, valid_loss_norm: 0.0188\n",
      " epoch: 173, train accuracy: 0.8785, train_loss_norm:0.0172, valid_acc: 0.8563, valid_loss_norm: 0.0187\n",
      " epoch: 174, train accuracy: 0.8787, train_loss_norm:0.0172, valid_acc: 0.8566, valid_loss_norm: 0.0187\n",
      " epoch: 175, train accuracy: 0.8790, train_loss_norm:0.0172, valid_acc: 0.8566, valid_loss_norm: 0.0187\n",
      " epoch: 176, train accuracy: 0.8792, train_loss_norm:0.0171, valid_acc: 0.8569, valid_loss_norm: 0.0186\n",
      " epoch: 177, train accuracy: 0.8795, train_loss_norm:0.0171, valid_acc: 0.8569, valid_loss_norm: 0.0186\n",
      " epoch: 178, train accuracy: 0.8798, train_loss_norm:0.0170, valid_acc: 0.8569, valid_loss_norm: 0.0185\n",
      " epoch: 179, train accuracy: 0.8800, train_loss_norm:0.0170, valid_acc: 0.8569, valid_loss_norm: 0.0185\n",
      " epoch: 180, train accuracy: 0.8802, train_loss_norm:0.0170, valid_acc: 0.8569, valid_loss_norm: 0.0185\n",
      " epoch: 181, train accuracy: 0.8804, train_loss_norm:0.0169, valid_acc: 0.8574, valid_loss_norm: 0.0184\n",
      " epoch: 182, train accuracy: 0.8806, train_loss_norm:0.0169, valid_acc: 0.8574, valid_loss_norm: 0.0184\n",
      " epoch: 183, train accuracy: 0.8809, train_loss_norm:0.0168, valid_acc: 0.8577, valid_loss_norm: 0.0184\n",
      " epoch: 184, train accuracy: 0.8813, train_loss_norm:0.0168, valid_acc: 0.8580, valid_loss_norm: 0.0183\n",
      " epoch: 185, train accuracy: 0.8815, train_loss_norm:0.0168, valid_acc: 0.8586, valid_loss_norm: 0.0183\n",
      " epoch: 186, train accuracy: 0.8818, train_loss_norm:0.0167, valid_acc: 0.8592, valid_loss_norm: 0.0183\n",
      " epoch: 187, train accuracy: 0.8820, train_loss_norm:0.0167, valid_acc: 0.8592, valid_loss_norm: 0.0182\n",
      " epoch: 188, train accuracy: 0.8821, train_loss_norm:0.0167, valid_acc: 0.8592, valid_loss_norm: 0.0182\n",
      " epoch: 189, train accuracy: 0.8824, train_loss_norm:0.0166, valid_acc: 0.8592, valid_loss_norm: 0.0182\n",
      " epoch: 190, train accuracy: 0.8826, train_loss_norm:0.0166, valid_acc: 0.8592, valid_loss_norm: 0.0182\n",
      " epoch: 191, train accuracy: 0.8829, train_loss_norm:0.0166, valid_acc: 0.8592, valid_loss_norm: 0.0181\n",
      " epoch: 192, train accuracy: 0.8831, train_loss_norm:0.0165, valid_acc: 0.8592, valid_loss_norm: 0.0181\n",
      " epoch: 193, train accuracy: 0.8833, train_loss_norm:0.0165, valid_acc: 0.8592, valid_loss_norm: 0.0181\n",
      " epoch: 194, train accuracy: 0.8836, train_loss_norm:0.0165, valid_acc: 0.8594, valid_loss_norm: 0.0180\n",
      " epoch: 195, train accuracy: 0.8837, train_loss_norm:0.0164, valid_acc: 0.8597, valid_loss_norm: 0.0180\n",
      " epoch: 196, train accuracy: 0.8841, train_loss_norm:0.0164, valid_acc: 0.8600, valid_loss_norm: 0.0180\n",
      " epoch: 197, train accuracy: 0.8842, train_loss_norm:0.0163, valid_acc: 0.8603, valid_loss_norm: 0.0179\n",
      " epoch: 198, train accuracy: 0.8842, train_loss_norm:0.0163, valid_acc: 0.8603, valid_loss_norm: 0.0179\n",
      " epoch: 199, train accuracy: 0.8846, train_loss_norm:0.0163, valid_acc: 0.8609, valid_loss_norm: 0.0179\n",
      " epoch: 200, train accuracy: 0.8847, train_loss_norm:0.0162, valid_acc: 0.8609, valid_loss_norm: 0.0179\n",
      " epoch: 201, train accuracy: 0.8848, train_loss_norm:0.0162, valid_acc: 0.8609, valid_loss_norm: 0.0178\n",
      " epoch: 202, train accuracy: 0.8851, train_loss_norm:0.0162, valid_acc: 0.8609, valid_loss_norm: 0.0178\n",
      " epoch: 203, train accuracy: 0.8853, train_loss_norm:0.0161, valid_acc: 0.8609, valid_loss_norm: 0.0178\n",
      " epoch: 204, train accuracy: 0.8856, train_loss_norm:0.0161, valid_acc: 0.8609, valid_loss_norm: 0.0177\n",
      " epoch: 205, train accuracy: 0.8858, train_loss_norm:0.0161, valid_acc: 0.8609, valid_loss_norm: 0.0177\n",
      " epoch: 206, train accuracy: 0.8861, train_loss_norm:0.0161, valid_acc: 0.8609, valid_loss_norm: 0.0177\n",
      " epoch: 207, train accuracy: 0.8861, train_loss_norm:0.0160, valid_acc: 0.8609, valid_loss_norm: 0.0177\n",
      " epoch: 208, train accuracy: 0.8865, train_loss_norm:0.0160, valid_acc: 0.8609, valid_loss_norm: 0.0176\n",
      " epoch: 209, train accuracy: 0.8867, train_loss_norm:0.0160, valid_acc: 0.8609, valid_loss_norm: 0.0176\n",
      " epoch: 210, train accuracy: 0.8869, train_loss_norm:0.0159, valid_acc: 0.8609, valid_loss_norm: 0.0176\n",
      " epoch: 211, train accuracy: 0.8872, train_loss_norm:0.0159, valid_acc: 0.8617, valid_loss_norm: 0.0176\n",
      " epoch: 212, train accuracy: 0.8874, train_loss_norm:0.0159, valid_acc: 0.8617, valid_loss_norm: 0.0175\n",
      " epoch: 213, train accuracy: 0.8875, train_loss_norm:0.0158, valid_acc: 0.8617, valid_loss_norm: 0.0175\n",
      " epoch: 214, train accuracy: 0.8876, train_loss_norm:0.0158, valid_acc: 0.8617, valid_loss_norm: 0.0175\n",
      " epoch: 215, train accuracy: 0.8880, train_loss_norm:0.0158, valid_acc: 0.8620, valid_loss_norm: 0.0175\n",
      " epoch: 216, train accuracy: 0.8882, train_loss_norm:0.0157, valid_acc: 0.8620, valid_loss_norm: 0.0174\n",
      " epoch: 217, train accuracy: 0.8885, train_loss_norm:0.0157, valid_acc: 0.8620, valid_loss_norm: 0.0174\n",
      " epoch: 218, train accuracy: 0.8888, train_loss_norm:0.0157, valid_acc: 0.8632, valid_loss_norm: 0.0174\n",
      " epoch: 219, train accuracy: 0.8890, train_loss_norm:0.0157, valid_acc: 0.8632, valid_loss_norm: 0.0174\n",
      " epoch: 220, train accuracy: 0.8892, train_loss_norm:0.0156, valid_acc: 0.8635, valid_loss_norm: 0.0173\n",
      " epoch: 221, train accuracy: 0.8893, train_loss_norm:0.0156, valid_acc: 0.8638, valid_loss_norm: 0.0173\n",
      " epoch: 222, train accuracy: 0.8896, train_loss_norm:0.0156, valid_acc: 0.8640, valid_loss_norm: 0.0173\n",
      " epoch: 223, train accuracy: 0.8897, train_loss_norm:0.0155, valid_acc: 0.8640, valid_loss_norm: 0.0173\n",
      " epoch: 224, train accuracy: 0.8899, train_loss_norm:0.0155, valid_acc: 0.8640, valid_loss_norm: 0.0172\n",
      " epoch: 225, train accuracy: 0.8901, train_loss_norm:0.0155, valid_acc: 0.8640, valid_loss_norm: 0.0172\n",
      " epoch: 226, train accuracy: 0.8901, train_loss_norm:0.0155, valid_acc: 0.8638, valid_loss_norm: 0.0172\n",
      " epoch: 227, train accuracy: 0.8904, train_loss_norm:0.0154, valid_acc: 0.8638, valid_loss_norm: 0.0172\n",
      " epoch: 228, train accuracy: 0.8907, train_loss_norm:0.0154, valid_acc: 0.8638, valid_loss_norm: 0.0171\n",
      " epoch: 229, train accuracy: 0.8908, train_loss_norm:0.0154, valid_acc: 0.8640, valid_loss_norm: 0.0171\n",
      " epoch: 230, train accuracy: 0.8909, train_loss_norm:0.0154, valid_acc: 0.8640, valid_loss_norm: 0.0171\n",
      " epoch: 231, train accuracy: 0.8911, train_loss_norm:0.0153, valid_acc: 0.8640, valid_loss_norm: 0.0171\n",
      " epoch: 232, train accuracy: 0.8913, train_loss_norm:0.0153, valid_acc: 0.8638, valid_loss_norm: 0.0170\n",
      " epoch: 233, train accuracy: 0.8913, train_loss_norm:0.0153, valid_acc: 0.8638, valid_loss_norm: 0.0170\n",
      " epoch: 234, train accuracy: 0.8917, train_loss_norm:0.0152, valid_acc: 0.8638, valid_loss_norm: 0.0170\n",
      " epoch: 235, train accuracy: 0.8919, train_loss_norm:0.0152, valid_acc: 0.8635, valid_loss_norm: 0.0170\n",
      " epoch: 236, train accuracy: 0.8920, train_loss_norm:0.0152, valid_acc: 0.8635, valid_loss_norm: 0.0170\n",
      " epoch: 237, train accuracy: 0.8923, train_loss_norm:0.0152, valid_acc: 0.8635, valid_loss_norm: 0.0169\n",
      " epoch: 238, train accuracy: 0.8923, train_loss_norm:0.0151, valid_acc: 0.8635, valid_loss_norm: 0.0169\n",
      " epoch: 239, train accuracy: 0.8924, train_loss_norm:0.0151, valid_acc: 0.8635, valid_loss_norm: 0.0169\n",
      " epoch: 240, train accuracy: 0.8925, train_loss_norm:0.0151, valid_acc: 0.8635, valid_loss_norm: 0.0169\n",
      " epoch: 241, train accuracy: 0.8925, train_loss_norm:0.0151, valid_acc: 0.8635, valid_loss_norm: 0.0169\n",
      " epoch: 242, train accuracy: 0.8927, train_loss_norm:0.0150, valid_acc: 0.8638, valid_loss_norm: 0.0168\n",
      " epoch: 243, train accuracy: 0.8928, train_loss_norm:0.0150, valid_acc: 0.8640, valid_loss_norm: 0.0168\n",
      " epoch: 244, train accuracy: 0.8929, train_loss_norm:0.0150, valid_acc: 0.8643, valid_loss_norm: 0.0168\n",
      " epoch: 245, train accuracy: 0.8930, train_loss_norm:0.0150, valid_acc: 0.8643, valid_loss_norm: 0.0168\n",
      " epoch: 246, train accuracy: 0.8932, train_loss_norm:0.0149, valid_acc: 0.8643, valid_loss_norm: 0.0167\n",
      " epoch: 247, train accuracy: 0.8933, train_loss_norm:0.0149, valid_acc: 0.8643, valid_loss_norm: 0.0167\n",
      " epoch: 248, train accuracy: 0.8935, train_loss_norm:0.0149, valid_acc: 0.8643, valid_loss_norm: 0.0167\n",
      " epoch: 249, train accuracy: 0.8937, train_loss_norm:0.0149, valid_acc: 0.8643, valid_loss_norm: 0.0167\n",
      " epoch: 250, train accuracy: 0.8938, train_loss_norm:0.0148, valid_acc: 0.8649, valid_loss_norm: 0.0167\n",
      " epoch: 251, train accuracy: 0.8940, train_loss_norm:0.0148, valid_acc: 0.8649, valid_loss_norm: 0.0166\n",
      " epoch: 252, train accuracy: 0.8941, train_loss_norm:0.0148, valid_acc: 0.8652, valid_loss_norm: 0.0166\n",
      " epoch: 253, train accuracy: 0.8943, train_loss_norm:0.0148, valid_acc: 0.8655, valid_loss_norm: 0.0166\n",
      " epoch: 254, train accuracy: 0.8944, train_loss_norm:0.0148, valid_acc: 0.8655, valid_loss_norm: 0.0166\n",
      " epoch: 255, train accuracy: 0.8945, train_loss_norm:0.0147, valid_acc: 0.8655, valid_loss_norm: 0.0166\n",
      " epoch: 256, train accuracy: 0.8947, train_loss_norm:0.0147, valid_acc: 0.8649, valid_loss_norm: 0.0166\n",
      " epoch: 257, train accuracy: 0.8948, train_loss_norm:0.0147, valid_acc: 0.8649, valid_loss_norm: 0.0165\n",
      " epoch: 258, train accuracy: 0.8950, train_loss_norm:0.0147, valid_acc: 0.8652, valid_loss_norm: 0.0165\n",
      " epoch: 259, train accuracy: 0.8950, train_loss_norm:0.0146, valid_acc: 0.8652, valid_loss_norm: 0.0165\n",
      " epoch: 260, train accuracy: 0.8952, train_loss_norm:0.0146, valid_acc: 0.8652, valid_loss_norm: 0.0165\n",
      " epoch: 261, train accuracy: 0.8953, train_loss_norm:0.0146, valid_acc: 0.8655, valid_loss_norm: 0.0165\n",
      " epoch: 262, train accuracy: 0.8954, train_loss_norm:0.0146, valid_acc: 0.8661, valid_loss_norm: 0.0164\n",
      " epoch: 263, train accuracy: 0.8957, train_loss_norm:0.0145, valid_acc: 0.8661, valid_loss_norm: 0.0164\n",
      " epoch: 264, train accuracy: 0.8958, train_loss_norm:0.0145, valid_acc: 0.8661, valid_loss_norm: 0.0164\n",
      " epoch: 265, train accuracy: 0.8958, train_loss_norm:0.0145, valid_acc: 0.8661, valid_loss_norm: 0.0164\n",
      " epoch: 266, train accuracy: 0.8959, train_loss_norm:0.0145, valid_acc: 0.8661, valid_loss_norm: 0.0164\n",
      " epoch: 267, train accuracy: 0.8961, train_loss_norm:0.0145, valid_acc: 0.8661, valid_loss_norm: 0.0163\n",
      " epoch: 268, train accuracy: 0.8963, train_loss_norm:0.0144, valid_acc: 0.8661, valid_loss_norm: 0.0163\n",
      " epoch: 269, train accuracy: 0.8963, train_loss_norm:0.0144, valid_acc: 0.8661, valid_loss_norm: 0.0163\n",
      " epoch: 270, train accuracy: 0.8964, train_loss_norm:0.0144, valid_acc: 0.8661, valid_loss_norm: 0.0163\n",
      " epoch: 271, train accuracy: 0.8965, train_loss_norm:0.0144, valid_acc: 0.8661, valid_loss_norm: 0.0163\n",
      " epoch: 272, train accuracy: 0.8966, train_loss_norm:0.0144, valid_acc: 0.8663, valid_loss_norm: 0.0163\n",
      " epoch: 273, train accuracy: 0.8968, train_loss_norm:0.0143, valid_acc: 0.8661, valid_loss_norm: 0.0162\n",
      " epoch: 274, train accuracy: 0.8968, train_loss_norm:0.0143, valid_acc: 0.8661, valid_loss_norm: 0.0162\n",
      " epoch: 275, train accuracy: 0.8970, train_loss_norm:0.0143, valid_acc: 0.8661, valid_loss_norm: 0.0162\n",
      " epoch: 276, train accuracy: 0.8971, train_loss_norm:0.0143, valid_acc: 0.8663, valid_loss_norm: 0.0162\n",
      " epoch: 277, train accuracy: 0.8973, train_loss_norm:0.0142, valid_acc: 0.8663, valid_loss_norm: 0.0162\n",
      " epoch: 278, train accuracy: 0.8975, train_loss_norm:0.0142, valid_acc: 0.8661, valid_loss_norm: 0.0162\n",
      " epoch: 279, train accuracy: 0.8974, train_loss_norm:0.0142, valid_acc: 0.8661, valid_loss_norm: 0.0161\n",
      " epoch: 280, train accuracy: 0.8976, train_loss_norm:0.0142, valid_acc: 0.8661, valid_loss_norm: 0.0161\n",
      " epoch: 281, train accuracy: 0.8977, train_loss_norm:0.0142, valid_acc: 0.8661, valid_loss_norm: 0.0161\n",
      " epoch: 282, train accuracy: 0.8978, train_loss_norm:0.0141, valid_acc: 0.8661, valid_loss_norm: 0.0161\n",
      " epoch: 283, train accuracy: 0.8981, train_loss_norm:0.0141, valid_acc: 0.8661, valid_loss_norm: 0.0161\n",
      " epoch: 284, train accuracy: 0.8983, train_loss_norm:0.0141, valid_acc: 0.8661, valid_loss_norm: 0.0161\n",
      " epoch: 285, train accuracy: 0.8984, train_loss_norm:0.0141, valid_acc: 0.8661, valid_loss_norm: 0.0160\n",
      " epoch: 286, train accuracy: 0.8984, train_loss_norm:0.0141, valid_acc: 0.8663, valid_loss_norm: 0.0160\n",
      " epoch: 287, train accuracy: 0.8985, train_loss_norm:0.0140, valid_acc: 0.8663, valid_loss_norm: 0.0160\n",
      " epoch: 288, train accuracy: 0.8986, train_loss_norm:0.0140, valid_acc: 0.8666, valid_loss_norm: 0.0160\n",
      " epoch: 289, train accuracy: 0.8988, train_loss_norm:0.0140, valid_acc: 0.8672, valid_loss_norm: 0.0160\n",
      " epoch: 290, train accuracy: 0.8990, train_loss_norm:0.0140, valid_acc: 0.8672, valid_loss_norm: 0.0160\n",
      " epoch: 291, train accuracy: 0.8991, train_loss_norm:0.0140, valid_acc: 0.8672, valid_loss_norm: 0.0159\n",
      " epoch: 292, train accuracy: 0.8991, train_loss_norm:0.0140, valid_acc: 0.8675, valid_loss_norm: 0.0159\n",
      " epoch: 293, train accuracy: 0.8992, train_loss_norm:0.0139, valid_acc: 0.8678, valid_loss_norm: 0.0159\n",
      " epoch: 294, train accuracy: 0.8993, train_loss_norm:0.0139, valid_acc: 0.8678, valid_loss_norm: 0.0159\n",
      " epoch: 295, train accuracy: 0.8996, train_loss_norm:0.0139, valid_acc: 0.8681, valid_loss_norm: 0.0159\n",
      " epoch: 296, train accuracy: 0.8996, train_loss_norm:0.0139, valid_acc: 0.8681, valid_loss_norm: 0.0159\n",
      " epoch: 297, train accuracy: 0.8997, train_loss_norm:0.0139, valid_acc: 0.8681, valid_loss_norm: 0.0159\n",
      " epoch: 298, train accuracy: 0.8999, train_loss_norm:0.0138, valid_acc: 0.8681, valid_loss_norm: 0.0158\n",
      " epoch: 299, train accuracy: 0.9000, train_loss_norm:0.0138, valid_acc: 0.8681, valid_loss_norm: 0.0158\n",
      " epoch: 300, train accuracy: 0.9002, train_loss_norm:0.0138, valid_acc: 0.8681, valid_loss_norm: 0.0158\n",
      "Test accuracy: 0.8646\n",
      "Test loss norm: 0.0168\n",
      "Cur fold: 1\n",
      "(27841, 300)\n",
      "(3479, 300)\n",
      "(3479, 300)\n",
      " epoch: 1, train accuracy: 0.7938, train_loss_norm:0.0836, valid_acc: 0.7804, valid_loss_norm: 0.0837\n",
      " epoch: 2, train accuracy: 0.7940, train_loss_norm:0.0799, valid_acc: 0.7798, valid_loss_norm: 0.0801\n",
      " epoch: 3, train accuracy: 0.7944, train_loss_norm:0.0763, valid_acc: 0.7798, valid_loss_norm: 0.0766\n",
      " epoch: 4, train accuracy: 0.7951, train_loss_norm:0.0729, valid_acc: 0.7801, valid_loss_norm: 0.0733\n",
      " epoch: 5, train accuracy: 0.7957, train_loss_norm:0.0697, valid_acc: 0.7804, valid_loss_norm: 0.0702\n",
      " epoch: 6, train accuracy: 0.7966, train_loss_norm:0.0667, valid_acc: 0.7813, valid_loss_norm: 0.0673\n",
      " epoch: 7, train accuracy: 0.7976, train_loss_norm:0.0639, valid_acc: 0.7830, valid_loss_norm: 0.0647\n",
      " epoch: 8, train accuracy: 0.7986, train_loss_norm:0.0614, valid_acc: 0.7830, valid_loss_norm: 0.0622\n",
      " epoch: 9, train accuracy: 0.8001, train_loss_norm:0.0591, valid_acc: 0.7844, valid_loss_norm: 0.0600\n",
      " epoch: 10, train accuracy: 0.8020, train_loss_norm:0.0570, valid_acc: 0.7856, valid_loss_norm: 0.0580\n",
      " epoch: 11, train accuracy: 0.8036, train_loss_norm:0.0551, valid_acc: 0.7864, valid_loss_norm: 0.0562\n",
      " epoch: 12, train accuracy: 0.8055, train_loss_norm:0.0534, valid_acc: 0.7887, valid_loss_norm: 0.0545\n",
      " epoch: 13, train accuracy: 0.8072, train_loss_norm:0.0518, valid_acc: 0.7910, valid_loss_norm: 0.0530\n",
      " epoch: 14, train accuracy: 0.8086, train_loss_norm:0.0504, valid_acc: 0.7928, valid_loss_norm: 0.0516\n",
      " epoch: 15, train accuracy: 0.8104, train_loss_norm:0.0490, valid_acc: 0.7948, valid_loss_norm: 0.0503\n",
      " epoch: 16, train accuracy: 0.8118, train_loss_norm:0.0478, valid_acc: 0.7951, valid_loss_norm: 0.0491\n",
      " epoch: 17, train accuracy: 0.8135, train_loss_norm:0.0467, valid_acc: 0.7951, valid_loss_norm: 0.0480\n",
      " epoch: 18, train accuracy: 0.8149, train_loss_norm:0.0456, valid_acc: 0.7971, valid_loss_norm: 0.0470\n",
      " epoch: 19, train accuracy: 0.8164, train_loss_norm:0.0446, valid_acc: 0.7976, valid_loss_norm: 0.0460\n",
      " epoch: 20, train accuracy: 0.8175, train_loss_norm:0.0437, valid_acc: 0.7982, valid_loss_norm: 0.0451\n",
      " epoch: 21, train accuracy: 0.8189, train_loss_norm:0.0428, valid_acc: 0.7994, valid_loss_norm: 0.0443\n",
      " epoch: 22, train accuracy: 0.8200, train_loss_norm:0.0419, valid_acc: 0.8002, valid_loss_norm: 0.0435\n",
      " epoch: 23, train accuracy: 0.8211, train_loss_norm:0.0412, valid_acc: 0.8014, valid_loss_norm: 0.0428\n",
      " epoch: 24, train accuracy: 0.8223, train_loss_norm:0.0404, valid_acc: 0.8017, valid_loss_norm: 0.0421\n",
      " epoch: 25, train accuracy: 0.8232, train_loss_norm:0.0397, valid_acc: 0.8037, valid_loss_norm: 0.0414\n",
      " epoch: 26, train accuracy: 0.8238, train_loss_norm:0.0391, valid_acc: 0.8043, valid_loss_norm: 0.0408\n",
      " epoch: 27, train accuracy: 0.8251, train_loss_norm:0.0384, valid_acc: 0.8043, valid_loss_norm: 0.0402\n",
      " epoch: 28, train accuracy: 0.8263, train_loss_norm:0.0378, valid_acc: 0.8051, valid_loss_norm: 0.0396\n",
      " epoch: 29, train accuracy: 0.8274, train_loss_norm:0.0373, valid_acc: 0.8066, valid_loss_norm: 0.0390\n",
      " epoch: 30, train accuracy: 0.8285, train_loss_norm:0.0367, valid_acc: 0.8068, valid_loss_norm: 0.0385\n",
      " epoch: 31, train accuracy: 0.8296, train_loss_norm:0.0362, valid_acc: 0.8068, valid_loss_norm: 0.0380\n",
      " epoch: 32, train accuracy: 0.8303, train_loss_norm:0.0357, valid_acc: 0.8077, valid_loss_norm: 0.0375\n",
      " epoch: 33, train accuracy: 0.8307, train_loss_norm:0.0352, valid_acc: 0.8091, valid_loss_norm: 0.0371\n",
      " epoch: 34, train accuracy: 0.8317, train_loss_norm:0.0348, valid_acc: 0.8100, valid_loss_norm: 0.0366\n",
      " epoch: 35, train accuracy: 0.8327, train_loss_norm:0.0343, valid_acc: 0.8114, valid_loss_norm: 0.0362\n",
      " epoch: 36, train accuracy: 0.8340, train_loss_norm:0.0339, valid_acc: 0.8114, valid_loss_norm: 0.0358\n",
      " epoch: 37, train accuracy: 0.8348, train_loss_norm:0.0335, valid_acc: 0.8109, valid_loss_norm: 0.0354\n",
      " epoch: 38, train accuracy: 0.8356, train_loss_norm:0.0331, valid_acc: 0.8117, valid_loss_norm: 0.0350\n",
      " epoch: 39, train accuracy: 0.8360, train_loss_norm:0.0327, valid_acc: 0.8117, valid_loss_norm: 0.0347\n",
      " epoch: 40, train accuracy: 0.8365, train_loss_norm:0.0324, valid_acc: 0.8120, valid_loss_norm: 0.0343\n",
      " epoch: 41, train accuracy: 0.8373, train_loss_norm:0.0320, valid_acc: 0.8126, valid_loss_norm: 0.0340\n",
      " epoch: 42, train accuracy: 0.8377, train_loss_norm:0.0317, valid_acc: 0.8137, valid_loss_norm: 0.0337\n",
      " epoch: 43, train accuracy: 0.8383, train_loss_norm:0.0313, valid_acc: 0.8143, valid_loss_norm: 0.0334\n",
      " epoch: 44, train accuracy: 0.8390, train_loss_norm:0.0310, valid_acc: 0.8152, valid_loss_norm: 0.0330\n",
      " epoch: 45, train accuracy: 0.8398, train_loss_norm:0.0307, valid_acc: 0.8155, valid_loss_norm: 0.0327\n",
      " epoch: 46, train accuracy: 0.8403, train_loss_norm:0.0304, valid_acc: 0.8158, valid_loss_norm: 0.0325\n",
      " epoch: 47, train accuracy: 0.8408, train_loss_norm:0.0301, valid_acc: 0.8169, valid_loss_norm: 0.0322\n",
      " epoch: 48, train accuracy: 0.8415, train_loss_norm:0.0298, valid_acc: 0.8183, valid_loss_norm: 0.0319\n",
      " epoch: 49, train accuracy: 0.8422, train_loss_norm:0.0296, valid_acc: 0.8183, valid_loss_norm: 0.0317\n",
      " epoch: 50, train accuracy: 0.8427, train_loss_norm:0.0293, valid_acc: 0.8192, valid_loss_norm: 0.0314\n",
      " epoch: 51, train accuracy: 0.8434, train_loss_norm:0.0290, valid_acc: 0.8201, valid_loss_norm: 0.0312\n",
      " epoch: 52, train accuracy: 0.8437, train_loss_norm:0.0288, valid_acc: 0.8209, valid_loss_norm: 0.0309\n",
      " epoch: 53, train accuracy: 0.8441, train_loss_norm:0.0285, valid_acc: 0.8215, valid_loss_norm: 0.0307\n",
      " epoch: 54, train accuracy: 0.8448, train_loss_norm:0.0283, valid_acc: 0.8227, valid_loss_norm: 0.0305\n",
      " epoch: 55, train accuracy: 0.8452, train_loss_norm:0.0281, valid_acc: 0.8229, valid_loss_norm: 0.0302\n",
      " epoch: 56, train accuracy: 0.8456, train_loss_norm:0.0278, valid_acc: 0.8235, valid_loss_norm: 0.0300\n",
      " epoch: 57, train accuracy: 0.8459, train_loss_norm:0.0276, valid_acc: 0.8232, valid_loss_norm: 0.0298\n",
      " epoch: 58, train accuracy: 0.8466, train_loss_norm:0.0274, valid_acc: 0.8238, valid_loss_norm: 0.0296\n",
      " epoch: 59, train accuracy: 0.8469, train_loss_norm:0.0272, valid_acc: 0.8238, valid_loss_norm: 0.0294\n",
      " epoch: 60, train accuracy: 0.8476, train_loss_norm:0.0270, valid_acc: 0.8244, valid_loss_norm: 0.0292\n",
      " epoch: 61, train accuracy: 0.8479, train_loss_norm:0.0268, valid_acc: 0.8252, valid_loss_norm: 0.0290\n",
      " epoch: 62, train accuracy: 0.8483, train_loss_norm:0.0266, valid_acc: 0.8252, valid_loss_norm: 0.0288\n",
      " epoch: 63, train accuracy: 0.8486, train_loss_norm:0.0264, valid_acc: 0.8255, valid_loss_norm: 0.0287\n",
      " epoch: 64, train accuracy: 0.8490, train_loss_norm:0.0262, valid_acc: 0.8267, valid_loss_norm: 0.0285\n",
      " epoch: 65, train accuracy: 0.8494, train_loss_norm:0.0260, valid_acc: 0.8275, valid_loss_norm: 0.0283\n",
      " epoch: 66, train accuracy: 0.8499, train_loss_norm:0.0259, valid_acc: 0.8278, valid_loss_norm: 0.0281\n",
      " epoch: 67, train accuracy: 0.8502, train_loss_norm:0.0257, valid_acc: 0.8272, valid_loss_norm: 0.0280\n",
      " epoch: 68, train accuracy: 0.8506, train_loss_norm:0.0255, valid_acc: 0.8272, valid_loss_norm: 0.0278\n",
      " epoch: 69, train accuracy: 0.8513, train_loss_norm:0.0254, valid_acc: 0.8287, valid_loss_norm: 0.0277\n",
      " epoch: 70, train accuracy: 0.8517, train_loss_norm:0.0252, valid_acc: 0.8301, valid_loss_norm: 0.0275\n",
      " epoch: 71, train accuracy: 0.8523, train_loss_norm:0.0250, valid_acc: 0.8310, valid_loss_norm: 0.0274\n",
      " epoch: 72, train accuracy: 0.8529, train_loss_norm:0.0249, valid_acc: 0.8316, valid_loss_norm: 0.0272\n",
      " epoch: 73, train accuracy: 0.8532, train_loss_norm:0.0247, valid_acc: 0.8313, valid_loss_norm: 0.0271\n",
      " epoch: 74, train accuracy: 0.8537, train_loss_norm:0.0246, valid_acc: 0.8316, valid_loss_norm: 0.0269\n",
      " epoch: 75, train accuracy: 0.8542, train_loss_norm:0.0244, valid_acc: 0.8318, valid_loss_norm: 0.0268\n",
      " epoch: 76, train accuracy: 0.8544, train_loss_norm:0.0243, valid_acc: 0.8318, valid_loss_norm: 0.0266\n",
      " epoch: 77, train accuracy: 0.8548, train_loss_norm:0.0242, valid_acc: 0.8324, valid_loss_norm: 0.0265\n",
      " epoch: 78, train accuracy: 0.8551, train_loss_norm:0.0240, valid_acc: 0.8333, valid_loss_norm: 0.0264\n",
      " epoch: 79, train accuracy: 0.8553, train_loss_norm:0.0239, valid_acc: 0.8336, valid_loss_norm: 0.0263\n",
      " epoch: 80, train accuracy: 0.8556, train_loss_norm:0.0238, valid_acc: 0.8336, valid_loss_norm: 0.0261\n",
      " epoch: 81, train accuracy: 0.8561, train_loss_norm:0.0236, valid_acc: 0.8341, valid_loss_norm: 0.0260\n",
      " epoch: 82, train accuracy: 0.8565, train_loss_norm:0.0235, valid_acc: 0.8347, valid_loss_norm: 0.0259\n",
      " epoch: 83, train accuracy: 0.8570, train_loss_norm:0.0234, valid_acc: 0.8350, valid_loss_norm: 0.0258\n",
      " epoch: 84, train accuracy: 0.8575, train_loss_norm:0.0232, valid_acc: 0.8350, valid_loss_norm: 0.0256\n",
      " epoch: 85, train accuracy: 0.8579, train_loss_norm:0.0231, valid_acc: 0.8359, valid_loss_norm: 0.0255\n",
      " epoch: 86, train accuracy: 0.8581, train_loss_norm:0.0230, valid_acc: 0.8356, valid_loss_norm: 0.0254\n",
      " epoch: 87, train accuracy: 0.8583, train_loss_norm:0.0229, valid_acc: 0.8353, valid_loss_norm: 0.0253\n",
      " epoch: 88, train accuracy: 0.8588, train_loss_norm:0.0228, valid_acc: 0.8350, valid_loss_norm: 0.0252\n",
      " epoch: 89, train accuracy: 0.8591, train_loss_norm:0.0227, valid_acc: 0.8350, valid_loss_norm: 0.0251\n",
      " epoch: 90, train accuracy: 0.8596, train_loss_norm:0.0226, valid_acc: 0.8356, valid_loss_norm: 0.0250\n",
      " epoch: 91, train accuracy: 0.8600, train_loss_norm:0.0224, valid_acc: 0.8362, valid_loss_norm: 0.0249\n",
      " epoch: 92, train accuracy: 0.8606, train_loss_norm:0.0223, valid_acc: 0.8367, valid_loss_norm: 0.0248\n",
      " epoch: 93, train accuracy: 0.8608, train_loss_norm:0.0222, valid_acc: 0.8370, valid_loss_norm: 0.0247\n",
      " epoch: 94, train accuracy: 0.8615, train_loss_norm:0.0221, valid_acc: 0.8379, valid_loss_norm: 0.0246\n",
      " epoch: 95, train accuracy: 0.8616, train_loss_norm:0.0220, valid_acc: 0.8379, valid_loss_norm: 0.0245\n",
      " epoch: 96, train accuracy: 0.8618, train_loss_norm:0.0219, valid_acc: 0.8379, valid_loss_norm: 0.0244\n",
      " epoch: 97, train accuracy: 0.8621, train_loss_norm:0.0218, valid_acc: 0.8379, valid_loss_norm: 0.0243\n",
      " epoch: 98, train accuracy: 0.8625, train_loss_norm:0.0217, valid_acc: 0.8379, valid_loss_norm: 0.0242\n",
      " epoch: 99, train accuracy: 0.8629, train_loss_norm:0.0216, valid_acc: 0.8382, valid_loss_norm: 0.0241\n",
      " epoch: 100, train accuracy: 0.8632, train_loss_norm:0.0215, valid_acc: 0.8385, valid_loss_norm: 0.0240\n",
      " epoch: 101, train accuracy: 0.8635, train_loss_norm:0.0214, valid_acc: 0.8385, valid_loss_norm: 0.0239\n",
      " epoch: 102, train accuracy: 0.8640, train_loss_norm:0.0214, valid_acc: 0.8382, valid_loss_norm: 0.0239\n",
      " epoch: 103, train accuracy: 0.8643, train_loss_norm:0.0213, valid_acc: 0.8382, valid_loss_norm: 0.0238\n",
      " epoch: 104, train accuracy: 0.8646, train_loss_norm:0.0212, valid_acc: 0.8387, valid_loss_norm: 0.0237\n",
      " epoch: 105, train accuracy: 0.8648, train_loss_norm:0.0211, valid_acc: 0.8385, valid_loss_norm: 0.0236\n",
      " epoch: 106, train accuracy: 0.8653, train_loss_norm:0.0210, valid_acc: 0.8387, valid_loss_norm: 0.0235\n",
      " epoch: 107, train accuracy: 0.8654, train_loss_norm:0.0209, valid_acc: 0.8390, valid_loss_norm: 0.0235\n",
      " epoch: 108, train accuracy: 0.8656, train_loss_norm:0.0208, valid_acc: 0.8402, valid_loss_norm: 0.0234\n",
      " epoch: 109, train accuracy: 0.8657, train_loss_norm:0.0207, valid_acc: 0.8399, valid_loss_norm: 0.0233\n",
      " epoch: 110, train accuracy: 0.8659, train_loss_norm:0.0207, valid_acc: 0.8402, valid_loss_norm: 0.0232\n",
      " epoch: 111, train accuracy: 0.8664, train_loss_norm:0.0206, valid_acc: 0.8402, valid_loss_norm: 0.0231\n",
      " epoch: 112, train accuracy: 0.8667, train_loss_norm:0.0205, valid_acc: 0.8405, valid_loss_norm: 0.0231\n",
      " epoch: 113, train accuracy: 0.8671, train_loss_norm:0.0204, valid_acc: 0.8399, valid_loss_norm: 0.0230\n",
      " epoch: 114, train accuracy: 0.8675, train_loss_norm:0.0204, valid_acc: 0.8408, valid_loss_norm: 0.0229\n",
      " epoch: 115, train accuracy: 0.8676, train_loss_norm:0.0203, valid_acc: 0.8410, valid_loss_norm: 0.0229\n",
      " epoch: 116, train accuracy: 0.8679, train_loss_norm:0.0202, valid_acc: 0.8410, valid_loss_norm: 0.0228\n",
      " epoch: 117, train accuracy: 0.8682, train_loss_norm:0.0201, valid_acc: 0.8413, valid_loss_norm: 0.0227\n",
      " epoch: 118, train accuracy: 0.8685, train_loss_norm:0.0201, valid_acc: 0.8416, valid_loss_norm: 0.0226\n",
      " epoch: 119, train accuracy: 0.8687, train_loss_norm:0.0200, valid_acc: 0.8419, valid_loss_norm: 0.0226\n",
      " epoch: 120, train accuracy: 0.8690, train_loss_norm:0.0199, valid_acc: 0.8419, valid_loss_norm: 0.0225\n",
      " epoch: 121, train accuracy: 0.8692, train_loss_norm:0.0198, valid_acc: 0.8419, valid_loss_norm: 0.0224\n",
      " epoch: 122, train accuracy: 0.8693, train_loss_norm:0.0198, valid_acc: 0.8419, valid_loss_norm: 0.0224\n",
      " epoch: 123, train accuracy: 0.8696, train_loss_norm:0.0197, valid_acc: 0.8422, valid_loss_norm: 0.0223\n",
      " epoch: 124, train accuracy: 0.8698, train_loss_norm:0.0196, valid_acc: 0.8422, valid_loss_norm: 0.0223\n",
      " epoch: 125, train accuracy: 0.8700, train_loss_norm:0.0196, valid_acc: 0.8416, valid_loss_norm: 0.0222\n",
      " epoch: 126, train accuracy: 0.8703, train_loss_norm:0.0195, valid_acc: 0.8419, valid_loss_norm: 0.0221\n",
      " epoch: 127, train accuracy: 0.8705, train_loss_norm:0.0194, valid_acc: 0.8419, valid_loss_norm: 0.0221\n",
      " epoch: 128, train accuracy: 0.8706, train_loss_norm:0.0194, valid_acc: 0.8422, valid_loss_norm: 0.0220\n",
      " epoch: 129, train accuracy: 0.8709, train_loss_norm:0.0193, valid_acc: 0.8425, valid_loss_norm: 0.0220\n",
      " epoch: 130, train accuracy: 0.8715, train_loss_norm:0.0192, valid_acc: 0.8431, valid_loss_norm: 0.0219\n",
      " epoch: 131, train accuracy: 0.8717, train_loss_norm:0.0192, valid_acc: 0.8433, valid_loss_norm: 0.0218\n",
      " epoch: 132, train accuracy: 0.8720, train_loss_norm:0.0191, valid_acc: 0.8436, valid_loss_norm: 0.0218\n",
      " epoch: 133, train accuracy: 0.8722, train_loss_norm:0.0191, valid_acc: 0.8436, valid_loss_norm: 0.0217\n",
      " epoch: 134, train accuracy: 0.8725, train_loss_norm:0.0190, valid_acc: 0.8445, valid_loss_norm: 0.0217\n",
      " epoch: 135, train accuracy: 0.8728, train_loss_norm:0.0189, valid_acc: 0.8445, valid_loss_norm: 0.0216\n",
      " epoch: 136, train accuracy: 0.8731, train_loss_norm:0.0189, valid_acc: 0.8448, valid_loss_norm: 0.0216\n",
      " epoch: 137, train accuracy: 0.8734, train_loss_norm:0.0188, valid_acc: 0.8451, valid_loss_norm: 0.0215\n",
      " epoch: 138, train accuracy: 0.8735, train_loss_norm:0.0188, valid_acc: 0.8454, valid_loss_norm: 0.0214\n",
      " epoch: 139, train accuracy: 0.8737, train_loss_norm:0.0187, valid_acc: 0.8454, valid_loss_norm: 0.0214\n",
      " epoch: 140, train accuracy: 0.8739, train_loss_norm:0.0186, valid_acc: 0.8451, valid_loss_norm: 0.0213\n",
      " epoch: 141, train accuracy: 0.8741, train_loss_norm:0.0186, valid_acc: 0.8451, valid_loss_norm: 0.0213\n",
      " epoch: 142, train accuracy: 0.8745, train_loss_norm:0.0185, valid_acc: 0.8454, valid_loss_norm: 0.0212\n",
      " epoch: 143, train accuracy: 0.8748, train_loss_norm:0.0185, valid_acc: 0.8456, valid_loss_norm: 0.0212\n",
      " epoch: 144, train accuracy: 0.8749, train_loss_norm:0.0184, valid_acc: 0.8459, valid_loss_norm: 0.0211\n",
      " epoch: 145, train accuracy: 0.8753, train_loss_norm:0.0184, valid_acc: 0.8465, valid_loss_norm: 0.0211\n",
      " epoch: 146, train accuracy: 0.8754, train_loss_norm:0.0183, valid_acc: 0.8468, valid_loss_norm: 0.0210\n",
      " epoch: 147, train accuracy: 0.8756, train_loss_norm:0.0183, valid_acc: 0.8471, valid_loss_norm: 0.0210\n",
      " epoch: 148, train accuracy: 0.8758, train_loss_norm:0.0182, valid_acc: 0.8474, valid_loss_norm: 0.0209\n",
      " epoch: 149, train accuracy: 0.8761, train_loss_norm:0.0182, valid_acc: 0.8474, valid_loss_norm: 0.0209\n",
      " epoch: 150, train accuracy: 0.8762, train_loss_norm:0.0181, valid_acc: 0.8474, valid_loss_norm: 0.0209\n",
      " epoch: 151, train accuracy: 0.8764, train_loss_norm:0.0181, valid_acc: 0.8474, valid_loss_norm: 0.0208\n",
      " epoch: 152, train accuracy: 0.8764, train_loss_norm:0.0180, valid_acc: 0.8477, valid_loss_norm: 0.0208\n",
      " epoch: 153, train accuracy: 0.8766, train_loss_norm:0.0180, valid_acc: 0.8477, valid_loss_norm: 0.0207\n",
      " epoch: 154, train accuracy: 0.8767, train_loss_norm:0.0179, valid_acc: 0.8482, valid_loss_norm: 0.0207\n",
      " epoch: 155, train accuracy: 0.8770, train_loss_norm:0.0179, valid_acc: 0.8482, valid_loss_norm: 0.0206\n",
      " epoch: 156, train accuracy: 0.8772, train_loss_norm:0.0178, valid_acc: 0.8485, valid_loss_norm: 0.0206\n",
      " epoch: 157, train accuracy: 0.8775, train_loss_norm:0.0178, valid_acc: 0.8485, valid_loss_norm: 0.0205\n",
      " epoch: 158, train accuracy: 0.8776, train_loss_norm:0.0177, valid_acc: 0.8488, valid_loss_norm: 0.0205\n",
      " epoch: 159, train accuracy: 0.8777, train_loss_norm:0.0177, valid_acc: 0.8488, valid_loss_norm: 0.0205\n",
      " epoch: 160, train accuracy: 0.8778, train_loss_norm:0.0176, valid_acc: 0.8488, valid_loss_norm: 0.0204\n",
      " epoch: 161, train accuracy: 0.8781, train_loss_norm:0.0176, valid_acc: 0.8491, valid_loss_norm: 0.0204\n",
      " epoch: 162, train accuracy: 0.8784, train_loss_norm:0.0175, valid_acc: 0.8494, valid_loss_norm: 0.0203\n",
      " epoch: 163, train accuracy: 0.8788, train_loss_norm:0.0175, valid_acc: 0.8494, valid_loss_norm: 0.0203\n",
      " epoch: 164, train accuracy: 0.8791, train_loss_norm:0.0174, valid_acc: 0.8491, valid_loss_norm: 0.0202\n",
      " epoch: 165, train accuracy: 0.8792, train_loss_norm:0.0174, valid_acc: 0.8488, valid_loss_norm: 0.0202\n",
      " epoch: 166, train accuracy: 0.8794, train_loss_norm:0.0174, valid_acc: 0.8491, valid_loss_norm: 0.0202\n",
      " epoch: 167, train accuracy: 0.8796, train_loss_norm:0.0173, valid_acc: 0.8494, valid_loss_norm: 0.0201\n",
      " epoch: 168, train accuracy: 0.8797, train_loss_norm:0.0173, valid_acc: 0.8500, valid_loss_norm: 0.0201\n",
      " epoch: 169, train accuracy: 0.8801, train_loss_norm:0.0172, valid_acc: 0.8502, valid_loss_norm: 0.0200\n",
      " epoch: 170, train accuracy: 0.8802, train_loss_norm:0.0172, valid_acc: 0.8502, valid_loss_norm: 0.0200\n",
      " epoch: 171, train accuracy: 0.8804, train_loss_norm:0.0171, valid_acc: 0.8502, valid_loss_norm: 0.0200\n",
      " epoch: 172, train accuracy: 0.8805, train_loss_norm:0.0171, valid_acc: 0.8502, valid_loss_norm: 0.0199\n",
      " epoch: 173, train accuracy: 0.8807, train_loss_norm:0.0171, valid_acc: 0.8502, valid_loss_norm: 0.0199\n",
      " epoch: 174, train accuracy: 0.8809, train_loss_norm:0.0170, valid_acc: 0.8502, valid_loss_norm: 0.0199\n",
      " epoch: 175, train accuracy: 0.8810, train_loss_norm:0.0170, valid_acc: 0.8511, valid_loss_norm: 0.0198\n",
      " epoch: 176, train accuracy: 0.8812, train_loss_norm:0.0169, valid_acc: 0.8514, valid_loss_norm: 0.0198\n",
      " epoch: 177, train accuracy: 0.8814, train_loss_norm:0.0169, valid_acc: 0.8514, valid_loss_norm: 0.0197\n",
      " epoch: 178, train accuracy: 0.8816, train_loss_norm:0.0169, valid_acc: 0.8514, valid_loss_norm: 0.0197\n",
      " epoch: 179, train accuracy: 0.8819, train_loss_norm:0.0168, valid_acc: 0.8514, valid_loss_norm: 0.0197\n",
      " epoch: 180, train accuracy: 0.8822, train_loss_norm:0.0168, valid_acc: 0.8517, valid_loss_norm: 0.0196\n",
      " epoch: 181, train accuracy: 0.8823, train_loss_norm:0.0167, valid_acc: 0.8517, valid_loss_norm: 0.0196\n",
      " epoch: 182, train accuracy: 0.8825, train_loss_norm:0.0167, valid_acc: 0.8517, valid_loss_norm: 0.0196\n",
      " epoch: 183, train accuracy: 0.8826, train_loss_norm:0.0167, valid_acc: 0.8517, valid_loss_norm: 0.0195\n",
      " epoch: 184, train accuracy: 0.8828, train_loss_norm:0.0166, valid_acc: 0.8517, valid_loss_norm: 0.0195\n",
      " epoch: 185, train accuracy: 0.8830, train_loss_norm:0.0166, valid_acc: 0.8520, valid_loss_norm: 0.0195\n",
      " epoch: 186, train accuracy: 0.8834, train_loss_norm:0.0166, valid_acc: 0.8525, valid_loss_norm: 0.0194\n",
      " epoch: 187, train accuracy: 0.8837, train_loss_norm:0.0165, valid_acc: 0.8528, valid_loss_norm: 0.0194\n",
      " epoch: 188, train accuracy: 0.8840, train_loss_norm:0.0165, valid_acc: 0.8531, valid_loss_norm: 0.0194\n",
      " epoch: 189, train accuracy: 0.8842, train_loss_norm:0.0165, valid_acc: 0.8531, valid_loss_norm: 0.0193\n",
      " epoch: 190, train accuracy: 0.8843, train_loss_norm:0.0164, valid_acc: 0.8531, valid_loss_norm: 0.0193\n",
      " epoch: 191, train accuracy: 0.8845, train_loss_norm:0.0164, valid_acc: 0.8531, valid_loss_norm: 0.0193\n",
      " epoch: 192, train accuracy: 0.8848, train_loss_norm:0.0163, valid_acc: 0.8528, valid_loss_norm: 0.0192\n",
      " epoch: 193, train accuracy: 0.8850, train_loss_norm:0.0163, valid_acc: 0.8528, valid_loss_norm: 0.0192\n",
      " epoch: 194, train accuracy: 0.8851, train_loss_norm:0.0163, valid_acc: 0.8525, valid_loss_norm: 0.0192\n",
      " epoch: 195, train accuracy: 0.8852, train_loss_norm:0.0162, valid_acc: 0.8525, valid_loss_norm: 0.0192\n",
      " epoch: 196, train accuracy: 0.8853, train_loss_norm:0.0162, valid_acc: 0.8525, valid_loss_norm: 0.0191\n",
      " epoch: 197, train accuracy: 0.8853, train_loss_norm:0.0162, valid_acc: 0.8528, valid_loss_norm: 0.0191\n",
      " epoch: 198, train accuracy: 0.8856, train_loss_norm:0.0161, valid_acc: 0.8528, valid_loss_norm: 0.0191\n",
      " epoch: 199, train accuracy: 0.8858, train_loss_norm:0.0161, valid_acc: 0.8531, valid_loss_norm: 0.0190\n",
      " epoch: 200, train accuracy: 0.8860, train_loss_norm:0.0161, valid_acc: 0.8531, valid_loss_norm: 0.0190\n",
      " epoch: 201, train accuracy: 0.8860, train_loss_norm:0.0160, valid_acc: 0.8531, valid_loss_norm: 0.0190\n",
      " epoch: 202, train accuracy: 0.8862, train_loss_norm:0.0160, valid_acc: 0.8531, valid_loss_norm: 0.0189\n",
      " epoch: 203, train accuracy: 0.8864, train_loss_norm:0.0160, valid_acc: 0.8537, valid_loss_norm: 0.0189\n",
      " epoch: 204, train accuracy: 0.8866, train_loss_norm:0.0159, valid_acc: 0.8537, valid_loss_norm: 0.0189\n",
      " epoch: 205, train accuracy: 0.8869, train_loss_norm:0.0159, valid_acc: 0.8540, valid_loss_norm: 0.0189\n",
      " epoch: 206, train accuracy: 0.8872, train_loss_norm:0.0159, valid_acc: 0.8546, valid_loss_norm: 0.0188\n",
      " epoch: 207, train accuracy: 0.8873, train_loss_norm:0.0158, valid_acc: 0.8546, valid_loss_norm: 0.0188\n",
      " epoch: 208, train accuracy: 0.8875, train_loss_norm:0.0158, valid_acc: 0.8543, valid_loss_norm: 0.0188\n",
      " epoch: 209, train accuracy: 0.8877, train_loss_norm:0.0158, valid_acc: 0.8543, valid_loss_norm: 0.0187\n",
      " epoch: 210, train accuracy: 0.8878, train_loss_norm:0.0158, valid_acc: 0.8543, valid_loss_norm: 0.0187\n",
      " epoch: 211, train accuracy: 0.8880, train_loss_norm:0.0157, valid_acc: 0.8546, valid_loss_norm: 0.0187\n",
      " epoch: 212, train accuracy: 0.8881, train_loss_norm:0.0157, valid_acc: 0.8546, valid_loss_norm: 0.0187\n",
      " epoch: 213, train accuracy: 0.8883, train_loss_norm:0.0157, valid_acc: 0.8546, valid_loss_norm: 0.0186\n",
      " epoch: 214, train accuracy: 0.8884, train_loss_norm:0.0156, valid_acc: 0.8548, valid_loss_norm: 0.0186\n",
      " epoch: 215, train accuracy: 0.8885, train_loss_norm:0.0156, valid_acc: 0.8548, valid_loss_norm: 0.0186\n",
      " epoch: 216, train accuracy: 0.8886, train_loss_norm:0.0156, valid_acc: 0.8551, valid_loss_norm: 0.0186\n",
      " epoch: 217, train accuracy: 0.8887, train_loss_norm:0.0155, valid_acc: 0.8557, valid_loss_norm: 0.0185\n",
      " epoch: 218, train accuracy: 0.8889, train_loss_norm:0.0155, valid_acc: 0.8560, valid_loss_norm: 0.0185\n",
      " epoch: 219, train accuracy: 0.8890, train_loss_norm:0.0155, valid_acc: 0.8563, valid_loss_norm: 0.0185\n",
      " epoch: 220, train accuracy: 0.8892, train_loss_norm:0.0155, valid_acc: 0.8566, valid_loss_norm: 0.0185\n",
      " epoch: 221, train accuracy: 0.8894, train_loss_norm:0.0154, valid_acc: 0.8563, valid_loss_norm: 0.0184\n",
      " epoch: 222, train accuracy: 0.8897, train_loss_norm:0.0154, valid_acc: 0.8563, valid_loss_norm: 0.0184\n",
      " epoch: 223, train accuracy: 0.8898, train_loss_norm:0.0154, valid_acc: 0.8563, valid_loss_norm: 0.0184\n",
      " epoch: 224, train accuracy: 0.8900, train_loss_norm:0.0153, valid_acc: 0.8563, valid_loss_norm: 0.0184\n",
      " epoch: 225, train accuracy: 0.8902, train_loss_norm:0.0153, valid_acc: 0.8560, valid_loss_norm: 0.0183\n",
      " epoch: 226, train accuracy: 0.8904, train_loss_norm:0.0153, valid_acc: 0.8563, valid_loss_norm: 0.0183\n",
      " epoch: 227, train accuracy: 0.8908, train_loss_norm:0.0153, valid_acc: 0.8560, valid_loss_norm: 0.0183\n",
      " epoch: 228, train accuracy: 0.8909, train_loss_norm:0.0152, valid_acc: 0.8560, valid_loss_norm: 0.0183\n",
      " epoch: 229, train accuracy: 0.8911, train_loss_norm:0.0152, valid_acc: 0.8563, valid_loss_norm: 0.0182\n",
      " epoch: 230, train accuracy: 0.8914, train_loss_norm:0.0152, valid_acc: 0.8563, valid_loss_norm: 0.0182\n",
      " epoch: 231, train accuracy: 0.8914, train_loss_norm:0.0152, valid_acc: 0.8569, valid_loss_norm: 0.0182\n",
      " epoch: 232, train accuracy: 0.8916, train_loss_norm:0.0151, valid_acc: 0.8569, valid_loss_norm: 0.0182\n",
      " epoch: 233, train accuracy: 0.8917, train_loss_norm:0.0151, valid_acc: 0.8566, valid_loss_norm: 0.0181\n",
      " epoch: 234, train accuracy: 0.8919, train_loss_norm:0.0151, valid_acc: 0.8569, valid_loss_norm: 0.0181\n",
      " epoch: 235, train accuracy: 0.8919, train_loss_norm:0.0151, valid_acc: 0.8569, valid_loss_norm: 0.0181\n",
      " epoch: 236, train accuracy: 0.8920, train_loss_norm:0.0150, valid_acc: 0.8569, valid_loss_norm: 0.0181\n",
      " epoch: 237, train accuracy: 0.8921, train_loss_norm:0.0150, valid_acc: 0.8571, valid_loss_norm: 0.0180\n",
      " epoch: 238, train accuracy: 0.8921, train_loss_norm:0.0150, valid_acc: 0.8571, valid_loss_norm: 0.0180\n",
      " epoch: 239, train accuracy: 0.8923, train_loss_norm:0.0149, valid_acc: 0.8577, valid_loss_norm: 0.0180\n",
      " epoch: 240, train accuracy: 0.8923, train_loss_norm:0.0149, valid_acc: 0.8577, valid_loss_norm: 0.0180\n",
      " epoch: 241, train accuracy: 0.8926, train_loss_norm:0.0149, valid_acc: 0.8580, valid_loss_norm: 0.0180\n",
      " epoch: 242, train accuracy: 0.8928, train_loss_norm:0.0149, valid_acc: 0.8580, valid_loss_norm: 0.0179\n",
      " epoch: 243, train accuracy: 0.8929, train_loss_norm:0.0148, valid_acc: 0.8586, valid_loss_norm: 0.0179\n",
      " epoch: 244, train accuracy: 0.8930, train_loss_norm:0.0148, valid_acc: 0.8586, valid_loss_norm: 0.0179\n",
      " epoch: 245, train accuracy: 0.8931, train_loss_norm:0.0148, valid_acc: 0.8589, valid_loss_norm: 0.0179\n",
      " epoch: 246, train accuracy: 0.8933, train_loss_norm:0.0148, valid_acc: 0.8592, valid_loss_norm: 0.0178\n",
      " epoch: 247, train accuracy: 0.8934, train_loss_norm:0.0148, valid_acc: 0.8594, valid_loss_norm: 0.0178\n",
      " epoch: 248, train accuracy: 0.8936, train_loss_norm:0.0147, valid_acc: 0.8594, valid_loss_norm: 0.0178\n",
      " epoch: 249, train accuracy: 0.8939, train_loss_norm:0.0147, valid_acc: 0.8600, valid_loss_norm: 0.0178\n",
      " epoch: 250, train accuracy: 0.8941, train_loss_norm:0.0147, valid_acc: 0.8600, valid_loss_norm: 0.0178\n",
      " epoch: 251, train accuracy: 0.8943, train_loss_norm:0.0147, valid_acc: 0.8600, valid_loss_norm: 0.0177\n",
      " epoch: 252, train accuracy: 0.8944, train_loss_norm:0.0146, valid_acc: 0.8600, valid_loss_norm: 0.0177\n",
      " epoch: 253, train accuracy: 0.8947, train_loss_norm:0.0146, valid_acc: 0.8600, valid_loss_norm: 0.0177\n",
      " epoch: 254, train accuracy: 0.8949, train_loss_norm:0.0146, valid_acc: 0.8603, valid_loss_norm: 0.0177\n",
      " epoch: 255, train accuracy: 0.8949, train_loss_norm:0.0146, valid_acc: 0.8603, valid_loss_norm: 0.0177\n",
      " epoch: 256, train accuracy: 0.8949, train_loss_norm:0.0145, valid_acc: 0.8603, valid_loss_norm: 0.0176\n",
      " epoch: 257, train accuracy: 0.8950, train_loss_norm:0.0145, valid_acc: 0.8603, valid_loss_norm: 0.0176\n",
      " epoch: 258, train accuracy: 0.8952, train_loss_norm:0.0145, valid_acc: 0.8606, valid_loss_norm: 0.0176\n",
      " epoch: 259, train accuracy: 0.8953, train_loss_norm:0.0145, valid_acc: 0.8606, valid_loss_norm: 0.0176\n",
      " epoch: 260, train accuracy: 0.8955, train_loss_norm:0.0144, valid_acc: 0.8609, valid_loss_norm: 0.0176\n",
      " epoch: 261, train accuracy: 0.8956, train_loss_norm:0.0144, valid_acc: 0.8609, valid_loss_norm: 0.0175\n",
      " epoch: 262, train accuracy: 0.8957, train_loss_norm:0.0144, valid_acc: 0.8609, valid_loss_norm: 0.0175\n",
      " epoch: 263, train accuracy: 0.8958, train_loss_norm:0.0144, valid_acc: 0.8617, valid_loss_norm: 0.0175\n",
      " epoch: 264, train accuracy: 0.8961, train_loss_norm:0.0144, valid_acc: 0.8617, valid_loss_norm: 0.0175\n",
      " epoch: 265, train accuracy: 0.8961, train_loss_norm:0.0143, valid_acc: 0.8617, valid_loss_norm: 0.0175\n",
      " epoch: 266, train accuracy: 0.8963, train_loss_norm:0.0143, valid_acc: 0.8620, valid_loss_norm: 0.0174\n",
      " epoch: 267, train accuracy: 0.8964, train_loss_norm:0.0143, valid_acc: 0.8620, valid_loss_norm: 0.0174\n",
      " epoch: 268, train accuracy: 0.8965, train_loss_norm:0.0143, valid_acc: 0.8620, valid_loss_norm: 0.0174\n",
      " epoch: 269, train accuracy: 0.8967, train_loss_norm:0.0143, valid_acc: 0.8620, valid_loss_norm: 0.0174\n",
      " epoch: 270, train accuracy: 0.8968, train_loss_norm:0.0142, valid_acc: 0.8620, valid_loss_norm: 0.0174\n",
      " epoch: 271, train accuracy: 0.8969, train_loss_norm:0.0142, valid_acc: 0.8620, valid_loss_norm: 0.0174\n",
      " epoch: 272, train accuracy: 0.8969, train_loss_norm:0.0142, valid_acc: 0.8623, valid_loss_norm: 0.0173\n",
      " epoch: 273, train accuracy: 0.8969, train_loss_norm:0.0142, valid_acc: 0.8623, valid_loss_norm: 0.0173\n",
      " epoch: 274, train accuracy: 0.8970, train_loss_norm:0.0141, valid_acc: 0.8626, valid_loss_norm: 0.0173\n",
      " epoch: 275, train accuracy: 0.8971, train_loss_norm:0.0141, valid_acc: 0.8626, valid_loss_norm: 0.0173\n",
      " epoch: 276, train accuracy: 0.8972, train_loss_norm:0.0141, valid_acc: 0.8626, valid_loss_norm: 0.0173\n",
      " epoch: 277, train accuracy: 0.8974, train_loss_norm:0.0141, valid_acc: 0.8626, valid_loss_norm: 0.0172\n",
      " epoch: 278, train accuracy: 0.8974, train_loss_norm:0.0141, valid_acc: 0.8626, valid_loss_norm: 0.0172\n",
      " epoch: 279, train accuracy: 0.8974, train_loss_norm:0.0140, valid_acc: 0.8623, valid_loss_norm: 0.0172\n",
      " epoch: 280, train accuracy: 0.8975, train_loss_norm:0.0140, valid_acc: 0.8623, valid_loss_norm: 0.0172\n",
      " epoch: 281, train accuracy: 0.8976, train_loss_norm:0.0140, valid_acc: 0.8623, valid_loss_norm: 0.0172\n",
      " epoch: 282, train accuracy: 0.8977, train_loss_norm:0.0140, valid_acc: 0.8623, valid_loss_norm: 0.0172\n",
      " epoch: 283, train accuracy: 0.8977, train_loss_norm:0.0140, valid_acc: 0.8623, valid_loss_norm: 0.0171\n",
      " epoch: 284, train accuracy: 0.8979, train_loss_norm:0.0139, valid_acc: 0.8623, valid_loss_norm: 0.0171\n",
      " epoch: 285, train accuracy: 0.8979, train_loss_norm:0.0139, valid_acc: 0.8623, valid_loss_norm: 0.0171\n",
      " epoch: 286, train accuracy: 0.8981, train_loss_norm:0.0139, valid_acc: 0.8623, valid_loss_norm: 0.0171\n",
      " epoch: 287, train accuracy: 0.8982, train_loss_norm:0.0139, valid_acc: 0.8620, valid_loss_norm: 0.0171\n",
      " epoch: 288, train accuracy: 0.8983, train_loss_norm:0.0139, valid_acc: 0.8620, valid_loss_norm: 0.0171\n",
      " epoch: 289, train accuracy: 0.8986, train_loss_norm:0.0138, valid_acc: 0.8620, valid_loss_norm: 0.0170\n",
      " epoch: 290, train accuracy: 0.8990, train_loss_norm:0.0138, valid_acc: 0.8620, valid_loss_norm: 0.0170\n",
      " epoch: 291, train accuracy: 0.8990, train_loss_norm:0.0138, valid_acc: 0.8620, valid_loss_norm: 0.0170\n",
      " epoch: 292, train accuracy: 0.8992, train_loss_norm:0.0138, valid_acc: 0.8620, valid_loss_norm: 0.0170\n",
      " epoch: 293, train accuracy: 0.8993, train_loss_norm:0.0138, valid_acc: 0.8620, valid_loss_norm: 0.0170\n",
      " epoch: 294, train accuracy: 0.8995, train_loss_norm:0.0138, valid_acc: 0.8620, valid_loss_norm: 0.0170\n",
      " epoch: 295, train accuracy: 0.8995, train_loss_norm:0.0137, valid_acc: 0.8620, valid_loss_norm: 0.0169\n",
      " epoch: 296, train accuracy: 0.8997, train_loss_norm:0.0137, valid_acc: 0.8620, valid_loss_norm: 0.0169\n",
      " epoch: 297, train accuracy: 0.8998, train_loss_norm:0.0137, valid_acc: 0.8623, valid_loss_norm: 0.0169\n",
      " epoch: 298, train accuracy: 0.8999, train_loss_norm:0.0137, valid_acc: 0.8623, valid_loss_norm: 0.0169\n",
      " epoch: 299, train accuracy: 0.9001, train_loss_norm:0.0137, valid_acc: 0.8623, valid_loss_norm: 0.0169\n",
      " epoch: 300, train accuracy: 0.9003, train_loss_norm:0.0136, valid_acc: 0.8623, valid_loss_norm: 0.0169\n",
      "Test accuracy: 0.8577\n",
      "Test loss norm: 0.0174\n",
      "Cur fold: 2\n",
      "(27841, 300)\n",
      "(3479, 300)\n",
      "(3479, 300)\n",
      " epoch: 1, train accuracy: 0.7930, train_loss_norm:0.0836, valid_acc: 0.7660, valid_loss_norm: 0.0837\n",
      " epoch: 2, train accuracy: 0.7931, train_loss_norm:0.0799, valid_acc: 0.7663, valid_loss_norm: 0.0800\n",
      " epoch: 3, train accuracy: 0.7934, train_loss_norm:0.0764, valid_acc: 0.7663, valid_loss_norm: 0.0765\n",
      " epoch: 4, train accuracy: 0.7936, train_loss_norm:0.0730, valid_acc: 0.7666, valid_loss_norm: 0.0732\n",
      " epoch: 5, train accuracy: 0.7945, train_loss_norm:0.0698, valid_acc: 0.7672, valid_loss_norm: 0.0700\n",
      " epoch: 6, train accuracy: 0.7954, train_loss_norm:0.0668, valid_acc: 0.7692, valid_loss_norm: 0.0671\n",
      " epoch: 7, train accuracy: 0.7963, train_loss_norm:0.0640, valid_acc: 0.7706, valid_loss_norm: 0.0644\n",
      " epoch: 8, train accuracy: 0.7971, train_loss_norm:0.0615, valid_acc: 0.7715, valid_loss_norm: 0.0620\n",
      " epoch: 9, train accuracy: 0.7987, train_loss_norm:0.0593, valid_acc: 0.7721, valid_loss_norm: 0.0598\n",
      " epoch: 10, train accuracy: 0.8002, train_loss_norm:0.0572, valid_acc: 0.7738, valid_loss_norm: 0.0578\n",
      " epoch: 11, train accuracy: 0.8019, train_loss_norm:0.0553, valid_acc: 0.7755, valid_loss_norm: 0.0559\n",
      " epoch: 12, train accuracy: 0.8032, train_loss_norm:0.0536, valid_acc: 0.7792, valid_loss_norm: 0.0543\n",
      " epoch: 13, train accuracy: 0.8050, train_loss_norm:0.0520, valid_acc: 0.7798, valid_loss_norm: 0.0528\n",
      " epoch: 14, train accuracy: 0.8067, train_loss_norm:0.0506, valid_acc: 0.7824, valid_loss_norm: 0.0514\n",
      " epoch: 15, train accuracy: 0.8084, train_loss_norm:0.0492, valid_acc: 0.7847, valid_loss_norm: 0.0501\n",
      " epoch: 16, train accuracy: 0.8101, train_loss_norm:0.0480, valid_acc: 0.7856, valid_loss_norm: 0.0489\n",
      " epoch: 17, train accuracy: 0.8115, train_loss_norm:0.0468, valid_acc: 0.7887, valid_loss_norm: 0.0478\n",
      " epoch: 18, train accuracy: 0.8129, train_loss_norm:0.0458, valid_acc: 0.7902, valid_loss_norm: 0.0468\n",
      " epoch: 19, train accuracy: 0.8141, train_loss_norm:0.0448, valid_acc: 0.7916, valid_loss_norm: 0.0458\n",
      " epoch: 20, train accuracy: 0.8161, train_loss_norm:0.0438, valid_acc: 0.7933, valid_loss_norm: 0.0449\n",
      " epoch: 21, train accuracy: 0.8174, train_loss_norm:0.0430, valid_acc: 0.7939, valid_loss_norm: 0.0441\n",
      " epoch: 22, train accuracy: 0.8189, train_loss_norm:0.0421, valid_acc: 0.7928, valid_loss_norm: 0.0433\n",
      " epoch: 23, train accuracy: 0.8201, train_loss_norm:0.0414, valid_acc: 0.7930, valid_loss_norm: 0.0425\n",
      " epoch: 24, train accuracy: 0.8210, train_loss_norm:0.0406, valid_acc: 0.7939, valid_loss_norm: 0.0418\n",
      " epoch: 25, train accuracy: 0.8222, train_loss_norm:0.0399, valid_acc: 0.7965, valid_loss_norm: 0.0412\n",
      " epoch: 26, train accuracy: 0.8232, train_loss_norm:0.0393, valid_acc: 0.7985, valid_loss_norm: 0.0406\n",
      " epoch: 27, train accuracy: 0.8243, train_loss_norm:0.0386, valid_acc: 0.8002, valid_loss_norm: 0.0400\n",
      " epoch: 28, train accuracy: 0.8253, train_loss_norm:0.0380, valid_acc: 0.8014, valid_loss_norm: 0.0394\n",
      " epoch: 29, train accuracy: 0.8262, train_loss_norm:0.0375, valid_acc: 0.8011, valid_loss_norm: 0.0389\n",
      " epoch: 30, train accuracy: 0.8271, train_loss_norm:0.0369, valid_acc: 0.8014, valid_loss_norm: 0.0383\n",
      " epoch: 31, train accuracy: 0.8280, train_loss_norm:0.0364, valid_acc: 0.8028, valid_loss_norm: 0.0378\n",
      " epoch: 32, train accuracy: 0.8288, train_loss_norm:0.0359, valid_acc: 0.8037, valid_loss_norm: 0.0374\n",
      " epoch: 33, train accuracy: 0.8299, train_loss_norm:0.0354, valid_acc: 0.8043, valid_loss_norm: 0.0369\n",
      " epoch: 34, train accuracy: 0.8305, train_loss_norm:0.0350, valid_acc: 0.8045, valid_loss_norm: 0.0365\n",
      " epoch: 35, train accuracy: 0.8314, train_loss_norm:0.0345, valid_acc: 0.8060, valid_loss_norm: 0.0361\n",
      " epoch: 36, train accuracy: 0.8320, train_loss_norm:0.0341, valid_acc: 0.8068, valid_loss_norm: 0.0357\n",
      " epoch: 37, train accuracy: 0.8329, train_loss_norm:0.0337, valid_acc: 0.8080, valid_loss_norm: 0.0353\n",
      " epoch: 38, train accuracy: 0.8337, train_loss_norm:0.0333, valid_acc: 0.8086, valid_loss_norm: 0.0349\n",
      " epoch: 39, train accuracy: 0.8345, train_loss_norm:0.0329, valid_acc: 0.8097, valid_loss_norm: 0.0346\n",
      " epoch: 40, train accuracy: 0.8351, train_loss_norm:0.0325, valid_acc: 0.8106, valid_loss_norm: 0.0342\n",
      " epoch: 41, train accuracy: 0.8362, train_loss_norm:0.0322, valid_acc: 0.8106, valid_loss_norm: 0.0339\n",
      " epoch: 42, train accuracy: 0.8371, train_loss_norm:0.0318, valid_acc: 0.8112, valid_loss_norm: 0.0336\n",
      " epoch: 43, train accuracy: 0.8374, train_loss_norm:0.0315, valid_acc: 0.8126, valid_loss_norm: 0.0333\n",
      " epoch: 44, train accuracy: 0.8382, train_loss_norm:0.0312, valid_acc: 0.8135, valid_loss_norm: 0.0330\n",
      " epoch: 45, train accuracy: 0.8388, train_loss_norm:0.0309, valid_acc: 0.8135, valid_loss_norm: 0.0327\n",
      " epoch: 46, train accuracy: 0.8397, train_loss_norm:0.0306, valid_acc: 0.8143, valid_loss_norm: 0.0324\n",
      " epoch: 47, train accuracy: 0.8405, train_loss_norm:0.0303, valid_acc: 0.8146, valid_loss_norm: 0.0321\n",
      " epoch: 48, train accuracy: 0.8409, train_loss_norm:0.0300, valid_acc: 0.8146, valid_loss_norm: 0.0319\n",
      " epoch: 49, train accuracy: 0.8412, train_loss_norm:0.0297, valid_acc: 0.8152, valid_loss_norm: 0.0316\n",
      " epoch: 50, train accuracy: 0.8420, train_loss_norm:0.0295, valid_acc: 0.8149, valid_loss_norm: 0.0314\n",
      " epoch: 51, train accuracy: 0.8425, train_loss_norm:0.0292, valid_acc: 0.8143, valid_loss_norm: 0.0311\n",
      " epoch: 52, train accuracy: 0.8429, train_loss_norm:0.0290, valid_acc: 0.8155, valid_loss_norm: 0.0309\n",
      " epoch: 53, train accuracy: 0.8433, train_loss_norm:0.0287, valid_acc: 0.8160, valid_loss_norm: 0.0307\n",
      " epoch: 54, train accuracy: 0.8440, train_loss_norm:0.0285, valid_acc: 0.8158, valid_loss_norm: 0.0304\n",
      " epoch: 55, train accuracy: 0.8440, train_loss_norm:0.0282, valid_acc: 0.8160, valid_loss_norm: 0.0302\n",
      " epoch: 56, train accuracy: 0.8440, train_loss_norm:0.0280, valid_acc: 0.8163, valid_loss_norm: 0.0300\n",
      " epoch: 57, train accuracy: 0.8445, train_loss_norm:0.0278, valid_acc: 0.8172, valid_loss_norm: 0.0298\n",
      " epoch: 58, train accuracy: 0.8449, train_loss_norm:0.0276, valid_acc: 0.8183, valid_loss_norm: 0.0296\n",
      " epoch: 59, train accuracy: 0.8455, train_loss_norm:0.0274, valid_acc: 0.8189, valid_loss_norm: 0.0294\n",
      " epoch: 60, train accuracy: 0.8463, train_loss_norm:0.0272, valid_acc: 0.8198, valid_loss_norm: 0.0292\n",
      " epoch: 61, train accuracy: 0.8470, train_loss_norm:0.0270, valid_acc: 0.8201, valid_loss_norm: 0.0290\n",
      " epoch: 62, train accuracy: 0.8473, train_loss_norm:0.0268, valid_acc: 0.8215, valid_loss_norm: 0.0289\n",
      " epoch: 63, train accuracy: 0.8476, train_loss_norm:0.0266, valid_acc: 0.8218, valid_loss_norm: 0.0287\n",
      " epoch: 64, train accuracy: 0.8481, train_loss_norm:0.0264, valid_acc: 0.8227, valid_loss_norm: 0.0285\n",
      " epoch: 65, train accuracy: 0.8487, train_loss_norm:0.0262, valid_acc: 0.8229, valid_loss_norm: 0.0284\n",
      " epoch: 66, train accuracy: 0.8493, train_loss_norm:0.0260, valid_acc: 0.8227, valid_loss_norm: 0.0282\n",
      " epoch: 67, train accuracy: 0.8497, train_loss_norm:0.0259, valid_acc: 0.8235, valid_loss_norm: 0.0280\n",
      " epoch: 68, train accuracy: 0.8502, train_loss_norm:0.0257, valid_acc: 0.8241, valid_loss_norm: 0.0279\n",
      " epoch: 69, train accuracy: 0.8507, train_loss_norm:0.0255, valid_acc: 0.8241, valid_loss_norm: 0.0277\n",
      " epoch: 70, train accuracy: 0.8510, train_loss_norm:0.0254, valid_acc: 0.8249, valid_loss_norm: 0.0276\n",
      " epoch: 71, train accuracy: 0.8512, train_loss_norm:0.0252, valid_acc: 0.8249, valid_loss_norm: 0.0274\n",
      " epoch: 72, train accuracy: 0.8515, train_loss_norm:0.0250, valid_acc: 0.8252, valid_loss_norm: 0.0273\n",
      " epoch: 73, train accuracy: 0.8520, train_loss_norm:0.0249, valid_acc: 0.8255, valid_loss_norm: 0.0272\n",
      " epoch: 74, train accuracy: 0.8525, train_loss_norm:0.0247, valid_acc: 0.8255, valid_loss_norm: 0.0270\n",
      " epoch: 75, train accuracy: 0.8530, train_loss_norm:0.0246, valid_acc: 0.8261, valid_loss_norm: 0.0269\n",
      " epoch: 76, train accuracy: 0.8532, train_loss_norm:0.0245, valid_acc: 0.8264, valid_loss_norm: 0.0268\n",
      " epoch: 77, train accuracy: 0.8537, train_loss_norm:0.0243, valid_acc: 0.8272, valid_loss_norm: 0.0266\n",
      " epoch: 78, train accuracy: 0.8542, train_loss_norm:0.0242, valid_acc: 0.8272, valid_loss_norm: 0.0265\n",
      " epoch: 79, train accuracy: 0.8545, train_loss_norm:0.0240, valid_acc: 0.8272, valid_loss_norm: 0.0264\n",
      " epoch: 80, train accuracy: 0.8548, train_loss_norm:0.0239, valid_acc: 0.8275, valid_loss_norm: 0.0263\n",
      " epoch: 81, train accuracy: 0.8550, train_loss_norm:0.0238, valid_acc: 0.8281, valid_loss_norm: 0.0261\n",
      " epoch: 82, train accuracy: 0.8551, train_loss_norm:0.0236, valid_acc: 0.8287, valid_loss_norm: 0.0260\n",
      " epoch: 83, train accuracy: 0.8555, train_loss_norm:0.0235, valid_acc: 0.8287, valid_loss_norm: 0.0259\n",
      " epoch: 84, train accuracy: 0.8559, train_loss_norm:0.0234, valid_acc: 0.8290, valid_loss_norm: 0.0258\n",
      " epoch: 85, train accuracy: 0.8561, train_loss_norm:0.0233, valid_acc: 0.8293, valid_loss_norm: 0.0257\n",
      " epoch: 86, train accuracy: 0.8565, train_loss_norm:0.0232, valid_acc: 0.8295, valid_loss_norm: 0.0256\n",
      " epoch: 87, train accuracy: 0.8570, train_loss_norm:0.0230, valid_acc: 0.8298, valid_loss_norm: 0.0255\n",
      " epoch: 88, train accuracy: 0.8574, train_loss_norm:0.0229, valid_acc: 0.8298, valid_loss_norm: 0.0254\n",
      " epoch: 89, train accuracy: 0.8574, train_loss_norm:0.0228, valid_acc: 0.8301, valid_loss_norm: 0.0253\n",
      " epoch: 90, train accuracy: 0.8578, train_loss_norm:0.0227, valid_acc: 0.8301, valid_loss_norm: 0.0252\n",
      " epoch: 91, train accuracy: 0.8581, train_loss_norm:0.0226, valid_acc: 0.8304, valid_loss_norm: 0.0251\n",
      " epoch: 92, train accuracy: 0.8584, train_loss_norm:0.0225, valid_acc: 0.8307, valid_loss_norm: 0.0250\n",
      " epoch: 93, train accuracy: 0.8588, train_loss_norm:0.0224, valid_acc: 0.8313, valid_loss_norm: 0.0249\n",
      " epoch: 94, train accuracy: 0.8593, train_loss_norm:0.0223, valid_acc: 0.8310, valid_loss_norm: 0.0248\n",
      " epoch: 95, train accuracy: 0.8598, train_loss_norm:0.0222, valid_acc: 0.8313, valid_loss_norm: 0.0247\n",
      " epoch: 96, train accuracy: 0.8601, train_loss_norm:0.0221, valid_acc: 0.8316, valid_loss_norm: 0.0246\n",
      " epoch: 97, train accuracy: 0.8605, train_loss_norm:0.0220, valid_acc: 0.8313, valid_loss_norm: 0.0245\n",
      " epoch: 98, train accuracy: 0.8609, train_loss_norm:0.0219, valid_acc: 0.8316, valid_loss_norm: 0.0244\n",
      " epoch: 99, train accuracy: 0.8611, train_loss_norm:0.0218, valid_acc: 0.8324, valid_loss_norm: 0.0243\n",
      " epoch: 100, train accuracy: 0.8614, train_loss_norm:0.0217, valid_acc: 0.8333, valid_loss_norm: 0.0243\n",
      " epoch: 101, train accuracy: 0.8617, train_loss_norm:0.0216, valid_acc: 0.8336, valid_loss_norm: 0.0242\n",
      " epoch: 102, train accuracy: 0.8621, train_loss_norm:0.0215, valid_acc: 0.8339, valid_loss_norm: 0.0241\n",
      " epoch: 103, train accuracy: 0.8623, train_loss_norm:0.0214, valid_acc: 0.8339, valid_loss_norm: 0.0240\n",
      " epoch: 104, train accuracy: 0.8625, train_loss_norm:0.0213, valid_acc: 0.8341, valid_loss_norm: 0.0239\n",
      " epoch: 105, train accuracy: 0.8628, train_loss_norm:0.0212, valid_acc: 0.8350, valid_loss_norm: 0.0238\n",
      " epoch: 106, train accuracy: 0.8630, train_loss_norm:0.0211, valid_acc: 0.8350, valid_loss_norm: 0.0238\n",
      " epoch: 107, train accuracy: 0.8632, train_loss_norm:0.0211, valid_acc: 0.8356, valid_loss_norm: 0.0237\n",
      " epoch: 108, train accuracy: 0.8636, train_loss_norm:0.0210, valid_acc: 0.8362, valid_loss_norm: 0.0236\n",
      " epoch: 109, train accuracy: 0.8637, train_loss_norm:0.0209, valid_acc: 0.8364, valid_loss_norm: 0.0235\n",
      " epoch: 110, train accuracy: 0.8639, train_loss_norm:0.0208, valid_acc: 0.8373, valid_loss_norm: 0.0235\n",
      " epoch: 111, train accuracy: 0.8643, train_loss_norm:0.0207, valid_acc: 0.8379, valid_loss_norm: 0.0234\n",
      " epoch: 112, train accuracy: 0.8645, train_loss_norm:0.0206, valid_acc: 0.8385, valid_loss_norm: 0.0233\n",
      " epoch: 113, train accuracy: 0.8648, train_loss_norm:0.0206, valid_acc: 0.8385, valid_loss_norm: 0.0233\n",
      " epoch: 114, train accuracy: 0.8649, train_loss_norm:0.0205, valid_acc: 0.8385, valid_loss_norm: 0.0232\n",
      " epoch: 115, train accuracy: 0.8651, train_loss_norm:0.0204, valid_acc: 0.8390, valid_loss_norm: 0.0231\n",
      " epoch: 116, train accuracy: 0.8653, train_loss_norm:0.0203, valid_acc: 0.8390, valid_loss_norm: 0.0231\n",
      " epoch: 117, train accuracy: 0.8656, train_loss_norm:0.0203, valid_acc: 0.8390, valid_loss_norm: 0.0230\n",
      " epoch: 118, train accuracy: 0.8660, train_loss_norm:0.0202, valid_acc: 0.8387, valid_loss_norm: 0.0229\n",
      " epoch: 119, train accuracy: 0.8662, train_loss_norm:0.0201, valid_acc: 0.8393, valid_loss_norm: 0.0229\n",
      " epoch: 120, train accuracy: 0.8667, train_loss_norm:0.0200, valid_acc: 0.8399, valid_loss_norm: 0.0228\n",
      " epoch: 121, train accuracy: 0.8671, train_loss_norm:0.0200, valid_acc: 0.8399, valid_loss_norm: 0.0227\n",
      " epoch: 122, train accuracy: 0.8673, train_loss_norm:0.0199, valid_acc: 0.8402, valid_loss_norm: 0.0227\n",
      " epoch: 123, train accuracy: 0.8675, train_loss_norm:0.0198, valid_acc: 0.8408, valid_loss_norm: 0.0226\n",
      " epoch: 124, train accuracy: 0.8679, train_loss_norm:0.0198, valid_acc: 0.8410, valid_loss_norm: 0.0226\n",
      " epoch: 125, train accuracy: 0.8682, train_loss_norm:0.0197, valid_acc: 0.8410, valid_loss_norm: 0.0225\n",
      " epoch: 126, train accuracy: 0.8685, train_loss_norm:0.0196, valid_acc: 0.8408, valid_loss_norm: 0.0224\n",
      " epoch: 127, train accuracy: 0.8686, train_loss_norm:0.0196, valid_acc: 0.8410, valid_loss_norm: 0.0224\n",
      " epoch: 128, train accuracy: 0.8689, train_loss_norm:0.0195, valid_acc: 0.8410, valid_loss_norm: 0.0223\n",
      " epoch: 129, train accuracy: 0.8693, train_loss_norm:0.0194, valid_acc: 0.8410, valid_loss_norm: 0.0223\n",
      " epoch: 130, train accuracy: 0.8698, train_loss_norm:0.0194, valid_acc: 0.8410, valid_loss_norm: 0.0222\n",
      " epoch: 131, train accuracy: 0.8700, train_loss_norm:0.0193, valid_acc: 0.8405, valid_loss_norm: 0.0221\n",
      " epoch: 132, train accuracy: 0.8701, train_loss_norm:0.0192, valid_acc: 0.8405, valid_loss_norm: 0.0221\n",
      " epoch: 133, train accuracy: 0.8705, train_loss_norm:0.0192, valid_acc: 0.8408, valid_loss_norm: 0.0220\n",
      " epoch: 134, train accuracy: 0.8710, train_loss_norm:0.0191, valid_acc: 0.8408, valid_loss_norm: 0.0220\n",
      " epoch: 135, train accuracy: 0.8712, train_loss_norm:0.0191, valid_acc: 0.8405, valid_loss_norm: 0.0219\n",
      " epoch: 136, train accuracy: 0.8717, train_loss_norm:0.0190, valid_acc: 0.8405, valid_loss_norm: 0.0219\n",
      " epoch: 137, train accuracy: 0.8721, train_loss_norm:0.0189, valid_acc: 0.8405, valid_loss_norm: 0.0218\n",
      " epoch: 138, train accuracy: 0.8723, train_loss_norm:0.0189, valid_acc: 0.8399, valid_loss_norm: 0.0218\n",
      " epoch: 139, train accuracy: 0.8727, train_loss_norm:0.0188, valid_acc: 0.8399, valid_loss_norm: 0.0217\n",
      " epoch: 140, train accuracy: 0.8728, train_loss_norm:0.0188, valid_acc: 0.8405, valid_loss_norm: 0.0217\n",
      " epoch: 141, train accuracy: 0.8733, train_loss_norm:0.0187, valid_acc: 0.8405, valid_loss_norm: 0.0216\n",
      " epoch: 142, train accuracy: 0.8734, train_loss_norm:0.0187, valid_acc: 0.8413, valid_loss_norm: 0.0216\n",
      " epoch: 143, train accuracy: 0.8735, train_loss_norm:0.0186, valid_acc: 0.8419, valid_loss_norm: 0.0215\n",
      " epoch: 144, train accuracy: 0.8738, train_loss_norm:0.0186, valid_acc: 0.8422, valid_loss_norm: 0.0215\n",
      " epoch: 145, train accuracy: 0.8740, train_loss_norm:0.0185, valid_acc: 0.8425, valid_loss_norm: 0.0214\n",
      " epoch: 146, train accuracy: 0.8743, train_loss_norm:0.0184, valid_acc: 0.8428, valid_loss_norm: 0.0214\n",
      " epoch: 147, train accuracy: 0.8745, train_loss_norm:0.0184, valid_acc: 0.8425, valid_loss_norm: 0.0213\n",
      " epoch: 148, train accuracy: 0.8746, train_loss_norm:0.0183, valid_acc: 0.8428, valid_loss_norm: 0.0213\n",
      " epoch: 149, train accuracy: 0.8749, train_loss_norm:0.0183, valid_acc: 0.8428, valid_loss_norm: 0.0213\n",
      " epoch: 150, train accuracy: 0.8753, train_loss_norm:0.0182, valid_acc: 0.8431, valid_loss_norm: 0.0212\n",
      " epoch: 151, train accuracy: 0.8755, train_loss_norm:0.0182, valid_acc: 0.8431, valid_loss_norm: 0.0212\n",
      " epoch: 152, train accuracy: 0.8759, train_loss_norm:0.0181, valid_acc: 0.8431, valid_loss_norm: 0.0211\n",
      " epoch: 153, train accuracy: 0.8760, train_loss_norm:0.0181, valid_acc: 0.8433, valid_loss_norm: 0.0211\n",
      " epoch: 154, train accuracy: 0.8764, train_loss_norm:0.0180, valid_acc: 0.8436, valid_loss_norm: 0.0210\n",
      " epoch: 155, train accuracy: 0.8766, train_loss_norm:0.0180, valid_acc: 0.8436, valid_loss_norm: 0.0210\n",
      " epoch: 156, train accuracy: 0.8767, train_loss_norm:0.0179, valid_acc: 0.8436, valid_loss_norm: 0.0210\n",
      " epoch: 157, train accuracy: 0.8768, train_loss_norm:0.0179, valid_acc: 0.8436, valid_loss_norm: 0.0209\n",
      " epoch: 158, train accuracy: 0.8770, train_loss_norm:0.0178, valid_acc: 0.8433, valid_loss_norm: 0.0209\n",
      " epoch: 159, train accuracy: 0.8771, train_loss_norm:0.0178, valid_acc: 0.8433, valid_loss_norm: 0.0208\n",
      " epoch: 160, train accuracy: 0.8774, train_loss_norm:0.0178, valid_acc: 0.8433, valid_loss_norm: 0.0208\n",
      " epoch: 161, train accuracy: 0.8778, train_loss_norm:0.0177, valid_acc: 0.8433, valid_loss_norm: 0.0208\n",
      " epoch: 162, train accuracy: 0.8779, train_loss_norm:0.0177, valid_acc: 0.8436, valid_loss_norm: 0.0207\n",
      " epoch: 163, train accuracy: 0.8782, train_loss_norm:0.0176, valid_acc: 0.8433, valid_loss_norm: 0.0207\n",
      " epoch: 164, train accuracy: 0.8785, train_loss_norm:0.0176, valid_acc: 0.8439, valid_loss_norm: 0.0206\n",
      " epoch: 165, train accuracy: 0.8787, train_loss_norm:0.0175, valid_acc: 0.8439, valid_loss_norm: 0.0206\n",
      " epoch: 166, train accuracy: 0.8790, train_loss_norm:0.0175, valid_acc: 0.8439, valid_loss_norm: 0.0206\n",
      " epoch: 167, train accuracy: 0.8792, train_loss_norm:0.0174, valid_acc: 0.8439, valid_loss_norm: 0.0205\n",
      " epoch: 168, train accuracy: 0.8795, train_loss_norm:0.0174, valid_acc: 0.8439, valid_loss_norm: 0.0205\n",
      " epoch: 169, train accuracy: 0.8797, train_loss_norm:0.0174, valid_acc: 0.8445, valid_loss_norm: 0.0205\n",
      " epoch: 170, train accuracy: 0.8800, train_loss_norm:0.0173, valid_acc: 0.8448, valid_loss_norm: 0.0204\n",
      " epoch: 171, train accuracy: 0.8800, train_loss_norm:0.0173, valid_acc: 0.8448, valid_loss_norm: 0.0204\n",
      " epoch: 172, train accuracy: 0.8802, train_loss_norm:0.0172, valid_acc: 0.8454, valid_loss_norm: 0.0203\n",
      " epoch: 173, train accuracy: 0.8804, train_loss_norm:0.0172, valid_acc: 0.8454, valid_loss_norm: 0.0203\n",
      " epoch: 174, train accuracy: 0.8806, train_loss_norm:0.0171, valid_acc: 0.8448, valid_loss_norm: 0.0203\n",
      " epoch: 175, train accuracy: 0.8808, train_loss_norm:0.0171, valid_acc: 0.8451, valid_loss_norm: 0.0202\n",
      " epoch: 176, train accuracy: 0.8811, train_loss_norm:0.0171, valid_acc: 0.8451, valid_loss_norm: 0.0202\n",
      " epoch: 177, train accuracy: 0.8814, train_loss_norm:0.0170, valid_acc: 0.8451, valid_loss_norm: 0.0202\n",
      " epoch: 178, train accuracy: 0.8815, train_loss_norm:0.0170, valid_acc: 0.8451, valid_loss_norm: 0.0201\n",
      " epoch: 179, train accuracy: 0.8817, train_loss_norm:0.0169, valid_acc: 0.8451, valid_loss_norm: 0.0201\n",
      " epoch: 180, train accuracy: 0.8819, train_loss_norm:0.0169, valid_acc: 0.8454, valid_loss_norm: 0.0201\n",
      " epoch: 181, train accuracy: 0.8821, train_loss_norm:0.0169, valid_acc: 0.8459, valid_loss_norm: 0.0200\n",
      " epoch: 182, train accuracy: 0.8824, train_loss_norm:0.0168, valid_acc: 0.8465, valid_loss_norm: 0.0200\n",
      " epoch: 183, train accuracy: 0.8826, train_loss_norm:0.0168, valid_acc: 0.8465, valid_loss_norm: 0.0200\n",
      " epoch: 184, train accuracy: 0.8828, train_loss_norm:0.0168, valid_acc: 0.8471, valid_loss_norm: 0.0199\n",
      " epoch: 185, train accuracy: 0.8829, train_loss_norm:0.0167, valid_acc: 0.8471, valid_loss_norm: 0.0199\n",
      " epoch: 186, train accuracy: 0.8829, train_loss_norm:0.0167, valid_acc: 0.8471, valid_loss_norm: 0.0199\n",
      " epoch: 187, train accuracy: 0.8831, train_loss_norm:0.0166, valid_acc: 0.8477, valid_loss_norm: 0.0198\n",
      " epoch: 188, train accuracy: 0.8833, train_loss_norm:0.0166, valid_acc: 0.8477, valid_loss_norm: 0.0198\n",
      " epoch: 189, train accuracy: 0.8836, train_loss_norm:0.0166, valid_acc: 0.8479, valid_loss_norm: 0.0198\n",
      " epoch: 190, train accuracy: 0.8838, train_loss_norm:0.0165, valid_acc: 0.8485, valid_loss_norm: 0.0198\n",
      " epoch: 191, train accuracy: 0.8839, train_loss_norm:0.0165, valid_acc: 0.8482, valid_loss_norm: 0.0197\n",
      " epoch: 192, train accuracy: 0.8841, train_loss_norm:0.0165, valid_acc: 0.8479, valid_loss_norm: 0.0197\n",
      " epoch: 193, train accuracy: 0.8841, train_loss_norm:0.0164, valid_acc: 0.8479, valid_loss_norm: 0.0197\n",
      " epoch: 194, train accuracy: 0.8843, train_loss_norm:0.0164, valid_acc: 0.8479, valid_loss_norm: 0.0196\n",
      " epoch: 195, train accuracy: 0.8845, train_loss_norm:0.0164, valid_acc: 0.8479, valid_loss_norm: 0.0196\n",
      " epoch: 196, train accuracy: 0.8847, train_loss_norm:0.0163, valid_acc: 0.8479, valid_loss_norm: 0.0196\n",
      " epoch: 197, train accuracy: 0.8849, train_loss_norm:0.0163, valid_acc: 0.8479, valid_loss_norm: 0.0195\n",
      " epoch: 198, train accuracy: 0.8852, train_loss_norm:0.0163, valid_acc: 0.8482, valid_loss_norm: 0.0195\n",
      " epoch: 199, train accuracy: 0.8853, train_loss_norm:0.0162, valid_acc: 0.8482, valid_loss_norm: 0.0195\n",
      " epoch: 200, train accuracy: 0.8855, train_loss_norm:0.0162, valid_acc: 0.8482, valid_loss_norm: 0.0195\n",
      " epoch: 201, train accuracy: 0.8856, train_loss_norm:0.0162, valid_acc: 0.8485, valid_loss_norm: 0.0194\n",
      " epoch: 202, train accuracy: 0.8856, train_loss_norm:0.0161, valid_acc: 0.8485, valid_loss_norm: 0.0194\n",
      " epoch: 203, train accuracy: 0.8858, train_loss_norm:0.0161, valid_acc: 0.8485, valid_loss_norm: 0.0194\n",
      " epoch: 204, train accuracy: 0.8860, train_loss_norm:0.0161, valid_acc: 0.8485, valid_loss_norm: 0.0194\n",
      " epoch: 205, train accuracy: 0.8863, train_loss_norm:0.0160, valid_acc: 0.8485, valid_loss_norm: 0.0193\n",
      " epoch: 206, train accuracy: 0.8864, train_loss_norm:0.0160, valid_acc: 0.8485, valid_loss_norm: 0.0193\n",
      " epoch: 207, train accuracy: 0.8866, train_loss_norm:0.0160, valid_acc: 0.8488, valid_loss_norm: 0.0193\n",
      " epoch: 208, train accuracy: 0.8866, train_loss_norm:0.0159, valid_acc: 0.8491, valid_loss_norm: 0.0192\n",
      " epoch: 209, train accuracy: 0.8868, train_loss_norm:0.0159, valid_acc: 0.8494, valid_loss_norm: 0.0192\n",
      " epoch: 210, train accuracy: 0.8870, train_loss_norm:0.0159, valid_acc: 0.8497, valid_loss_norm: 0.0192\n",
      " epoch: 211, train accuracy: 0.8873, train_loss_norm:0.0158, valid_acc: 0.8497, valid_loss_norm: 0.0192\n",
      " epoch: 212, train accuracy: 0.8873, train_loss_norm:0.0158, valid_acc: 0.8500, valid_loss_norm: 0.0191\n",
      " epoch: 213, train accuracy: 0.8875, train_loss_norm:0.0158, valid_acc: 0.8500, valid_loss_norm: 0.0191\n",
      " epoch: 214, train accuracy: 0.8876, train_loss_norm:0.0157, valid_acc: 0.8502, valid_loss_norm: 0.0191\n",
      " epoch: 215, train accuracy: 0.8877, train_loss_norm:0.0157, valid_acc: 0.8505, valid_loss_norm: 0.0191\n",
      " epoch: 216, train accuracy: 0.8878, train_loss_norm:0.0157, valid_acc: 0.8502, valid_loss_norm: 0.0190\n",
      " epoch: 217, train accuracy: 0.8880, train_loss_norm:0.0157, valid_acc: 0.8500, valid_loss_norm: 0.0190\n",
      " epoch: 218, train accuracy: 0.8883, train_loss_norm:0.0156, valid_acc: 0.8505, valid_loss_norm: 0.0190\n",
      " epoch: 219, train accuracy: 0.8884, train_loss_norm:0.0156, valid_acc: 0.8502, valid_loss_norm: 0.0190\n",
      " epoch: 220, train accuracy: 0.8886, train_loss_norm:0.0156, valid_acc: 0.8502, valid_loss_norm: 0.0189\n",
      " epoch: 221, train accuracy: 0.8890, train_loss_norm:0.0155, valid_acc: 0.8505, valid_loss_norm: 0.0189\n",
      " epoch: 222, train accuracy: 0.8890, train_loss_norm:0.0155, valid_acc: 0.8505, valid_loss_norm: 0.0189\n",
      " epoch: 223, train accuracy: 0.8892, train_loss_norm:0.0155, valid_acc: 0.8505, valid_loss_norm: 0.0189\n",
      " epoch: 224, train accuracy: 0.8893, train_loss_norm:0.0155, valid_acc: 0.8508, valid_loss_norm: 0.0189\n",
      " epoch: 225, train accuracy: 0.8895, train_loss_norm:0.0154, valid_acc: 0.8508, valid_loss_norm: 0.0188\n",
      " epoch: 226, train accuracy: 0.8898, train_loss_norm:0.0154, valid_acc: 0.8508, valid_loss_norm: 0.0188\n",
      " epoch: 227, train accuracy: 0.8898, train_loss_norm:0.0154, valid_acc: 0.8508, valid_loss_norm: 0.0188\n",
      " epoch: 228, train accuracy: 0.8902, train_loss_norm:0.0153, valid_acc: 0.8508, valid_loss_norm: 0.0188\n",
      " epoch: 229, train accuracy: 0.8903, train_loss_norm:0.0153, valid_acc: 0.8502, valid_loss_norm: 0.0187\n",
      " epoch: 230, train accuracy: 0.8904, train_loss_norm:0.0153, valid_acc: 0.8508, valid_loss_norm: 0.0187\n",
      " epoch: 231, train accuracy: 0.8906, train_loss_norm:0.0153, valid_acc: 0.8508, valid_loss_norm: 0.0187\n",
      " epoch: 232, train accuracy: 0.8908, train_loss_norm:0.0152, valid_acc: 0.8505, valid_loss_norm: 0.0187\n",
      " epoch: 233, train accuracy: 0.8910, train_loss_norm:0.0152, valid_acc: 0.8502, valid_loss_norm: 0.0186\n",
      " epoch: 234, train accuracy: 0.8914, train_loss_norm:0.0152, valid_acc: 0.8505, valid_loss_norm: 0.0186\n",
      " epoch: 235, train accuracy: 0.8914, train_loss_norm:0.0152, valid_acc: 0.8505, valid_loss_norm: 0.0186\n",
      " epoch: 236, train accuracy: 0.8915, train_loss_norm:0.0151, valid_acc: 0.8508, valid_loss_norm: 0.0186\n",
      " epoch: 237, train accuracy: 0.8918, train_loss_norm:0.0151, valid_acc: 0.8508, valid_loss_norm: 0.0186\n",
      " epoch: 238, train accuracy: 0.8918, train_loss_norm:0.0151, valid_acc: 0.8508, valid_loss_norm: 0.0185\n",
      " epoch: 239, train accuracy: 0.8919, train_loss_norm:0.0151, valid_acc: 0.8508, valid_loss_norm: 0.0185\n",
      " epoch: 240, train accuracy: 0.8920, train_loss_norm:0.0150, valid_acc: 0.8508, valid_loss_norm: 0.0185\n",
      " epoch: 241, train accuracy: 0.8922, train_loss_norm:0.0150, valid_acc: 0.8511, valid_loss_norm: 0.0185\n",
      " epoch: 242, train accuracy: 0.8924, train_loss_norm:0.0150, valid_acc: 0.8511, valid_loss_norm: 0.0185\n",
      " epoch: 243, train accuracy: 0.8926, train_loss_norm:0.0150, valid_acc: 0.8511, valid_loss_norm: 0.0184\n",
      " epoch: 244, train accuracy: 0.8927, train_loss_norm:0.0149, valid_acc: 0.8511, valid_loss_norm: 0.0184\n",
      " epoch: 245, train accuracy: 0.8927, train_loss_norm:0.0149, valid_acc: 0.8511, valid_loss_norm: 0.0184\n",
      " epoch: 246, train accuracy: 0.8929, train_loss_norm:0.0149, valid_acc: 0.8511, valid_loss_norm: 0.0184\n",
      " epoch: 247, train accuracy: 0.8930, train_loss_norm:0.0149, valid_acc: 0.8511, valid_loss_norm: 0.0184\n",
      " epoch: 248, train accuracy: 0.8933, train_loss_norm:0.0148, valid_acc: 0.8511, valid_loss_norm: 0.0183\n",
      " epoch: 249, train accuracy: 0.8935, train_loss_norm:0.0148, valid_acc: 0.8511, valid_loss_norm: 0.0183\n",
      " epoch: 250, train accuracy: 0.8937, train_loss_norm:0.0148, valid_acc: 0.8514, valid_loss_norm: 0.0183\n",
      " epoch: 251, train accuracy: 0.8940, train_loss_norm:0.0148, valid_acc: 0.8514, valid_loss_norm: 0.0183\n",
      " epoch: 252, train accuracy: 0.8941, train_loss_norm:0.0147, valid_acc: 0.8514, valid_loss_norm: 0.0183\n",
      " epoch: 253, train accuracy: 0.8944, train_loss_norm:0.0147, valid_acc: 0.8514, valid_loss_norm: 0.0182\n",
      " epoch: 254, train accuracy: 0.8946, train_loss_norm:0.0147, valid_acc: 0.8514, valid_loss_norm: 0.0182\n",
      " epoch: 255, train accuracy: 0.8948, train_loss_norm:0.0147, valid_acc: 0.8511, valid_loss_norm: 0.0182\n",
      " epoch: 256, train accuracy: 0.8948, train_loss_norm:0.0146, valid_acc: 0.8511, valid_loss_norm: 0.0182\n",
      " epoch: 257, train accuracy: 0.8949, train_loss_norm:0.0146, valid_acc: 0.8508, valid_loss_norm: 0.0182\n",
      " epoch: 258, train accuracy: 0.8951, train_loss_norm:0.0146, valid_acc: 0.8508, valid_loss_norm: 0.0181\n",
      " epoch: 259, train accuracy: 0.8952, train_loss_norm:0.0146, valid_acc: 0.8511, valid_loss_norm: 0.0181\n",
      " epoch: 260, train accuracy: 0.8954, train_loss_norm:0.0145, valid_acc: 0.8514, valid_loss_norm: 0.0181\n",
      " epoch: 261, train accuracy: 0.8955, train_loss_norm:0.0145, valid_acc: 0.8517, valid_loss_norm: 0.0181\n",
      " epoch: 262, train accuracy: 0.8957, train_loss_norm:0.0145, valid_acc: 0.8520, valid_loss_norm: 0.0181\n",
      " epoch: 263, train accuracy: 0.8958, train_loss_norm:0.0145, valid_acc: 0.8520, valid_loss_norm: 0.0181\n",
      " epoch: 264, train accuracy: 0.8958, train_loss_norm:0.0145, valid_acc: 0.8525, valid_loss_norm: 0.0180\n",
      " epoch: 265, train accuracy: 0.8960, train_loss_norm:0.0144, valid_acc: 0.8525, valid_loss_norm: 0.0180\n",
      " epoch: 266, train accuracy: 0.8960, train_loss_norm:0.0144, valid_acc: 0.8525, valid_loss_norm: 0.0180\n",
      " epoch: 267, train accuracy: 0.8961, train_loss_norm:0.0144, valid_acc: 0.8525, valid_loss_norm: 0.0180\n",
      " epoch: 268, train accuracy: 0.8963, train_loss_norm:0.0144, valid_acc: 0.8525, valid_loss_norm: 0.0180\n",
      " epoch: 269, train accuracy: 0.8963, train_loss_norm:0.0144, valid_acc: 0.8531, valid_loss_norm: 0.0179\n",
      " epoch: 270, train accuracy: 0.8964, train_loss_norm:0.0143, valid_acc: 0.8531, valid_loss_norm: 0.0179\n",
      " epoch: 271, train accuracy: 0.8966, train_loss_norm:0.0143, valid_acc: 0.8531, valid_loss_norm: 0.0179\n",
      " epoch: 272, train accuracy: 0.8967, train_loss_norm:0.0143, valid_acc: 0.8534, valid_loss_norm: 0.0179\n",
      " epoch: 273, train accuracy: 0.8968, train_loss_norm:0.0143, valid_acc: 0.8537, valid_loss_norm: 0.0179\n",
      " epoch: 274, train accuracy: 0.8970, train_loss_norm:0.0142, valid_acc: 0.8543, valid_loss_norm: 0.0179\n",
      " epoch: 275, train accuracy: 0.8971, train_loss_norm:0.0142, valid_acc: 0.8543, valid_loss_norm: 0.0178\n",
      " epoch: 276, train accuracy: 0.8974, train_loss_norm:0.0142, valid_acc: 0.8543, valid_loss_norm: 0.0178\n",
      " epoch: 277, train accuracy: 0.8976, train_loss_norm:0.0142, valid_acc: 0.8540, valid_loss_norm: 0.0178\n",
      " epoch: 278, train accuracy: 0.8977, train_loss_norm:0.0142, valid_acc: 0.8540, valid_loss_norm: 0.0178\n",
      " epoch: 279, train accuracy: 0.8979, train_loss_norm:0.0141, valid_acc: 0.8537, valid_loss_norm: 0.0178\n",
      " epoch: 280, train accuracy: 0.8981, train_loss_norm:0.0141, valid_acc: 0.8540, valid_loss_norm: 0.0178\n",
      " epoch: 281, train accuracy: 0.8982, train_loss_norm:0.0141, valid_acc: 0.8540, valid_loss_norm: 0.0177\n",
      " epoch: 282, train accuracy: 0.8984, train_loss_norm:0.0141, valid_acc: 0.8540, valid_loss_norm: 0.0177\n",
      " epoch: 283, train accuracy: 0.8986, train_loss_norm:0.0141, valid_acc: 0.8540, valid_loss_norm: 0.0177\n",
      " epoch: 284, train accuracy: 0.8988, train_loss_norm:0.0140, valid_acc: 0.8540, valid_loss_norm: 0.0177\n",
      " epoch: 285, train accuracy: 0.8990, train_loss_norm:0.0140, valid_acc: 0.8540, valid_loss_norm: 0.0177\n",
      " epoch: 286, train accuracy: 0.8990, train_loss_norm:0.0140, valid_acc: 0.8543, valid_loss_norm: 0.0177\n",
      " epoch: 287, train accuracy: 0.8991, train_loss_norm:0.0140, valid_acc: 0.8546, valid_loss_norm: 0.0177\n",
      " epoch: 288, train accuracy: 0.8991, train_loss_norm:0.0140, valid_acc: 0.8546, valid_loss_norm: 0.0176\n",
      " epoch: 289, train accuracy: 0.8993, train_loss_norm:0.0139, valid_acc: 0.8548, valid_loss_norm: 0.0176\n",
      " epoch: 290, train accuracy: 0.8995, train_loss_norm:0.0139, valid_acc: 0.8551, valid_loss_norm: 0.0176\n",
      " epoch: 291, train accuracy: 0.8996, train_loss_norm:0.0139, valid_acc: 0.8554, valid_loss_norm: 0.0176\n",
      " epoch: 292, train accuracy: 0.8998, train_loss_norm:0.0139, valid_acc: 0.8554, valid_loss_norm: 0.0176\n",
      " epoch: 293, train accuracy: 0.8998, train_loss_norm:0.0139, valid_acc: 0.8554, valid_loss_norm: 0.0176\n",
      " epoch: 294, train accuracy: 0.8999, train_loss_norm:0.0138, valid_acc: 0.8554, valid_loss_norm: 0.0175\n",
      " epoch: 295, train accuracy: 0.8999, train_loss_norm:0.0138, valid_acc: 0.8554, valid_loss_norm: 0.0175\n",
      " epoch: 296, train accuracy: 0.9000, train_loss_norm:0.0138, valid_acc: 0.8554, valid_loss_norm: 0.0175\n",
      " epoch: 297, train accuracy: 0.9002, train_loss_norm:0.0138, valid_acc: 0.8557, valid_loss_norm: 0.0175\n",
      " epoch: 298, train accuracy: 0.9002, train_loss_norm:0.0138, valid_acc: 0.8557, valid_loss_norm: 0.0175\n",
      " epoch: 299, train accuracy: 0.9003, train_loss_norm:0.0138, valid_acc: 0.8560, valid_loss_norm: 0.0175\n",
      " epoch: 300, train accuracy: 0.9005, train_loss_norm:0.0137, valid_acc: 0.8560, valid_loss_norm: 0.0175\n",
      "Test accuracy: 0.8767\n",
      "Test loss norm: 0.0158\n",
      "Cur fold: 3\n",
      "(27841, 300)\n",
      "(3479, 300)\n",
      "(3479, 300)\n",
      " epoch: 1, train accuracy: 0.7905, train_loss_norm:0.0837, valid_acc: 0.7910, valid_loss_norm: 0.0836\n",
      " epoch: 2, train accuracy: 0.7906, train_loss_norm:0.0800, valid_acc: 0.7907, valid_loss_norm: 0.0799\n",
      " epoch: 3, train accuracy: 0.7908, train_loss_norm:0.0764, valid_acc: 0.7907, valid_loss_norm: 0.0764\n",
      " epoch: 4, train accuracy: 0.7909, train_loss_norm:0.0730, valid_acc: 0.7910, valid_loss_norm: 0.0730\n",
      " epoch: 5, train accuracy: 0.7919, train_loss_norm:0.0698, valid_acc: 0.7913, valid_loss_norm: 0.0698\n",
      " epoch: 6, train accuracy: 0.7922, train_loss_norm:0.0668, valid_acc: 0.7913, valid_loss_norm: 0.0668\n",
      " epoch: 7, train accuracy: 0.7935, train_loss_norm:0.0641, valid_acc: 0.7913, valid_loss_norm: 0.0640\n",
      " epoch: 8, train accuracy: 0.7944, train_loss_norm:0.0616, valid_acc: 0.7913, valid_loss_norm: 0.0615\n",
      " epoch: 9, train accuracy: 0.7959, train_loss_norm:0.0593, valid_acc: 0.7928, valid_loss_norm: 0.0592\n",
      " epoch: 10, train accuracy: 0.7975, train_loss_norm:0.0573, valid_acc: 0.7939, valid_loss_norm: 0.0572\n",
      " epoch: 11, train accuracy: 0.7987, train_loss_norm:0.0554, valid_acc: 0.7948, valid_loss_norm: 0.0553\n",
      " epoch: 12, train accuracy: 0.8000, train_loss_norm:0.0537, valid_acc: 0.7959, valid_loss_norm: 0.0536\n",
      " epoch: 13, train accuracy: 0.8014, train_loss_norm:0.0521, valid_acc: 0.7985, valid_loss_norm: 0.0520\n",
      " epoch: 14, train accuracy: 0.8028, train_loss_norm:0.0507, valid_acc: 0.7997, valid_loss_norm: 0.0506\n",
      " epoch: 15, train accuracy: 0.8049, train_loss_norm:0.0493, valid_acc: 0.8017, valid_loss_norm: 0.0492\n",
      " epoch: 16, train accuracy: 0.8067, train_loss_norm:0.0481, valid_acc: 0.8022, valid_loss_norm: 0.0480\n",
      " epoch: 17, train accuracy: 0.8081, train_loss_norm:0.0469, valid_acc: 0.8028, valid_loss_norm: 0.0469\n",
      " epoch: 18, train accuracy: 0.8097, train_loss_norm:0.0459, valid_acc: 0.8034, valid_loss_norm: 0.0458\n",
      " epoch: 19, train accuracy: 0.8112, train_loss_norm:0.0449, valid_acc: 0.8048, valid_loss_norm: 0.0448\n",
      " epoch: 20, train accuracy: 0.8128, train_loss_norm:0.0440, valid_acc: 0.8054, valid_loss_norm: 0.0439\n",
      " epoch: 21, train accuracy: 0.8140, train_loss_norm:0.0431, valid_acc: 0.8074, valid_loss_norm: 0.0431\n",
      " epoch: 22, train accuracy: 0.8155, train_loss_norm:0.0423, valid_acc: 0.8077, valid_loss_norm: 0.0423\n",
      " epoch: 23, train accuracy: 0.8165, train_loss_norm:0.0415, valid_acc: 0.8086, valid_loss_norm: 0.0415\n",
      " epoch: 24, train accuracy: 0.8178, train_loss_norm:0.0407, valid_acc: 0.8094, valid_loss_norm: 0.0408\n",
      " epoch: 25, train accuracy: 0.8187, train_loss_norm:0.0400, valid_acc: 0.8112, valid_loss_norm: 0.0401\n",
      " epoch: 26, train accuracy: 0.8201, train_loss_norm:0.0394, valid_acc: 0.8120, valid_loss_norm: 0.0395\n",
      " epoch: 27, train accuracy: 0.8213, train_loss_norm:0.0388, valid_acc: 0.8129, valid_loss_norm: 0.0388\n",
      " epoch: 28, train accuracy: 0.8227, train_loss_norm:0.0382, valid_acc: 0.8143, valid_loss_norm: 0.0383\n",
      " epoch: 29, train accuracy: 0.8237, train_loss_norm:0.0376, valid_acc: 0.8143, valid_loss_norm: 0.0377\n",
      " epoch: 30, train accuracy: 0.8245, train_loss_norm:0.0370, valid_acc: 0.8140, valid_loss_norm: 0.0372\n",
      " epoch: 31, train accuracy: 0.8251, train_loss_norm:0.0365, valid_acc: 0.8140, valid_loss_norm: 0.0367\n",
      " epoch: 32, train accuracy: 0.8263, train_loss_norm:0.0360, valid_acc: 0.8143, valid_loss_norm: 0.0362\n",
      " epoch: 33, train accuracy: 0.8276, train_loss_norm:0.0355, valid_acc: 0.8152, valid_loss_norm: 0.0357\n",
      " epoch: 34, train accuracy: 0.8287, train_loss_norm:0.0351, valid_acc: 0.8163, valid_loss_norm: 0.0353\n",
      " epoch: 35, train accuracy: 0.8298, train_loss_norm:0.0347, valid_acc: 0.8169, valid_loss_norm: 0.0349\n",
      " epoch: 36, train accuracy: 0.8304, train_loss_norm:0.0342, valid_acc: 0.8166, valid_loss_norm: 0.0345\n",
      " epoch: 37, train accuracy: 0.8314, train_loss_norm:0.0338, valid_acc: 0.8181, valid_loss_norm: 0.0341\n",
      " epoch: 38, train accuracy: 0.8322, train_loss_norm:0.0334, valid_acc: 0.8186, valid_loss_norm: 0.0337\n",
      " epoch: 39, train accuracy: 0.8329, train_loss_norm:0.0330, valid_acc: 0.8201, valid_loss_norm: 0.0333\n",
      " epoch: 40, train accuracy: 0.8337, train_loss_norm:0.0327, valid_acc: 0.8218, valid_loss_norm: 0.0330\n",
      " epoch: 41, train accuracy: 0.8346, train_loss_norm:0.0323, valid_acc: 0.8227, valid_loss_norm: 0.0326\n",
      " epoch: 42, train accuracy: 0.8353, train_loss_norm:0.0320, valid_acc: 0.8238, valid_loss_norm: 0.0323\n",
      " epoch: 43, train accuracy: 0.8361, train_loss_norm:0.0317, valid_acc: 0.8247, valid_loss_norm: 0.0320\n",
      " epoch: 44, train accuracy: 0.8364, train_loss_norm:0.0313, valid_acc: 0.8255, valid_loss_norm: 0.0317\n",
      " epoch: 45, train accuracy: 0.8371, train_loss_norm:0.0310, valid_acc: 0.8264, valid_loss_norm: 0.0314\n",
      " epoch: 46, train accuracy: 0.8378, train_loss_norm:0.0307, valid_acc: 0.8272, valid_loss_norm: 0.0311\n",
      " epoch: 47, train accuracy: 0.8380, train_loss_norm:0.0304, valid_acc: 0.8272, valid_loss_norm: 0.0308\n",
      " epoch: 48, train accuracy: 0.8388, train_loss_norm:0.0302, valid_acc: 0.8275, valid_loss_norm: 0.0305\n",
      " epoch: 49, train accuracy: 0.8393, train_loss_norm:0.0299, valid_acc: 0.8287, valid_loss_norm: 0.0303\n",
      " epoch: 50, train accuracy: 0.8395, train_loss_norm:0.0296, valid_acc: 0.8290, valid_loss_norm: 0.0300\n",
      " epoch: 51, train accuracy: 0.8401, train_loss_norm:0.0294, valid_acc: 0.8290, valid_loss_norm: 0.0298\n",
      " epoch: 52, train accuracy: 0.8407, train_loss_norm:0.0291, valid_acc: 0.8287, valid_loss_norm: 0.0295\n",
      " epoch: 53, train accuracy: 0.8414, train_loss_norm:0.0289, valid_acc: 0.8293, valid_loss_norm: 0.0293\n",
      " epoch: 54, train accuracy: 0.8418, train_loss_norm:0.0286, valid_acc: 0.8301, valid_loss_norm: 0.0291\n",
      " epoch: 55, train accuracy: 0.8425, train_loss_norm:0.0284, valid_acc: 0.8301, valid_loss_norm: 0.0289\n",
      " epoch: 56, train accuracy: 0.8427, train_loss_norm:0.0282, valid_acc: 0.8304, valid_loss_norm: 0.0286\n",
      " epoch: 57, train accuracy: 0.8434, train_loss_norm:0.0279, valid_acc: 0.8318, valid_loss_norm: 0.0284\n",
      " epoch: 58, train accuracy: 0.8439, train_loss_norm:0.0277, valid_acc: 0.8327, valid_loss_norm: 0.0282\n",
      " epoch: 59, train accuracy: 0.8444, train_loss_norm:0.0275, valid_acc: 0.8333, valid_loss_norm: 0.0280\n",
      " epoch: 60, train accuracy: 0.8450, train_loss_norm:0.0273, valid_acc: 0.8333, valid_loss_norm: 0.0278\n",
      " epoch: 61, train accuracy: 0.8456, train_loss_norm:0.0271, valid_acc: 0.8336, valid_loss_norm: 0.0277\n",
      " epoch: 62, train accuracy: 0.8461, train_loss_norm:0.0269, valid_acc: 0.8347, valid_loss_norm: 0.0275\n",
      " epoch: 63, train accuracy: 0.8465, train_loss_norm:0.0267, valid_acc: 0.8356, valid_loss_norm: 0.0273\n",
      " epoch: 64, train accuracy: 0.8469, train_loss_norm:0.0265, valid_acc: 0.8367, valid_loss_norm: 0.0271\n",
      " epoch: 65, train accuracy: 0.8474, train_loss_norm:0.0264, valid_acc: 0.8376, valid_loss_norm: 0.0269\n",
      " epoch: 66, train accuracy: 0.8479, train_loss_norm:0.0262, valid_acc: 0.8387, valid_loss_norm: 0.0268\n",
      " epoch: 67, train accuracy: 0.8481, train_loss_norm:0.0260, valid_acc: 0.8399, valid_loss_norm: 0.0266\n",
      " epoch: 68, train accuracy: 0.8486, train_loss_norm:0.0258, valid_acc: 0.8408, valid_loss_norm: 0.0265\n",
      " epoch: 69, train accuracy: 0.8489, train_loss_norm:0.0257, valid_acc: 0.8410, valid_loss_norm: 0.0263\n",
      " epoch: 70, train accuracy: 0.8495, train_loss_norm:0.0255, valid_acc: 0.8408, valid_loss_norm: 0.0262\n",
      " epoch: 71, train accuracy: 0.8498, train_loss_norm:0.0253, valid_acc: 0.8410, valid_loss_norm: 0.0260\n",
      " epoch: 72, train accuracy: 0.8504, train_loss_norm:0.0252, valid_acc: 0.8416, valid_loss_norm: 0.0259\n",
      " epoch: 73, train accuracy: 0.8507, train_loss_norm:0.0250, valid_acc: 0.8419, valid_loss_norm: 0.0257\n",
      " epoch: 74, train accuracy: 0.8512, train_loss_norm:0.0249, valid_acc: 0.8419, valid_loss_norm: 0.0256\n",
      " epoch: 75, train accuracy: 0.8516, train_loss_norm:0.0247, valid_acc: 0.8422, valid_loss_norm: 0.0254\n",
      " epoch: 76, train accuracy: 0.8518, train_loss_norm:0.0246, valid_acc: 0.8428, valid_loss_norm: 0.0253\n",
      " epoch: 77, train accuracy: 0.8522, train_loss_norm:0.0245, valid_acc: 0.8428, valid_loss_norm: 0.0252\n",
      " epoch: 78, train accuracy: 0.8524, train_loss_norm:0.0243, valid_acc: 0.8428, valid_loss_norm: 0.0250\n",
      " epoch: 79, train accuracy: 0.8528, train_loss_norm:0.0242, valid_acc: 0.8433, valid_loss_norm: 0.0249\n",
      " epoch: 80, train accuracy: 0.8532, train_loss_norm:0.0241, valid_acc: 0.8448, valid_loss_norm: 0.0248\n",
      " epoch: 81, train accuracy: 0.8535, train_loss_norm:0.0239, valid_acc: 0.8459, valid_loss_norm: 0.0247\n",
      " epoch: 82, train accuracy: 0.8537, train_loss_norm:0.0238, valid_acc: 0.8462, valid_loss_norm: 0.0245\n",
      " epoch: 83, train accuracy: 0.8541, train_loss_norm:0.0237, valid_acc: 0.8465, valid_loss_norm: 0.0244\n",
      " epoch: 84, train accuracy: 0.8545, train_loss_norm:0.0235, valid_acc: 0.8468, valid_loss_norm: 0.0243\n",
      " epoch: 85, train accuracy: 0.8550, train_loss_norm:0.0234, valid_acc: 0.8468, valid_loss_norm: 0.0242\n",
      " epoch: 86, train accuracy: 0.8552, train_loss_norm:0.0233, valid_acc: 0.8471, valid_loss_norm: 0.0241\n",
      " epoch: 87, train accuracy: 0.8558, train_loss_norm:0.0232, valid_acc: 0.8471, valid_loss_norm: 0.0240\n",
      " epoch: 88, train accuracy: 0.8562, train_loss_norm:0.0231, valid_acc: 0.8471, valid_loss_norm: 0.0239\n",
      " epoch: 89, train accuracy: 0.8565, train_loss_norm:0.0230, valid_acc: 0.8474, valid_loss_norm: 0.0238\n",
      " epoch: 90, train accuracy: 0.8567, train_loss_norm:0.0228, valid_acc: 0.8482, valid_loss_norm: 0.0237\n",
      " epoch: 91, train accuracy: 0.8570, train_loss_norm:0.0227, valid_acc: 0.8491, valid_loss_norm: 0.0236\n",
      " epoch: 92, train accuracy: 0.8572, train_loss_norm:0.0226, valid_acc: 0.8497, valid_loss_norm: 0.0235\n",
      " epoch: 93, train accuracy: 0.8577, train_loss_norm:0.0225, valid_acc: 0.8494, valid_loss_norm: 0.0234\n",
      " epoch: 94, train accuracy: 0.8581, train_loss_norm:0.0224, valid_acc: 0.8500, valid_loss_norm: 0.0233\n",
      " epoch: 95, train accuracy: 0.8587, train_loss_norm:0.0223, valid_acc: 0.8500, valid_loss_norm: 0.0232\n",
      " epoch: 96, train accuracy: 0.8591, train_loss_norm:0.0222, valid_acc: 0.8500, valid_loss_norm: 0.0231\n",
      " epoch: 97, train accuracy: 0.8594, train_loss_norm:0.0221, valid_acc: 0.8500, valid_loss_norm: 0.0230\n",
      " epoch: 98, train accuracy: 0.8596, train_loss_norm:0.0220, valid_acc: 0.8502, valid_loss_norm: 0.0229\n",
      " epoch: 99, train accuracy: 0.8599, train_loss_norm:0.0219, valid_acc: 0.8508, valid_loss_norm: 0.0228\n",
      " epoch: 100, train accuracy: 0.8602, train_loss_norm:0.0218, valid_acc: 0.8508, valid_loss_norm: 0.0227\n",
      " epoch: 101, train accuracy: 0.8602, train_loss_norm:0.0217, valid_acc: 0.8508, valid_loss_norm: 0.0226\n",
      " epoch: 102, train accuracy: 0.8605, train_loss_norm:0.0216, valid_acc: 0.8505, valid_loss_norm: 0.0226\n",
      " epoch: 103, train accuracy: 0.8609, train_loss_norm:0.0215, valid_acc: 0.8508, valid_loss_norm: 0.0225\n",
      " epoch: 104, train accuracy: 0.8613, train_loss_norm:0.0215, valid_acc: 0.8508, valid_loss_norm: 0.0224\n",
      " epoch: 105, train accuracy: 0.8615, train_loss_norm:0.0214, valid_acc: 0.8508, valid_loss_norm: 0.0223\n",
      " epoch: 106, train accuracy: 0.8617, train_loss_norm:0.0213, valid_acc: 0.8508, valid_loss_norm: 0.0222\n",
      " epoch: 107, train accuracy: 0.8620, train_loss_norm:0.0212, valid_acc: 0.8508, valid_loss_norm: 0.0222\n",
      " epoch: 108, train accuracy: 0.8621, train_loss_norm:0.0211, valid_acc: 0.8511, valid_loss_norm: 0.0221\n",
      " epoch: 109, train accuracy: 0.8623, train_loss_norm:0.0210, valid_acc: 0.8511, valid_loss_norm: 0.0220\n",
      " epoch: 110, train accuracy: 0.8625, train_loss_norm:0.0209, valid_acc: 0.8514, valid_loss_norm: 0.0219\n",
      " epoch: 111, train accuracy: 0.8628, train_loss_norm:0.0209, valid_acc: 0.8517, valid_loss_norm: 0.0219\n",
      " epoch: 112, train accuracy: 0.8635, train_loss_norm:0.0208, valid_acc: 0.8528, valid_loss_norm: 0.0218\n",
      " epoch: 113, train accuracy: 0.8638, train_loss_norm:0.0207, valid_acc: 0.8525, valid_loss_norm: 0.0217\n",
      " epoch: 114, train accuracy: 0.8642, train_loss_norm:0.0206, valid_acc: 0.8525, valid_loss_norm: 0.0216\n",
      " epoch: 115, train accuracy: 0.8644, train_loss_norm:0.0206, valid_acc: 0.8523, valid_loss_norm: 0.0216\n",
      " epoch: 116, train accuracy: 0.8648, train_loss_norm:0.0205, valid_acc: 0.8525, valid_loss_norm: 0.0215\n",
      " epoch: 117, train accuracy: 0.8652, train_loss_norm:0.0204, valid_acc: 0.8523, valid_loss_norm: 0.0214\n",
      " epoch: 118, train accuracy: 0.8654, train_loss_norm:0.0203, valid_acc: 0.8528, valid_loss_norm: 0.0214\n",
      " epoch: 119, train accuracy: 0.8657, train_loss_norm:0.0203, valid_acc: 0.8528, valid_loss_norm: 0.0213\n",
      " epoch: 120, train accuracy: 0.8659, train_loss_norm:0.0202, valid_acc: 0.8528, valid_loss_norm: 0.0212\n",
      " epoch: 121, train accuracy: 0.8661, train_loss_norm:0.0201, valid_acc: 0.8528, valid_loss_norm: 0.0212\n",
      " epoch: 122, train accuracy: 0.8664, train_loss_norm:0.0200, valid_acc: 0.8528, valid_loss_norm: 0.0211\n",
      " epoch: 123, train accuracy: 0.8666, train_loss_norm:0.0200, valid_acc: 0.8528, valid_loss_norm: 0.0210\n",
      " epoch: 124, train accuracy: 0.8669, train_loss_norm:0.0199, valid_acc: 0.8537, valid_loss_norm: 0.0210\n",
      " epoch: 125, train accuracy: 0.8672, train_loss_norm:0.0198, valid_acc: 0.8543, valid_loss_norm: 0.0209\n",
      " epoch: 126, train accuracy: 0.8675, train_loss_norm:0.0198, valid_acc: 0.8543, valid_loss_norm: 0.0209\n",
      " epoch: 127, train accuracy: 0.8676, train_loss_norm:0.0197, valid_acc: 0.8543, valid_loss_norm: 0.0208\n",
      " epoch: 128, train accuracy: 0.8679, train_loss_norm:0.0196, valid_acc: 0.8548, valid_loss_norm: 0.0207\n",
      " epoch: 129, train accuracy: 0.8681, train_loss_norm:0.0196, valid_acc: 0.8543, valid_loss_norm: 0.0207\n",
      " epoch: 130, train accuracy: 0.8682, train_loss_norm:0.0195, valid_acc: 0.8546, valid_loss_norm: 0.0206\n",
      " epoch: 131, train accuracy: 0.8682, train_loss_norm:0.0194, valid_acc: 0.8551, valid_loss_norm: 0.0206\n",
      " epoch: 132, train accuracy: 0.8683, train_loss_norm:0.0194, valid_acc: 0.8551, valid_loss_norm: 0.0205\n",
      " epoch: 133, train accuracy: 0.8685, train_loss_norm:0.0193, valid_acc: 0.8557, valid_loss_norm: 0.0205\n",
      " epoch: 134, train accuracy: 0.8688, train_loss_norm:0.0193, valid_acc: 0.8560, valid_loss_norm: 0.0204\n",
      " epoch: 135, train accuracy: 0.8689, train_loss_norm:0.0192, valid_acc: 0.8560, valid_loss_norm: 0.0203\n",
      " epoch: 136, train accuracy: 0.8693, train_loss_norm:0.0191, valid_acc: 0.8566, valid_loss_norm: 0.0203\n",
      " epoch: 137, train accuracy: 0.8695, train_loss_norm:0.0191, valid_acc: 0.8569, valid_loss_norm: 0.0202\n",
      " epoch: 138, train accuracy: 0.8697, train_loss_norm:0.0190, valid_acc: 0.8569, valid_loss_norm: 0.0202\n",
      " epoch: 139, train accuracy: 0.8700, train_loss_norm:0.0190, valid_acc: 0.8586, valid_loss_norm: 0.0201\n",
      " epoch: 140, train accuracy: 0.8702, train_loss_norm:0.0189, valid_acc: 0.8583, valid_loss_norm: 0.0201\n",
      " epoch: 141, train accuracy: 0.8706, train_loss_norm:0.0189, valid_acc: 0.8583, valid_loss_norm: 0.0200\n",
      " epoch: 142, train accuracy: 0.8708, train_loss_norm:0.0188, valid_acc: 0.8586, valid_loss_norm: 0.0200\n",
      " epoch: 143, train accuracy: 0.8710, train_loss_norm:0.0187, valid_acc: 0.8586, valid_loss_norm: 0.0199\n",
      " epoch: 144, train accuracy: 0.8714, train_loss_norm:0.0187, valid_acc: 0.8586, valid_loss_norm: 0.0199\n",
      " epoch: 145, train accuracy: 0.8718, train_loss_norm:0.0186, valid_acc: 0.8594, valid_loss_norm: 0.0198\n",
      " epoch: 146, train accuracy: 0.8721, train_loss_norm:0.0186, valid_acc: 0.8594, valid_loss_norm: 0.0198\n",
      " epoch: 147, train accuracy: 0.8723, train_loss_norm:0.0185, valid_acc: 0.8594, valid_loss_norm: 0.0197\n",
      " epoch: 148, train accuracy: 0.8725, train_loss_norm:0.0185, valid_acc: 0.8597, valid_loss_norm: 0.0197\n",
      " epoch: 149, train accuracy: 0.8727, train_loss_norm:0.0184, valid_acc: 0.8603, valid_loss_norm: 0.0197\n",
      " epoch: 150, train accuracy: 0.8729, train_loss_norm:0.0184, valid_acc: 0.8615, valid_loss_norm: 0.0196\n",
      " epoch: 151, train accuracy: 0.8730, train_loss_norm:0.0183, valid_acc: 0.8612, valid_loss_norm: 0.0196\n",
      " epoch: 152, train accuracy: 0.8735, train_loss_norm:0.0183, valid_acc: 0.8609, valid_loss_norm: 0.0195\n",
      " epoch: 153, train accuracy: 0.8735, train_loss_norm:0.0182, valid_acc: 0.8612, valid_loss_norm: 0.0195\n",
      " epoch: 154, train accuracy: 0.8740, train_loss_norm:0.0182, valid_acc: 0.8612, valid_loss_norm: 0.0194\n",
      " epoch: 155, train accuracy: 0.8742, train_loss_norm:0.0181, valid_acc: 0.8612, valid_loss_norm: 0.0194\n",
      " epoch: 156, train accuracy: 0.8744, train_loss_norm:0.0181, valid_acc: 0.8615, valid_loss_norm: 0.0193\n",
      " epoch: 157, train accuracy: 0.8747, train_loss_norm:0.0180, valid_acc: 0.8617, valid_loss_norm: 0.0193\n",
      " epoch: 158, train accuracy: 0.8748, train_loss_norm:0.0180, valid_acc: 0.8620, valid_loss_norm: 0.0193\n",
      " epoch: 159, train accuracy: 0.8748, train_loss_norm:0.0179, valid_acc: 0.8626, valid_loss_norm: 0.0192\n",
      " epoch: 160, train accuracy: 0.8750, train_loss_norm:0.0179, valid_acc: 0.8626, valid_loss_norm: 0.0192\n",
      " epoch: 161, train accuracy: 0.8751, train_loss_norm:0.0178, valid_acc: 0.8623, valid_loss_norm: 0.0191\n",
      " epoch: 162, train accuracy: 0.8754, train_loss_norm:0.0178, valid_acc: 0.8623, valid_loss_norm: 0.0191\n",
      " epoch: 163, train accuracy: 0.8755, train_loss_norm:0.0177, valid_acc: 0.8626, valid_loss_norm: 0.0191\n",
      " epoch: 164, train accuracy: 0.8757, train_loss_norm:0.0177, valid_acc: 0.8626, valid_loss_norm: 0.0190\n",
      " epoch: 165, train accuracy: 0.8759, train_loss_norm:0.0177, valid_acc: 0.8632, valid_loss_norm: 0.0190\n",
      " epoch: 166, train accuracy: 0.8760, train_loss_norm:0.0176, valid_acc: 0.8632, valid_loss_norm: 0.0189\n",
      " epoch: 167, train accuracy: 0.8764, train_loss_norm:0.0176, valid_acc: 0.8638, valid_loss_norm: 0.0189\n",
      " epoch: 168, train accuracy: 0.8767, train_loss_norm:0.0175, valid_acc: 0.8640, valid_loss_norm: 0.0189\n",
      " epoch: 169, train accuracy: 0.8769, train_loss_norm:0.0175, valid_acc: 0.8640, valid_loss_norm: 0.0188\n",
      " epoch: 170, train accuracy: 0.8771, train_loss_norm:0.0174, valid_acc: 0.8640, valid_loss_norm: 0.0188\n",
      " epoch: 171, train accuracy: 0.8771, train_loss_norm:0.0174, valid_acc: 0.8640, valid_loss_norm: 0.0187\n",
      " epoch: 172, train accuracy: 0.8773, train_loss_norm:0.0174, valid_acc: 0.8640, valid_loss_norm: 0.0187\n",
      " epoch: 173, train accuracy: 0.8777, train_loss_norm:0.0173, valid_acc: 0.8640, valid_loss_norm: 0.0187\n",
      " epoch: 174, train accuracy: 0.8780, train_loss_norm:0.0173, valid_acc: 0.8649, valid_loss_norm: 0.0186\n",
      " epoch: 175, train accuracy: 0.8783, train_loss_norm:0.0172, valid_acc: 0.8652, valid_loss_norm: 0.0186\n",
      " epoch: 176, train accuracy: 0.8786, train_loss_norm:0.0172, valid_acc: 0.8643, valid_loss_norm: 0.0186\n",
      " epoch: 177, train accuracy: 0.8787, train_loss_norm:0.0172, valid_acc: 0.8649, valid_loss_norm: 0.0185\n",
      " epoch: 178, train accuracy: 0.8791, train_loss_norm:0.0171, valid_acc: 0.8652, valid_loss_norm: 0.0185\n",
      " epoch: 179, train accuracy: 0.8794, train_loss_norm:0.0171, valid_acc: 0.8655, valid_loss_norm: 0.0185\n",
      " epoch: 180, train accuracy: 0.8796, train_loss_norm:0.0170, valid_acc: 0.8658, valid_loss_norm: 0.0184\n",
      " epoch: 181, train accuracy: 0.8797, train_loss_norm:0.0170, valid_acc: 0.8663, valid_loss_norm: 0.0184\n",
      " epoch: 182, train accuracy: 0.8801, train_loss_norm:0.0170, valid_acc: 0.8669, valid_loss_norm: 0.0184\n",
      " epoch: 183, train accuracy: 0.8802, train_loss_norm:0.0169, valid_acc: 0.8663, valid_loss_norm: 0.0183\n",
      " epoch: 184, train accuracy: 0.8805, train_loss_norm:0.0169, valid_acc: 0.8666, valid_loss_norm: 0.0183\n",
      " epoch: 185, train accuracy: 0.8806, train_loss_norm:0.0168, valid_acc: 0.8666, valid_loss_norm: 0.0183\n",
      " epoch: 186, train accuracy: 0.8809, train_loss_norm:0.0168, valid_acc: 0.8663, valid_loss_norm: 0.0182\n",
      " epoch: 187, train accuracy: 0.8811, train_loss_norm:0.0168, valid_acc: 0.8663, valid_loss_norm: 0.0182\n",
      " epoch: 188, train accuracy: 0.8814, train_loss_norm:0.0167, valid_acc: 0.8666, valid_loss_norm: 0.0182\n",
      " epoch: 189, train accuracy: 0.8815, train_loss_norm:0.0167, valid_acc: 0.8672, valid_loss_norm: 0.0181\n",
      " epoch: 190, train accuracy: 0.8816, train_loss_norm:0.0167, valid_acc: 0.8672, valid_loss_norm: 0.0181\n",
      " epoch: 191, train accuracy: 0.8818, train_loss_norm:0.0166, valid_acc: 0.8672, valid_loss_norm: 0.0181\n",
      " epoch: 192, train accuracy: 0.8819, train_loss_norm:0.0166, valid_acc: 0.8675, valid_loss_norm: 0.0180\n",
      " epoch: 193, train accuracy: 0.8821, train_loss_norm:0.0166, valid_acc: 0.8675, valid_loss_norm: 0.0180\n",
      " epoch: 194, train accuracy: 0.8824, train_loss_norm:0.0165, valid_acc: 0.8678, valid_loss_norm: 0.0180\n",
      " epoch: 195, train accuracy: 0.8826, train_loss_norm:0.0165, valid_acc: 0.8678, valid_loss_norm: 0.0180\n",
      " epoch: 196, train accuracy: 0.8829, train_loss_norm:0.0165, valid_acc: 0.8678, valid_loss_norm: 0.0179\n",
      " epoch: 197, train accuracy: 0.8829, train_loss_norm:0.0164, valid_acc: 0.8678, valid_loss_norm: 0.0179\n",
      " epoch: 198, train accuracy: 0.8832, train_loss_norm:0.0164, valid_acc: 0.8678, valid_loss_norm: 0.0179\n",
      " epoch: 199, train accuracy: 0.8834, train_loss_norm:0.0164, valid_acc: 0.8678, valid_loss_norm: 0.0178\n",
      " epoch: 200, train accuracy: 0.8835, train_loss_norm:0.0163, valid_acc: 0.8678, valid_loss_norm: 0.0178\n",
      " epoch: 201, train accuracy: 0.8836, train_loss_norm:0.0163, valid_acc: 0.8672, valid_loss_norm: 0.0178\n",
      " epoch: 202, train accuracy: 0.8839, train_loss_norm:0.0163, valid_acc: 0.8675, valid_loss_norm: 0.0177\n",
      " epoch: 203, train accuracy: 0.8841, train_loss_norm:0.0162, valid_acc: 0.8672, valid_loss_norm: 0.0177\n",
      " epoch: 204, train accuracy: 0.8841, train_loss_norm:0.0162, valid_acc: 0.8675, valid_loss_norm: 0.0177\n",
      " epoch: 205, train accuracy: 0.8843, train_loss_norm:0.0162, valid_acc: 0.8675, valid_loss_norm: 0.0177\n",
      " epoch: 206, train accuracy: 0.8845, train_loss_norm:0.0161, valid_acc: 0.8675, valid_loss_norm: 0.0176\n",
      " epoch: 207, train accuracy: 0.8848, train_loss_norm:0.0161, valid_acc: 0.8675, valid_loss_norm: 0.0176\n",
      " epoch: 208, train accuracy: 0.8850, train_loss_norm:0.0161, valid_acc: 0.8675, valid_loss_norm: 0.0176\n",
      " epoch: 209, train accuracy: 0.8851, train_loss_norm:0.0160, valid_acc: 0.8675, valid_loss_norm: 0.0176\n",
      " epoch: 210, train accuracy: 0.8852, train_loss_norm:0.0160, valid_acc: 0.8675, valid_loss_norm: 0.0175\n",
      " epoch: 211, train accuracy: 0.8854, train_loss_norm:0.0160, valid_acc: 0.8675, valid_loss_norm: 0.0175\n",
      " epoch: 212, train accuracy: 0.8857, train_loss_norm:0.0159, valid_acc: 0.8675, valid_loss_norm: 0.0175\n",
      " epoch: 213, train accuracy: 0.8860, train_loss_norm:0.0159, valid_acc: 0.8675, valid_loss_norm: 0.0174\n",
      " epoch: 214, train accuracy: 0.8862, train_loss_norm:0.0159, valid_acc: 0.8672, valid_loss_norm: 0.0174\n",
      " epoch: 215, train accuracy: 0.8865, train_loss_norm:0.0158, valid_acc: 0.8672, valid_loss_norm: 0.0174\n",
      " epoch: 216, train accuracy: 0.8867, train_loss_norm:0.0158, valid_acc: 0.8672, valid_loss_norm: 0.0174\n",
      " epoch: 217, train accuracy: 0.8871, train_loss_norm:0.0158, valid_acc: 0.8675, valid_loss_norm: 0.0173\n",
      " epoch: 218, train accuracy: 0.8871, train_loss_norm:0.0158, valid_acc: 0.8678, valid_loss_norm: 0.0173\n",
      " epoch: 219, train accuracy: 0.8874, train_loss_norm:0.0157, valid_acc: 0.8678, valid_loss_norm: 0.0173\n",
      " epoch: 220, train accuracy: 0.8875, train_loss_norm:0.0157, valid_acc: 0.8684, valid_loss_norm: 0.0173\n",
      " epoch: 221, train accuracy: 0.8875, train_loss_norm:0.0157, valid_acc: 0.8684, valid_loss_norm: 0.0172\n",
      " epoch: 222, train accuracy: 0.8877, train_loss_norm:0.0156, valid_acc: 0.8686, valid_loss_norm: 0.0172\n",
      " epoch: 223, train accuracy: 0.8879, train_loss_norm:0.0156, valid_acc: 0.8689, valid_loss_norm: 0.0172\n",
      " epoch: 224, train accuracy: 0.8881, train_loss_norm:0.0156, valid_acc: 0.8686, valid_loss_norm: 0.0172\n",
      " epoch: 225, train accuracy: 0.8882, train_loss_norm:0.0156, valid_acc: 0.8689, valid_loss_norm: 0.0172\n",
      " epoch: 226, train accuracy: 0.8884, train_loss_norm:0.0155, valid_acc: 0.8689, valid_loss_norm: 0.0171\n",
      " epoch: 227, train accuracy: 0.8884, train_loss_norm:0.0155, valid_acc: 0.8689, valid_loss_norm: 0.0171\n",
      " epoch: 228, train accuracy: 0.8887, train_loss_norm:0.0155, valid_acc: 0.8689, valid_loss_norm: 0.0171\n",
      " epoch: 229, train accuracy: 0.8889, train_loss_norm:0.0154, valid_acc: 0.8692, valid_loss_norm: 0.0171\n",
      " epoch: 230, train accuracy: 0.8892, train_loss_norm:0.0154, valid_acc: 0.8701, valid_loss_norm: 0.0170\n",
      " epoch: 231, train accuracy: 0.8893, train_loss_norm:0.0154, valid_acc: 0.8701, valid_loss_norm: 0.0170\n",
      " epoch: 232, train accuracy: 0.8894, train_loss_norm:0.0154, valid_acc: 0.8701, valid_loss_norm: 0.0170\n",
      " epoch: 233, train accuracy: 0.8896, train_loss_norm:0.0153, valid_acc: 0.8701, valid_loss_norm: 0.0170\n",
      " epoch: 234, train accuracy: 0.8899, train_loss_norm:0.0153, valid_acc: 0.8704, valid_loss_norm: 0.0169\n",
      " epoch: 235, train accuracy: 0.8900, train_loss_norm:0.0153, valid_acc: 0.8704, valid_loss_norm: 0.0169\n",
      " epoch: 236, train accuracy: 0.8902, train_loss_norm:0.0153, valid_acc: 0.8707, valid_loss_norm: 0.0169\n",
      " epoch: 237, train accuracy: 0.8903, train_loss_norm:0.0152, valid_acc: 0.8707, valid_loss_norm: 0.0169\n",
      " epoch: 238, train accuracy: 0.8903, train_loss_norm:0.0152, valid_acc: 0.8709, valid_loss_norm: 0.0169\n",
      " epoch: 239, train accuracy: 0.8906, train_loss_norm:0.0152, valid_acc: 0.8709, valid_loss_norm: 0.0168\n",
      " epoch: 240, train accuracy: 0.8908, train_loss_norm:0.0152, valid_acc: 0.8709, valid_loss_norm: 0.0168\n",
      " epoch: 241, train accuracy: 0.8910, train_loss_norm:0.0151, valid_acc: 0.8709, valid_loss_norm: 0.0168\n",
      " epoch: 242, train accuracy: 0.8913, train_loss_norm:0.0151, valid_acc: 0.8707, valid_loss_norm: 0.0168\n",
      " epoch: 243, train accuracy: 0.8915, train_loss_norm:0.0151, valid_acc: 0.8707, valid_loss_norm: 0.0168\n",
      " epoch: 244, train accuracy: 0.8918, train_loss_norm:0.0151, valid_acc: 0.8707, valid_loss_norm: 0.0167\n",
      " epoch: 245, train accuracy: 0.8920, train_loss_norm:0.0150, valid_acc: 0.8707, valid_loss_norm: 0.0167\n",
      " epoch: 246, train accuracy: 0.8922, train_loss_norm:0.0150, valid_acc: 0.8707, valid_loss_norm: 0.0167\n",
      " epoch: 247, train accuracy: 0.8923, train_loss_norm:0.0150, valid_acc: 0.8707, valid_loss_norm: 0.0167\n",
      " epoch: 248, train accuracy: 0.8924, train_loss_norm:0.0150, valid_acc: 0.8707, valid_loss_norm: 0.0166\n",
      " epoch: 249, train accuracy: 0.8926, train_loss_norm:0.0149, valid_acc: 0.8709, valid_loss_norm: 0.0166\n",
      " epoch: 250, train accuracy: 0.8927, train_loss_norm:0.0149, valid_acc: 0.8709, valid_loss_norm: 0.0166\n",
      " epoch: 251, train accuracy: 0.8929, train_loss_norm:0.0149, valid_acc: 0.8712, valid_loss_norm: 0.0166\n",
      " epoch: 252, train accuracy: 0.8930, train_loss_norm:0.0149, valid_acc: 0.8715, valid_loss_norm: 0.0166\n",
      " epoch: 253, train accuracy: 0.8930, train_loss_norm:0.0148, valid_acc: 0.8715, valid_loss_norm: 0.0165\n",
      " epoch: 254, train accuracy: 0.8930, train_loss_norm:0.0148, valid_acc: 0.8718, valid_loss_norm: 0.0165\n",
      " epoch: 255, train accuracy: 0.8931, train_loss_norm:0.0148, valid_acc: 0.8718, valid_loss_norm: 0.0165\n",
      " epoch: 256, train accuracy: 0.8932, train_loss_norm:0.0148, valid_acc: 0.8718, valid_loss_norm: 0.0165\n",
      " epoch: 257, train accuracy: 0.8934, train_loss_norm:0.0147, valid_acc: 0.8718, valid_loss_norm: 0.0165\n",
      " epoch: 258, train accuracy: 0.8934, train_loss_norm:0.0147, valid_acc: 0.8718, valid_loss_norm: 0.0165\n",
      " epoch: 259, train accuracy: 0.8936, train_loss_norm:0.0147, valid_acc: 0.8718, valid_loss_norm: 0.0164\n",
      " epoch: 260, train accuracy: 0.8937, train_loss_norm:0.0147, valid_acc: 0.8721, valid_loss_norm: 0.0164\n",
      " epoch: 261, train accuracy: 0.8939, train_loss_norm:0.0147, valid_acc: 0.8721, valid_loss_norm: 0.0164\n",
      " epoch: 262, train accuracy: 0.8940, train_loss_norm:0.0146, valid_acc: 0.8718, valid_loss_norm: 0.0164\n",
      " epoch: 263, train accuracy: 0.8942, train_loss_norm:0.0146, valid_acc: 0.8718, valid_loss_norm: 0.0164\n",
      " epoch: 264, train accuracy: 0.8943, train_loss_norm:0.0146, valid_acc: 0.8715, valid_loss_norm: 0.0163\n",
      " epoch: 265, train accuracy: 0.8946, train_loss_norm:0.0146, valid_acc: 0.8715, valid_loss_norm: 0.0163\n",
      " epoch: 266, train accuracy: 0.8947, train_loss_norm:0.0145, valid_acc: 0.8718, valid_loss_norm: 0.0163\n",
      " epoch: 267, train accuracy: 0.8947, train_loss_norm:0.0145, valid_acc: 0.8718, valid_loss_norm: 0.0163\n",
      " epoch: 268, train accuracy: 0.8949, train_loss_norm:0.0145, valid_acc: 0.8718, valid_loss_norm: 0.0163\n",
      " epoch: 269, train accuracy: 0.8950, train_loss_norm:0.0145, valid_acc: 0.8718, valid_loss_norm: 0.0162\n",
      " epoch: 270, train accuracy: 0.8950, train_loss_norm:0.0145, valid_acc: 0.8718, valid_loss_norm: 0.0162\n",
      " epoch: 271, train accuracy: 0.8952, train_loss_norm:0.0144, valid_acc: 0.8718, valid_loss_norm: 0.0162\n",
      " epoch: 272, train accuracy: 0.8954, train_loss_norm:0.0144, valid_acc: 0.8718, valid_loss_norm: 0.0162\n",
      " epoch: 273, train accuracy: 0.8957, train_loss_norm:0.0144, valid_acc: 0.8718, valid_loss_norm: 0.0162\n",
      " epoch: 274, train accuracy: 0.8957, train_loss_norm:0.0144, valid_acc: 0.8721, valid_loss_norm: 0.0162\n",
      " epoch: 275, train accuracy: 0.8957, train_loss_norm:0.0144, valid_acc: 0.8724, valid_loss_norm: 0.0161\n",
      " epoch: 276, train accuracy: 0.8957, train_loss_norm:0.0143, valid_acc: 0.8727, valid_loss_norm: 0.0161\n",
      " epoch: 277, train accuracy: 0.8958, train_loss_norm:0.0143, valid_acc: 0.8727, valid_loss_norm: 0.0161\n",
      " epoch: 278, train accuracy: 0.8958, train_loss_norm:0.0143, valid_acc: 0.8727, valid_loss_norm: 0.0161\n",
      " epoch: 279, train accuracy: 0.8959, train_loss_norm:0.0143, valid_acc: 0.8727, valid_loss_norm: 0.0161\n",
      " epoch: 280, train accuracy: 0.8959, train_loss_norm:0.0142, valid_acc: 0.8724, valid_loss_norm: 0.0161\n",
      " epoch: 281, train accuracy: 0.8961, train_loss_norm:0.0142, valid_acc: 0.8724, valid_loss_norm: 0.0160\n",
      " epoch: 282, train accuracy: 0.8961, train_loss_norm:0.0142, valid_acc: 0.8721, valid_loss_norm: 0.0160\n",
      " epoch: 283, train accuracy: 0.8964, train_loss_norm:0.0142, valid_acc: 0.8721, valid_loss_norm: 0.0160\n",
      " epoch: 284, train accuracy: 0.8966, train_loss_norm:0.0142, valid_acc: 0.8721, valid_loss_norm: 0.0160\n",
      " epoch: 285, train accuracy: 0.8967, train_loss_norm:0.0141, valid_acc: 0.8724, valid_loss_norm: 0.0160\n",
      " epoch: 286, train accuracy: 0.8968, train_loss_norm:0.0141, valid_acc: 0.8727, valid_loss_norm: 0.0160\n",
      " epoch: 287, train accuracy: 0.8970, train_loss_norm:0.0141, valid_acc: 0.8727, valid_loss_norm: 0.0159\n",
      " epoch: 288, train accuracy: 0.8970, train_loss_norm:0.0141, valid_acc: 0.8727, valid_loss_norm: 0.0159\n",
      " epoch: 289, train accuracy: 0.8972, train_loss_norm:0.0141, valid_acc: 0.8727, valid_loss_norm: 0.0159\n",
      " epoch: 290, train accuracy: 0.8973, train_loss_norm:0.0141, valid_acc: 0.8732, valid_loss_norm: 0.0159\n",
      " epoch: 291, train accuracy: 0.8975, train_loss_norm:0.0140, valid_acc: 0.8732, valid_loss_norm: 0.0159\n",
      " epoch: 292, train accuracy: 0.8975, train_loss_norm:0.0140, valid_acc: 0.8732, valid_loss_norm: 0.0159\n",
      " epoch: 293, train accuracy: 0.8977, train_loss_norm:0.0140, valid_acc: 0.8732, valid_loss_norm: 0.0159\n",
      " epoch: 294, train accuracy: 0.8978, train_loss_norm:0.0140, valid_acc: 0.8732, valid_loss_norm: 0.0158\n",
      " epoch: 295, train accuracy: 0.8979, train_loss_norm:0.0140, valid_acc: 0.8732, valid_loss_norm: 0.0158\n",
      " epoch: 296, train accuracy: 0.8981, train_loss_norm:0.0139, valid_acc: 0.8732, valid_loss_norm: 0.0158\n",
      " epoch: 297, train accuracy: 0.8982, train_loss_norm:0.0139, valid_acc: 0.8732, valid_loss_norm: 0.0158\n",
      " epoch: 298, train accuracy: 0.8984, train_loss_norm:0.0139, valid_acc: 0.8735, valid_loss_norm: 0.0158\n",
      " epoch: 299, train accuracy: 0.8985, train_loss_norm:0.0139, valid_acc: 0.8738, valid_loss_norm: 0.0158\n",
      " epoch: 300, train accuracy: 0.8987, train_loss_norm:0.0139, valid_acc: 0.8738, valid_loss_norm: 0.0157\n",
      "Test accuracy: 0.8643\n",
      "Test loss norm: 0.0164\n",
      "Cur fold: 4\n",
      "(27841, 300)\n",
      "(3479, 300)\n",
      "(3479, 300)\n",
      " epoch: 1, train accuracy: 0.7906, train_loss_norm:0.0836, valid_acc: 0.7792, valid_loss_norm: 0.0837\n",
      " epoch: 2, train accuracy: 0.7907, train_loss_norm:0.0799, valid_acc: 0.7795, valid_loss_norm: 0.0801\n",
      " epoch: 3, train accuracy: 0.7909, train_loss_norm:0.0763, valid_acc: 0.7792, valid_loss_norm: 0.0766\n",
      " epoch: 4, train accuracy: 0.7911, train_loss_norm:0.0729, valid_acc: 0.7801, valid_loss_norm: 0.0733\n",
      " epoch: 5, train accuracy: 0.7920, train_loss_norm:0.0697, valid_acc: 0.7807, valid_loss_norm: 0.0701\n",
      " epoch: 6, train accuracy: 0.7932, train_loss_norm:0.0667, valid_acc: 0.7813, valid_loss_norm: 0.0672\n",
      " epoch: 7, train accuracy: 0.7943, train_loss_norm:0.0640, valid_acc: 0.7824, valid_loss_norm: 0.0646\n",
      " epoch: 8, train accuracy: 0.7957, train_loss_norm:0.0614, valid_acc: 0.7844, valid_loss_norm: 0.0621\n",
      " epoch: 9, train accuracy: 0.7974, train_loss_norm:0.0592, valid_acc: 0.7841, valid_loss_norm: 0.0599\n",
      " epoch: 10, train accuracy: 0.7988, train_loss_norm:0.0571, valid_acc: 0.7853, valid_loss_norm: 0.0579\n",
      " epoch: 11, train accuracy: 0.8004, train_loss_norm:0.0552, valid_acc: 0.7876, valid_loss_norm: 0.0560\n",
      " epoch: 12, train accuracy: 0.8022, train_loss_norm:0.0535, valid_acc: 0.7893, valid_loss_norm: 0.0544\n",
      " epoch: 13, train accuracy: 0.8037, train_loss_norm:0.0519, valid_acc: 0.7913, valid_loss_norm: 0.0528\n",
      " epoch: 14, train accuracy: 0.8054, train_loss_norm:0.0505, valid_acc: 0.7928, valid_loss_norm: 0.0514\n",
      " epoch: 15, train accuracy: 0.8071, train_loss_norm:0.0491, valid_acc: 0.7939, valid_loss_norm: 0.0501\n",
      " epoch: 16, train accuracy: 0.8083, train_loss_norm:0.0479, valid_acc: 0.7953, valid_loss_norm: 0.0489\n",
      " epoch: 17, train accuracy: 0.8095, train_loss_norm:0.0468, valid_acc: 0.7985, valid_loss_norm: 0.0478\n",
      " epoch: 18, train accuracy: 0.8111, train_loss_norm:0.0457, valid_acc: 0.7997, valid_loss_norm: 0.0468\n",
      " epoch: 19, train accuracy: 0.8124, train_loss_norm:0.0447, valid_acc: 0.8002, valid_loss_norm: 0.0458\n",
      " epoch: 20, train accuracy: 0.8134, train_loss_norm:0.0438, valid_acc: 0.8005, valid_loss_norm: 0.0449\n",
      " epoch: 21, train accuracy: 0.8149, train_loss_norm:0.0429, valid_acc: 0.8008, valid_loss_norm: 0.0441\n",
      " epoch: 22, train accuracy: 0.8161, train_loss_norm:0.0421, valid_acc: 0.8043, valid_loss_norm: 0.0433\n",
      " epoch: 23, train accuracy: 0.8174, train_loss_norm:0.0413, valid_acc: 0.8048, valid_loss_norm: 0.0425\n",
      " epoch: 24, train accuracy: 0.8181, train_loss_norm:0.0406, valid_acc: 0.8060, valid_loss_norm: 0.0418\n",
      " epoch: 25, train accuracy: 0.8197, train_loss_norm:0.0399, valid_acc: 0.8063, valid_loss_norm: 0.0411\n",
      " epoch: 26, train accuracy: 0.8213, train_loss_norm:0.0392, valid_acc: 0.8074, valid_loss_norm: 0.0405\n",
      " epoch: 27, train accuracy: 0.8226, train_loss_norm:0.0386, valid_acc: 0.8080, valid_loss_norm: 0.0399\n",
      " epoch: 28, train accuracy: 0.8234, train_loss_norm:0.0380, valid_acc: 0.8100, valid_loss_norm: 0.0393\n",
      " epoch: 29, train accuracy: 0.8242, train_loss_norm:0.0374, valid_acc: 0.8106, valid_loss_norm: 0.0387\n",
      " epoch: 30, train accuracy: 0.8253, train_loss_norm:0.0369, valid_acc: 0.8117, valid_loss_norm: 0.0382\n",
      " epoch: 31, train accuracy: 0.8260, train_loss_norm:0.0364, valid_acc: 0.8143, valid_loss_norm: 0.0377\n",
      " epoch: 32, train accuracy: 0.8270, train_loss_norm:0.0359, valid_acc: 0.8155, valid_loss_norm: 0.0372\n",
      " epoch: 33, train accuracy: 0.8277, train_loss_norm:0.0354, valid_acc: 0.8169, valid_loss_norm: 0.0368\n",
      " epoch: 34, train accuracy: 0.8286, train_loss_norm:0.0349, valid_acc: 0.8175, valid_loss_norm: 0.0363\n",
      " epoch: 35, train accuracy: 0.8298, train_loss_norm:0.0345, valid_acc: 0.8181, valid_loss_norm: 0.0359\n",
      " epoch: 36, train accuracy: 0.8309, train_loss_norm:0.0341, valid_acc: 0.8192, valid_loss_norm: 0.0355\n",
      " epoch: 37, train accuracy: 0.8313, train_loss_norm:0.0337, valid_acc: 0.8192, valid_loss_norm: 0.0351\n",
      " epoch: 38, train accuracy: 0.8322, train_loss_norm:0.0333, valid_acc: 0.8192, valid_loss_norm: 0.0347\n",
      " epoch: 39, train accuracy: 0.8333, train_loss_norm:0.0329, valid_acc: 0.8204, valid_loss_norm: 0.0343\n",
      " epoch: 40, train accuracy: 0.8341, train_loss_norm:0.0325, valid_acc: 0.8209, valid_loss_norm: 0.0340\n",
      " epoch: 41, train accuracy: 0.8346, train_loss_norm:0.0322, valid_acc: 0.8209, valid_loss_norm: 0.0336\n",
      " epoch: 42, train accuracy: 0.8353, train_loss_norm:0.0318, valid_acc: 0.8204, valid_loss_norm: 0.0333\n",
      " epoch: 43, train accuracy: 0.8360, train_loss_norm:0.0315, valid_acc: 0.8206, valid_loss_norm: 0.0330\n",
      " epoch: 44, train accuracy: 0.8369, train_loss_norm:0.0312, valid_acc: 0.8209, valid_loss_norm: 0.0327\n",
      " epoch: 45, train accuracy: 0.8375, train_loss_norm:0.0309, valid_acc: 0.8221, valid_loss_norm: 0.0324\n",
      " epoch: 46, train accuracy: 0.8379, train_loss_norm:0.0306, valid_acc: 0.8235, valid_loss_norm: 0.0321\n",
      " epoch: 47, train accuracy: 0.8389, train_loss_norm:0.0303, valid_acc: 0.8238, valid_loss_norm: 0.0318\n",
      " epoch: 48, train accuracy: 0.8392, train_loss_norm:0.0300, valid_acc: 0.8244, valid_loss_norm: 0.0315\n",
      " epoch: 49, train accuracy: 0.8398, train_loss_norm:0.0297, valid_acc: 0.8249, valid_loss_norm: 0.0313\n",
      " epoch: 50, train accuracy: 0.8405, train_loss_norm:0.0295, valid_acc: 0.8247, valid_loss_norm: 0.0310\n",
      " epoch: 51, train accuracy: 0.8412, train_loss_norm:0.0292, valid_acc: 0.8252, valid_loss_norm: 0.0308\n",
      " epoch: 52, train accuracy: 0.8416, train_loss_norm:0.0290, valid_acc: 0.8252, valid_loss_norm: 0.0305\n",
      " epoch: 53, train accuracy: 0.8421, train_loss_norm:0.0287, valid_acc: 0.8255, valid_loss_norm: 0.0303\n",
      " epoch: 54, train accuracy: 0.8426, train_loss_norm:0.0285, valid_acc: 0.8252, valid_loss_norm: 0.0301\n",
      " epoch: 55, train accuracy: 0.8434, train_loss_norm:0.0282, valid_acc: 0.8267, valid_loss_norm: 0.0298\n",
      " epoch: 56, train accuracy: 0.8441, train_loss_norm:0.0280, valid_acc: 0.8275, valid_loss_norm: 0.0296\n",
      " epoch: 57, train accuracy: 0.8443, train_loss_norm:0.0278, valid_acc: 0.8278, valid_loss_norm: 0.0294\n",
      " epoch: 58, train accuracy: 0.8444, train_loss_norm:0.0276, valid_acc: 0.8284, valid_loss_norm: 0.0292\n",
      " epoch: 59, train accuracy: 0.8447, train_loss_norm:0.0274, valid_acc: 0.8284, valid_loss_norm: 0.0290\n",
      " epoch: 60, train accuracy: 0.8452, train_loss_norm:0.0272, valid_acc: 0.8275, valid_loss_norm: 0.0288\n",
      " epoch: 61, train accuracy: 0.8456, train_loss_norm:0.0270, valid_acc: 0.8275, valid_loss_norm: 0.0286\n",
      " epoch: 62, train accuracy: 0.8462, train_loss_norm:0.0268, valid_acc: 0.8275, valid_loss_norm: 0.0284\n",
      " epoch: 63, train accuracy: 0.8467, train_loss_norm:0.0266, valid_acc: 0.8278, valid_loss_norm: 0.0282\n",
      " epoch: 64, train accuracy: 0.8472, train_loss_norm:0.0264, valid_acc: 0.8275, valid_loss_norm: 0.0281\n",
      " epoch: 65, train accuracy: 0.8475, train_loss_norm:0.0262, valid_acc: 0.8281, valid_loss_norm: 0.0279\n",
      " epoch: 66, train accuracy: 0.8479, train_loss_norm:0.0261, valid_acc: 0.8295, valid_loss_norm: 0.0277\n",
      " epoch: 67, train accuracy: 0.8482, train_loss_norm:0.0259, valid_acc: 0.8304, valid_loss_norm: 0.0276\n",
      " epoch: 68, train accuracy: 0.8486, train_loss_norm:0.0257, valid_acc: 0.8310, valid_loss_norm: 0.0274\n",
      " epoch: 69, train accuracy: 0.8490, train_loss_norm:0.0255, valid_acc: 0.8316, valid_loss_norm: 0.0272\n",
      " epoch: 70, train accuracy: 0.8494, train_loss_norm:0.0254, valid_acc: 0.8327, valid_loss_norm: 0.0271\n",
      " epoch: 71, train accuracy: 0.8498, train_loss_norm:0.0252, valid_acc: 0.8330, valid_loss_norm: 0.0269\n",
      " epoch: 72, train accuracy: 0.8502, train_loss_norm:0.0251, valid_acc: 0.8336, valid_loss_norm: 0.0268\n",
      " epoch: 73, train accuracy: 0.8506, train_loss_norm:0.0249, valid_acc: 0.8336, valid_loss_norm: 0.0266\n",
      " epoch: 74, train accuracy: 0.8511, train_loss_norm:0.0248, valid_acc: 0.8350, valid_loss_norm: 0.0265\n",
      " epoch: 75, train accuracy: 0.8515, train_loss_norm:0.0246, valid_acc: 0.8359, valid_loss_norm: 0.0263\n",
      " epoch: 76, train accuracy: 0.8521, train_loss_norm:0.0245, valid_acc: 0.8356, valid_loss_norm: 0.0262\n",
      " epoch: 77, train accuracy: 0.8525, train_loss_norm:0.0243, valid_acc: 0.8356, valid_loss_norm: 0.0261\n",
      " epoch: 78, train accuracy: 0.8528, train_loss_norm:0.0242, valid_acc: 0.8362, valid_loss_norm: 0.0259\n",
      " epoch: 79, train accuracy: 0.8534, train_loss_norm:0.0241, valid_acc: 0.8367, valid_loss_norm: 0.0258\n",
      " epoch: 80, train accuracy: 0.8537, train_loss_norm:0.0239, valid_acc: 0.8376, valid_loss_norm: 0.0257\n",
      " epoch: 81, train accuracy: 0.8539, train_loss_norm:0.0238, valid_acc: 0.8376, valid_loss_norm: 0.0256\n",
      " epoch: 82, train accuracy: 0.8545, train_loss_norm:0.0237, valid_acc: 0.8373, valid_loss_norm: 0.0254\n",
      " epoch: 83, train accuracy: 0.8548, train_loss_norm:0.0236, valid_acc: 0.8370, valid_loss_norm: 0.0253\n",
      " epoch: 84, train accuracy: 0.8550, train_loss_norm:0.0234, valid_acc: 0.8367, valid_loss_norm: 0.0252\n",
      " epoch: 85, train accuracy: 0.8555, train_loss_norm:0.0233, valid_acc: 0.8376, valid_loss_norm: 0.0251\n",
      " epoch: 86, train accuracy: 0.8557, train_loss_norm:0.0232, valid_acc: 0.8387, valid_loss_norm: 0.0250\n",
      " epoch: 87, train accuracy: 0.8561, train_loss_norm:0.0231, valid_acc: 0.8393, valid_loss_norm: 0.0249\n",
      " epoch: 88, train accuracy: 0.8563, train_loss_norm:0.0230, valid_acc: 0.8393, valid_loss_norm: 0.0248\n",
      " epoch: 89, train accuracy: 0.8568, train_loss_norm:0.0229, valid_acc: 0.8393, valid_loss_norm: 0.0246\n",
      " epoch: 90, train accuracy: 0.8569, train_loss_norm:0.0227, valid_acc: 0.8393, valid_loss_norm: 0.0245\n",
      " epoch: 91, train accuracy: 0.8575, train_loss_norm:0.0226, valid_acc: 0.8390, valid_loss_norm: 0.0244\n",
      " epoch: 92, train accuracy: 0.8577, train_loss_norm:0.0225, valid_acc: 0.8402, valid_loss_norm: 0.0243\n",
      " epoch: 93, train accuracy: 0.8581, train_loss_norm:0.0224, valid_acc: 0.8402, valid_loss_norm: 0.0242\n",
      " epoch: 94, train accuracy: 0.8584, train_loss_norm:0.0223, valid_acc: 0.8408, valid_loss_norm: 0.0241\n",
      " epoch: 95, train accuracy: 0.8590, train_loss_norm:0.0222, valid_acc: 0.8410, valid_loss_norm: 0.0240\n",
      " epoch: 96, train accuracy: 0.8592, train_loss_norm:0.0221, valid_acc: 0.8410, valid_loss_norm: 0.0239\n",
      " epoch: 97, train accuracy: 0.8596, train_loss_norm:0.0220, valid_acc: 0.8410, valid_loss_norm: 0.0238\n",
      " epoch: 98, train accuracy: 0.8601, train_loss_norm:0.0219, valid_acc: 0.8410, valid_loss_norm: 0.0238\n",
      " epoch: 99, train accuracy: 0.8603, train_loss_norm:0.0218, valid_acc: 0.8413, valid_loss_norm: 0.0237\n",
      " epoch: 100, train accuracy: 0.8607, train_loss_norm:0.0217, valid_acc: 0.8413, valid_loss_norm: 0.0236\n",
      " epoch: 101, train accuracy: 0.8610, train_loss_norm:0.0216, valid_acc: 0.8419, valid_loss_norm: 0.0235\n",
      " epoch: 102, train accuracy: 0.8614, train_loss_norm:0.0215, valid_acc: 0.8419, valid_loss_norm: 0.0234\n",
      " epoch: 103, train accuracy: 0.8618, train_loss_norm:0.0215, valid_acc: 0.8425, valid_loss_norm: 0.0233\n",
      " epoch: 104, train accuracy: 0.8621, train_loss_norm:0.0214, valid_acc: 0.8436, valid_loss_norm: 0.0232\n",
      " epoch: 105, train accuracy: 0.8625, train_loss_norm:0.0213, valid_acc: 0.8445, valid_loss_norm: 0.0231\n",
      " epoch: 106, train accuracy: 0.8627, train_loss_norm:0.0212, valid_acc: 0.8451, valid_loss_norm: 0.0231\n",
      " epoch: 107, train accuracy: 0.8629, train_loss_norm:0.0211, valid_acc: 0.8451, valid_loss_norm: 0.0230\n",
      " epoch: 108, train accuracy: 0.8632, train_loss_norm:0.0210, valid_acc: 0.8456, valid_loss_norm: 0.0229\n",
      " epoch: 109, train accuracy: 0.8634, train_loss_norm:0.0209, valid_acc: 0.8456, valid_loss_norm: 0.0228\n",
      " epoch: 110, train accuracy: 0.8637, train_loss_norm:0.0209, valid_acc: 0.8456, valid_loss_norm: 0.0228\n",
      " epoch: 111, train accuracy: 0.8642, train_loss_norm:0.0208, valid_acc: 0.8454, valid_loss_norm: 0.0227\n",
      " epoch: 112, train accuracy: 0.8645, train_loss_norm:0.0207, valid_acc: 0.8456, valid_loss_norm: 0.0226\n",
      " epoch: 113, train accuracy: 0.8647, train_loss_norm:0.0206, valid_acc: 0.8456, valid_loss_norm: 0.0225\n",
      " epoch: 114, train accuracy: 0.8652, train_loss_norm:0.0205, valid_acc: 0.8456, valid_loss_norm: 0.0225\n",
      " epoch: 115, train accuracy: 0.8655, train_loss_norm:0.0205, valid_acc: 0.8462, valid_loss_norm: 0.0224\n",
      " epoch: 116, train accuracy: 0.8658, train_loss_norm:0.0204, valid_acc: 0.8465, valid_loss_norm: 0.0223\n",
      " epoch: 117, train accuracy: 0.8660, train_loss_norm:0.0203, valid_acc: 0.8456, valid_loss_norm: 0.0222\n",
      " epoch: 118, train accuracy: 0.8662, train_loss_norm:0.0202, valid_acc: 0.8454, valid_loss_norm: 0.0222\n",
      " epoch: 119, train accuracy: 0.8667, train_loss_norm:0.0202, valid_acc: 0.8456, valid_loss_norm: 0.0221\n",
      " epoch: 120, train accuracy: 0.8673, train_loss_norm:0.0201, valid_acc: 0.8462, valid_loss_norm: 0.0220\n",
      " epoch: 121, train accuracy: 0.8675, train_loss_norm:0.0200, valid_acc: 0.8462, valid_loss_norm: 0.0220\n",
      " epoch: 122, train accuracy: 0.8677, train_loss_norm:0.0200, valid_acc: 0.8462, valid_loss_norm: 0.0219\n",
      " epoch: 123, train accuracy: 0.8680, train_loss_norm:0.0199, valid_acc: 0.8462, valid_loss_norm: 0.0218\n",
      " epoch: 124, train accuracy: 0.8683, train_loss_norm:0.0198, valid_acc: 0.8468, valid_loss_norm: 0.0218\n",
      " epoch: 125, train accuracy: 0.8685, train_loss_norm:0.0198, valid_acc: 0.8471, valid_loss_norm: 0.0217\n",
      " epoch: 126, train accuracy: 0.8688, train_loss_norm:0.0197, valid_acc: 0.8468, valid_loss_norm: 0.0217\n",
      " epoch: 127, train accuracy: 0.8691, train_loss_norm:0.0196, valid_acc: 0.8465, valid_loss_norm: 0.0216\n",
      " epoch: 128, train accuracy: 0.8694, train_loss_norm:0.0196, valid_acc: 0.8468, valid_loss_norm: 0.0215\n",
      " epoch: 129, train accuracy: 0.8695, train_loss_norm:0.0195, valid_acc: 0.8465, valid_loss_norm: 0.0215\n",
      " epoch: 130, train accuracy: 0.8698, train_loss_norm:0.0194, valid_acc: 0.8468, valid_loss_norm: 0.0214\n",
      " epoch: 131, train accuracy: 0.8700, train_loss_norm:0.0194, valid_acc: 0.8471, valid_loss_norm: 0.0214\n",
      " epoch: 132, train accuracy: 0.8703, train_loss_norm:0.0193, valid_acc: 0.8474, valid_loss_norm: 0.0213\n",
      " epoch: 133, train accuracy: 0.8706, train_loss_norm:0.0192, valid_acc: 0.8474, valid_loss_norm: 0.0212\n",
      " epoch: 134, train accuracy: 0.8709, train_loss_norm:0.0192, valid_acc: 0.8477, valid_loss_norm: 0.0212\n",
      " epoch: 135, train accuracy: 0.8712, train_loss_norm:0.0191, valid_acc: 0.8477, valid_loss_norm: 0.0211\n",
      " epoch: 136, train accuracy: 0.8716, train_loss_norm:0.0191, valid_acc: 0.8482, valid_loss_norm: 0.0211\n",
      " epoch: 137, train accuracy: 0.8719, train_loss_norm:0.0190, valid_acc: 0.8488, valid_loss_norm: 0.0210\n",
      " epoch: 138, train accuracy: 0.8721, train_loss_norm:0.0189, valid_acc: 0.8491, valid_loss_norm: 0.0210\n",
      " epoch: 139, train accuracy: 0.8724, train_loss_norm:0.0189, valid_acc: 0.8491, valid_loss_norm: 0.0209\n",
      " epoch: 140, train accuracy: 0.8725, train_loss_norm:0.0188, valid_acc: 0.8494, valid_loss_norm: 0.0209\n",
      " epoch: 141, train accuracy: 0.8727, train_loss_norm:0.0188, valid_acc: 0.8502, valid_loss_norm: 0.0208\n",
      " epoch: 142, train accuracy: 0.8726, train_loss_norm:0.0187, valid_acc: 0.8502, valid_loss_norm: 0.0208\n",
      " epoch: 143, train accuracy: 0.8728, train_loss_norm:0.0187, valid_acc: 0.8500, valid_loss_norm: 0.0207\n",
      " epoch: 144, train accuracy: 0.8731, train_loss_norm:0.0186, valid_acc: 0.8502, valid_loss_norm: 0.0207\n",
      " epoch: 145, train accuracy: 0.8732, train_loss_norm:0.0186, valid_acc: 0.8500, valid_loss_norm: 0.0206\n",
      " epoch: 146, train accuracy: 0.8734, train_loss_norm:0.0185, valid_acc: 0.8497, valid_loss_norm: 0.0206\n",
      " epoch: 147, train accuracy: 0.8738, train_loss_norm:0.0185, valid_acc: 0.8500, valid_loss_norm: 0.0205\n",
      " epoch: 148, train accuracy: 0.8741, train_loss_norm:0.0184, valid_acc: 0.8500, valid_loss_norm: 0.0205\n",
      " epoch: 149, train accuracy: 0.8745, train_loss_norm:0.0183, valid_acc: 0.8502, valid_loss_norm: 0.0204\n",
      " epoch: 150, train accuracy: 0.8746, train_loss_norm:0.0183, valid_acc: 0.8502, valid_loss_norm: 0.0204\n",
      " epoch: 151, train accuracy: 0.8749, train_loss_norm:0.0182, valid_acc: 0.8502, valid_loss_norm: 0.0203\n",
      " epoch: 152, train accuracy: 0.8751, train_loss_norm:0.0182, valid_acc: 0.8508, valid_loss_norm: 0.0203\n",
      " epoch: 153, train accuracy: 0.8753, train_loss_norm:0.0181, valid_acc: 0.8505, valid_loss_norm: 0.0202\n",
      " epoch: 154, train accuracy: 0.8755, train_loss_norm:0.0181, valid_acc: 0.8505, valid_loss_norm: 0.0202\n",
      " epoch: 155, train accuracy: 0.8758, train_loss_norm:0.0181, valid_acc: 0.8502, valid_loss_norm: 0.0202\n",
      " epoch: 156, train accuracy: 0.8760, train_loss_norm:0.0180, valid_acc: 0.8500, valid_loss_norm: 0.0201\n",
      " epoch: 157, train accuracy: 0.8762, train_loss_norm:0.0180, valid_acc: 0.8505, valid_loss_norm: 0.0201\n",
      " epoch: 158, train accuracy: 0.8764, train_loss_norm:0.0179, valid_acc: 0.8505, valid_loss_norm: 0.0200\n",
      " epoch: 159, train accuracy: 0.8766, train_loss_norm:0.0179, valid_acc: 0.8508, valid_loss_norm: 0.0200\n",
      " epoch: 160, train accuracy: 0.8769, train_loss_norm:0.0178, valid_acc: 0.8508, valid_loss_norm: 0.0199\n",
      " epoch: 161, train accuracy: 0.8772, train_loss_norm:0.0178, valid_acc: 0.8502, valid_loss_norm: 0.0199\n",
      " epoch: 162, train accuracy: 0.8777, train_loss_norm:0.0177, valid_acc: 0.8505, valid_loss_norm: 0.0199\n",
      " epoch: 163, train accuracy: 0.8778, train_loss_norm:0.0177, valid_acc: 0.8508, valid_loss_norm: 0.0198\n",
      " epoch: 164, train accuracy: 0.8780, train_loss_norm:0.0176, valid_acc: 0.8514, valid_loss_norm: 0.0198\n",
      " epoch: 165, train accuracy: 0.8785, train_loss_norm:0.0176, valid_acc: 0.8511, valid_loss_norm: 0.0197\n",
      " epoch: 166, train accuracy: 0.8787, train_loss_norm:0.0175, valid_acc: 0.8514, valid_loss_norm: 0.0197\n",
      " epoch: 167, train accuracy: 0.8790, train_loss_norm:0.0175, valid_acc: 0.8514, valid_loss_norm: 0.0197\n",
      " epoch: 168, train accuracy: 0.8792, train_loss_norm:0.0175, valid_acc: 0.8514, valid_loss_norm: 0.0196\n",
      " epoch: 169, train accuracy: 0.8795, train_loss_norm:0.0174, valid_acc: 0.8514, valid_loss_norm: 0.0196\n",
      " epoch: 170, train accuracy: 0.8796, train_loss_norm:0.0174, valid_acc: 0.8514, valid_loss_norm: 0.0195\n",
      " epoch: 171, train accuracy: 0.8798, train_loss_norm:0.0173, valid_acc: 0.8514, valid_loss_norm: 0.0195\n",
      " epoch: 172, train accuracy: 0.8800, train_loss_norm:0.0173, valid_acc: 0.8517, valid_loss_norm: 0.0195\n",
      " epoch: 173, train accuracy: 0.8802, train_loss_norm:0.0172, valid_acc: 0.8514, valid_loss_norm: 0.0194\n",
      " epoch: 174, train accuracy: 0.8805, train_loss_norm:0.0172, valid_acc: 0.8523, valid_loss_norm: 0.0194\n",
      " epoch: 175, train accuracy: 0.8806, train_loss_norm:0.0172, valid_acc: 0.8525, valid_loss_norm: 0.0194\n",
      " epoch: 176, train accuracy: 0.8809, train_loss_norm:0.0171, valid_acc: 0.8525, valid_loss_norm: 0.0193\n",
      " epoch: 177, train accuracy: 0.8810, train_loss_norm:0.0171, valid_acc: 0.8520, valid_loss_norm: 0.0193\n",
      " epoch: 178, train accuracy: 0.8812, train_loss_norm:0.0170, valid_acc: 0.8523, valid_loss_norm: 0.0192\n",
      " epoch: 179, train accuracy: 0.8815, train_loss_norm:0.0170, valid_acc: 0.8525, valid_loss_norm: 0.0192\n",
      " epoch: 180, train accuracy: 0.8817, train_loss_norm:0.0170, valid_acc: 0.8528, valid_loss_norm: 0.0192\n",
      " epoch: 181, train accuracy: 0.8820, train_loss_norm:0.0169, valid_acc: 0.8528, valid_loss_norm: 0.0191\n",
      " epoch: 182, train accuracy: 0.8823, train_loss_norm:0.0169, valid_acc: 0.8531, valid_loss_norm: 0.0191\n",
      " epoch: 183, train accuracy: 0.8823, train_loss_norm:0.0169, valid_acc: 0.8531, valid_loss_norm: 0.0191\n",
      " epoch: 184, train accuracy: 0.8825, train_loss_norm:0.0168, valid_acc: 0.8528, valid_loss_norm: 0.0190\n",
      " epoch: 185, train accuracy: 0.8827, train_loss_norm:0.0168, valid_acc: 0.8528, valid_loss_norm: 0.0190\n",
      " epoch: 186, train accuracy: 0.8829, train_loss_norm:0.0167, valid_acc: 0.8531, valid_loss_norm: 0.0190\n",
      " epoch: 187, train accuracy: 0.8831, train_loss_norm:0.0167, valid_acc: 0.8528, valid_loss_norm: 0.0189\n",
      " epoch: 188, train accuracy: 0.8833, train_loss_norm:0.0167, valid_acc: 0.8528, valid_loss_norm: 0.0189\n",
      " epoch: 189, train accuracy: 0.8834, train_loss_norm:0.0166, valid_acc: 0.8528, valid_loss_norm: 0.0189\n",
      " epoch: 190, train accuracy: 0.8838, train_loss_norm:0.0166, valid_acc: 0.8531, valid_loss_norm: 0.0188\n",
      " epoch: 191, train accuracy: 0.8839, train_loss_norm:0.0166, valid_acc: 0.8531, valid_loss_norm: 0.0188\n",
      " epoch: 192, train accuracy: 0.8841, train_loss_norm:0.0165, valid_acc: 0.8531, valid_loss_norm: 0.0188\n",
      " epoch: 193, train accuracy: 0.8843, train_loss_norm:0.0165, valid_acc: 0.8534, valid_loss_norm: 0.0187\n",
      " epoch: 194, train accuracy: 0.8844, train_loss_norm:0.0165, valid_acc: 0.8534, valid_loss_norm: 0.0187\n",
      " epoch: 195, train accuracy: 0.8845, train_loss_norm:0.0164, valid_acc: 0.8540, valid_loss_norm: 0.0187\n",
      " epoch: 196, train accuracy: 0.8846, train_loss_norm:0.0164, valid_acc: 0.8543, valid_loss_norm: 0.0187\n",
      " epoch: 197, train accuracy: 0.8848, train_loss_norm:0.0164, valid_acc: 0.8546, valid_loss_norm: 0.0186\n",
      " epoch: 198, train accuracy: 0.8851, train_loss_norm:0.0163, valid_acc: 0.8548, valid_loss_norm: 0.0186\n",
      " epoch: 199, train accuracy: 0.8853, train_loss_norm:0.0163, valid_acc: 0.8548, valid_loss_norm: 0.0186\n",
      " epoch: 200, train accuracy: 0.8855, train_loss_norm:0.0163, valid_acc: 0.8551, valid_loss_norm: 0.0185\n",
      " epoch: 201, train accuracy: 0.8856, train_loss_norm:0.0162, valid_acc: 0.8551, valid_loss_norm: 0.0185\n",
      " epoch: 202, train accuracy: 0.8858, train_loss_norm:0.0162, valid_acc: 0.8551, valid_loss_norm: 0.0185\n",
      " epoch: 203, train accuracy: 0.8859, train_loss_norm:0.0162, valid_acc: 0.8548, valid_loss_norm: 0.0185\n",
      " epoch: 204, train accuracy: 0.8860, train_loss_norm:0.0161, valid_acc: 0.8548, valid_loss_norm: 0.0184\n",
      " epoch: 205, train accuracy: 0.8861, train_loss_norm:0.0161, valid_acc: 0.8548, valid_loss_norm: 0.0184\n",
      " epoch: 206, train accuracy: 0.8861, train_loss_norm:0.0161, valid_acc: 0.8548, valid_loss_norm: 0.0184\n",
      " epoch: 207, train accuracy: 0.8863, train_loss_norm:0.0160, valid_acc: 0.8548, valid_loss_norm: 0.0183\n",
      " epoch: 208, train accuracy: 0.8864, train_loss_norm:0.0160, valid_acc: 0.8548, valid_loss_norm: 0.0183\n",
      " epoch: 209, train accuracy: 0.8866, train_loss_norm:0.0160, valid_acc: 0.8548, valid_loss_norm: 0.0183\n",
      " epoch: 210, train accuracy: 0.8867, train_loss_norm:0.0159, valid_acc: 0.8548, valid_loss_norm: 0.0183\n",
      " epoch: 211, train accuracy: 0.8869, train_loss_norm:0.0159, valid_acc: 0.8548, valid_loss_norm: 0.0182\n",
      " epoch: 212, train accuracy: 0.8871, train_loss_norm:0.0159, valid_acc: 0.8551, valid_loss_norm: 0.0182\n",
      " epoch: 213, train accuracy: 0.8872, train_loss_norm:0.0158, valid_acc: 0.8554, valid_loss_norm: 0.0182\n",
      " epoch: 214, train accuracy: 0.8874, train_loss_norm:0.0158, valid_acc: 0.8554, valid_loss_norm: 0.0182\n",
      " epoch: 215, train accuracy: 0.8874, train_loss_norm:0.0158, valid_acc: 0.8557, valid_loss_norm: 0.0181\n",
      " epoch: 216, train accuracy: 0.8876, train_loss_norm:0.0158, valid_acc: 0.8557, valid_loss_norm: 0.0181\n",
      " epoch: 217, train accuracy: 0.8878, train_loss_norm:0.0157, valid_acc: 0.8557, valid_loss_norm: 0.0181\n",
      " epoch: 218, train accuracy: 0.8880, train_loss_norm:0.0157, valid_acc: 0.8557, valid_loss_norm: 0.0180\n",
      " epoch: 219, train accuracy: 0.8882, train_loss_norm:0.0157, valid_acc: 0.8557, valid_loss_norm: 0.0180\n",
      " epoch: 220, train accuracy: 0.8883, train_loss_norm:0.0156, valid_acc: 0.8557, valid_loss_norm: 0.0180\n",
      " epoch: 221, train accuracy: 0.8885, train_loss_norm:0.0156, valid_acc: 0.8557, valid_loss_norm: 0.0180\n",
      " epoch: 222, train accuracy: 0.8885, train_loss_norm:0.0156, valid_acc: 0.8560, valid_loss_norm: 0.0179\n",
      " epoch: 223, train accuracy: 0.8886, train_loss_norm:0.0156, valid_acc: 0.8557, valid_loss_norm: 0.0179\n",
      " epoch: 224, train accuracy: 0.8888, train_loss_norm:0.0155, valid_acc: 0.8557, valid_loss_norm: 0.0179\n",
      " epoch: 225, train accuracy: 0.8889, train_loss_norm:0.0155, valid_acc: 0.8560, valid_loss_norm: 0.0179\n",
      " epoch: 226, train accuracy: 0.8890, train_loss_norm:0.0155, valid_acc: 0.8557, valid_loss_norm: 0.0179\n",
      " epoch: 227, train accuracy: 0.8893, train_loss_norm:0.0154, valid_acc: 0.8557, valid_loss_norm: 0.0178\n",
      " epoch: 228, train accuracy: 0.8893, train_loss_norm:0.0154, valid_acc: 0.8557, valid_loss_norm: 0.0178\n",
      " epoch: 229, train accuracy: 0.8896, train_loss_norm:0.0154, valid_acc: 0.8557, valid_loss_norm: 0.0178\n",
      " epoch: 230, train accuracy: 0.8897, train_loss_norm:0.0154, valid_acc: 0.8560, valid_loss_norm: 0.0178\n",
      " epoch: 231, train accuracy: 0.8898, train_loss_norm:0.0153, valid_acc: 0.8560, valid_loss_norm: 0.0177\n",
      " epoch: 232, train accuracy: 0.8901, train_loss_norm:0.0153, valid_acc: 0.8560, valid_loss_norm: 0.0177\n",
      " epoch: 233, train accuracy: 0.8903, train_loss_norm:0.0153, valid_acc: 0.8560, valid_loss_norm: 0.0177\n",
      " epoch: 234, train accuracy: 0.8905, train_loss_norm:0.0153, valid_acc: 0.8560, valid_loss_norm: 0.0177\n",
      " epoch: 235, train accuracy: 0.8906, train_loss_norm:0.0152, valid_acc: 0.8560, valid_loss_norm: 0.0176\n",
      " epoch: 236, train accuracy: 0.8906, train_loss_norm:0.0152, valid_acc: 0.8560, valid_loss_norm: 0.0176\n",
      " epoch: 237, train accuracy: 0.8907, train_loss_norm:0.0152, valid_acc: 0.8560, valid_loss_norm: 0.0176\n",
      " epoch: 238, train accuracy: 0.8911, train_loss_norm:0.0152, valid_acc: 0.8560, valid_loss_norm: 0.0176\n",
      " epoch: 239, train accuracy: 0.8912, train_loss_norm:0.0151, valid_acc: 0.8560, valid_loss_norm: 0.0176\n",
      " epoch: 240, train accuracy: 0.8913, train_loss_norm:0.0151, valid_acc: 0.8563, valid_loss_norm: 0.0175\n",
      " epoch: 241, train accuracy: 0.8915, train_loss_norm:0.0151, valid_acc: 0.8569, valid_loss_norm: 0.0175\n",
      " epoch: 242, train accuracy: 0.8916, train_loss_norm:0.0151, valid_acc: 0.8569, valid_loss_norm: 0.0175\n",
      " epoch: 243, train accuracy: 0.8919, train_loss_norm:0.0150, valid_acc: 0.8571, valid_loss_norm: 0.0175\n",
      " epoch: 244, train accuracy: 0.8920, train_loss_norm:0.0150, valid_acc: 0.8574, valid_loss_norm: 0.0174\n",
      " epoch: 245, train accuracy: 0.8921, train_loss_norm:0.0150, valid_acc: 0.8574, valid_loss_norm: 0.0174\n",
      " epoch: 246, train accuracy: 0.8921, train_loss_norm:0.0150, valid_acc: 0.8577, valid_loss_norm: 0.0174\n",
      " epoch: 247, train accuracy: 0.8922, train_loss_norm:0.0149, valid_acc: 0.8580, valid_loss_norm: 0.0174\n",
      " epoch: 248, train accuracy: 0.8924, train_loss_norm:0.0149, valid_acc: 0.8586, valid_loss_norm: 0.0174\n",
      " epoch: 249, train accuracy: 0.8925, train_loss_norm:0.0149, valid_acc: 0.8583, valid_loss_norm: 0.0173\n",
      " epoch: 250, train accuracy: 0.8926, train_loss_norm:0.0149, valid_acc: 0.8583, valid_loss_norm: 0.0173\n",
      " epoch: 251, train accuracy: 0.8927, train_loss_norm:0.0148, valid_acc: 0.8583, valid_loss_norm: 0.0173\n",
      " epoch: 252, train accuracy: 0.8930, train_loss_norm:0.0148, valid_acc: 0.8583, valid_loss_norm: 0.0173\n",
      " epoch: 253, train accuracy: 0.8930, train_loss_norm:0.0148, valid_acc: 0.8583, valid_loss_norm: 0.0173\n",
      " epoch: 254, train accuracy: 0.8931, train_loss_norm:0.0148, valid_acc: 0.8583, valid_loss_norm: 0.0172\n",
      " epoch: 255, train accuracy: 0.8932, train_loss_norm:0.0147, valid_acc: 0.8586, valid_loss_norm: 0.0172\n",
      " epoch: 256, train accuracy: 0.8932, train_loss_norm:0.0147, valid_acc: 0.8592, valid_loss_norm: 0.0172\n",
      " epoch: 257, train accuracy: 0.8935, train_loss_norm:0.0147, valid_acc: 0.8592, valid_loss_norm: 0.0172\n",
      " epoch: 258, train accuracy: 0.8938, train_loss_norm:0.0147, valid_acc: 0.8592, valid_loss_norm: 0.0172\n",
      " epoch: 259, train accuracy: 0.8938, train_loss_norm:0.0146, valid_acc: 0.8592, valid_loss_norm: 0.0171\n",
      " epoch: 260, train accuracy: 0.8939, train_loss_norm:0.0146, valid_acc: 0.8589, valid_loss_norm: 0.0171\n",
      " epoch: 261, train accuracy: 0.8940, train_loss_norm:0.0146, valid_acc: 0.8592, valid_loss_norm: 0.0171\n",
      " epoch: 262, train accuracy: 0.8940, train_loss_norm:0.0146, valid_acc: 0.8594, valid_loss_norm: 0.0171\n",
      " epoch: 263, train accuracy: 0.8941, train_loss_norm:0.0146, valid_acc: 0.8597, valid_loss_norm: 0.0171\n",
      " epoch: 264, train accuracy: 0.8942, train_loss_norm:0.0145, valid_acc: 0.8597, valid_loss_norm: 0.0171\n",
      " epoch: 265, train accuracy: 0.8944, train_loss_norm:0.0145, valid_acc: 0.8597, valid_loss_norm: 0.0170\n",
      " epoch: 266, train accuracy: 0.8947, train_loss_norm:0.0145, valid_acc: 0.8597, valid_loss_norm: 0.0170\n",
      " epoch: 267, train accuracy: 0.8949, train_loss_norm:0.0145, valid_acc: 0.8600, valid_loss_norm: 0.0170\n",
      " epoch: 268, train accuracy: 0.8949, train_loss_norm:0.0145, valid_acc: 0.8606, valid_loss_norm: 0.0170\n",
      " epoch: 269, train accuracy: 0.8950, train_loss_norm:0.0144, valid_acc: 0.8606, valid_loss_norm: 0.0170\n",
      " epoch: 270, train accuracy: 0.8951, train_loss_norm:0.0144, valid_acc: 0.8609, valid_loss_norm: 0.0169\n",
      " epoch: 271, train accuracy: 0.8952, train_loss_norm:0.0144, valid_acc: 0.8609, valid_loss_norm: 0.0169\n",
      " epoch: 272, train accuracy: 0.8953, train_loss_norm:0.0144, valid_acc: 0.8612, valid_loss_norm: 0.0169\n",
      " epoch: 273, train accuracy: 0.8954, train_loss_norm:0.0143, valid_acc: 0.8612, valid_loss_norm: 0.0169\n",
      " epoch: 274, train accuracy: 0.8955, train_loss_norm:0.0143, valid_acc: 0.8612, valid_loss_norm: 0.0169\n",
      " epoch: 275, train accuracy: 0.8957, train_loss_norm:0.0143, valid_acc: 0.8612, valid_loss_norm: 0.0169\n",
      " epoch: 276, train accuracy: 0.8959, train_loss_norm:0.0143, valid_acc: 0.8612, valid_loss_norm: 0.0168\n",
      " epoch: 277, train accuracy: 0.8960, train_loss_norm:0.0143, valid_acc: 0.8615, valid_loss_norm: 0.0168\n",
      " epoch: 278, train accuracy: 0.8961, train_loss_norm:0.0142, valid_acc: 0.8615, valid_loss_norm: 0.0168\n",
      " epoch: 279, train accuracy: 0.8962, train_loss_norm:0.0142, valid_acc: 0.8615, valid_loss_norm: 0.0168\n",
      " epoch: 280, train accuracy: 0.8965, train_loss_norm:0.0142, valid_acc: 0.8615, valid_loss_norm: 0.0168\n",
      " epoch: 281, train accuracy: 0.8968, train_loss_norm:0.0142, valid_acc: 0.8617, valid_loss_norm: 0.0168\n",
      " epoch: 282, train accuracy: 0.8969, train_loss_norm:0.0142, valid_acc: 0.8617, valid_loss_norm: 0.0167\n",
      " epoch: 283, train accuracy: 0.8970, train_loss_norm:0.0141, valid_acc: 0.8617, valid_loss_norm: 0.0167\n",
      " epoch: 284, train accuracy: 0.8971, train_loss_norm:0.0141, valid_acc: 0.8620, valid_loss_norm: 0.0167\n",
      " epoch: 285, train accuracy: 0.8972, train_loss_norm:0.0141, valid_acc: 0.8620, valid_loss_norm: 0.0167\n",
      " epoch: 286, train accuracy: 0.8972, train_loss_norm:0.0141, valid_acc: 0.8620, valid_loss_norm: 0.0167\n",
      " epoch: 287, train accuracy: 0.8975, train_loss_norm:0.0141, valid_acc: 0.8623, valid_loss_norm: 0.0167\n",
      " epoch: 288, train accuracy: 0.8975, train_loss_norm:0.0140, valid_acc: 0.8623, valid_loss_norm: 0.0166\n",
      " epoch: 289, train accuracy: 0.8976, train_loss_norm:0.0140, valid_acc: 0.8629, valid_loss_norm: 0.0166\n",
      " epoch: 290, train accuracy: 0.8978, train_loss_norm:0.0140, valid_acc: 0.8629, valid_loss_norm: 0.0166\n",
      " epoch: 291, train accuracy: 0.8980, train_loss_norm:0.0140, valid_acc: 0.8629, valid_loss_norm: 0.0166\n",
      " epoch: 292, train accuracy: 0.8980, train_loss_norm:0.0140, valid_acc: 0.8629, valid_loss_norm: 0.0166\n",
      " epoch: 293, train accuracy: 0.8981, train_loss_norm:0.0139, valid_acc: 0.8626, valid_loss_norm: 0.0166\n",
      " epoch: 294, train accuracy: 0.8981, train_loss_norm:0.0139, valid_acc: 0.8626, valid_loss_norm: 0.0165\n",
      " epoch: 295, train accuracy: 0.8982, train_loss_norm:0.0139, valid_acc: 0.8626, valid_loss_norm: 0.0165\n",
      " epoch: 296, train accuracy: 0.8983, train_loss_norm:0.0139, valid_acc: 0.8626, valid_loss_norm: 0.0165\n",
      " epoch: 297, train accuracy: 0.8983, train_loss_norm:0.0139, valid_acc: 0.8626, valid_loss_norm: 0.0165\n",
      " epoch: 298, train accuracy: 0.8985, train_loss_norm:0.0139, valid_acc: 0.8626, valid_loss_norm: 0.0165\n",
      " epoch: 299, train accuracy: 0.8988, train_loss_norm:0.0138, valid_acc: 0.8626, valid_loss_norm: 0.0165\n",
      " epoch: 300, train accuracy: 0.8989, train_loss_norm:0.0138, valid_acc: 0.8626, valid_loss_norm: 0.0164\n",
      "Test accuracy: 0.8615\n",
      "Test loss norm: 0.0168\n",
      "Cur fold: 5\n",
      "(27841, 300)\n",
      "(3479, 300)\n",
      "(3479, 300)\n",
      " epoch: 1, train accuracy: 0.7936, train_loss_norm:0.0836, valid_acc: 0.7634, valid_loss_norm: 0.0839\n",
      " epoch: 2, train accuracy: 0.7940, train_loss_norm:0.0799, valid_acc: 0.7634, valid_loss_norm: 0.0804\n",
      " epoch: 3, train accuracy: 0.7943, train_loss_norm:0.0763, valid_acc: 0.7637, valid_loss_norm: 0.0770\n",
      " epoch: 4, train accuracy: 0.7946, train_loss_norm:0.0729, valid_acc: 0.7646, valid_loss_norm: 0.0738\n",
      " epoch: 5, train accuracy: 0.7953, train_loss_norm:0.0697, valid_acc: 0.7657, valid_loss_norm: 0.0708\n",
      " epoch: 6, train accuracy: 0.7960, train_loss_norm:0.0667, valid_acc: 0.7669, valid_loss_norm: 0.0679\n",
      " epoch: 7, train accuracy: 0.7969, train_loss_norm:0.0639, valid_acc: 0.7686, valid_loss_norm: 0.0653\n",
      " epoch: 8, train accuracy: 0.7985, train_loss_norm:0.0614, valid_acc: 0.7698, valid_loss_norm: 0.0629\n",
      " epoch: 9, train accuracy: 0.7997, train_loss_norm:0.0591, valid_acc: 0.7715, valid_loss_norm: 0.0608\n",
      " epoch: 10, train accuracy: 0.8011, train_loss_norm:0.0571, valid_acc: 0.7729, valid_loss_norm: 0.0588\n",
      " epoch: 11, train accuracy: 0.8026, train_loss_norm:0.0552, valid_acc: 0.7755, valid_loss_norm: 0.0570\n",
      " epoch: 12, train accuracy: 0.8043, train_loss_norm:0.0534, valid_acc: 0.7772, valid_loss_norm: 0.0553\n",
      " epoch: 13, train accuracy: 0.8061, train_loss_norm:0.0519, valid_acc: 0.7778, valid_loss_norm: 0.0538\n",
      " epoch: 14, train accuracy: 0.8077, train_loss_norm:0.0504, valid_acc: 0.7795, valid_loss_norm: 0.0524\n",
      " epoch: 15, train accuracy: 0.8092, train_loss_norm:0.0491, valid_acc: 0.7815, valid_loss_norm: 0.0511\n",
      " epoch: 16, train accuracy: 0.8106, train_loss_norm:0.0479, valid_acc: 0.7824, valid_loss_norm: 0.0499\n",
      " epoch: 17, train accuracy: 0.8116, train_loss_norm:0.0467, valid_acc: 0.7850, valid_loss_norm: 0.0488\n",
      " epoch: 18, train accuracy: 0.8134, train_loss_norm:0.0456, valid_acc: 0.7870, valid_loss_norm: 0.0477\n",
      " epoch: 19, train accuracy: 0.8144, train_loss_norm:0.0446, valid_acc: 0.7876, valid_loss_norm: 0.0467\n",
      " epoch: 20, train accuracy: 0.8161, train_loss_norm:0.0437, valid_acc: 0.7899, valid_loss_norm: 0.0458\n",
      " epoch: 21, train accuracy: 0.8174, train_loss_norm:0.0428, valid_acc: 0.7910, valid_loss_norm: 0.0450\n",
      " epoch: 22, train accuracy: 0.8188, train_loss_norm:0.0420, valid_acc: 0.7907, valid_loss_norm: 0.0441\n",
      " epoch: 23, train accuracy: 0.8199, train_loss_norm:0.0412, valid_acc: 0.7922, valid_loss_norm: 0.0434\n",
      " epoch: 24, train accuracy: 0.8214, train_loss_norm:0.0405, valid_acc: 0.7930, valid_loss_norm: 0.0427\n",
      " epoch: 25, train accuracy: 0.8224, train_loss_norm:0.0398, valid_acc: 0.7945, valid_loss_norm: 0.0420\n",
      " epoch: 26, train accuracy: 0.8236, train_loss_norm:0.0391, valid_acc: 0.7951, valid_loss_norm: 0.0413\n",
      " epoch: 27, train accuracy: 0.8244, train_loss_norm:0.0385, valid_acc: 0.7959, valid_loss_norm: 0.0407\n",
      " epoch: 28, train accuracy: 0.8249, train_loss_norm:0.0379, valid_acc: 0.7968, valid_loss_norm: 0.0401\n",
      " epoch: 29, train accuracy: 0.8254, train_loss_norm:0.0374, valid_acc: 0.7971, valid_loss_norm: 0.0395\n",
      " epoch: 30, train accuracy: 0.8266, train_loss_norm:0.0368, valid_acc: 0.7976, valid_loss_norm: 0.0390\n",
      " epoch: 31, train accuracy: 0.8278, train_loss_norm:0.0363, valid_acc: 0.8002, valid_loss_norm: 0.0385\n",
      " epoch: 32, train accuracy: 0.8285, train_loss_norm:0.0358, valid_acc: 0.8028, valid_loss_norm: 0.0380\n",
      " epoch: 33, train accuracy: 0.8293, train_loss_norm:0.0353, valid_acc: 0.8034, valid_loss_norm: 0.0375\n",
      " epoch: 34, train accuracy: 0.8305, train_loss_norm:0.0349, valid_acc: 0.8034, valid_loss_norm: 0.0371\n",
      " epoch: 35, train accuracy: 0.8318, train_loss_norm:0.0344, valid_acc: 0.8031, valid_loss_norm: 0.0366\n",
      " epoch: 36, train accuracy: 0.8329, train_loss_norm:0.0340, valid_acc: 0.8034, valid_loss_norm: 0.0362\n",
      " epoch: 37, train accuracy: 0.8340, train_loss_norm:0.0336, valid_acc: 0.8057, valid_loss_norm: 0.0358\n",
      " epoch: 38, train accuracy: 0.8347, train_loss_norm:0.0332, valid_acc: 0.8071, valid_loss_norm: 0.0354\n",
      " epoch: 39, train accuracy: 0.8357, train_loss_norm:0.0328, valid_acc: 0.8083, valid_loss_norm: 0.0351\n",
      " epoch: 40, train accuracy: 0.8364, train_loss_norm:0.0325, valid_acc: 0.8094, valid_loss_norm: 0.0347\n",
      " epoch: 41, train accuracy: 0.8368, train_loss_norm:0.0321, valid_acc: 0.8112, valid_loss_norm: 0.0343\n",
      " epoch: 42, train accuracy: 0.8375, train_loss_norm:0.0318, valid_acc: 0.8117, valid_loss_norm: 0.0340\n",
      " epoch: 43, train accuracy: 0.8381, train_loss_norm:0.0314, valid_acc: 0.8123, valid_loss_norm: 0.0337\n",
      " epoch: 44, train accuracy: 0.8385, train_loss_norm:0.0311, valid_acc: 0.8126, valid_loss_norm: 0.0334\n",
      " epoch: 45, train accuracy: 0.8394, train_loss_norm:0.0308, valid_acc: 0.8132, valid_loss_norm: 0.0331\n",
      " epoch: 46, train accuracy: 0.8401, train_loss_norm:0.0305, valid_acc: 0.8140, valid_loss_norm: 0.0328\n",
      " epoch: 47, train accuracy: 0.8407, train_loss_norm:0.0302, valid_acc: 0.8146, valid_loss_norm: 0.0325\n",
      " epoch: 48, train accuracy: 0.8417, train_loss_norm:0.0299, valid_acc: 0.8155, valid_loss_norm: 0.0322\n",
      " epoch: 49, train accuracy: 0.8424, train_loss_norm:0.0297, valid_acc: 0.8163, valid_loss_norm: 0.0319\n",
      " epoch: 50, train accuracy: 0.8429, train_loss_norm:0.0294, valid_acc: 0.8166, valid_loss_norm: 0.0317\n",
      " epoch: 51, train accuracy: 0.8433, train_loss_norm:0.0291, valid_acc: 0.8169, valid_loss_norm: 0.0314\n",
      " epoch: 52, train accuracy: 0.8435, train_loss_norm:0.0289, valid_acc: 0.8169, valid_loss_norm: 0.0312\n",
      " epoch: 53, train accuracy: 0.8439, train_loss_norm:0.0286, valid_acc: 0.8163, valid_loss_norm: 0.0309\n",
      " epoch: 54, train accuracy: 0.8439, train_loss_norm:0.0284, valid_acc: 0.8166, valid_loss_norm: 0.0307\n",
      " epoch: 55, train accuracy: 0.8444, train_loss_norm:0.0282, valid_acc: 0.8178, valid_loss_norm: 0.0305\n",
      " epoch: 56, train accuracy: 0.8451, train_loss_norm:0.0279, valid_acc: 0.8175, valid_loss_norm: 0.0302\n",
      " epoch: 57, train accuracy: 0.8457, train_loss_norm:0.0277, valid_acc: 0.8181, valid_loss_norm: 0.0300\n",
      " epoch: 58, train accuracy: 0.8460, train_loss_norm:0.0275, valid_acc: 0.8189, valid_loss_norm: 0.0298\n",
      " epoch: 59, train accuracy: 0.8462, train_loss_norm:0.0273, valid_acc: 0.8195, valid_loss_norm: 0.0296\n",
      " epoch: 60, train accuracy: 0.8468, train_loss_norm:0.0271, valid_acc: 0.8198, valid_loss_norm: 0.0294\n",
      " epoch: 61, train accuracy: 0.8474, train_loss_norm:0.0269, valid_acc: 0.8201, valid_loss_norm: 0.0292\n",
      " epoch: 62, train accuracy: 0.8480, train_loss_norm:0.0267, valid_acc: 0.8206, valid_loss_norm: 0.0290\n",
      " epoch: 63, train accuracy: 0.8485, train_loss_norm:0.0265, valid_acc: 0.8209, valid_loss_norm: 0.0288\n",
      " epoch: 64, train accuracy: 0.8490, train_loss_norm:0.0263, valid_acc: 0.8218, valid_loss_norm: 0.0287\n",
      " epoch: 65, train accuracy: 0.8494, train_loss_norm:0.0262, valid_acc: 0.8212, valid_loss_norm: 0.0285\n",
      " epoch: 66, train accuracy: 0.8497, train_loss_norm:0.0260, valid_acc: 0.8212, valid_loss_norm: 0.0283\n",
      " epoch: 67, train accuracy: 0.8504, train_loss_norm:0.0258, valid_acc: 0.8218, valid_loss_norm: 0.0281\n",
      " epoch: 68, train accuracy: 0.8508, train_loss_norm:0.0256, valid_acc: 0.8227, valid_loss_norm: 0.0280\n",
      " epoch: 69, train accuracy: 0.8513, train_loss_norm:0.0255, valid_acc: 0.8229, valid_loss_norm: 0.0278\n",
      " epoch: 70, train accuracy: 0.8518, train_loss_norm:0.0253, valid_acc: 0.8232, valid_loss_norm: 0.0276\n",
      " epoch: 71, train accuracy: 0.8521, train_loss_norm:0.0252, valid_acc: 0.8232, valid_loss_norm: 0.0275\n",
      " epoch: 72, train accuracy: 0.8522, train_loss_norm:0.0250, valid_acc: 0.8238, valid_loss_norm: 0.0273\n",
      " epoch: 73, train accuracy: 0.8527, train_loss_norm:0.0248, valid_acc: 0.8235, valid_loss_norm: 0.0272\n",
      " epoch: 74, train accuracy: 0.8536, train_loss_norm:0.0247, valid_acc: 0.8229, valid_loss_norm: 0.0270\n",
      " epoch: 75, train accuracy: 0.8541, train_loss_norm:0.0246, valid_acc: 0.8227, valid_loss_norm: 0.0269\n",
      " epoch: 76, train accuracy: 0.8544, train_loss_norm:0.0244, valid_acc: 0.8232, valid_loss_norm: 0.0268\n",
      " epoch: 77, train accuracy: 0.8546, train_loss_norm:0.0243, valid_acc: 0.8232, valid_loss_norm: 0.0266\n",
      " epoch: 78, train accuracy: 0.8551, train_loss_norm:0.0241, valid_acc: 0.8241, valid_loss_norm: 0.0265\n",
      " epoch: 79, train accuracy: 0.8555, train_loss_norm:0.0240, valid_acc: 0.8244, valid_loss_norm: 0.0264\n",
      " epoch: 80, train accuracy: 0.8555, train_loss_norm:0.0239, valid_acc: 0.8247, valid_loss_norm: 0.0262\n",
      " epoch: 81, train accuracy: 0.8559, train_loss_norm:0.0237, valid_acc: 0.8249, valid_loss_norm: 0.0261\n",
      " epoch: 82, train accuracy: 0.8565, train_loss_norm:0.0236, valid_acc: 0.8255, valid_loss_norm: 0.0260\n",
      " epoch: 83, train accuracy: 0.8568, train_loss_norm:0.0235, valid_acc: 0.8255, valid_loss_norm: 0.0258\n",
      " epoch: 84, train accuracy: 0.8570, train_loss_norm:0.0234, valid_acc: 0.8258, valid_loss_norm: 0.0257\n",
      " epoch: 85, train accuracy: 0.8573, train_loss_norm:0.0232, valid_acc: 0.8258, valid_loss_norm: 0.0256\n",
      " epoch: 86, train accuracy: 0.8577, train_loss_norm:0.0231, valid_acc: 0.8261, valid_loss_norm: 0.0255\n",
      " epoch: 87, train accuracy: 0.8583, train_loss_norm:0.0230, valid_acc: 0.8267, valid_loss_norm: 0.0254\n",
      " epoch: 88, train accuracy: 0.8587, train_loss_norm:0.0229, valid_acc: 0.8270, valid_loss_norm: 0.0253\n",
      " epoch: 89, train accuracy: 0.8591, train_loss_norm:0.0228, valid_acc: 0.8275, valid_loss_norm: 0.0252\n",
      " epoch: 90, train accuracy: 0.8594, train_loss_norm:0.0227, valid_acc: 0.8284, valid_loss_norm: 0.0251\n",
      " epoch: 91, train accuracy: 0.8598, train_loss_norm:0.0226, valid_acc: 0.8290, valid_loss_norm: 0.0249\n",
      " epoch: 92, train accuracy: 0.8602, train_loss_norm:0.0224, valid_acc: 0.8287, valid_loss_norm: 0.0248\n",
      " epoch: 93, train accuracy: 0.8604, train_loss_norm:0.0223, valid_acc: 0.8290, valid_loss_norm: 0.0247\n",
      " epoch: 94, train accuracy: 0.8607, train_loss_norm:0.0222, valid_acc: 0.8293, valid_loss_norm: 0.0246\n",
      " epoch: 95, train accuracy: 0.8607, train_loss_norm:0.0221, valid_acc: 0.8298, valid_loss_norm: 0.0245\n",
      " epoch: 96, train accuracy: 0.8610, train_loss_norm:0.0220, valid_acc: 0.8295, valid_loss_norm: 0.0244\n",
      " epoch: 97, train accuracy: 0.8614, train_loss_norm:0.0219, valid_acc: 0.8298, valid_loss_norm: 0.0243\n",
      " epoch: 98, train accuracy: 0.8616, train_loss_norm:0.0218, valid_acc: 0.8298, valid_loss_norm: 0.0242\n",
      " epoch: 99, train accuracy: 0.8619, train_loss_norm:0.0217, valid_acc: 0.8307, valid_loss_norm: 0.0242\n",
      " epoch: 100, train accuracy: 0.8621, train_loss_norm:0.0216, valid_acc: 0.8321, valid_loss_norm: 0.0241\n",
      " epoch: 101, train accuracy: 0.8625, train_loss_norm:0.0216, valid_acc: 0.8327, valid_loss_norm: 0.0240\n",
      " epoch: 102, train accuracy: 0.8630, train_loss_norm:0.0215, valid_acc: 0.8327, valid_loss_norm: 0.0239\n",
      " epoch: 103, train accuracy: 0.8633, train_loss_norm:0.0214, valid_acc: 0.8333, valid_loss_norm: 0.0238\n",
      " epoch: 104, train accuracy: 0.8636, train_loss_norm:0.0213, valid_acc: 0.8341, valid_loss_norm: 0.0237\n",
      " epoch: 105, train accuracy: 0.8639, train_loss_norm:0.0212, valid_acc: 0.8344, valid_loss_norm: 0.0236\n",
      " epoch: 106, train accuracy: 0.8644, train_loss_norm:0.0211, valid_acc: 0.8347, valid_loss_norm: 0.0235\n",
      " epoch: 107, train accuracy: 0.8647, train_loss_norm:0.0210, valid_acc: 0.8356, valid_loss_norm: 0.0235\n",
      " epoch: 108, train accuracy: 0.8650, train_loss_norm:0.0209, valid_acc: 0.8359, valid_loss_norm: 0.0234\n",
      " epoch: 109, train accuracy: 0.8653, train_loss_norm:0.0209, valid_acc: 0.8359, valid_loss_norm: 0.0233\n",
      " epoch: 110, train accuracy: 0.8654, train_loss_norm:0.0208, valid_acc: 0.8356, valid_loss_norm: 0.0232\n",
      " epoch: 111, train accuracy: 0.8658, train_loss_norm:0.0207, valid_acc: 0.8359, valid_loss_norm: 0.0231\n",
      " epoch: 112, train accuracy: 0.8662, train_loss_norm:0.0206, valid_acc: 0.8362, valid_loss_norm: 0.0231\n",
      " epoch: 113, train accuracy: 0.8665, train_loss_norm:0.0205, valid_acc: 0.8362, valid_loss_norm: 0.0230\n",
      " epoch: 114, train accuracy: 0.8667, train_loss_norm:0.0205, valid_acc: 0.8362, valid_loss_norm: 0.0229\n",
      " epoch: 115, train accuracy: 0.8671, train_loss_norm:0.0204, valid_acc: 0.8364, valid_loss_norm: 0.0228\n",
      " epoch: 116, train accuracy: 0.8673, train_loss_norm:0.0203, valid_acc: 0.8364, valid_loss_norm: 0.0228\n",
      " epoch: 117, train accuracy: 0.8676, train_loss_norm:0.0202, valid_acc: 0.8364, valid_loss_norm: 0.0227\n",
      " epoch: 118, train accuracy: 0.8679, train_loss_norm:0.0202, valid_acc: 0.8364, valid_loss_norm: 0.0226\n",
      " epoch: 119, train accuracy: 0.8679, train_loss_norm:0.0201, valid_acc: 0.8367, valid_loss_norm: 0.0226\n",
      " epoch: 120, train accuracy: 0.8684, train_loss_norm:0.0200, valid_acc: 0.8370, valid_loss_norm: 0.0225\n",
      " epoch: 121, train accuracy: 0.8688, train_loss_norm:0.0199, valid_acc: 0.8373, valid_loss_norm: 0.0224\n",
      " epoch: 122, train accuracy: 0.8689, train_loss_norm:0.0199, valid_acc: 0.8373, valid_loss_norm: 0.0224\n",
      " epoch: 123, train accuracy: 0.8690, train_loss_norm:0.0198, valid_acc: 0.8379, valid_loss_norm: 0.0223\n",
      " epoch: 124, train accuracy: 0.8694, train_loss_norm:0.0197, valid_acc: 0.8382, valid_loss_norm: 0.0222\n",
      " epoch: 125, train accuracy: 0.8697, train_loss_norm:0.0197, valid_acc: 0.8382, valid_loss_norm: 0.0222\n",
      " epoch: 126, train accuracy: 0.8697, train_loss_norm:0.0196, valid_acc: 0.8382, valid_loss_norm: 0.0221\n",
      " epoch: 127, train accuracy: 0.8700, train_loss_norm:0.0195, valid_acc: 0.8382, valid_loss_norm: 0.0220\n",
      " epoch: 128, train accuracy: 0.8703, train_loss_norm:0.0195, valid_acc: 0.8382, valid_loss_norm: 0.0220\n",
      " epoch: 129, train accuracy: 0.8704, train_loss_norm:0.0194, valid_acc: 0.8393, valid_loss_norm: 0.0219\n",
      " epoch: 130, train accuracy: 0.8707, train_loss_norm:0.0193, valid_acc: 0.8393, valid_loss_norm: 0.0218\n",
      " epoch: 131, train accuracy: 0.8709, train_loss_norm:0.0193, valid_acc: 0.8396, valid_loss_norm: 0.0218\n",
      " epoch: 132, train accuracy: 0.8712, train_loss_norm:0.0192, valid_acc: 0.8393, valid_loss_norm: 0.0217\n",
      " epoch: 133, train accuracy: 0.8715, train_loss_norm:0.0192, valid_acc: 0.8390, valid_loss_norm: 0.0217\n",
      " epoch: 134, train accuracy: 0.8718, train_loss_norm:0.0191, valid_acc: 0.8390, valid_loss_norm: 0.0216\n",
      " epoch: 135, train accuracy: 0.8721, train_loss_norm:0.0190, valid_acc: 0.8399, valid_loss_norm: 0.0216\n",
      " epoch: 136, train accuracy: 0.8724, train_loss_norm:0.0190, valid_acc: 0.8402, valid_loss_norm: 0.0215\n",
      " epoch: 137, train accuracy: 0.8726, train_loss_norm:0.0189, valid_acc: 0.8408, valid_loss_norm: 0.0214\n",
      " epoch: 138, train accuracy: 0.8728, train_loss_norm:0.0189, valid_acc: 0.8410, valid_loss_norm: 0.0214\n",
      " epoch: 139, train accuracy: 0.8731, train_loss_norm:0.0188, valid_acc: 0.8410, valid_loss_norm: 0.0213\n",
      " epoch: 140, train accuracy: 0.8732, train_loss_norm:0.0188, valid_acc: 0.8410, valid_loss_norm: 0.0213\n",
      " epoch: 141, train accuracy: 0.8734, train_loss_norm:0.0187, valid_acc: 0.8410, valid_loss_norm: 0.0212\n",
      " epoch: 142, train accuracy: 0.8735, train_loss_norm:0.0186, valid_acc: 0.8408, valid_loss_norm: 0.0212\n",
      " epoch: 143, train accuracy: 0.8736, train_loss_norm:0.0186, valid_acc: 0.8413, valid_loss_norm: 0.0211\n",
      " epoch: 144, train accuracy: 0.8739, train_loss_norm:0.0185, valid_acc: 0.8419, valid_loss_norm: 0.0211\n",
      " epoch: 145, train accuracy: 0.8741, train_loss_norm:0.0185, valid_acc: 0.8428, valid_loss_norm: 0.0210\n",
      " epoch: 146, train accuracy: 0.8744, train_loss_norm:0.0184, valid_acc: 0.8428, valid_loss_norm: 0.0210\n",
      " epoch: 147, train accuracy: 0.8745, train_loss_norm:0.0184, valid_acc: 0.8428, valid_loss_norm: 0.0209\n",
      " epoch: 148, train accuracy: 0.8747, train_loss_norm:0.0183, valid_acc: 0.8431, valid_loss_norm: 0.0209\n",
      " epoch: 149, train accuracy: 0.8750, train_loss_norm:0.0183, valid_acc: 0.8436, valid_loss_norm: 0.0208\n",
      " epoch: 150, train accuracy: 0.8752, train_loss_norm:0.0182, valid_acc: 0.8436, valid_loss_norm: 0.0208\n",
      " epoch: 151, train accuracy: 0.8754, train_loss_norm:0.0182, valid_acc: 0.8445, valid_loss_norm: 0.0207\n",
      " epoch: 152, train accuracy: 0.8755, train_loss_norm:0.0181, valid_acc: 0.8451, valid_loss_norm: 0.0207\n",
      " epoch: 153, train accuracy: 0.8758, train_loss_norm:0.0181, valid_acc: 0.8454, valid_loss_norm: 0.0206\n",
      " epoch: 154, train accuracy: 0.8760, train_loss_norm:0.0180, valid_acc: 0.8456, valid_loss_norm: 0.0206\n",
      " epoch: 155, train accuracy: 0.8762, train_loss_norm:0.0180, valid_acc: 0.8462, valid_loss_norm: 0.0205\n",
      " epoch: 156, train accuracy: 0.8763, train_loss_norm:0.0179, valid_acc: 0.8465, valid_loss_norm: 0.0205\n",
      " epoch: 157, train accuracy: 0.8765, train_loss_norm:0.0179, valid_acc: 0.8465, valid_loss_norm: 0.0204\n",
      " epoch: 158, train accuracy: 0.8768, train_loss_norm:0.0178, valid_acc: 0.8474, valid_loss_norm: 0.0204\n",
      " epoch: 159, train accuracy: 0.8769, train_loss_norm:0.0178, valid_acc: 0.8477, valid_loss_norm: 0.0204\n",
      " epoch: 160, train accuracy: 0.8771, train_loss_norm:0.0177, valid_acc: 0.8479, valid_loss_norm: 0.0203\n",
      " epoch: 161, train accuracy: 0.8773, train_loss_norm:0.0177, valid_acc: 0.8485, valid_loss_norm: 0.0203\n",
      " epoch: 162, train accuracy: 0.8776, train_loss_norm:0.0176, valid_acc: 0.8488, valid_loss_norm: 0.0202\n",
      " epoch: 163, train accuracy: 0.8777, train_loss_norm:0.0176, valid_acc: 0.8494, valid_loss_norm: 0.0202\n",
      " epoch: 164, train accuracy: 0.8779, train_loss_norm:0.0176, valid_acc: 0.8494, valid_loss_norm: 0.0201\n",
      " epoch: 165, train accuracy: 0.8781, train_loss_norm:0.0175, valid_acc: 0.8500, valid_loss_norm: 0.0201\n",
      " epoch: 166, train accuracy: 0.8783, train_loss_norm:0.0175, valid_acc: 0.8500, valid_loss_norm: 0.0201\n",
      " epoch: 167, train accuracy: 0.8783, train_loss_norm:0.0174, valid_acc: 0.8505, valid_loss_norm: 0.0200\n",
      " epoch: 168, train accuracy: 0.8785, train_loss_norm:0.0174, valid_acc: 0.8502, valid_loss_norm: 0.0200\n",
      " epoch: 169, train accuracy: 0.8787, train_loss_norm:0.0173, valid_acc: 0.8502, valid_loss_norm: 0.0199\n",
      " epoch: 170, train accuracy: 0.8790, train_loss_norm:0.0173, valid_acc: 0.8505, valid_loss_norm: 0.0199\n",
      " epoch: 171, train accuracy: 0.8792, train_loss_norm:0.0173, valid_acc: 0.8511, valid_loss_norm: 0.0199\n",
      " epoch: 172, train accuracy: 0.8793, train_loss_norm:0.0172, valid_acc: 0.8514, valid_loss_norm: 0.0198\n",
      " epoch: 173, train accuracy: 0.8795, train_loss_norm:0.0172, valid_acc: 0.8514, valid_loss_norm: 0.0198\n",
      " epoch: 174, train accuracy: 0.8799, train_loss_norm:0.0171, valid_acc: 0.8514, valid_loss_norm: 0.0197\n",
      " epoch: 175, train accuracy: 0.8800, train_loss_norm:0.0171, valid_acc: 0.8517, valid_loss_norm: 0.0197\n",
      " epoch: 176, train accuracy: 0.8803, train_loss_norm:0.0170, valid_acc: 0.8517, valid_loss_norm: 0.0197\n",
      " epoch: 177, train accuracy: 0.8804, train_loss_norm:0.0170, valid_acc: 0.8514, valid_loss_norm: 0.0196\n",
      " epoch: 178, train accuracy: 0.8808, train_loss_norm:0.0170, valid_acc: 0.8520, valid_loss_norm: 0.0196\n",
      " epoch: 179, train accuracy: 0.8809, train_loss_norm:0.0169, valid_acc: 0.8523, valid_loss_norm: 0.0196\n",
      " epoch: 180, train accuracy: 0.8811, train_loss_norm:0.0169, valid_acc: 0.8523, valid_loss_norm: 0.0195\n",
      " epoch: 181, train accuracy: 0.8815, train_loss_norm:0.0169, valid_acc: 0.8520, valid_loss_norm: 0.0195\n",
      " epoch: 182, train accuracy: 0.8816, train_loss_norm:0.0168, valid_acc: 0.8520, valid_loss_norm: 0.0195\n",
      " epoch: 183, train accuracy: 0.8819, train_loss_norm:0.0168, valid_acc: 0.8520, valid_loss_norm: 0.0194\n",
      " epoch: 184, train accuracy: 0.8820, train_loss_norm:0.0167, valid_acc: 0.8520, valid_loss_norm: 0.0194\n",
      " epoch: 185, train accuracy: 0.8820, train_loss_norm:0.0167, valid_acc: 0.8523, valid_loss_norm: 0.0193\n",
      " epoch: 186, train accuracy: 0.8822, train_loss_norm:0.0167, valid_acc: 0.8525, valid_loss_norm: 0.0193\n",
      " epoch: 187, train accuracy: 0.8823, train_loss_norm:0.0166, valid_acc: 0.8525, valid_loss_norm: 0.0193\n",
      " epoch: 188, train accuracy: 0.8824, train_loss_norm:0.0166, valid_acc: 0.8528, valid_loss_norm: 0.0192\n",
      " epoch: 189, train accuracy: 0.8826, train_loss_norm:0.0166, valid_acc: 0.8528, valid_loss_norm: 0.0192\n",
      " epoch: 190, train accuracy: 0.8827, train_loss_norm:0.0165, valid_acc: 0.8528, valid_loss_norm: 0.0192\n",
      " epoch: 191, train accuracy: 0.8829, train_loss_norm:0.0165, valid_acc: 0.8528, valid_loss_norm: 0.0191\n",
      " epoch: 192, train accuracy: 0.8831, train_loss_norm:0.0165, valid_acc: 0.8531, valid_loss_norm: 0.0191\n",
      " epoch: 193, train accuracy: 0.8834, train_loss_norm:0.0164, valid_acc: 0.8531, valid_loss_norm: 0.0191\n",
      " epoch: 194, train accuracy: 0.8834, train_loss_norm:0.0164, valid_acc: 0.8534, valid_loss_norm: 0.0190\n",
      " epoch: 195, train accuracy: 0.8835, train_loss_norm:0.0163, valid_acc: 0.8534, valid_loss_norm: 0.0190\n",
      " epoch: 196, train accuracy: 0.8836, train_loss_norm:0.0163, valid_acc: 0.8534, valid_loss_norm: 0.0190\n",
      " epoch: 197, train accuracy: 0.8838, train_loss_norm:0.0163, valid_acc: 0.8537, valid_loss_norm: 0.0190\n",
      " epoch: 198, train accuracy: 0.8841, train_loss_norm:0.0162, valid_acc: 0.8537, valid_loss_norm: 0.0189\n",
      " epoch: 199, train accuracy: 0.8843, train_loss_norm:0.0162, valid_acc: 0.8537, valid_loss_norm: 0.0189\n",
      " epoch: 200, train accuracy: 0.8844, train_loss_norm:0.0162, valid_acc: 0.8537, valid_loss_norm: 0.0189\n",
      " epoch: 201, train accuracy: 0.8846, train_loss_norm:0.0161, valid_acc: 0.8537, valid_loss_norm: 0.0188\n",
      " epoch: 202, train accuracy: 0.8847, train_loss_norm:0.0161, valid_acc: 0.8543, valid_loss_norm: 0.0188\n",
      " epoch: 203, train accuracy: 0.8849, train_loss_norm:0.0161, valid_acc: 0.8543, valid_loss_norm: 0.0188\n",
      " epoch: 204, train accuracy: 0.8850, train_loss_norm:0.0160, valid_acc: 0.8543, valid_loss_norm: 0.0187\n",
      " epoch: 205, train accuracy: 0.8851, train_loss_norm:0.0160, valid_acc: 0.8543, valid_loss_norm: 0.0187\n",
      " epoch: 206, train accuracy: 0.8852, train_loss_norm:0.0160, valid_acc: 0.8546, valid_loss_norm: 0.0187\n",
      " epoch: 207, train accuracy: 0.8854, train_loss_norm:0.0160, valid_acc: 0.8546, valid_loss_norm: 0.0187\n",
      " epoch: 208, train accuracy: 0.8854, train_loss_norm:0.0159, valid_acc: 0.8546, valid_loss_norm: 0.0186\n",
      " epoch: 209, train accuracy: 0.8857, train_loss_norm:0.0159, valid_acc: 0.8548, valid_loss_norm: 0.0186\n",
      " epoch: 210, train accuracy: 0.8859, train_loss_norm:0.0159, valid_acc: 0.8554, valid_loss_norm: 0.0186\n",
      " epoch: 211, train accuracy: 0.8860, train_loss_norm:0.0158, valid_acc: 0.8554, valid_loss_norm: 0.0185\n",
      " epoch: 212, train accuracy: 0.8862, train_loss_norm:0.0158, valid_acc: 0.8557, valid_loss_norm: 0.0185\n",
      " epoch: 213, train accuracy: 0.8862, train_loss_norm:0.0158, valid_acc: 0.8557, valid_loss_norm: 0.0185\n",
      " epoch: 214, train accuracy: 0.8865, train_loss_norm:0.0157, valid_acc: 0.8557, valid_loss_norm: 0.0185\n",
      " epoch: 215, train accuracy: 0.8868, train_loss_norm:0.0157, valid_acc: 0.8560, valid_loss_norm: 0.0184\n",
      " epoch: 216, train accuracy: 0.8870, train_loss_norm:0.0157, valid_acc: 0.8563, valid_loss_norm: 0.0184\n",
      " epoch: 217, train accuracy: 0.8873, train_loss_norm:0.0156, valid_acc: 0.8574, valid_loss_norm: 0.0184\n",
      " epoch: 218, train accuracy: 0.8875, train_loss_norm:0.0156, valid_acc: 0.8574, valid_loss_norm: 0.0183\n",
      " epoch: 219, train accuracy: 0.8877, train_loss_norm:0.0156, valid_acc: 0.8580, valid_loss_norm: 0.0183\n",
      " epoch: 220, train accuracy: 0.8879, train_loss_norm:0.0156, valid_acc: 0.8580, valid_loss_norm: 0.0183\n",
      " epoch: 221, train accuracy: 0.8881, train_loss_norm:0.0155, valid_acc: 0.8580, valid_loss_norm: 0.0183\n",
      " epoch: 222, train accuracy: 0.8882, train_loss_norm:0.0155, valid_acc: 0.8580, valid_loss_norm: 0.0182\n",
      " epoch: 223, train accuracy: 0.8883, train_loss_norm:0.0155, valid_acc: 0.8580, valid_loss_norm: 0.0182\n",
      " epoch: 224, train accuracy: 0.8884, train_loss_norm:0.0154, valid_acc: 0.8580, valid_loss_norm: 0.0182\n",
      " epoch: 225, train accuracy: 0.8885, train_loss_norm:0.0154, valid_acc: 0.8580, valid_loss_norm: 0.0182\n",
      " epoch: 226, train accuracy: 0.8887, train_loss_norm:0.0154, valid_acc: 0.8580, valid_loss_norm: 0.0181\n",
      " epoch: 227, train accuracy: 0.8888, train_loss_norm:0.0154, valid_acc: 0.8580, valid_loss_norm: 0.0181\n",
      " epoch: 228, train accuracy: 0.8889, train_loss_norm:0.0153, valid_acc: 0.8580, valid_loss_norm: 0.0181\n",
      " epoch: 229, train accuracy: 0.8892, train_loss_norm:0.0153, valid_acc: 0.8580, valid_loss_norm: 0.0181\n",
      " epoch: 230, train accuracy: 0.8893, train_loss_norm:0.0153, valid_acc: 0.8580, valid_loss_norm: 0.0180\n",
      " epoch: 231, train accuracy: 0.8897, train_loss_norm:0.0153, valid_acc: 0.8580, valid_loss_norm: 0.0180\n",
      " epoch: 232, train accuracy: 0.8898, train_loss_norm:0.0152, valid_acc: 0.8580, valid_loss_norm: 0.0180\n",
      " epoch: 233, train accuracy: 0.8899, train_loss_norm:0.0152, valid_acc: 0.8580, valid_loss_norm: 0.0180\n",
      " epoch: 234, train accuracy: 0.8901, train_loss_norm:0.0152, valid_acc: 0.8580, valid_loss_norm: 0.0179\n",
      " epoch: 235, train accuracy: 0.8903, train_loss_norm:0.0152, valid_acc: 0.8580, valid_loss_norm: 0.0179\n",
      " epoch: 236, train accuracy: 0.8904, train_loss_norm:0.0151, valid_acc: 0.8583, valid_loss_norm: 0.0179\n",
      " epoch: 237, train accuracy: 0.8906, train_loss_norm:0.0151, valid_acc: 0.8583, valid_loss_norm: 0.0179\n",
      " epoch: 238, train accuracy: 0.8907, train_loss_norm:0.0151, valid_acc: 0.8583, valid_loss_norm: 0.0178\n",
      " epoch: 239, train accuracy: 0.8908, train_loss_norm:0.0151, valid_acc: 0.8583, valid_loss_norm: 0.0178\n",
      " epoch: 240, train accuracy: 0.8908, train_loss_norm:0.0150, valid_acc: 0.8583, valid_loss_norm: 0.0178\n",
      " epoch: 241, train accuracy: 0.8910, train_loss_norm:0.0150, valid_acc: 0.8589, valid_loss_norm: 0.0178\n",
      " epoch: 242, train accuracy: 0.8913, train_loss_norm:0.0150, valid_acc: 0.8594, valid_loss_norm: 0.0178\n",
      " epoch: 243, train accuracy: 0.8915, train_loss_norm:0.0150, valid_acc: 0.8594, valid_loss_norm: 0.0177\n",
      " epoch: 244, train accuracy: 0.8916, train_loss_norm:0.0149, valid_acc: 0.8597, valid_loss_norm: 0.0177\n",
      " epoch: 245, train accuracy: 0.8917, train_loss_norm:0.0149, valid_acc: 0.8603, valid_loss_norm: 0.0177\n",
      " epoch: 246, train accuracy: 0.8918, train_loss_norm:0.0149, valid_acc: 0.8603, valid_loss_norm: 0.0177\n",
      " epoch: 247, train accuracy: 0.8920, train_loss_norm:0.0149, valid_acc: 0.8603, valid_loss_norm: 0.0176\n",
      " epoch: 248, train accuracy: 0.8920, train_loss_norm:0.0148, valid_acc: 0.8600, valid_loss_norm: 0.0176\n",
      " epoch: 249, train accuracy: 0.8923, train_loss_norm:0.0148, valid_acc: 0.8600, valid_loss_norm: 0.0176\n",
      " epoch: 250, train accuracy: 0.8925, train_loss_norm:0.0148, valid_acc: 0.8600, valid_loss_norm: 0.0176\n",
      " epoch: 251, train accuracy: 0.8926, train_loss_norm:0.0148, valid_acc: 0.8600, valid_loss_norm: 0.0176\n",
      " epoch: 252, train accuracy: 0.8926, train_loss_norm:0.0147, valid_acc: 0.8606, valid_loss_norm: 0.0175\n",
      " epoch: 253, train accuracy: 0.8927, train_loss_norm:0.0147, valid_acc: 0.8600, valid_loss_norm: 0.0175\n",
      " epoch: 254, train accuracy: 0.8929, train_loss_norm:0.0147, valid_acc: 0.8600, valid_loss_norm: 0.0175\n",
      " epoch: 255, train accuracy: 0.8930, train_loss_norm:0.0147, valid_acc: 0.8600, valid_loss_norm: 0.0175\n",
      " epoch: 256, train accuracy: 0.8931, train_loss_norm:0.0146, valid_acc: 0.8600, valid_loss_norm: 0.0175\n",
      " epoch: 257, train accuracy: 0.8933, train_loss_norm:0.0146, valid_acc: 0.8600, valid_loss_norm: 0.0174\n",
      " epoch: 258, train accuracy: 0.8935, train_loss_norm:0.0146, valid_acc: 0.8600, valid_loss_norm: 0.0174\n",
      " epoch: 259, train accuracy: 0.8937, train_loss_norm:0.0146, valid_acc: 0.8600, valid_loss_norm: 0.0174\n",
      " epoch: 260, train accuracy: 0.8939, train_loss_norm:0.0145, valid_acc: 0.8603, valid_loss_norm: 0.0174\n",
      " epoch: 261, train accuracy: 0.8941, train_loss_norm:0.0145, valid_acc: 0.8603, valid_loss_norm: 0.0174\n",
      " epoch: 262, train accuracy: 0.8944, train_loss_norm:0.0145, valid_acc: 0.8603, valid_loss_norm: 0.0173\n",
      " epoch: 263, train accuracy: 0.8947, train_loss_norm:0.0145, valid_acc: 0.8606, valid_loss_norm: 0.0173\n",
      " epoch: 264, train accuracy: 0.8948, train_loss_norm:0.0145, valid_acc: 0.8606, valid_loss_norm: 0.0173\n",
      " epoch: 265, train accuracy: 0.8948, train_loss_norm:0.0144, valid_acc: 0.8609, valid_loss_norm: 0.0173\n",
      " epoch: 266, train accuracy: 0.8950, train_loss_norm:0.0144, valid_acc: 0.8612, valid_loss_norm: 0.0173\n",
      " epoch: 267, train accuracy: 0.8951, train_loss_norm:0.0144, valid_acc: 0.8612, valid_loss_norm: 0.0172\n",
      " epoch: 268, train accuracy: 0.8953, train_loss_norm:0.0144, valid_acc: 0.8617, valid_loss_norm: 0.0172\n",
      " epoch: 269, train accuracy: 0.8954, train_loss_norm:0.0144, valid_acc: 0.8617, valid_loss_norm: 0.0172\n",
      " epoch: 270, train accuracy: 0.8955, train_loss_norm:0.0143, valid_acc: 0.8617, valid_loss_norm: 0.0172\n",
      " epoch: 271, train accuracy: 0.8957, train_loss_norm:0.0143, valid_acc: 0.8620, valid_loss_norm: 0.0172\n",
      " epoch: 272, train accuracy: 0.8958, train_loss_norm:0.0143, valid_acc: 0.8620, valid_loss_norm: 0.0171\n",
      " epoch: 273, train accuracy: 0.8961, train_loss_norm:0.0143, valid_acc: 0.8620, valid_loss_norm: 0.0171\n",
      " epoch: 274, train accuracy: 0.8961, train_loss_norm:0.0142, valid_acc: 0.8623, valid_loss_norm: 0.0171\n",
      " epoch: 275, train accuracy: 0.8963, train_loss_norm:0.0142, valid_acc: 0.8623, valid_loss_norm: 0.0171\n",
      " epoch: 276, train accuracy: 0.8963, train_loss_norm:0.0142, valid_acc: 0.8623, valid_loss_norm: 0.0171\n",
      " epoch: 277, train accuracy: 0.8964, train_loss_norm:0.0142, valid_acc: 0.8623, valid_loss_norm: 0.0170\n",
      " epoch: 278, train accuracy: 0.8966, train_loss_norm:0.0142, valid_acc: 0.8623, valid_loss_norm: 0.0170\n",
      " epoch: 279, train accuracy: 0.8966, train_loss_norm:0.0141, valid_acc: 0.8623, valid_loss_norm: 0.0170\n",
      " epoch: 280, train accuracy: 0.8968, train_loss_norm:0.0141, valid_acc: 0.8626, valid_loss_norm: 0.0170\n",
      " epoch: 281, train accuracy: 0.8969, train_loss_norm:0.0141, valid_acc: 0.8626, valid_loss_norm: 0.0170\n",
      " epoch: 282, train accuracy: 0.8971, train_loss_norm:0.0141, valid_acc: 0.8626, valid_loss_norm: 0.0170\n",
      " epoch: 283, train accuracy: 0.8973, train_loss_norm:0.0141, valid_acc: 0.8626, valid_loss_norm: 0.0169\n",
      " epoch: 284, train accuracy: 0.8973, train_loss_norm:0.0140, valid_acc: 0.8629, valid_loss_norm: 0.0169\n",
      " epoch: 285, train accuracy: 0.8976, train_loss_norm:0.0140, valid_acc: 0.8629, valid_loss_norm: 0.0169\n",
      " epoch: 286, train accuracy: 0.8977, train_loss_norm:0.0140, valid_acc: 0.8632, valid_loss_norm: 0.0169\n",
      " epoch: 287, train accuracy: 0.8979, train_loss_norm:0.0140, valid_acc: 0.8632, valid_loss_norm: 0.0169\n",
      " epoch: 288, train accuracy: 0.8980, train_loss_norm:0.0140, valid_acc: 0.8635, valid_loss_norm: 0.0169\n",
      " epoch: 289, train accuracy: 0.8980, train_loss_norm:0.0139, valid_acc: 0.8638, valid_loss_norm: 0.0168\n",
      " epoch: 290, train accuracy: 0.8980, train_loss_norm:0.0139, valid_acc: 0.8638, valid_loss_norm: 0.0168\n",
      " epoch: 291, train accuracy: 0.8982, train_loss_norm:0.0139, valid_acc: 0.8640, valid_loss_norm: 0.0168\n",
      " epoch: 292, train accuracy: 0.8982, train_loss_norm:0.0139, valid_acc: 0.8643, valid_loss_norm: 0.0168\n",
      " epoch: 293, train accuracy: 0.8984, train_loss_norm:0.0139, valid_acc: 0.8646, valid_loss_norm: 0.0168\n",
      " epoch: 294, train accuracy: 0.8985, train_loss_norm:0.0139, valid_acc: 0.8646, valid_loss_norm: 0.0168\n",
      " epoch: 295, train accuracy: 0.8986, train_loss_norm:0.0138, valid_acc: 0.8646, valid_loss_norm: 0.0167\n",
      " epoch: 296, train accuracy: 0.8987, train_loss_norm:0.0138, valid_acc: 0.8649, valid_loss_norm: 0.0167\n",
      " epoch: 297, train accuracy: 0.8991, train_loss_norm:0.0138, valid_acc: 0.8652, valid_loss_norm: 0.0167\n",
      " epoch: 298, train accuracy: 0.8992, train_loss_norm:0.0138, valid_acc: 0.8655, valid_loss_norm: 0.0167\n",
      " epoch: 299, train accuracy: 0.8995, train_loss_norm:0.0138, valid_acc: 0.8655, valid_loss_norm: 0.0167\n",
      " epoch: 300, train accuracy: 0.8996, train_loss_norm:0.0137, valid_acc: 0.8658, valid_loss_norm: 0.0167\n",
      "Test accuracy: 0.8597\n",
      "Test loss norm: 0.0168\n",
      "Cur fold: 6\n",
      "(27841, 300)\n",
      "(3479, 300)\n",
      "(3479, 300)\n",
      " epoch: 1, train accuracy: 0.7939, train_loss_norm:0.0836, valid_acc: 0.7657, valid_loss_norm: 0.0836\n",
      " epoch: 2, train accuracy: 0.7941, train_loss_norm:0.0799, valid_acc: 0.7649, valid_loss_norm: 0.0799\n",
      " epoch: 3, train accuracy: 0.7946, train_loss_norm:0.0764, valid_acc: 0.7652, valid_loss_norm: 0.0764\n",
      " epoch: 4, train accuracy: 0.7951, train_loss_norm:0.0730, valid_acc: 0.7660, valid_loss_norm: 0.0730\n",
      " epoch: 5, train accuracy: 0.7956, train_loss_norm:0.0698, valid_acc: 0.7669, valid_loss_norm: 0.0698\n",
      " epoch: 6, train accuracy: 0.7965, train_loss_norm:0.0668, valid_acc: 0.7683, valid_loss_norm: 0.0668\n",
      " epoch: 7, train accuracy: 0.7972, train_loss_norm:0.0640, valid_acc: 0.7698, valid_loss_norm: 0.0641\n",
      " epoch: 8, train accuracy: 0.7980, train_loss_norm:0.0615, valid_acc: 0.7712, valid_loss_norm: 0.0617\n",
      " epoch: 9, train accuracy: 0.7993, train_loss_norm:0.0592, valid_acc: 0.7744, valid_loss_norm: 0.0594\n",
      " epoch: 10, train accuracy: 0.8008, train_loss_norm:0.0572, valid_acc: 0.7749, valid_loss_norm: 0.0574\n",
      " epoch: 11, train accuracy: 0.8026, train_loss_norm:0.0553, valid_acc: 0.7769, valid_loss_norm: 0.0555\n",
      " epoch: 12, train accuracy: 0.8045, train_loss_norm:0.0536, valid_acc: 0.7772, valid_loss_norm: 0.0539\n",
      " epoch: 13, train accuracy: 0.8060, train_loss_norm:0.0520, valid_acc: 0.7781, valid_loss_norm: 0.0523\n",
      " epoch: 14, train accuracy: 0.8072, train_loss_norm:0.0505, valid_acc: 0.7801, valid_loss_norm: 0.0509\n",
      " epoch: 15, train accuracy: 0.8088, train_loss_norm:0.0492, valid_acc: 0.7807, valid_loss_norm: 0.0497\n",
      " epoch: 16, train accuracy: 0.8103, train_loss_norm:0.0479, valid_acc: 0.7818, valid_loss_norm: 0.0485\n",
      " epoch: 17, train accuracy: 0.8126, train_loss_norm:0.0468, valid_acc: 0.7838, valid_loss_norm: 0.0474\n",
      " epoch: 18, train accuracy: 0.8142, train_loss_norm:0.0457, valid_acc: 0.7864, valid_loss_norm: 0.0463\n",
      " epoch: 19, train accuracy: 0.8160, train_loss_norm:0.0447, valid_acc: 0.7876, valid_loss_norm: 0.0454\n",
      " epoch: 20, train accuracy: 0.8174, train_loss_norm:0.0438, valid_acc: 0.7876, valid_loss_norm: 0.0445\n",
      " epoch: 21, train accuracy: 0.8189, train_loss_norm:0.0429, valid_acc: 0.7899, valid_loss_norm: 0.0437\n",
      " epoch: 22, train accuracy: 0.8202, train_loss_norm:0.0421, valid_acc: 0.7896, valid_loss_norm: 0.0429\n",
      " epoch: 23, train accuracy: 0.8208, train_loss_norm:0.0413, valid_acc: 0.7905, valid_loss_norm: 0.0421\n",
      " epoch: 24, train accuracy: 0.8217, train_loss_norm:0.0406, valid_acc: 0.7907, valid_loss_norm: 0.0414\n",
      " epoch: 25, train accuracy: 0.8232, train_loss_norm:0.0399, valid_acc: 0.7913, valid_loss_norm: 0.0408\n",
      " epoch: 26, train accuracy: 0.8244, train_loss_norm:0.0392, valid_acc: 0.7925, valid_loss_norm: 0.0402\n",
      " epoch: 27, train accuracy: 0.8257, train_loss_norm:0.0386, valid_acc: 0.7930, valid_loss_norm: 0.0396\n",
      " epoch: 28, train accuracy: 0.8266, train_loss_norm:0.0380, valid_acc: 0.7939, valid_loss_norm: 0.0390\n",
      " epoch: 29, train accuracy: 0.8276, train_loss_norm:0.0374, valid_acc: 0.7956, valid_loss_norm: 0.0385\n",
      " epoch: 30, train accuracy: 0.8287, train_loss_norm:0.0369, valid_acc: 0.7968, valid_loss_norm: 0.0379\n",
      " epoch: 31, train accuracy: 0.8292, train_loss_norm:0.0364, valid_acc: 0.7979, valid_loss_norm: 0.0375\n",
      " epoch: 32, train accuracy: 0.8302, train_loss_norm:0.0359, valid_acc: 0.7988, valid_loss_norm: 0.0370\n",
      " epoch: 33, train accuracy: 0.8313, train_loss_norm:0.0354, valid_acc: 0.8008, valid_loss_norm: 0.0365\n",
      " epoch: 34, train accuracy: 0.8321, train_loss_norm:0.0349, valid_acc: 0.8025, valid_loss_norm: 0.0361\n",
      " epoch: 35, train accuracy: 0.8331, train_loss_norm:0.0345, valid_acc: 0.8043, valid_loss_norm: 0.0357\n",
      " epoch: 36, train accuracy: 0.8339, train_loss_norm:0.0341, valid_acc: 0.8048, valid_loss_norm: 0.0353\n",
      " epoch: 37, train accuracy: 0.8347, train_loss_norm:0.0336, valid_acc: 0.8060, valid_loss_norm: 0.0349\n",
      " epoch: 38, train accuracy: 0.8357, train_loss_norm:0.0333, valid_acc: 0.8068, valid_loss_norm: 0.0345\n",
      " epoch: 39, train accuracy: 0.8366, train_loss_norm:0.0329, valid_acc: 0.8071, valid_loss_norm: 0.0342\n",
      " epoch: 40, train accuracy: 0.8376, train_loss_norm:0.0325, valid_acc: 0.8083, valid_loss_norm: 0.0338\n",
      " epoch: 41, train accuracy: 0.8383, train_loss_norm:0.0322, valid_acc: 0.8091, valid_loss_norm: 0.0335\n",
      " epoch: 42, train accuracy: 0.8389, train_loss_norm:0.0318, valid_acc: 0.8094, valid_loss_norm: 0.0332\n",
      " epoch: 43, train accuracy: 0.8395, train_loss_norm:0.0315, valid_acc: 0.8094, valid_loss_norm: 0.0329\n",
      " epoch: 44, train accuracy: 0.8403, train_loss_norm:0.0312, valid_acc: 0.8094, valid_loss_norm: 0.0326\n",
      " epoch: 45, train accuracy: 0.8412, train_loss_norm:0.0309, valid_acc: 0.8106, valid_loss_norm: 0.0323\n",
      " epoch: 46, train accuracy: 0.8419, train_loss_norm:0.0306, valid_acc: 0.8117, valid_loss_norm: 0.0320\n",
      " epoch: 47, train accuracy: 0.8426, train_loss_norm:0.0303, valid_acc: 0.8126, valid_loss_norm: 0.0317\n",
      " epoch: 48, train accuracy: 0.8429, train_loss_norm:0.0300, valid_acc: 0.8135, valid_loss_norm: 0.0315\n",
      " epoch: 49, train accuracy: 0.8436, train_loss_norm:0.0297, valid_acc: 0.8140, valid_loss_norm: 0.0312\n",
      " epoch: 50, train accuracy: 0.8443, train_loss_norm:0.0294, valid_acc: 0.8146, valid_loss_norm: 0.0309\n",
      " epoch: 51, train accuracy: 0.8447, train_loss_norm:0.0292, valid_acc: 0.8146, valid_loss_norm: 0.0307\n",
      " epoch: 52, train accuracy: 0.8450, train_loss_norm:0.0289, valid_acc: 0.8160, valid_loss_norm: 0.0305\n",
      " epoch: 53, train accuracy: 0.8453, train_loss_norm:0.0287, valid_acc: 0.8166, valid_loss_norm: 0.0302\n",
      " epoch: 54, train accuracy: 0.8457, train_loss_norm:0.0284, valid_acc: 0.8160, valid_loss_norm: 0.0300\n",
      " epoch: 55, train accuracy: 0.8462, train_loss_norm:0.0282, valid_acc: 0.8160, valid_loss_norm: 0.0298\n",
      " epoch: 56, train accuracy: 0.8466, train_loss_norm:0.0280, valid_acc: 0.8163, valid_loss_norm: 0.0296\n",
      " epoch: 57, train accuracy: 0.8471, train_loss_norm:0.0278, valid_acc: 0.8178, valid_loss_norm: 0.0294\n",
      " epoch: 58, train accuracy: 0.8474, train_loss_norm:0.0276, valid_acc: 0.8178, valid_loss_norm: 0.0292\n",
      " epoch: 59, train accuracy: 0.8478, train_loss_norm:0.0273, valid_acc: 0.8183, valid_loss_norm: 0.0290\n",
      " epoch: 60, train accuracy: 0.8485, train_loss_norm:0.0271, valid_acc: 0.8183, valid_loss_norm: 0.0288\n",
      " epoch: 61, train accuracy: 0.8489, train_loss_norm:0.0269, valid_acc: 0.8183, valid_loss_norm: 0.0286\n",
      " epoch: 62, train accuracy: 0.8495, train_loss_norm:0.0267, valid_acc: 0.8181, valid_loss_norm: 0.0284\n",
      " epoch: 63, train accuracy: 0.8501, train_loss_norm:0.0266, valid_acc: 0.8181, valid_loss_norm: 0.0283\n",
      " epoch: 64, train accuracy: 0.8503, train_loss_norm:0.0264, valid_acc: 0.8183, valid_loss_norm: 0.0281\n",
      " epoch: 65, train accuracy: 0.8508, train_loss_norm:0.0262, valid_acc: 0.8183, valid_loss_norm: 0.0279\n",
      " epoch: 66, train accuracy: 0.8512, train_loss_norm:0.0260, valid_acc: 0.8186, valid_loss_norm: 0.0277\n",
      " epoch: 67, train accuracy: 0.8518, train_loss_norm:0.0258, valid_acc: 0.8189, valid_loss_norm: 0.0276\n",
      " epoch: 68, train accuracy: 0.8522, train_loss_norm:0.0257, valid_acc: 0.8186, valid_loss_norm: 0.0274\n",
      " epoch: 69, train accuracy: 0.8527, train_loss_norm:0.0255, valid_acc: 0.8195, valid_loss_norm: 0.0273\n",
      " epoch: 70, train accuracy: 0.8530, train_loss_norm:0.0253, valid_acc: 0.8201, valid_loss_norm: 0.0271\n",
      " epoch: 71, train accuracy: 0.8535, train_loss_norm:0.0252, valid_acc: 0.8209, valid_loss_norm: 0.0270\n",
      " epoch: 72, train accuracy: 0.8540, train_loss_norm:0.0250, valid_acc: 0.8212, valid_loss_norm: 0.0268\n",
      " epoch: 73, train accuracy: 0.8545, train_loss_norm:0.0249, valid_acc: 0.8224, valid_loss_norm: 0.0267\n",
      " epoch: 74, train accuracy: 0.8551, train_loss_norm:0.0247, valid_acc: 0.8232, valid_loss_norm: 0.0266\n",
      " epoch: 75, train accuracy: 0.8555, train_loss_norm:0.0246, valid_acc: 0.8238, valid_loss_norm: 0.0264\n",
      " epoch: 76, train accuracy: 0.8558, train_loss_norm:0.0244, valid_acc: 0.8241, valid_loss_norm: 0.0263\n",
      " epoch: 77, train accuracy: 0.8563, train_loss_norm:0.0243, valid_acc: 0.8247, valid_loss_norm: 0.0262\n",
      " epoch: 78, train accuracy: 0.8567, train_loss_norm:0.0242, valid_acc: 0.8249, valid_loss_norm: 0.0260\n",
      " epoch: 79, train accuracy: 0.8569, train_loss_norm:0.0240, valid_acc: 0.8249, valid_loss_norm: 0.0259\n",
      " epoch: 80, train accuracy: 0.8572, train_loss_norm:0.0239, valid_acc: 0.8255, valid_loss_norm: 0.0258\n",
      " epoch: 81, train accuracy: 0.8577, train_loss_norm:0.0238, valid_acc: 0.8264, valid_loss_norm: 0.0257\n",
      " epoch: 82, train accuracy: 0.8579, train_loss_norm:0.0236, valid_acc: 0.8261, valid_loss_norm: 0.0255\n",
      " epoch: 83, train accuracy: 0.8582, train_loss_norm:0.0235, valid_acc: 0.8261, valid_loss_norm: 0.0254\n",
      " epoch: 84, train accuracy: 0.8585, train_loss_norm:0.0234, valid_acc: 0.8267, valid_loss_norm: 0.0253\n",
      " epoch: 85, train accuracy: 0.8588, train_loss_norm:0.0233, valid_acc: 0.8264, valid_loss_norm: 0.0252\n",
      " epoch: 86, train accuracy: 0.8592, train_loss_norm:0.0231, valid_acc: 0.8267, valid_loss_norm: 0.0251\n",
      " epoch: 87, train accuracy: 0.8595, train_loss_norm:0.0230, valid_acc: 0.8272, valid_loss_norm: 0.0250\n",
      " epoch: 88, train accuracy: 0.8597, train_loss_norm:0.0229, valid_acc: 0.8272, valid_loss_norm: 0.0249\n",
      " epoch: 89, train accuracy: 0.8600, train_loss_norm:0.0228, valid_acc: 0.8278, valid_loss_norm: 0.0248\n",
      " epoch: 90, train accuracy: 0.8602, train_loss_norm:0.0227, valid_acc: 0.8284, valid_loss_norm: 0.0247\n",
      " epoch: 91, train accuracy: 0.8604, train_loss_norm:0.0226, valid_acc: 0.8287, valid_loss_norm: 0.0246\n",
      " epoch: 92, train accuracy: 0.8606, train_loss_norm:0.0225, valid_acc: 0.8290, valid_loss_norm: 0.0245\n",
      " epoch: 93, train accuracy: 0.8609, train_loss_norm:0.0224, valid_acc: 0.8298, valid_loss_norm: 0.0244\n",
      " epoch: 94, train accuracy: 0.8613, train_loss_norm:0.0223, valid_acc: 0.8301, valid_loss_norm: 0.0243\n",
      " epoch: 95, train accuracy: 0.8616, train_loss_norm:0.0222, valid_acc: 0.8304, valid_loss_norm: 0.0242\n",
      " epoch: 96, train accuracy: 0.8622, train_loss_norm:0.0221, valid_acc: 0.8310, valid_loss_norm: 0.0241\n",
      " epoch: 97, train accuracy: 0.8625, train_loss_norm:0.0220, valid_acc: 0.8316, valid_loss_norm: 0.0240\n",
      " epoch: 98, train accuracy: 0.8629, train_loss_norm:0.0219, valid_acc: 0.8318, valid_loss_norm: 0.0239\n",
      " epoch: 99, train accuracy: 0.8632, train_loss_norm:0.0218, valid_acc: 0.8318, valid_loss_norm: 0.0238\n",
      " epoch: 100, train accuracy: 0.8635, train_loss_norm:0.0217, valid_acc: 0.8321, valid_loss_norm: 0.0237\n",
      " epoch: 101, train accuracy: 0.8638, train_loss_norm:0.0216, valid_acc: 0.8318, valid_loss_norm: 0.0237\n",
      " epoch: 102, train accuracy: 0.8645, train_loss_norm:0.0215, valid_acc: 0.8324, valid_loss_norm: 0.0236\n",
      " epoch: 103, train accuracy: 0.8649, train_loss_norm:0.0214, valid_acc: 0.8333, valid_loss_norm: 0.0235\n",
      " epoch: 104, train accuracy: 0.8654, train_loss_norm:0.0213, valid_acc: 0.8341, valid_loss_norm: 0.0234\n",
      " epoch: 105, train accuracy: 0.8658, train_loss_norm:0.0212, valid_acc: 0.8353, valid_loss_norm: 0.0233\n",
      " epoch: 106, train accuracy: 0.8662, train_loss_norm:0.0211, valid_acc: 0.8356, valid_loss_norm: 0.0233\n",
      " epoch: 107, train accuracy: 0.8665, train_loss_norm:0.0210, valid_acc: 0.8356, valid_loss_norm: 0.0232\n",
      " epoch: 108, train accuracy: 0.8667, train_loss_norm:0.0210, valid_acc: 0.8356, valid_loss_norm: 0.0231\n",
      " epoch: 109, train accuracy: 0.8668, train_loss_norm:0.0209, valid_acc: 0.8356, valid_loss_norm: 0.0230\n",
      " epoch: 110, train accuracy: 0.8671, train_loss_norm:0.0208, valid_acc: 0.8353, valid_loss_norm: 0.0230\n",
      " epoch: 111, train accuracy: 0.8673, train_loss_norm:0.0207, valid_acc: 0.8353, valid_loss_norm: 0.0229\n",
      " epoch: 112, train accuracy: 0.8675, train_loss_norm:0.0206, valid_acc: 0.8350, valid_loss_norm: 0.0228\n",
      " epoch: 113, train accuracy: 0.8679, train_loss_norm:0.0206, valid_acc: 0.8350, valid_loss_norm: 0.0227\n",
      " epoch: 114, train accuracy: 0.8683, train_loss_norm:0.0205, valid_acc: 0.8350, valid_loss_norm: 0.0227\n",
      " epoch: 115, train accuracy: 0.8685, train_loss_norm:0.0204, valid_acc: 0.8362, valid_loss_norm: 0.0226\n",
      " epoch: 116, train accuracy: 0.8686, train_loss_norm:0.0203, valid_acc: 0.8362, valid_loss_norm: 0.0225\n",
      " epoch: 117, train accuracy: 0.8690, train_loss_norm:0.0202, valid_acc: 0.8362, valid_loss_norm: 0.0225\n",
      " epoch: 118, train accuracy: 0.8697, train_loss_norm:0.0202, valid_acc: 0.8367, valid_loss_norm: 0.0224\n",
      " epoch: 119, train accuracy: 0.8698, train_loss_norm:0.0201, valid_acc: 0.8370, valid_loss_norm: 0.0223\n",
      " epoch: 120, train accuracy: 0.8700, train_loss_norm:0.0200, valid_acc: 0.8379, valid_loss_norm: 0.0223\n",
      " epoch: 121, train accuracy: 0.8702, train_loss_norm:0.0200, valid_acc: 0.8382, valid_loss_norm: 0.0222\n",
      " epoch: 122, train accuracy: 0.8703, train_loss_norm:0.0199, valid_acc: 0.8387, valid_loss_norm: 0.0221\n",
      " epoch: 123, train accuracy: 0.8706, train_loss_norm:0.0198, valid_acc: 0.8390, valid_loss_norm: 0.0221\n",
      " epoch: 124, train accuracy: 0.8709, train_loss_norm:0.0198, valid_acc: 0.8393, valid_loss_norm: 0.0220\n",
      " epoch: 125, train accuracy: 0.8711, train_loss_norm:0.0197, valid_acc: 0.8390, valid_loss_norm: 0.0220\n",
      " epoch: 126, train accuracy: 0.8713, train_loss_norm:0.0196, valid_acc: 0.8390, valid_loss_norm: 0.0219\n",
      " epoch: 127, train accuracy: 0.8713, train_loss_norm:0.0196, valid_acc: 0.8390, valid_loss_norm: 0.0218\n",
      " epoch: 128, train accuracy: 0.8716, train_loss_norm:0.0195, valid_acc: 0.8390, valid_loss_norm: 0.0218\n",
      " epoch: 129, train accuracy: 0.8717, train_loss_norm:0.0194, valid_acc: 0.8396, valid_loss_norm: 0.0217\n",
      " epoch: 130, train accuracy: 0.8722, train_loss_norm:0.0194, valid_acc: 0.8396, valid_loss_norm: 0.0217\n",
      " epoch: 131, train accuracy: 0.8725, train_loss_norm:0.0193, valid_acc: 0.8405, valid_loss_norm: 0.0216\n",
      " epoch: 132, train accuracy: 0.8726, train_loss_norm:0.0192, valid_acc: 0.8410, valid_loss_norm: 0.0216\n",
      " epoch: 133, train accuracy: 0.8729, train_loss_norm:0.0192, valid_acc: 0.8416, valid_loss_norm: 0.0215\n",
      " epoch: 134, train accuracy: 0.8732, train_loss_norm:0.0191, valid_acc: 0.8419, valid_loss_norm: 0.0214\n",
      " epoch: 135, train accuracy: 0.8733, train_loss_norm:0.0191, valid_acc: 0.8422, valid_loss_norm: 0.0214\n",
      " epoch: 136, train accuracy: 0.8734, train_loss_norm:0.0190, valid_acc: 0.8428, valid_loss_norm: 0.0213\n",
      " epoch: 137, train accuracy: 0.8736, train_loss_norm:0.0189, valid_acc: 0.8431, valid_loss_norm: 0.0213\n",
      " epoch: 138, train accuracy: 0.8740, train_loss_norm:0.0189, valid_acc: 0.8433, valid_loss_norm: 0.0212\n",
      " epoch: 139, train accuracy: 0.8744, train_loss_norm:0.0188, valid_acc: 0.8436, valid_loss_norm: 0.0212\n",
      " epoch: 140, train accuracy: 0.8746, train_loss_norm:0.0188, valid_acc: 0.8439, valid_loss_norm: 0.0211\n",
      " epoch: 141, train accuracy: 0.8751, train_loss_norm:0.0187, valid_acc: 0.8445, valid_loss_norm: 0.0211\n",
      " epoch: 142, train accuracy: 0.8755, train_loss_norm:0.0186, valid_acc: 0.8442, valid_loss_norm: 0.0210\n",
      " epoch: 143, train accuracy: 0.8758, train_loss_norm:0.0186, valid_acc: 0.8445, valid_loss_norm: 0.0210\n",
      " epoch: 144, train accuracy: 0.8763, train_loss_norm:0.0185, valid_acc: 0.8445, valid_loss_norm: 0.0209\n",
      " epoch: 145, train accuracy: 0.8765, train_loss_norm:0.0185, valid_acc: 0.8448, valid_loss_norm: 0.0209\n",
      " epoch: 146, train accuracy: 0.8768, train_loss_norm:0.0184, valid_acc: 0.8451, valid_loss_norm: 0.0208\n",
      " epoch: 147, train accuracy: 0.8771, train_loss_norm:0.0184, valid_acc: 0.8448, valid_loss_norm: 0.0208\n",
      " epoch: 148, train accuracy: 0.8774, train_loss_norm:0.0183, valid_acc: 0.8448, valid_loss_norm: 0.0208\n",
      " epoch: 149, train accuracy: 0.8776, train_loss_norm:0.0183, valid_acc: 0.8451, valid_loss_norm: 0.0207\n",
      " epoch: 150, train accuracy: 0.8777, train_loss_norm:0.0182, valid_acc: 0.8454, valid_loss_norm: 0.0207\n",
      " epoch: 151, train accuracy: 0.8779, train_loss_norm:0.0182, valid_acc: 0.8456, valid_loss_norm: 0.0206\n",
      " epoch: 152, train accuracy: 0.8782, train_loss_norm:0.0181, valid_acc: 0.8456, valid_loss_norm: 0.0206\n",
      " epoch: 153, train accuracy: 0.8785, train_loss_norm:0.0181, valid_acc: 0.8456, valid_loss_norm: 0.0205\n",
      " epoch: 154, train accuracy: 0.8787, train_loss_norm:0.0180, valid_acc: 0.8462, valid_loss_norm: 0.0205\n",
      " epoch: 155, train accuracy: 0.8789, train_loss_norm:0.0180, valid_acc: 0.8462, valid_loss_norm: 0.0204\n",
      " epoch: 156, train accuracy: 0.8793, train_loss_norm:0.0179, valid_acc: 0.8459, valid_loss_norm: 0.0204\n",
      " epoch: 157, train accuracy: 0.8795, train_loss_norm:0.0179, valid_acc: 0.8459, valid_loss_norm: 0.0204\n",
      " epoch: 158, train accuracy: 0.8797, train_loss_norm:0.0178, valid_acc: 0.8459, valid_loss_norm: 0.0203\n",
      " epoch: 159, train accuracy: 0.8799, train_loss_norm:0.0178, valid_acc: 0.8459, valid_loss_norm: 0.0203\n",
      " epoch: 160, train accuracy: 0.8800, train_loss_norm:0.0177, valid_acc: 0.8462, valid_loss_norm: 0.0202\n",
      " epoch: 161, train accuracy: 0.8803, train_loss_norm:0.0177, valid_acc: 0.8465, valid_loss_norm: 0.0202\n",
      " epoch: 162, train accuracy: 0.8804, train_loss_norm:0.0176, valid_acc: 0.8465, valid_loss_norm: 0.0202\n",
      " epoch: 163, train accuracy: 0.8805, train_loss_norm:0.0176, valid_acc: 0.8471, valid_loss_norm: 0.0201\n",
      " epoch: 164, train accuracy: 0.8808, train_loss_norm:0.0176, valid_acc: 0.8474, valid_loss_norm: 0.0201\n",
      " epoch: 165, train accuracy: 0.8810, train_loss_norm:0.0175, valid_acc: 0.8474, valid_loss_norm: 0.0200\n",
      " epoch: 166, train accuracy: 0.8813, train_loss_norm:0.0175, valid_acc: 0.8474, valid_loss_norm: 0.0200\n",
      " epoch: 167, train accuracy: 0.8816, train_loss_norm:0.0174, valid_acc: 0.8474, valid_loss_norm: 0.0200\n",
      " epoch: 168, train accuracy: 0.8820, train_loss_norm:0.0174, valid_acc: 0.8474, valid_loss_norm: 0.0199\n",
      " epoch: 169, train accuracy: 0.8822, train_loss_norm:0.0173, valid_acc: 0.8477, valid_loss_norm: 0.0199\n",
      " epoch: 170, train accuracy: 0.8827, train_loss_norm:0.0173, valid_acc: 0.8482, valid_loss_norm: 0.0199\n",
      " epoch: 171, train accuracy: 0.8829, train_loss_norm:0.0173, valid_acc: 0.8482, valid_loss_norm: 0.0198\n",
      " epoch: 172, train accuracy: 0.8831, train_loss_norm:0.0172, valid_acc: 0.8482, valid_loss_norm: 0.0198\n",
      " epoch: 173, train accuracy: 0.8834, train_loss_norm:0.0172, valid_acc: 0.8491, valid_loss_norm: 0.0197\n",
      " epoch: 174, train accuracy: 0.8835, train_loss_norm:0.0171, valid_acc: 0.8491, valid_loss_norm: 0.0197\n",
      " epoch: 175, train accuracy: 0.8836, train_loss_norm:0.0171, valid_acc: 0.8491, valid_loss_norm: 0.0197\n",
      " epoch: 176, train accuracy: 0.8836, train_loss_norm:0.0171, valid_acc: 0.8497, valid_loss_norm: 0.0196\n",
      " epoch: 177, train accuracy: 0.8837, train_loss_norm:0.0170, valid_acc: 0.8497, valid_loss_norm: 0.0196\n",
      " epoch: 178, train accuracy: 0.8839, train_loss_norm:0.0170, valid_acc: 0.8497, valid_loss_norm: 0.0196\n",
      " epoch: 179, train accuracy: 0.8842, train_loss_norm:0.0169, valid_acc: 0.8500, valid_loss_norm: 0.0195\n",
      " epoch: 180, train accuracy: 0.8843, train_loss_norm:0.0169, valid_acc: 0.8500, valid_loss_norm: 0.0195\n",
      " epoch: 181, train accuracy: 0.8845, train_loss_norm:0.0169, valid_acc: 0.8500, valid_loss_norm: 0.0195\n",
      " epoch: 182, train accuracy: 0.8846, train_loss_norm:0.0168, valid_acc: 0.8500, valid_loss_norm: 0.0194\n",
      " epoch: 183, train accuracy: 0.8848, train_loss_norm:0.0168, valid_acc: 0.8500, valid_loss_norm: 0.0194\n",
      " epoch: 184, train accuracy: 0.8850, train_loss_norm:0.0167, valid_acc: 0.8502, valid_loss_norm: 0.0194\n",
      " epoch: 185, train accuracy: 0.8853, train_loss_norm:0.0167, valid_acc: 0.8505, valid_loss_norm: 0.0193\n",
      " epoch: 186, train accuracy: 0.8854, train_loss_norm:0.0167, valid_acc: 0.8508, valid_loss_norm: 0.0193\n",
      " epoch: 187, train accuracy: 0.8857, train_loss_norm:0.0166, valid_acc: 0.8511, valid_loss_norm: 0.0193\n",
      " epoch: 188, train accuracy: 0.8857, train_loss_norm:0.0166, valid_acc: 0.8511, valid_loss_norm: 0.0192\n",
      " epoch: 189, train accuracy: 0.8859, train_loss_norm:0.0166, valid_acc: 0.8511, valid_loss_norm: 0.0192\n",
      " epoch: 190, train accuracy: 0.8859, train_loss_norm:0.0165, valid_acc: 0.8508, valid_loss_norm: 0.0192\n",
      " epoch: 191, train accuracy: 0.8860, train_loss_norm:0.0165, valid_acc: 0.8508, valid_loss_norm: 0.0192\n",
      " epoch: 192, train accuracy: 0.8861, train_loss_norm:0.0165, valid_acc: 0.8508, valid_loss_norm: 0.0191\n",
      " epoch: 193, train accuracy: 0.8864, train_loss_norm:0.0164, valid_acc: 0.8511, valid_loss_norm: 0.0191\n",
      " epoch: 194, train accuracy: 0.8863, train_loss_norm:0.0164, valid_acc: 0.8517, valid_loss_norm: 0.0191\n",
      " epoch: 195, train accuracy: 0.8864, train_loss_norm:0.0163, valid_acc: 0.8517, valid_loss_norm: 0.0190\n",
      " epoch: 196, train accuracy: 0.8866, train_loss_norm:0.0163, valid_acc: 0.8517, valid_loss_norm: 0.0190\n",
      " epoch: 197, train accuracy: 0.8869, train_loss_norm:0.0163, valid_acc: 0.8517, valid_loss_norm: 0.0190\n",
      " epoch: 198, train accuracy: 0.8870, train_loss_norm:0.0162, valid_acc: 0.8517, valid_loss_norm: 0.0189\n",
      " epoch: 199, train accuracy: 0.8871, train_loss_norm:0.0162, valid_acc: 0.8517, valid_loss_norm: 0.0189\n",
      " epoch: 200, train accuracy: 0.8874, train_loss_norm:0.0162, valid_acc: 0.8520, valid_loss_norm: 0.0189\n",
      " epoch: 201, train accuracy: 0.8876, train_loss_norm:0.0161, valid_acc: 0.8520, valid_loss_norm: 0.0189\n",
      " epoch: 202, train accuracy: 0.8879, train_loss_norm:0.0161, valid_acc: 0.8520, valid_loss_norm: 0.0188\n",
      " epoch: 203, train accuracy: 0.8879, train_loss_norm:0.0161, valid_acc: 0.8523, valid_loss_norm: 0.0188\n",
      " epoch: 204, train accuracy: 0.8880, train_loss_norm:0.0160, valid_acc: 0.8523, valid_loss_norm: 0.0188\n",
      " epoch: 205, train accuracy: 0.8882, train_loss_norm:0.0160, valid_acc: 0.8520, valid_loss_norm: 0.0188\n",
      " epoch: 206, train accuracy: 0.8884, train_loss_norm:0.0160, valid_acc: 0.8523, valid_loss_norm: 0.0187\n",
      " epoch: 207, train accuracy: 0.8886, train_loss_norm:0.0160, valid_acc: 0.8523, valid_loss_norm: 0.0187\n",
      " epoch: 208, train accuracy: 0.8888, train_loss_norm:0.0159, valid_acc: 0.8525, valid_loss_norm: 0.0187\n",
      " epoch: 209, train accuracy: 0.8889, train_loss_norm:0.0159, valid_acc: 0.8525, valid_loss_norm: 0.0186\n",
      " epoch: 210, train accuracy: 0.8889, train_loss_norm:0.0159, valid_acc: 0.8523, valid_loss_norm: 0.0186\n",
      " epoch: 211, train accuracy: 0.8892, train_loss_norm:0.0158, valid_acc: 0.8523, valid_loss_norm: 0.0186\n",
      " epoch: 212, train accuracy: 0.8894, train_loss_norm:0.0158, valid_acc: 0.8531, valid_loss_norm: 0.0186\n",
      " epoch: 213, train accuracy: 0.8895, train_loss_norm:0.0158, valid_acc: 0.8531, valid_loss_norm: 0.0185\n",
      " epoch: 214, train accuracy: 0.8896, train_loss_norm:0.0157, valid_acc: 0.8531, valid_loss_norm: 0.0185\n",
      " epoch: 215, train accuracy: 0.8897, train_loss_norm:0.0157, valid_acc: 0.8531, valid_loss_norm: 0.0185\n",
      " epoch: 216, train accuracy: 0.8898, train_loss_norm:0.0157, valid_acc: 0.8534, valid_loss_norm: 0.0185\n",
      " epoch: 217, train accuracy: 0.8899, train_loss_norm:0.0156, valid_acc: 0.8534, valid_loss_norm: 0.0184\n",
      " epoch: 218, train accuracy: 0.8901, train_loss_norm:0.0156, valid_acc: 0.8534, valid_loss_norm: 0.0184\n",
      " epoch: 219, train accuracy: 0.8902, train_loss_norm:0.0156, valid_acc: 0.8534, valid_loss_norm: 0.0184\n",
      " epoch: 220, train accuracy: 0.8905, train_loss_norm:0.0156, valid_acc: 0.8537, valid_loss_norm: 0.0184\n",
      " epoch: 221, train accuracy: 0.8908, train_loss_norm:0.0155, valid_acc: 0.8540, valid_loss_norm: 0.0184\n",
      " epoch: 222, train accuracy: 0.8909, train_loss_norm:0.0155, valid_acc: 0.8540, valid_loss_norm: 0.0183\n",
      " epoch: 223, train accuracy: 0.8911, train_loss_norm:0.0155, valid_acc: 0.8543, valid_loss_norm: 0.0183\n",
      " epoch: 224, train accuracy: 0.8915, train_loss_norm:0.0154, valid_acc: 0.8546, valid_loss_norm: 0.0183\n",
      " epoch: 225, train accuracy: 0.8916, train_loss_norm:0.0154, valid_acc: 0.8551, valid_loss_norm: 0.0183\n",
      " epoch: 226, train accuracy: 0.8919, train_loss_norm:0.0154, valid_acc: 0.8551, valid_loss_norm: 0.0182\n",
      " epoch: 227, train accuracy: 0.8920, train_loss_norm:0.0154, valid_acc: 0.8551, valid_loss_norm: 0.0182\n",
      " epoch: 228, train accuracy: 0.8920, train_loss_norm:0.0153, valid_acc: 0.8551, valid_loss_norm: 0.0182\n",
      " epoch: 229, train accuracy: 0.8922, train_loss_norm:0.0153, valid_acc: 0.8551, valid_loss_norm: 0.0182\n",
      " epoch: 230, train accuracy: 0.8923, train_loss_norm:0.0153, valid_acc: 0.8554, valid_loss_norm: 0.0181\n",
      " epoch: 231, train accuracy: 0.8925, train_loss_norm:0.0153, valid_acc: 0.8554, valid_loss_norm: 0.0181\n",
      " epoch: 232, train accuracy: 0.8926, train_loss_norm:0.0152, valid_acc: 0.8560, valid_loss_norm: 0.0181\n",
      " epoch: 233, train accuracy: 0.8927, train_loss_norm:0.0152, valid_acc: 0.8560, valid_loss_norm: 0.0181\n",
      " epoch: 234, train accuracy: 0.8929, train_loss_norm:0.0152, valid_acc: 0.8560, valid_loss_norm: 0.0181\n",
      " epoch: 235, train accuracy: 0.8931, train_loss_norm:0.0151, valid_acc: 0.8560, valid_loss_norm: 0.0180\n",
      " epoch: 236, train accuracy: 0.8932, train_loss_norm:0.0151, valid_acc: 0.8563, valid_loss_norm: 0.0180\n",
      " epoch: 237, train accuracy: 0.8933, train_loss_norm:0.0151, valid_acc: 0.8569, valid_loss_norm: 0.0180\n",
      " epoch: 238, train accuracy: 0.8936, train_loss_norm:0.0151, valid_acc: 0.8569, valid_loss_norm: 0.0180\n",
      " epoch: 239, train accuracy: 0.8936, train_loss_norm:0.0150, valid_acc: 0.8571, valid_loss_norm: 0.0180\n",
      " epoch: 240, train accuracy: 0.8936, train_loss_norm:0.0150, valid_acc: 0.8571, valid_loss_norm: 0.0179\n",
      " epoch: 241, train accuracy: 0.8938, train_loss_norm:0.0150, valid_acc: 0.8571, valid_loss_norm: 0.0179\n",
      " epoch: 242, train accuracy: 0.8940, train_loss_norm:0.0150, valid_acc: 0.8571, valid_loss_norm: 0.0179\n",
      " epoch: 243, train accuracy: 0.8941, train_loss_norm:0.0149, valid_acc: 0.8571, valid_loss_norm: 0.0179\n",
      " epoch: 244, train accuracy: 0.8941, train_loss_norm:0.0149, valid_acc: 0.8571, valid_loss_norm: 0.0178\n",
      " epoch: 245, train accuracy: 0.8942, train_loss_norm:0.0149, valid_acc: 0.8571, valid_loss_norm: 0.0178\n",
      " epoch: 246, train accuracy: 0.8944, train_loss_norm:0.0149, valid_acc: 0.8571, valid_loss_norm: 0.0178\n",
      " epoch: 247, train accuracy: 0.8945, train_loss_norm:0.0148, valid_acc: 0.8571, valid_loss_norm: 0.0178\n",
      " epoch: 248, train accuracy: 0.8945, train_loss_norm:0.0148, valid_acc: 0.8574, valid_loss_norm: 0.0178\n",
      " epoch: 249, train accuracy: 0.8945, train_loss_norm:0.0148, valid_acc: 0.8577, valid_loss_norm: 0.0177\n",
      " epoch: 250, train accuracy: 0.8948, train_loss_norm:0.0148, valid_acc: 0.8577, valid_loss_norm: 0.0177\n",
      " epoch: 251, train accuracy: 0.8950, train_loss_norm:0.0148, valid_acc: 0.8577, valid_loss_norm: 0.0177\n",
      " epoch: 252, train accuracy: 0.8952, train_loss_norm:0.0147, valid_acc: 0.8577, valid_loss_norm: 0.0177\n",
      " epoch: 253, train accuracy: 0.8953, train_loss_norm:0.0147, valid_acc: 0.8580, valid_loss_norm: 0.0177\n",
      " epoch: 254, train accuracy: 0.8954, train_loss_norm:0.0147, valid_acc: 0.8589, valid_loss_norm: 0.0177\n",
      " epoch: 255, train accuracy: 0.8955, train_loss_norm:0.0147, valid_acc: 0.8589, valid_loss_norm: 0.0176\n",
      " epoch: 256, train accuracy: 0.8958, train_loss_norm:0.0146, valid_acc: 0.8592, valid_loss_norm: 0.0176\n",
      " epoch: 257, train accuracy: 0.8959, train_loss_norm:0.0146, valid_acc: 0.8592, valid_loss_norm: 0.0176\n",
      " epoch: 258, train accuracy: 0.8962, train_loss_norm:0.0146, valid_acc: 0.8589, valid_loss_norm: 0.0176\n",
      " epoch: 259, train accuracy: 0.8963, train_loss_norm:0.0146, valid_acc: 0.8594, valid_loss_norm: 0.0176\n",
      " epoch: 260, train accuracy: 0.8964, train_loss_norm:0.0145, valid_acc: 0.8594, valid_loss_norm: 0.0175\n",
      " epoch: 261, train accuracy: 0.8968, train_loss_norm:0.0145, valid_acc: 0.8594, valid_loss_norm: 0.0175\n",
      " epoch: 262, train accuracy: 0.8969, train_loss_norm:0.0145, valid_acc: 0.8597, valid_loss_norm: 0.0175\n",
      " epoch: 263, train accuracy: 0.8970, train_loss_norm:0.0145, valid_acc: 0.8597, valid_loss_norm: 0.0175\n",
      " epoch: 264, train accuracy: 0.8972, train_loss_norm:0.0145, valid_acc: 0.8597, valid_loss_norm: 0.0175\n",
      " epoch: 265, train accuracy: 0.8974, train_loss_norm:0.0144, valid_acc: 0.8597, valid_loss_norm: 0.0175\n",
      " epoch: 266, train accuracy: 0.8975, train_loss_norm:0.0144, valid_acc: 0.8597, valid_loss_norm: 0.0174\n",
      " epoch: 267, train accuracy: 0.8976, train_loss_norm:0.0144, valid_acc: 0.8597, valid_loss_norm: 0.0174\n",
      " epoch: 268, train accuracy: 0.8977, train_loss_norm:0.0144, valid_acc: 0.8600, valid_loss_norm: 0.0174\n",
      " epoch: 269, train accuracy: 0.8978, train_loss_norm:0.0143, valid_acc: 0.8603, valid_loss_norm: 0.0174\n",
      " epoch: 270, train accuracy: 0.8980, train_loss_norm:0.0143, valid_acc: 0.8603, valid_loss_norm: 0.0174\n",
      " epoch: 271, train accuracy: 0.8980, train_loss_norm:0.0143, valid_acc: 0.8603, valid_loss_norm: 0.0173\n",
      " epoch: 272, train accuracy: 0.8981, train_loss_norm:0.0143, valid_acc: 0.8603, valid_loss_norm: 0.0173\n",
      " epoch: 273, train accuracy: 0.8982, train_loss_norm:0.0143, valid_acc: 0.8603, valid_loss_norm: 0.0173\n",
      " epoch: 274, train accuracy: 0.8982, train_loss_norm:0.0142, valid_acc: 0.8603, valid_loss_norm: 0.0173\n",
      " epoch: 275, train accuracy: 0.8985, train_loss_norm:0.0142, valid_acc: 0.8603, valid_loss_norm: 0.0173\n",
      " epoch: 276, train accuracy: 0.8985, train_loss_norm:0.0142, valid_acc: 0.8603, valid_loss_norm: 0.0173\n",
      " epoch: 277, train accuracy: 0.8986, train_loss_norm:0.0142, valid_acc: 0.8603, valid_loss_norm: 0.0172\n",
      " epoch: 278, train accuracy: 0.8987, train_loss_norm:0.0142, valid_acc: 0.8606, valid_loss_norm: 0.0172\n",
      " epoch: 279, train accuracy: 0.8989, train_loss_norm:0.0141, valid_acc: 0.8606, valid_loss_norm: 0.0172\n",
      " epoch: 280, train accuracy: 0.8990, train_loss_norm:0.0141, valid_acc: 0.8606, valid_loss_norm: 0.0172\n",
      " epoch: 281, train accuracy: 0.8991, train_loss_norm:0.0141, valid_acc: 0.8606, valid_loss_norm: 0.0172\n",
      " epoch: 282, train accuracy: 0.8991, train_loss_norm:0.0141, valid_acc: 0.8606, valid_loss_norm: 0.0172\n",
      " epoch: 283, train accuracy: 0.8992, train_loss_norm:0.0141, valid_acc: 0.8609, valid_loss_norm: 0.0172\n",
      " epoch: 284, train accuracy: 0.8993, train_loss_norm:0.0140, valid_acc: 0.8609, valid_loss_norm: 0.0171\n",
      " epoch: 285, train accuracy: 0.8995, train_loss_norm:0.0140, valid_acc: 0.8609, valid_loss_norm: 0.0171\n",
      " epoch: 286, train accuracy: 0.8996, train_loss_norm:0.0140, valid_acc: 0.8612, valid_loss_norm: 0.0171\n",
      " epoch: 287, train accuracy: 0.8998, train_loss_norm:0.0140, valid_acc: 0.8612, valid_loss_norm: 0.0171\n",
      " epoch: 288, train accuracy: 0.8999, train_loss_norm:0.0140, valid_acc: 0.8612, valid_loss_norm: 0.0171\n",
      " epoch: 289, train accuracy: 0.9000, train_loss_norm:0.0139, valid_acc: 0.8612, valid_loss_norm: 0.0171\n",
      " epoch: 290, train accuracy: 0.9000, train_loss_norm:0.0139, valid_acc: 0.8612, valid_loss_norm: 0.0170\n",
      " epoch: 291, train accuracy: 0.9000, train_loss_norm:0.0139, valid_acc: 0.8615, valid_loss_norm: 0.0170\n",
      " epoch: 292, train accuracy: 0.9000, train_loss_norm:0.0139, valid_acc: 0.8612, valid_loss_norm: 0.0170\n",
      " epoch: 293, train accuracy: 0.9001, train_loss_norm:0.0139, valid_acc: 0.8615, valid_loss_norm: 0.0170\n",
      " epoch: 294, train accuracy: 0.9004, train_loss_norm:0.0138, valid_acc: 0.8615, valid_loss_norm: 0.0170\n",
      " epoch: 295, train accuracy: 0.9005, train_loss_norm:0.0138, valid_acc: 0.8615, valid_loss_norm: 0.0170\n",
      " epoch: 296, train accuracy: 0.9007, train_loss_norm:0.0138, valid_acc: 0.8617, valid_loss_norm: 0.0170\n",
      " epoch: 297, train accuracy: 0.9007, train_loss_norm:0.0138, valid_acc: 0.8617, valid_loss_norm: 0.0169\n",
      " epoch: 298, train accuracy: 0.9008, train_loss_norm:0.0138, valid_acc: 0.8617, valid_loss_norm: 0.0169\n",
      " epoch: 299, train accuracy: 0.9009, train_loss_norm:0.0138, valid_acc: 0.8617, valid_loss_norm: 0.0169\n",
      " epoch: 300, train accuracy: 0.9010, train_loss_norm:0.0137, valid_acc: 0.8620, valid_loss_norm: 0.0169\n",
      "Test accuracy: 0.8669\n",
      "Test loss norm: 0.0164\n",
      "Cur fold: 7\n",
      "(27841, 300)\n",
      "(3479, 300)\n",
      "(3479, 300)\n",
      " epoch: 1, train accuracy: 0.7929, train_loss_norm:0.0836, valid_acc: 0.7896, valid_loss_norm: 0.0837\n",
      " epoch: 2, train accuracy: 0.7929, train_loss_norm:0.0799, valid_acc: 0.7899, valid_loss_norm: 0.0801\n",
      " epoch: 3, train accuracy: 0.7933, train_loss_norm:0.0764, valid_acc: 0.7899, valid_loss_norm: 0.0766\n",
      " epoch: 4, train accuracy: 0.7938, train_loss_norm:0.0730, valid_acc: 0.7902, valid_loss_norm: 0.0732\n",
      " epoch: 5, train accuracy: 0.7942, train_loss_norm:0.0698, valid_acc: 0.7913, valid_loss_norm: 0.0701\n",
      " epoch: 6, train accuracy: 0.7951, train_loss_norm:0.0668, valid_acc: 0.7916, valid_loss_norm: 0.0671\n",
      " epoch: 7, train accuracy: 0.7962, train_loss_norm:0.0640, valid_acc: 0.7928, valid_loss_norm: 0.0645\n",
      " epoch: 8, train accuracy: 0.7974, train_loss_norm:0.0615, valid_acc: 0.7936, valid_loss_norm: 0.0620\n",
      " epoch: 9, train accuracy: 0.7993, train_loss_norm:0.0593, valid_acc: 0.7959, valid_loss_norm: 0.0598\n",
      " epoch: 10, train accuracy: 0.8007, train_loss_norm:0.0572, valid_acc: 0.7976, valid_loss_norm: 0.0577\n",
      " epoch: 11, train accuracy: 0.8023, train_loss_norm:0.0553, valid_acc: 0.7979, valid_loss_norm: 0.0559\n",
      " epoch: 12, train accuracy: 0.8039, train_loss_norm:0.0536, valid_acc: 0.7994, valid_loss_norm: 0.0542\n",
      " epoch: 13, train accuracy: 0.8055, train_loss_norm:0.0520, valid_acc: 0.7988, valid_loss_norm: 0.0527\n",
      " epoch: 14, train accuracy: 0.8068, train_loss_norm:0.0505, valid_acc: 0.7994, valid_loss_norm: 0.0513\n",
      " epoch: 15, train accuracy: 0.8090, train_loss_norm:0.0492, valid_acc: 0.8014, valid_loss_norm: 0.0500\n",
      " epoch: 16, train accuracy: 0.8104, train_loss_norm:0.0480, valid_acc: 0.8028, valid_loss_norm: 0.0488\n",
      " epoch: 17, train accuracy: 0.8114, train_loss_norm:0.0468, valid_acc: 0.8045, valid_loss_norm: 0.0476\n",
      " epoch: 18, train accuracy: 0.8129, train_loss_norm:0.0458, valid_acc: 0.8068, valid_loss_norm: 0.0466\n",
      " epoch: 19, train accuracy: 0.8141, train_loss_norm:0.0448, valid_acc: 0.8077, valid_loss_norm: 0.0456\n",
      " epoch: 20, train accuracy: 0.8157, train_loss_norm:0.0438, valid_acc: 0.8080, valid_loss_norm: 0.0447\n",
      " epoch: 21, train accuracy: 0.8171, train_loss_norm:0.0430, valid_acc: 0.8097, valid_loss_norm: 0.0439\n",
      " epoch: 22, train accuracy: 0.8181, train_loss_norm:0.0421, valid_acc: 0.8103, valid_loss_norm: 0.0431\n",
      " epoch: 23, train accuracy: 0.8194, train_loss_norm:0.0414, valid_acc: 0.8112, valid_loss_norm: 0.0423\n",
      " epoch: 24, train accuracy: 0.8209, train_loss_norm:0.0406, valid_acc: 0.8126, valid_loss_norm: 0.0416\n",
      " epoch: 25, train accuracy: 0.8223, train_loss_norm:0.0399, valid_acc: 0.8143, valid_loss_norm: 0.0409\n",
      " epoch: 26, train accuracy: 0.8232, train_loss_norm:0.0393, valid_acc: 0.8149, valid_loss_norm: 0.0403\n",
      " epoch: 27, train accuracy: 0.8247, train_loss_norm:0.0386, valid_acc: 0.8149, valid_loss_norm: 0.0397\n",
      " epoch: 28, train accuracy: 0.8258, train_loss_norm:0.0380, valid_acc: 0.8158, valid_loss_norm: 0.0391\n",
      " epoch: 29, train accuracy: 0.8264, train_loss_norm:0.0375, valid_acc: 0.8175, valid_loss_norm: 0.0385\n",
      " epoch: 30, train accuracy: 0.8275, train_loss_norm:0.0369, valid_acc: 0.8178, valid_loss_norm: 0.0380\n",
      " epoch: 31, train accuracy: 0.8286, train_loss_norm:0.0364, valid_acc: 0.8178, valid_loss_norm: 0.0375\n",
      " epoch: 32, train accuracy: 0.8294, train_loss_norm:0.0359, valid_acc: 0.8186, valid_loss_norm: 0.0370\n",
      " epoch: 33, train accuracy: 0.8304, train_loss_norm:0.0354, valid_acc: 0.8189, valid_loss_norm: 0.0365\n",
      " epoch: 34, train accuracy: 0.8316, train_loss_norm:0.0350, valid_acc: 0.8192, valid_loss_norm: 0.0361\n",
      " epoch: 35, train accuracy: 0.8327, train_loss_norm:0.0345, valid_acc: 0.8204, valid_loss_norm: 0.0357\n",
      " epoch: 36, train accuracy: 0.8338, train_loss_norm:0.0341, valid_acc: 0.8206, valid_loss_norm: 0.0353\n",
      " epoch: 37, train accuracy: 0.8346, train_loss_norm:0.0337, valid_acc: 0.8227, valid_loss_norm: 0.0349\n",
      " epoch: 38, train accuracy: 0.8352, train_loss_norm:0.0333, valid_acc: 0.8238, valid_loss_norm: 0.0345\n",
      " epoch: 39, train accuracy: 0.8359, train_loss_norm:0.0329, valid_acc: 0.8238, valid_loss_norm: 0.0341\n",
      " epoch: 40, train accuracy: 0.8362, train_loss_norm:0.0325, valid_acc: 0.8229, valid_loss_norm: 0.0338\n",
      " epoch: 41, train accuracy: 0.8374, train_loss_norm:0.0322, valid_acc: 0.8235, valid_loss_norm: 0.0334\n",
      " epoch: 42, train accuracy: 0.8381, train_loss_norm:0.0318, valid_acc: 0.8238, valid_loss_norm: 0.0331\n",
      " epoch: 43, train accuracy: 0.8389, train_loss_norm:0.0315, valid_acc: 0.8238, valid_loss_norm: 0.0328\n",
      " epoch: 44, train accuracy: 0.8398, train_loss_norm:0.0312, valid_acc: 0.8241, valid_loss_norm: 0.0325\n",
      " epoch: 45, train accuracy: 0.8406, train_loss_norm:0.0309, valid_acc: 0.8247, valid_loss_norm: 0.0322\n",
      " epoch: 46, train accuracy: 0.8415, train_loss_norm:0.0306, valid_acc: 0.8247, valid_loss_norm: 0.0319\n",
      " epoch: 47, train accuracy: 0.8419, train_loss_norm:0.0303, valid_acc: 0.8258, valid_loss_norm: 0.0316\n",
      " epoch: 48, train accuracy: 0.8427, train_loss_norm:0.0300, valid_acc: 0.8258, valid_loss_norm: 0.0313\n",
      " epoch: 49, train accuracy: 0.8432, train_loss_norm:0.0297, valid_acc: 0.8264, valid_loss_norm: 0.0311\n",
      " epoch: 50, train accuracy: 0.8438, train_loss_norm:0.0295, valid_acc: 0.8261, valid_loss_norm: 0.0308\n",
      " epoch: 51, train accuracy: 0.8444, train_loss_norm:0.0292, valid_acc: 0.8270, valid_loss_norm: 0.0306\n",
      " epoch: 52, train accuracy: 0.8451, train_loss_norm:0.0290, valid_acc: 0.8275, valid_loss_norm: 0.0303\n",
      " epoch: 53, train accuracy: 0.8456, train_loss_norm:0.0287, valid_acc: 0.8293, valid_loss_norm: 0.0301\n",
      " epoch: 54, train accuracy: 0.8464, train_loss_norm:0.0285, valid_acc: 0.8290, valid_loss_norm: 0.0299\n",
      " epoch: 55, train accuracy: 0.8469, train_loss_norm:0.0282, valid_acc: 0.8298, valid_loss_norm: 0.0296\n",
      " epoch: 56, train accuracy: 0.8472, train_loss_norm:0.0280, valid_acc: 0.8295, valid_loss_norm: 0.0294\n",
      " epoch: 57, train accuracy: 0.8476, train_loss_norm:0.0278, valid_acc: 0.8295, valid_loss_norm: 0.0292\n",
      " epoch: 58, train accuracy: 0.8481, train_loss_norm:0.0276, valid_acc: 0.8301, valid_loss_norm: 0.0290\n",
      " epoch: 59, train accuracy: 0.8484, train_loss_norm:0.0274, valid_acc: 0.8307, valid_loss_norm: 0.0288\n",
      " epoch: 60, train accuracy: 0.8489, train_loss_norm:0.0272, valid_acc: 0.8307, valid_loss_norm: 0.0286\n",
      " epoch: 61, train accuracy: 0.8497, train_loss_norm:0.0270, valid_acc: 0.8318, valid_loss_norm: 0.0284\n",
      " epoch: 62, train accuracy: 0.8500, train_loss_norm:0.0268, valid_acc: 0.8321, valid_loss_norm: 0.0283\n",
      " epoch: 63, train accuracy: 0.8507, train_loss_norm:0.0266, valid_acc: 0.8321, valid_loss_norm: 0.0281\n",
      " epoch: 64, train accuracy: 0.8510, train_loss_norm:0.0264, valid_acc: 0.8327, valid_loss_norm: 0.0279\n",
      " epoch: 65, train accuracy: 0.8516, train_loss_norm:0.0262, valid_acc: 0.8327, valid_loss_norm: 0.0277\n",
      " epoch: 66, train accuracy: 0.8521, train_loss_norm:0.0260, valid_acc: 0.8336, valid_loss_norm: 0.0276\n",
      " epoch: 67, train accuracy: 0.8524, train_loss_norm:0.0259, valid_acc: 0.8336, valid_loss_norm: 0.0274\n",
      " epoch: 68, train accuracy: 0.8527, train_loss_norm:0.0257, valid_acc: 0.8330, valid_loss_norm: 0.0272\n",
      " epoch: 69, train accuracy: 0.8530, train_loss_norm:0.0255, valid_acc: 0.8330, valid_loss_norm: 0.0271\n",
      " epoch: 70, train accuracy: 0.8534, train_loss_norm:0.0254, valid_acc: 0.8321, valid_loss_norm: 0.0269\n",
      " epoch: 71, train accuracy: 0.8539, train_loss_norm:0.0252, valid_acc: 0.8327, valid_loss_norm: 0.0268\n",
      " epoch: 72, train accuracy: 0.8545, train_loss_norm:0.0250, valid_acc: 0.8333, valid_loss_norm: 0.0266\n",
      " epoch: 73, train accuracy: 0.8550, train_loss_norm:0.0249, valid_acc: 0.8336, valid_loss_norm: 0.0265\n",
      " epoch: 74, train accuracy: 0.8554, train_loss_norm:0.0247, valid_acc: 0.8339, valid_loss_norm: 0.0263\n",
      " epoch: 75, train accuracy: 0.8557, train_loss_norm:0.0246, valid_acc: 0.8339, valid_loss_norm: 0.0262\n",
      " epoch: 76, train accuracy: 0.8559, train_loss_norm:0.0245, valid_acc: 0.8341, valid_loss_norm: 0.0261\n",
      " epoch: 77, train accuracy: 0.8563, train_loss_norm:0.0243, valid_acc: 0.8344, valid_loss_norm: 0.0259\n",
      " epoch: 78, train accuracy: 0.8569, train_loss_norm:0.0242, valid_acc: 0.8347, valid_loss_norm: 0.0258\n",
      " epoch: 79, train accuracy: 0.8573, train_loss_norm:0.0240, valid_acc: 0.8356, valid_loss_norm: 0.0257\n",
      " epoch: 80, train accuracy: 0.8577, train_loss_norm:0.0239, valid_acc: 0.8356, valid_loss_norm: 0.0256\n",
      " epoch: 81, train accuracy: 0.8581, train_loss_norm:0.0238, valid_acc: 0.8359, valid_loss_norm: 0.0254\n",
      " epoch: 82, train accuracy: 0.8584, train_loss_norm:0.0236, valid_acc: 0.8362, valid_loss_norm: 0.0253\n",
      " epoch: 83, train accuracy: 0.8586, train_loss_norm:0.0235, valid_acc: 0.8362, valid_loss_norm: 0.0252\n",
      " epoch: 84, train accuracy: 0.8589, train_loss_norm:0.0234, valid_acc: 0.8362, valid_loss_norm: 0.0251\n",
      " epoch: 85, train accuracy: 0.8595, train_loss_norm:0.0233, valid_acc: 0.8364, valid_loss_norm: 0.0250\n",
      " epoch: 86, train accuracy: 0.8597, train_loss_norm:0.0232, valid_acc: 0.8364, valid_loss_norm: 0.0249\n",
      " epoch: 87, train accuracy: 0.8598, train_loss_norm:0.0230, valid_acc: 0.8362, valid_loss_norm: 0.0248\n",
      " epoch: 88, train accuracy: 0.8601, train_loss_norm:0.0229, valid_acc: 0.8362, valid_loss_norm: 0.0247\n",
      " epoch: 89, train accuracy: 0.8606, train_loss_norm:0.0228, valid_acc: 0.8362, valid_loss_norm: 0.0246\n",
      " epoch: 90, train accuracy: 0.8609, train_loss_norm:0.0227, valid_acc: 0.8362, valid_loss_norm: 0.0244\n",
      " epoch: 91, train accuracy: 0.8612, train_loss_norm:0.0226, valid_acc: 0.8359, valid_loss_norm: 0.0243\n",
      " epoch: 92, train accuracy: 0.8614, train_loss_norm:0.0225, valid_acc: 0.8362, valid_loss_norm: 0.0242\n",
      " epoch: 93, train accuracy: 0.8618, train_loss_norm:0.0224, valid_acc: 0.8359, valid_loss_norm: 0.0241\n",
      " epoch: 94, train accuracy: 0.8620, train_loss_norm:0.0223, valid_acc: 0.8362, valid_loss_norm: 0.0241\n",
      " epoch: 95, train accuracy: 0.8623, train_loss_norm:0.0222, valid_acc: 0.8362, valid_loss_norm: 0.0240\n",
      " epoch: 96, train accuracy: 0.8626, train_loss_norm:0.0221, valid_acc: 0.8362, valid_loss_norm: 0.0239\n",
      " epoch: 97, train accuracy: 0.8629, train_loss_norm:0.0220, valid_acc: 0.8364, valid_loss_norm: 0.0238\n",
      " epoch: 98, train accuracy: 0.8633, train_loss_norm:0.0219, valid_acc: 0.8367, valid_loss_norm: 0.0237\n",
      " epoch: 99, train accuracy: 0.8638, train_loss_norm:0.0218, valid_acc: 0.8370, valid_loss_norm: 0.0236\n",
      " epoch: 100, train accuracy: 0.8641, train_loss_norm:0.0217, valid_acc: 0.8370, valid_loss_norm: 0.0235\n",
      " epoch: 101, train accuracy: 0.8644, train_loss_norm:0.0216, valid_acc: 0.8370, valid_loss_norm: 0.0234\n",
      " epoch: 102, train accuracy: 0.8646, train_loss_norm:0.0215, valid_acc: 0.8373, valid_loss_norm: 0.0233\n",
      " epoch: 103, train accuracy: 0.8649, train_loss_norm:0.0214, valid_acc: 0.8373, valid_loss_norm: 0.0233\n",
      " epoch: 104, train accuracy: 0.8650, train_loss_norm:0.0213, valid_acc: 0.8370, valid_loss_norm: 0.0232\n",
      " epoch: 105, train accuracy: 0.8653, train_loss_norm:0.0212, valid_acc: 0.8373, valid_loss_norm: 0.0231\n",
      " epoch: 106, train accuracy: 0.8660, train_loss_norm:0.0211, valid_acc: 0.8376, valid_loss_norm: 0.0230\n",
      " epoch: 107, train accuracy: 0.8664, train_loss_norm:0.0211, valid_acc: 0.8379, valid_loss_norm: 0.0229\n",
      " epoch: 108, train accuracy: 0.8669, train_loss_norm:0.0210, valid_acc: 0.8385, valid_loss_norm: 0.0229\n",
      " epoch: 109, train accuracy: 0.8670, train_loss_norm:0.0209, valid_acc: 0.8387, valid_loss_norm: 0.0228\n",
      " epoch: 110, train accuracy: 0.8673, train_loss_norm:0.0208, valid_acc: 0.8393, valid_loss_norm: 0.0227\n",
      " epoch: 111, train accuracy: 0.8675, train_loss_norm:0.0207, valid_acc: 0.8402, valid_loss_norm: 0.0226\n",
      " epoch: 112, train accuracy: 0.8679, train_loss_norm:0.0206, valid_acc: 0.8405, valid_loss_norm: 0.0226\n",
      " epoch: 113, train accuracy: 0.8684, train_loss_norm:0.0206, valid_acc: 0.8408, valid_loss_norm: 0.0225\n",
      " epoch: 114, train accuracy: 0.8688, train_loss_norm:0.0205, valid_acc: 0.8408, valid_loss_norm: 0.0224\n",
      " epoch: 115, train accuracy: 0.8691, train_loss_norm:0.0204, valid_acc: 0.8410, valid_loss_norm: 0.0224\n",
      " epoch: 116, train accuracy: 0.8694, train_loss_norm:0.0203, valid_acc: 0.8413, valid_loss_norm: 0.0223\n",
      " epoch: 117, train accuracy: 0.8696, train_loss_norm:0.0203, valid_acc: 0.8416, valid_loss_norm: 0.0222\n",
      " epoch: 118, train accuracy: 0.8699, train_loss_norm:0.0202, valid_acc: 0.8413, valid_loss_norm: 0.0221\n",
      " epoch: 119, train accuracy: 0.8702, train_loss_norm:0.0201, valid_acc: 0.8413, valid_loss_norm: 0.0221\n",
      " epoch: 120, train accuracy: 0.8703, train_loss_norm:0.0200, valid_acc: 0.8413, valid_loss_norm: 0.0220\n",
      " epoch: 121, train accuracy: 0.8706, train_loss_norm:0.0200, valid_acc: 0.8419, valid_loss_norm: 0.0220\n",
      " epoch: 122, train accuracy: 0.8708, train_loss_norm:0.0199, valid_acc: 0.8425, valid_loss_norm: 0.0219\n",
      " epoch: 123, train accuracy: 0.8708, train_loss_norm:0.0198, valid_acc: 0.8422, valid_loss_norm: 0.0218\n",
      " epoch: 124, train accuracy: 0.8711, train_loss_norm:0.0198, valid_acc: 0.8422, valid_loss_norm: 0.0218\n",
      " epoch: 125, train accuracy: 0.8713, train_loss_norm:0.0197, valid_acc: 0.8428, valid_loss_norm: 0.0217\n",
      " epoch: 126, train accuracy: 0.8716, train_loss_norm:0.0196, valid_acc: 0.8431, valid_loss_norm: 0.0216\n",
      " epoch: 127, train accuracy: 0.8716, train_loss_norm:0.0196, valid_acc: 0.8431, valid_loss_norm: 0.0216\n",
      " epoch: 128, train accuracy: 0.8719, train_loss_norm:0.0195, valid_acc: 0.8436, valid_loss_norm: 0.0215\n",
      " epoch: 129, train accuracy: 0.8722, train_loss_norm:0.0194, valid_acc: 0.8436, valid_loss_norm: 0.0215\n",
      " epoch: 130, train accuracy: 0.8725, train_loss_norm:0.0194, valid_acc: 0.8439, valid_loss_norm: 0.0214\n",
      " epoch: 131, train accuracy: 0.8725, train_loss_norm:0.0193, valid_acc: 0.8439, valid_loss_norm: 0.0214\n",
      " epoch: 132, train accuracy: 0.8728, train_loss_norm:0.0192, valid_acc: 0.8439, valid_loss_norm: 0.0213\n",
      " epoch: 133, train accuracy: 0.8732, train_loss_norm:0.0192, valid_acc: 0.8442, valid_loss_norm: 0.0212\n",
      " epoch: 134, train accuracy: 0.8734, train_loss_norm:0.0191, valid_acc: 0.8442, valid_loss_norm: 0.0212\n",
      " epoch: 135, train accuracy: 0.8739, train_loss_norm:0.0191, valid_acc: 0.8445, valid_loss_norm: 0.0211\n",
      " epoch: 136, train accuracy: 0.8741, train_loss_norm:0.0190, valid_acc: 0.8445, valid_loss_norm: 0.0211\n",
      " epoch: 137, train accuracy: 0.8744, train_loss_norm:0.0189, valid_acc: 0.8445, valid_loss_norm: 0.0210\n",
      " epoch: 138, train accuracy: 0.8748, train_loss_norm:0.0189, valid_acc: 0.8448, valid_loss_norm: 0.0210\n",
      " epoch: 139, train accuracy: 0.8750, train_loss_norm:0.0188, valid_acc: 0.8448, valid_loss_norm: 0.0209\n",
      " epoch: 140, train accuracy: 0.8751, train_loss_norm:0.0188, valid_acc: 0.8448, valid_loss_norm: 0.0209\n",
      " epoch: 141, train accuracy: 0.8754, train_loss_norm:0.0187, valid_acc: 0.8448, valid_loss_norm: 0.0208\n",
      " epoch: 142, train accuracy: 0.8758, train_loss_norm:0.0187, valid_acc: 0.8448, valid_loss_norm: 0.0208\n",
      " epoch: 143, train accuracy: 0.8762, train_loss_norm:0.0186, valid_acc: 0.8448, valid_loss_norm: 0.0207\n",
      " epoch: 144, train accuracy: 0.8765, train_loss_norm:0.0186, valid_acc: 0.8445, valid_loss_norm: 0.0207\n",
      " epoch: 145, train accuracy: 0.8768, train_loss_norm:0.0185, valid_acc: 0.8451, valid_loss_norm: 0.0206\n",
      " epoch: 146, train accuracy: 0.8770, train_loss_norm:0.0184, valid_acc: 0.8451, valid_loss_norm: 0.0206\n",
      " epoch: 147, train accuracy: 0.8772, train_loss_norm:0.0184, valid_acc: 0.8456, valid_loss_norm: 0.0205\n",
      " epoch: 148, train accuracy: 0.8776, train_loss_norm:0.0183, valid_acc: 0.8456, valid_loss_norm: 0.0205\n",
      " epoch: 149, train accuracy: 0.8777, train_loss_norm:0.0183, valid_acc: 0.8462, valid_loss_norm: 0.0204\n",
      " epoch: 150, train accuracy: 0.8777, train_loss_norm:0.0182, valid_acc: 0.8468, valid_loss_norm: 0.0204\n",
      " epoch: 151, train accuracy: 0.8778, train_loss_norm:0.0182, valid_acc: 0.8477, valid_loss_norm: 0.0204\n",
      " epoch: 152, train accuracy: 0.8779, train_loss_norm:0.0181, valid_acc: 0.8474, valid_loss_norm: 0.0203\n",
      " epoch: 153, train accuracy: 0.8782, train_loss_norm:0.0181, valid_acc: 0.8474, valid_loss_norm: 0.0203\n",
      " epoch: 154, train accuracy: 0.8785, train_loss_norm:0.0180, valid_acc: 0.8474, valid_loss_norm: 0.0202\n",
      " epoch: 155, train accuracy: 0.8787, train_loss_norm:0.0180, valid_acc: 0.8477, valid_loss_norm: 0.0202\n",
      " epoch: 156, train accuracy: 0.8790, train_loss_norm:0.0179, valid_acc: 0.8479, valid_loss_norm: 0.0201\n",
      " epoch: 157, train accuracy: 0.8791, train_loss_norm:0.0179, valid_acc: 0.8482, valid_loss_norm: 0.0201\n",
      " epoch: 158, train accuracy: 0.8793, train_loss_norm:0.0178, valid_acc: 0.8485, valid_loss_norm: 0.0200\n",
      " epoch: 159, train accuracy: 0.8793, train_loss_norm:0.0178, valid_acc: 0.8491, valid_loss_norm: 0.0200\n",
      " epoch: 160, train accuracy: 0.8795, train_loss_norm:0.0178, valid_acc: 0.8491, valid_loss_norm: 0.0200\n",
      " epoch: 161, train accuracy: 0.8797, train_loss_norm:0.0177, valid_acc: 0.8491, valid_loss_norm: 0.0199\n",
      " epoch: 162, train accuracy: 0.8801, train_loss_norm:0.0177, valid_acc: 0.8494, valid_loss_norm: 0.0199\n",
      " epoch: 163, train accuracy: 0.8802, train_loss_norm:0.0176, valid_acc: 0.8497, valid_loss_norm: 0.0198\n",
      " epoch: 164, train accuracy: 0.8803, train_loss_norm:0.0176, valid_acc: 0.8497, valid_loss_norm: 0.0198\n",
      " epoch: 165, train accuracy: 0.8806, train_loss_norm:0.0175, valid_acc: 0.8497, valid_loss_norm: 0.0198\n",
      " epoch: 166, train accuracy: 0.8809, train_loss_norm:0.0175, valid_acc: 0.8497, valid_loss_norm: 0.0197\n",
      " epoch: 167, train accuracy: 0.8810, train_loss_norm:0.0174, valid_acc: 0.8502, valid_loss_norm: 0.0197\n",
      " epoch: 168, train accuracy: 0.8811, train_loss_norm:0.0174, valid_acc: 0.8505, valid_loss_norm: 0.0197\n",
      " epoch: 169, train accuracy: 0.8814, train_loss_norm:0.0174, valid_acc: 0.8505, valid_loss_norm: 0.0196\n",
      " epoch: 170, train accuracy: 0.8814, train_loss_norm:0.0173, valid_acc: 0.8508, valid_loss_norm: 0.0196\n",
      " epoch: 171, train accuracy: 0.8816, train_loss_norm:0.0173, valid_acc: 0.8505, valid_loss_norm: 0.0195\n",
      " epoch: 172, train accuracy: 0.8818, train_loss_norm:0.0172, valid_acc: 0.8508, valid_loss_norm: 0.0195\n",
      " epoch: 173, train accuracy: 0.8819, train_loss_norm:0.0172, valid_acc: 0.8511, valid_loss_norm: 0.0195\n",
      " epoch: 174, train accuracy: 0.8821, train_loss_norm:0.0171, valid_acc: 0.8514, valid_loss_norm: 0.0194\n",
      " epoch: 175, train accuracy: 0.8822, train_loss_norm:0.0171, valid_acc: 0.8514, valid_loss_norm: 0.0194\n",
      " epoch: 176, train accuracy: 0.8823, train_loss_norm:0.0171, valid_acc: 0.8517, valid_loss_norm: 0.0194\n",
      " epoch: 177, train accuracy: 0.8824, train_loss_norm:0.0170, valid_acc: 0.8517, valid_loss_norm: 0.0193\n",
      " epoch: 178, train accuracy: 0.8826, train_loss_norm:0.0170, valid_acc: 0.8514, valid_loss_norm: 0.0193\n",
      " epoch: 179, train accuracy: 0.8827, train_loss_norm:0.0169, valid_acc: 0.8517, valid_loss_norm: 0.0193\n",
      " epoch: 180, train accuracy: 0.8829, train_loss_norm:0.0169, valid_acc: 0.8514, valid_loss_norm: 0.0192\n",
      " epoch: 181, train accuracy: 0.8832, train_loss_norm:0.0169, valid_acc: 0.8517, valid_loss_norm: 0.0192\n",
      " epoch: 182, train accuracy: 0.8834, train_loss_norm:0.0168, valid_acc: 0.8517, valid_loss_norm: 0.0192\n",
      " epoch: 183, train accuracy: 0.8836, train_loss_norm:0.0168, valid_acc: 0.8520, valid_loss_norm: 0.0191\n",
      " epoch: 184, train accuracy: 0.8837, train_loss_norm:0.0168, valid_acc: 0.8528, valid_loss_norm: 0.0191\n",
      " epoch: 185, train accuracy: 0.8838, train_loss_norm:0.0167, valid_acc: 0.8531, valid_loss_norm: 0.0191\n",
      " epoch: 186, train accuracy: 0.8839, train_loss_norm:0.0167, valid_acc: 0.8534, valid_loss_norm: 0.0190\n",
      " epoch: 187, train accuracy: 0.8841, train_loss_norm:0.0166, valid_acc: 0.8534, valid_loss_norm: 0.0190\n",
      " epoch: 188, train accuracy: 0.8842, train_loss_norm:0.0166, valid_acc: 0.8540, valid_loss_norm: 0.0190\n",
      " epoch: 189, train accuracy: 0.8843, train_loss_norm:0.0166, valid_acc: 0.8543, valid_loss_norm: 0.0189\n",
      " epoch: 190, train accuracy: 0.8845, train_loss_norm:0.0165, valid_acc: 0.8543, valid_loss_norm: 0.0189\n",
      " epoch: 191, train accuracy: 0.8847, train_loss_norm:0.0165, valid_acc: 0.8548, valid_loss_norm: 0.0189\n",
      " epoch: 192, train accuracy: 0.8849, train_loss_norm:0.0165, valid_acc: 0.8551, valid_loss_norm: 0.0188\n",
      " epoch: 193, train accuracy: 0.8851, train_loss_norm:0.0164, valid_acc: 0.8563, valid_loss_norm: 0.0188\n",
      " epoch: 194, train accuracy: 0.8853, train_loss_norm:0.0164, valid_acc: 0.8563, valid_loss_norm: 0.0188\n",
      " epoch: 195, train accuracy: 0.8855, train_loss_norm:0.0164, valid_acc: 0.8563, valid_loss_norm: 0.0187\n",
      " epoch: 196, train accuracy: 0.8856, train_loss_norm:0.0163, valid_acc: 0.8566, valid_loss_norm: 0.0187\n",
      " epoch: 197, train accuracy: 0.8857, train_loss_norm:0.0163, valid_acc: 0.8566, valid_loss_norm: 0.0187\n",
      " epoch: 198, train accuracy: 0.8859, train_loss_norm:0.0163, valid_acc: 0.8569, valid_loss_norm: 0.0187\n",
      " epoch: 199, train accuracy: 0.8861, train_loss_norm:0.0162, valid_acc: 0.8566, valid_loss_norm: 0.0186\n",
      " epoch: 200, train accuracy: 0.8862, train_loss_norm:0.0162, valid_acc: 0.8566, valid_loss_norm: 0.0186\n",
      " epoch: 201, train accuracy: 0.8865, train_loss_norm:0.0162, valid_acc: 0.8569, valid_loss_norm: 0.0186\n",
      " epoch: 202, train accuracy: 0.8865, train_loss_norm:0.0161, valid_acc: 0.8569, valid_loss_norm: 0.0185\n",
      " epoch: 203, train accuracy: 0.8868, train_loss_norm:0.0161, valid_acc: 0.8569, valid_loss_norm: 0.0185\n",
      " epoch: 204, train accuracy: 0.8869, train_loss_norm:0.0161, valid_acc: 0.8569, valid_loss_norm: 0.0185\n",
      " epoch: 205, train accuracy: 0.8871, train_loss_norm:0.0160, valid_acc: 0.8569, valid_loss_norm: 0.0185\n",
      " epoch: 206, train accuracy: 0.8871, train_loss_norm:0.0160, valid_acc: 0.8574, valid_loss_norm: 0.0184\n",
      " epoch: 207, train accuracy: 0.8873, train_loss_norm:0.0160, valid_acc: 0.8574, valid_loss_norm: 0.0184\n",
      " epoch: 208, train accuracy: 0.8875, train_loss_norm:0.0159, valid_acc: 0.8574, valid_loss_norm: 0.0184\n",
      " epoch: 209, train accuracy: 0.8875, train_loss_norm:0.0159, valid_acc: 0.8577, valid_loss_norm: 0.0183\n",
      " epoch: 210, train accuracy: 0.8878, train_loss_norm:0.0159, valid_acc: 0.8580, valid_loss_norm: 0.0183\n",
      " epoch: 211, train accuracy: 0.8878, train_loss_norm:0.0158, valid_acc: 0.8583, valid_loss_norm: 0.0183\n",
      " epoch: 212, train accuracy: 0.8880, train_loss_norm:0.0158, valid_acc: 0.8583, valid_loss_norm: 0.0183\n",
      " epoch: 213, train accuracy: 0.8882, train_loss_norm:0.0158, valid_acc: 0.8583, valid_loss_norm: 0.0182\n",
      " epoch: 214, train accuracy: 0.8885, train_loss_norm:0.0157, valid_acc: 0.8583, valid_loss_norm: 0.0182\n",
      " epoch: 215, train accuracy: 0.8887, train_loss_norm:0.0157, valid_acc: 0.8586, valid_loss_norm: 0.0182\n",
      " epoch: 216, train accuracy: 0.8888, train_loss_norm:0.0157, valid_acc: 0.8586, valid_loss_norm: 0.0182\n",
      " epoch: 217, train accuracy: 0.8890, train_loss_norm:0.0157, valid_acc: 0.8586, valid_loss_norm: 0.0181\n",
      " epoch: 218, train accuracy: 0.8893, train_loss_norm:0.0156, valid_acc: 0.8586, valid_loss_norm: 0.0181\n",
      " epoch: 219, train accuracy: 0.8893, train_loss_norm:0.0156, valid_acc: 0.8586, valid_loss_norm: 0.0181\n",
      " epoch: 220, train accuracy: 0.8894, train_loss_norm:0.0156, valid_acc: 0.8589, valid_loss_norm: 0.0181\n",
      " epoch: 221, train accuracy: 0.8897, train_loss_norm:0.0155, valid_acc: 0.8589, valid_loss_norm: 0.0180\n",
      " epoch: 222, train accuracy: 0.8899, train_loss_norm:0.0155, valid_acc: 0.8589, valid_loss_norm: 0.0180\n",
      " epoch: 223, train accuracy: 0.8901, train_loss_norm:0.0155, valid_acc: 0.8589, valid_loss_norm: 0.0180\n",
      " epoch: 224, train accuracy: 0.8901, train_loss_norm:0.0155, valid_acc: 0.8592, valid_loss_norm: 0.0180\n",
      " epoch: 225, train accuracy: 0.8902, train_loss_norm:0.0154, valid_acc: 0.8592, valid_loss_norm: 0.0179\n",
      " epoch: 226, train accuracy: 0.8903, train_loss_norm:0.0154, valid_acc: 0.8592, valid_loss_norm: 0.0179\n",
      " epoch: 227, train accuracy: 0.8905, train_loss_norm:0.0154, valid_acc: 0.8594, valid_loss_norm: 0.0179\n",
      " epoch: 228, train accuracy: 0.8906, train_loss_norm:0.0153, valid_acc: 0.8594, valid_loss_norm: 0.0179\n",
      " epoch: 229, train accuracy: 0.8906, train_loss_norm:0.0153, valid_acc: 0.8594, valid_loss_norm: 0.0179\n",
      " epoch: 230, train accuracy: 0.8908, train_loss_norm:0.0153, valid_acc: 0.8594, valid_loss_norm: 0.0178\n",
      " epoch: 231, train accuracy: 0.8910, train_loss_norm:0.0153, valid_acc: 0.8594, valid_loss_norm: 0.0178\n",
      " epoch: 232, train accuracy: 0.8910, train_loss_norm:0.0152, valid_acc: 0.8594, valid_loss_norm: 0.0178\n",
      " epoch: 233, train accuracy: 0.8910, train_loss_norm:0.0152, valid_acc: 0.8594, valid_loss_norm: 0.0178\n",
      " epoch: 234, train accuracy: 0.8912, train_loss_norm:0.0152, valid_acc: 0.8594, valid_loss_norm: 0.0177\n",
      " epoch: 235, train accuracy: 0.8913, train_loss_norm:0.0152, valid_acc: 0.8600, valid_loss_norm: 0.0177\n",
      " epoch: 236, train accuracy: 0.8916, train_loss_norm:0.0151, valid_acc: 0.8600, valid_loss_norm: 0.0177\n",
      " epoch: 237, train accuracy: 0.8916, train_loss_norm:0.0151, valid_acc: 0.8606, valid_loss_norm: 0.0177\n",
      " epoch: 238, train accuracy: 0.8917, train_loss_norm:0.0151, valid_acc: 0.8606, valid_loss_norm: 0.0176\n",
      " epoch: 239, train accuracy: 0.8920, train_loss_norm:0.0151, valid_acc: 0.8612, valid_loss_norm: 0.0176\n",
      " epoch: 240, train accuracy: 0.8921, train_loss_norm:0.0150, valid_acc: 0.8615, valid_loss_norm: 0.0176\n",
      " epoch: 241, train accuracy: 0.8922, train_loss_norm:0.0150, valid_acc: 0.8620, valid_loss_norm: 0.0176\n",
      " epoch: 242, train accuracy: 0.8925, train_loss_norm:0.0150, valid_acc: 0.8620, valid_loss_norm: 0.0176\n",
      " epoch: 243, train accuracy: 0.8926, train_loss_norm:0.0150, valid_acc: 0.8623, valid_loss_norm: 0.0175\n",
      " epoch: 244, train accuracy: 0.8927, train_loss_norm:0.0149, valid_acc: 0.8623, valid_loss_norm: 0.0175\n",
      " epoch: 245, train accuracy: 0.8930, train_loss_norm:0.0149, valid_acc: 0.8623, valid_loss_norm: 0.0175\n",
      " epoch: 246, train accuracy: 0.8933, train_loss_norm:0.0149, valid_acc: 0.8620, valid_loss_norm: 0.0175\n",
      " epoch: 247, train accuracy: 0.8935, train_loss_norm:0.0149, valid_acc: 0.8623, valid_loss_norm: 0.0175\n",
      " epoch: 248, train accuracy: 0.8935, train_loss_norm:0.0148, valid_acc: 0.8626, valid_loss_norm: 0.0174\n",
      " epoch: 249, train accuracy: 0.8936, train_loss_norm:0.0148, valid_acc: 0.8626, valid_loss_norm: 0.0174\n",
      " epoch: 250, train accuracy: 0.8937, train_loss_norm:0.0148, valid_acc: 0.8626, valid_loss_norm: 0.0174\n",
      " epoch: 251, train accuracy: 0.8937, train_loss_norm:0.0148, valid_acc: 0.8626, valid_loss_norm: 0.0174\n",
      " epoch: 252, train accuracy: 0.8939, train_loss_norm:0.0147, valid_acc: 0.8629, valid_loss_norm: 0.0174\n",
      " epoch: 253, train accuracy: 0.8939, train_loss_norm:0.0147, valid_acc: 0.8629, valid_loss_norm: 0.0173\n",
      " epoch: 254, train accuracy: 0.8940, train_loss_norm:0.0147, valid_acc: 0.8635, valid_loss_norm: 0.0173\n",
      " epoch: 255, train accuracy: 0.8942, train_loss_norm:0.0147, valid_acc: 0.8635, valid_loss_norm: 0.0173\n",
      " epoch: 256, train accuracy: 0.8943, train_loss_norm:0.0146, valid_acc: 0.8635, valid_loss_norm: 0.0173\n",
      " epoch: 257, train accuracy: 0.8945, train_loss_norm:0.0146, valid_acc: 0.8632, valid_loss_norm: 0.0173\n",
      " epoch: 258, train accuracy: 0.8945, train_loss_norm:0.0146, valid_acc: 0.8635, valid_loss_norm: 0.0172\n",
      " epoch: 259, train accuracy: 0.8946, train_loss_norm:0.0146, valid_acc: 0.8635, valid_loss_norm: 0.0172\n",
      " epoch: 260, train accuracy: 0.8947, train_loss_norm:0.0146, valid_acc: 0.8635, valid_loss_norm: 0.0172\n",
      " epoch: 261, train accuracy: 0.8948, train_loss_norm:0.0145, valid_acc: 0.8635, valid_loss_norm: 0.0172\n",
      " epoch: 262, train accuracy: 0.8950, train_loss_norm:0.0145, valid_acc: 0.8638, valid_loss_norm: 0.0172\n",
      " epoch: 263, train accuracy: 0.8950, train_loss_norm:0.0145, valid_acc: 0.8638, valid_loss_norm: 0.0171\n",
      " epoch: 264, train accuracy: 0.8953, train_loss_norm:0.0145, valid_acc: 0.8640, valid_loss_norm: 0.0171\n",
      " epoch: 265, train accuracy: 0.8954, train_loss_norm:0.0144, valid_acc: 0.8640, valid_loss_norm: 0.0171\n",
      " epoch: 266, train accuracy: 0.8956, train_loss_norm:0.0144, valid_acc: 0.8640, valid_loss_norm: 0.0171\n",
      " epoch: 267, train accuracy: 0.8957, train_loss_norm:0.0144, valid_acc: 0.8638, valid_loss_norm: 0.0171\n",
      " epoch: 268, train accuracy: 0.8960, train_loss_norm:0.0144, valid_acc: 0.8640, valid_loss_norm: 0.0171\n",
      " epoch: 269, train accuracy: 0.8961, train_loss_norm:0.0144, valid_acc: 0.8640, valid_loss_norm: 0.0170\n",
      " epoch: 270, train accuracy: 0.8962, train_loss_norm:0.0143, valid_acc: 0.8643, valid_loss_norm: 0.0170\n",
      " epoch: 271, train accuracy: 0.8962, train_loss_norm:0.0143, valid_acc: 0.8646, valid_loss_norm: 0.0170\n",
      " epoch: 272, train accuracy: 0.8963, train_loss_norm:0.0143, valid_acc: 0.8646, valid_loss_norm: 0.0170\n",
      " epoch: 273, train accuracy: 0.8963, train_loss_norm:0.0143, valid_acc: 0.8649, valid_loss_norm: 0.0170\n",
      " epoch: 274, train accuracy: 0.8965, train_loss_norm:0.0143, valid_acc: 0.8649, valid_loss_norm: 0.0169\n",
      " epoch: 275, train accuracy: 0.8967, train_loss_norm:0.0142, valid_acc: 0.8649, valid_loss_norm: 0.0169\n",
      " epoch: 276, train accuracy: 0.8970, train_loss_norm:0.0142, valid_acc: 0.8649, valid_loss_norm: 0.0169\n",
      " epoch: 277, train accuracy: 0.8971, train_loss_norm:0.0142, valid_acc: 0.8649, valid_loss_norm: 0.0169\n",
      " epoch: 278, train accuracy: 0.8973, train_loss_norm:0.0142, valid_acc: 0.8655, valid_loss_norm: 0.0169\n",
      " epoch: 279, train accuracy: 0.8973, train_loss_norm:0.0141, valid_acc: 0.8655, valid_loss_norm: 0.0169\n",
      " epoch: 280, train accuracy: 0.8974, train_loss_norm:0.0141, valid_acc: 0.8655, valid_loss_norm: 0.0168\n",
      " epoch: 281, train accuracy: 0.8977, train_loss_norm:0.0141, valid_acc: 0.8658, valid_loss_norm: 0.0168\n",
      " epoch: 282, train accuracy: 0.8978, train_loss_norm:0.0141, valid_acc: 0.8658, valid_loss_norm: 0.0168\n",
      " epoch: 283, train accuracy: 0.8980, train_loss_norm:0.0141, valid_acc: 0.8658, valid_loss_norm: 0.0168\n",
      " epoch: 284, train accuracy: 0.8981, train_loss_norm:0.0140, valid_acc: 0.8658, valid_loss_norm: 0.0168\n",
      " epoch: 285, train accuracy: 0.8982, train_loss_norm:0.0140, valid_acc: 0.8661, valid_loss_norm: 0.0168\n",
      " epoch: 286, train accuracy: 0.8986, train_loss_norm:0.0140, valid_acc: 0.8658, valid_loss_norm: 0.0167\n",
      " epoch: 287, train accuracy: 0.8986, train_loss_norm:0.0140, valid_acc: 0.8658, valid_loss_norm: 0.0167\n",
      " epoch: 288, train accuracy: 0.8986, train_loss_norm:0.0140, valid_acc: 0.8658, valid_loss_norm: 0.0167\n",
      " epoch: 289, train accuracy: 0.8988, train_loss_norm:0.0139, valid_acc: 0.8658, valid_loss_norm: 0.0167\n",
      " epoch: 290, train accuracy: 0.8989, train_loss_norm:0.0139, valid_acc: 0.8658, valid_loss_norm: 0.0167\n",
      " epoch: 291, train accuracy: 0.8989, train_loss_norm:0.0139, valid_acc: 0.8661, valid_loss_norm: 0.0167\n",
      " epoch: 292, train accuracy: 0.8991, train_loss_norm:0.0139, valid_acc: 0.8661, valid_loss_norm: 0.0166\n",
      " epoch: 293, train accuracy: 0.8991, train_loss_norm:0.0139, valid_acc: 0.8661, valid_loss_norm: 0.0166\n",
      " epoch: 294, train accuracy: 0.8992, train_loss_norm:0.0139, valid_acc: 0.8658, valid_loss_norm: 0.0166\n",
      " epoch: 295, train accuracy: 0.8993, train_loss_norm:0.0138, valid_acc: 0.8661, valid_loss_norm: 0.0166\n",
      " epoch: 296, train accuracy: 0.8994, train_loss_norm:0.0138, valid_acc: 0.8661, valid_loss_norm: 0.0166\n",
      " epoch: 297, train accuracy: 0.8995, train_loss_norm:0.0138, valid_acc: 0.8661, valid_loss_norm: 0.0166\n",
      " epoch: 298, train accuracy: 0.8997, train_loss_norm:0.0138, valid_acc: 0.8663, valid_loss_norm: 0.0166\n",
      " epoch: 299, train accuracy: 0.8998, train_loss_norm:0.0138, valid_acc: 0.8663, valid_loss_norm: 0.0165\n",
      " epoch: 300, train accuracy: 0.8999, train_loss_norm:0.0137, valid_acc: 0.8666, valid_loss_norm: 0.0165\n",
      "Test accuracy: 0.8649\n",
      "Test loss norm: 0.0168\n",
      "Cur fold: 8\n",
      "(27841, 300)\n",
      "(3479, 300)\n",
      "(3479, 300)\n",
      " epoch: 1, train accuracy: 0.7929, train_loss_norm:0.0836, valid_acc: 0.7810, valid_loss_norm: 0.0837\n",
      " epoch: 2, train accuracy: 0.7929, train_loss_norm:0.0799, valid_acc: 0.7813, valid_loss_norm: 0.0801\n",
      " epoch: 3, train accuracy: 0.7931, train_loss_norm:0.0764, valid_acc: 0.7810, valid_loss_norm: 0.0766\n",
      " epoch: 4, train accuracy: 0.7936, train_loss_norm:0.0730, valid_acc: 0.7813, valid_loss_norm: 0.0733\n",
      " epoch: 5, train accuracy: 0.7944, train_loss_norm:0.0698, valid_acc: 0.7815, valid_loss_norm: 0.0701\n",
      " epoch: 6, train accuracy: 0.7956, train_loss_norm:0.0668, valid_acc: 0.7821, valid_loss_norm: 0.0672\n",
      " epoch: 7, train accuracy: 0.7966, train_loss_norm:0.0641, valid_acc: 0.7827, valid_loss_norm: 0.0646\n",
      " epoch: 8, train accuracy: 0.7976, train_loss_norm:0.0615, valid_acc: 0.7838, valid_loss_norm: 0.0621\n",
      " epoch: 9, train accuracy: 0.7990, train_loss_norm:0.0593, valid_acc: 0.7861, valid_loss_norm: 0.0599\n",
      " epoch: 10, train accuracy: 0.8007, train_loss_norm:0.0572, valid_acc: 0.7870, valid_loss_norm: 0.0579\n",
      " epoch: 11, train accuracy: 0.8027, train_loss_norm:0.0553, valid_acc: 0.7890, valid_loss_norm: 0.0560\n",
      " epoch: 12, train accuracy: 0.8041, train_loss_norm:0.0536, valid_acc: 0.7910, valid_loss_norm: 0.0543\n",
      " epoch: 13, train accuracy: 0.8055, train_loss_norm:0.0520, valid_acc: 0.7919, valid_loss_norm: 0.0528\n",
      " epoch: 14, train accuracy: 0.8068, train_loss_norm:0.0506, valid_acc: 0.7925, valid_loss_norm: 0.0514\n",
      " epoch: 15, train accuracy: 0.8085, train_loss_norm:0.0492, valid_acc: 0.7939, valid_loss_norm: 0.0501\n",
      " epoch: 16, train accuracy: 0.8097, train_loss_norm:0.0480, valid_acc: 0.7965, valid_loss_norm: 0.0489\n",
      " epoch: 17, train accuracy: 0.8115, train_loss_norm:0.0468, valid_acc: 0.7976, valid_loss_norm: 0.0478\n",
      " epoch: 18, train accuracy: 0.8125, train_loss_norm:0.0458, valid_acc: 0.7979, valid_loss_norm: 0.0467\n",
      " epoch: 19, train accuracy: 0.8142, train_loss_norm:0.0448, valid_acc: 0.7999, valid_loss_norm: 0.0458\n",
      " epoch: 20, train accuracy: 0.8155, train_loss_norm:0.0438, valid_acc: 0.8008, valid_loss_norm: 0.0449\n",
      " epoch: 21, train accuracy: 0.8170, train_loss_norm:0.0430, valid_acc: 0.8020, valid_loss_norm: 0.0440\n",
      " epoch: 22, train accuracy: 0.8184, train_loss_norm:0.0421, valid_acc: 0.8020, valid_loss_norm: 0.0432\n",
      " epoch: 23, train accuracy: 0.8195, train_loss_norm:0.0413, valid_acc: 0.8028, valid_loss_norm: 0.0425\n",
      " epoch: 24, train accuracy: 0.8206, train_loss_norm:0.0406, valid_acc: 0.8037, valid_loss_norm: 0.0418\n",
      " epoch: 25, train accuracy: 0.8217, train_loss_norm:0.0399, valid_acc: 0.8048, valid_loss_norm: 0.0411\n",
      " epoch: 26, train accuracy: 0.8227, train_loss_norm:0.0393, valid_acc: 0.8057, valid_loss_norm: 0.0404\n",
      " epoch: 27, train accuracy: 0.8241, train_loss_norm:0.0386, valid_acc: 0.8066, valid_loss_norm: 0.0398\n",
      " epoch: 28, train accuracy: 0.8251, train_loss_norm:0.0380, valid_acc: 0.8066, valid_loss_norm: 0.0393\n",
      " epoch: 29, train accuracy: 0.8259, train_loss_norm:0.0375, valid_acc: 0.8080, valid_loss_norm: 0.0387\n",
      " epoch: 30, train accuracy: 0.8268, train_loss_norm:0.0369, valid_acc: 0.8083, valid_loss_norm: 0.0382\n",
      " epoch: 31, train accuracy: 0.8275, train_loss_norm:0.0364, valid_acc: 0.8091, valid_loss_norm: 0.0377\n",
      " epoch: 32, train accuracy: 0.8285, train_loss_norm:0.0359, valid_acc: 0.8091, valid_loss_norm: 0.0372\n",
      " epoch: 33, train accuracy: 0.8295, train_loss_norm:0.0354, valid_acc: 0.8114, valid_loss_norm: 0.0367\n",
      " epoch: 34, train accuracy: 0.8307, train_loss_norm:0.0349, valid_acc: 0.8126, valid_loss_norm: 0.0363\n",
      " epoch: 35, train accuracy: 0.8319, train_loss_norm:0.0345, valid_acc: 0.8129, valid_loss_norm: 0.0359\n",
      " epoch: 36, train accuracy: 0.8327, train_loss_norm:0.0341, valid_acc: 0.8143, valid_loss_norm: 0.0355\n",
      " epoch: 37, train accuracy: 0.8338, train_loss_norm:0.0337, valid_acc: 0.8149, valid_loss_norm: 0.0351\n",
      " epoch: 38, train accuracy: 0.8346, train_loss_norm:0.0333, valid_acc: 0.8146, valid_loss_norm: 0.0347\n",
      " epoch: 39, train accuracy: 0.8356, train_loss_norm:0.0329, valid_acc: 0.8155, valid_loss_norm: 0.0343\n",
      " epoch: 40, train accuracy: 0.8368, train_loss_norm:0.0325, valid_acc: 0.8166, valid_loss_norm: 0.0340\n",
      " epoch: 41, train accuracy: 0.8375, train_loss_norm:0.0322, valid_acc: 0.8172, valid_loss_norm: 0.0337\n",
      " epoch: 42, train accuracy: 0.8383, train_loss_norm:0.0318, valid_acc: 0.8172, valid_loss_norm: 0.0333\n",
      " epoch: 43, train accuracy: 0.8389, train_loss_norm:0.0315, valid_acc: 0.8189, valid_loss_norm: 0.0330\n",
      " epoch: 44, train accuracy: 0.8393, train_loss_norm:0.0312, valid_acc: 0.8192, valid_loss_norm: 0.0327\n",
      " epoch: 45, train accuracy: 0.8398, train_loss_norm:0.0309, valid_acc: 0.8192, valid_loss_norm: 0.0324\n",
      " epoch: 46, train accuracy: 0.8403, train_loss_norm:0.0306, valid_acc: 0.8204, valid_loss_norm: 0.0321\n",
      " epoch: 47, train accuracy: 0.8408, train_loss_norm:0.0303, valid_acc: 0.8209, valid_loss_norm: 0.0318\n",
      " epoch: 48, train accuracy: 0.8414, train_loss_norm:0.0300, valid_acc: 0.8212, valid_loss_norm: 0.0316\n",
      " epoch: 49, train accuracy: 0.8421, train_loss_norm:0.0297, valid_acc: 0.8209, valid_loss_norm: 0.0313\n",
      " epoch: 50, train accuracy: 0.8430, train_loss_norm:0.0295, valid_acc: 0.8206, valid_loss_norm: 0.0311\n",
      " epoch: 51, train accuracy: 0.8437, train_loss_norm:0.0292, valid_acc: 0.8204, valid_loss_norm: 0.0308\n",
      " epoch: 52, train accuracy: 0.8443, train_loss_norm:0.0289, valid_acc: 0.8215, valid_loss_norm: 0.0306\n",
      " epoch: 53, train accuracy: 0.8446, train_loss_norm:0.0287, valid_acc: 0.8218, valid_loss_norm: 0.0303\n",
      " epoch: 54, train accuracy: 0.8451, train_loss_norm:0.0285, valid_acc: 0.8218, valid_loss_norm: 0.0301\n",
      " epoch: 55, train accuracy: 0.8457, train_loss_norm:0.0282, valid_acc: 0.8215, valid_loss_norm: 0.0299\n",
      " epoch: 56, train accuracy: 0.8464, train_loss_norm:0.0280, valid_acc: 0.8218, valid_loss_norm: 0.0297\n",
      " epoch: 57, train accuracy: 0.8470, train_loss_norm:0.0278, valid_acc: 0.8218, valid_loss_norm: 0.0295\n",
      " epoch: 58, train accuracy: 0.8475, train_loss_norm:0.0276, valid_acc: 0.8221, valid_loss_norm: 0.0293\n",
      " epoch: 59, train accuracy: 0.8479, train_loss_norm:0.0274, valid_acc: 0.8221, valid_loss_norm: 0.0291\n",
      " epoch: 60, train accuracy: 0.8486, train_loss_norm:0.0271, valid_acc: 0.8229, valid_loss_norm: 0.0289\n",
      " epoch: 61, train accuracy: 0.8490, train_loss_norm:0.0269, valid_acc: 0.8232, valid_loss_norm: 0.0287\n",
      " epoch: 62, train accuracy: 0.8494, train_loss_norm:0.0268, valid_acc: 0.8235, valid_loss_norm: 0.0285\n",
      " epoch: 63, train accuracy: 0.8499, train_loss_norm:0.0266, valid_acc: 0.8241, valid_loss_norm: 0.0283\n",
      " epoch: 64, train accuracy: 0.8504, train_loss_norm:0.0264, valid_acc: 0.8252, valid_loss_norm: 0.0282\n",
      " epoch: 65, train accuracy: 0.8506, train_loss_norm:0.0262, valid_acc: 0.8252, valid_loss_norm: 0.0280\n",
      " epoch: 66, train accuracy: 0.8509, train_loss_norm:0.0260, valid_acc: 0.8252, valid_loss_norm: 0.0278\n",
      " epoch: 67, train accuracy: 0.8513, train_loss_norm:0.0258, valid_acc: 0.8252, valid_loss_norm: 0.0277\n",
      " epoch: 68, train accuracy: 0.8517, train_loss_norm:0.0257, valid_acc: 0.8252, valid_loss_norm: 0.0275\n",
      " epoch: 69, train accuracy: 0.8521, train_loss_norm:0.0255, valid_acc: 0.8249, valid_loss_norm: 0.0273\n",
      " epoch: 70, train accuracy: 0.8526, train_loss_norm:0.0253, valid_acc: 0.8249, valid_loss_norm: 0.0272\n",
      " epoch: 71, train accuracy: 0.8532, train_loss_norm:0.0252, valid_acc: 0.8258, valid_loss_norm: 0.0270\n",
      " epoch: 72, train accuracy: 0.8539, train_loss_norm:0.0250, valid_acc: 0.8261, valid_loss_norm: 0.0269\n",
      " epoch: 73, train accuracy: 0.8542, train_loss_norm:0.0249, valid_acc: 0.8264, valid_loss_norm: 0.0267\n",
      " epoch: 74, train accuracy: 0.8547, train_loss_norm:0.0247, valid_acc: 0.8264, valid_loss_norm: 0.0266\n",
      " epoch: 75, train accuracy: 0.8550, train_loss_norm:0.0246, valid_acc: 0.8270, valid_loss_norm: 0.0265\n",
      " epoch: 76, train accuracy: 0.8552, train_loss_norm:0.0244, valid_acc: 0.8270, valid_loss_norm: 0.0263\n",
      " epoch: 77, train accuracy: 0.8558, train_loss_norm:0.0243, valid_acc: 0.8275, valid_loss_norm: 0.0262\n",
      " epoch: 78, train accuracy: 0.8562, train_loss_norm:0.0242, valid_acc: 0.8278, valid_loss_norm: 0.0261\n",
      " epoch: 79, train accuracy: 0.8568, train_loss_norm:0.0240, valid_acc: 0.8281, valid_loss_norm: 0.0259\n",
      " epoch: 80, train accuracy: 0.8570, train_loss_norm:0.0239, valid_acc: 0.8290, valid_loss_norm: 0.0258\n",
      " epoch: 81, train accuracy: 0.8574, train_loss_norm:0.0238, valid_acc: 0.8295, valid_loss_norm: 0.0257\n",
      " epoch: 82, train accuracy: 0.8577, train_loss_norm:0.0236, valid_acc: 0.8304, valid_loss_norm: 0.0256\n",
      " epoch: 83, train accuracy: 0.8582, train_loss_norm:0.0235, valid_acc: 0.8307, valid_loss_norm: 0.0255\n",
      " epoch: 84, train accuracy: 0.8585, train_loss_norm:0.0234, valid_acc: 0.8301, valid_loss_norm: 0.0253\n",
      " epoch: 85, train accuracy: 0.8589, train_loss_norm:0.0233, valid_acc: 0.8295, valid_loss_norm: 0.0252\n",
      " epoch: 86, train accuracy: 0.8593, train_loss_norm:0.0231, valid_acc: 0.8301, valid_loss_norm: 0.0251\n",
      " epoch: 87, train accuracy: 0.8598, train_loss_norm:0.0230, valid_acc: 0.8304, valid_loss_norm: 0.0250\n",
      " epoch: 88, train accuracy: 0.8601, train_loss_norm:0.0229, valid_acc: 0.8313, valid_loss_norm: 0.0249\n",
      " epoch: 89, train accuracy: 0.8606, train_loss_norm:0.0228, valid_acc: 0.8321, valid_loss_norm: 0.0248\n",
      " epoch: 90, train accuracy: 0.8608, train_loss_norm:0.0227, valid_acc: 0.8327, valid_loss_norm: 0.0247\n",
      " epoch: 91, train accuracy: 0.8610, train_loss_norm:0.0226, valid_acc: 0.8330, valid_loss_norm: 0.0246\n",
      " epoch: 92, train accuracy: 0.8614, train_loss_norm:0.0225, valid_acc: 0.8339, valid_loss_norm: 0.0245\n",
      " epoch: 93, train accuracy: 0.8618, train_loss_norm:0.0224, valid_acc: 0.8339, valid_loss_norm: 0.0244\n",
      " epoch: 94, train accuracy: 0.8622, train_loss_norm:0.0223, valid_acc: 0.8339, valid_loss_norm: 0.0243\n",
      " epoch: 95, train accuracy: 0.8626, train_loss_norm:0.0222, valid_acc: 0.8339, valid_loss_norm: 0.0242\n",
      " epoch: 96, train accuracy: 0.8632, train_loss_norm:0.0221, valid_acc: 0.8341, valid_loss_norm: 0.0241\n",
      " epoch: 97, train accuracy: 0.8636, train_loss_norm:0.0220, valid_acc: 0.8339, valid_loss_norm: 0.0240\n",
      " epoch: 98, train accuracy: 0.8639, train_loss_norm:0.0219, valid_acc: 0.8339, valid_loss_norm: 0.0239\n",
      " epoch: 99, train accuracy: 0.8644, train_loss_norm:0.0218, valid_acc: 0.8339, valid_loss_norm: 0.0238\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_37692/4047419396.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[0mcur_ex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_d\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m             \u001b[0mcur_label\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m             \u001b[0my_hat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoftmax_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcur_ex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m             \u001b[1;31m# Update Weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Victor\\OneDrive\\Documents\\UCSD\\0CSE251B\\hw1\\CSE251B\\cse251b_PA1_starter\\model\\softmax.py\u001b[0m in \u001b[0;36mmodel\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[0mModel\u001b[0m \u001b[0mNetwork\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mSoftmax\u001b[0m \u001b[0mRegression\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         '''\n\u001b[1;32m---> 34\u001b[1;33m         \u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### Q6(b) - Stochastic Gradient Descent\n",
    "\n",
    "print(\"Q6(b) - Stochastic Gradient Descent\")\n",
    "\n",
    "# (i)\n",
    "# Load aligned data\n",
    "X, y = traffic_sign(True)\n",
    "X = X.astype(np.float32) # cast to float32 as float64 running out of memory\n",
    "X = z_score_normalize(X) \n",
    "\n",
    "# Softmax Regression Parameters\n",
    "lr = 0.5\n",
    "num_features = X.shape[1]\n",
    "num_classes = y.max() + 1\n",
    "k = 10\n",
    "train_loss_record = []\n",
    "train_accuracy_record = []\n",
    "holdout_loss_record = []\n",
    "holdout_accuracy_record = []\n",
    "test_accuracy_record = []\n",
    "\n",
    "\n",
    "# PCA number of principal components\n",
    "n_components = 300\n",
    "\n",
    "first_plot = True\n",
    "\n",
    "num_epochs = 300\n",
    "epochs_print = [50, 100, 150, 200, 250, 300]\n",
    "\n",
    "cur_fold = 0\n",
    "\n",
    "total_test_loss = 0\n",
    "\n",
    "for train, valid, test in generate_k_fold_set((X, y), k = 10):\n",
    "    print(\"Cur fold:\", cur_fold)\n",
    "    train_data, train_label = train\n",
    "    valid_data, valid_label = valid\n",
    "    test_data, test_label = test\n",
    "    \n",
    "    # Project data onto principal components\n",
    "    pca = PCA(n_components)\n",
    "    projected = pca.fit_transform(train_data)\n",
    "    \n",
    "    # Plot principal components\n",
    "    if first_plot == True : \n",
    "        pca.plot_PC()\n",
    "        first_plot = False\n",
    "    train_d = append_bias(projected)     \n",
    "    valid_d = append_bias(pca.PCA_generate(valid_data))\n",
    "    test_d = append_bias(pca.PCA_generate(test_data))\n",
    "\n",
    "    softmax_model = SoftmaxRegression(lr, n_components, num_classes)\n",
    "\n",
    "    valid_label_onehot = onehot_encode(valid_label)\n",
    "    test_label_onehot = onehot_encode(test_label)\n",
    "\n",
    "    # SGD\n",
    "    for epoch in range(num_epochs):\n",
    "        # Shuffle indices\n",
    "        indices = np.arange(len(train_d))\n",
    "        indices = np.random.shuffle(indices)\n",
    "\n",
    "        train_d = train_d[indices].squeeze(0)\n",
    "        train_label = train_label[indices].squeeze(0)\n",
    "        \n",
    "        # Onehot encode labels\n",
    "        y_true = onehot_encode(train_label)\n",
    "            \n",
    "        # Iterate over each example\n",
    "        for i in range(len(train_d)):\n",
    "            cur_ex = train_d[i][np.newaxis, :]\n",
    "            cur_label = y_true[i][np.newaxis, :]\n",
    "            y_hat = softmax_model.model(cur_ex)\n",
    "\n",
    "            # Update Weights\n",
    "            softmax_model.update_weights(cur_ex, cur_label, y_hat)\n",
    "\n",
    "        # Training Loss\n",
    "        y_hat = softmax_model.model(train_d)\n",
    "\n",
    "        raw_train_loss = softmax_model.cross_entropy(y_true, y_hat)\n",
    "        train_loss_norm = raw_train_loss / len(train_d) / num_classes\n",
    "\n",
    "        train_loss_record.append(train_loss_norm)\n",
    "\n",
    "        train_accuracy = softmax_model.accuracy(y_true, y_hat)\n",
    "        train_accuracy_record.append(train_accuracy)\n",
    "\n",
    "        # Validation Loss\n",
    "        holdout_y = softmax_model.model(valid_d)\n",
    "\n",
    "        holdout_loss = softmax_model.cross_entropy(valid_label_onehot, holdout_y)\n",
    "        holdout_loss_norm = holdout_loss / len(valid_d) / num_classes # holdout loss normalized by # examples and classes\n",
    "        holdout_loss_record.append(holdout_loss_norm)\n",
    "\n",
    "        holdout_accuracy = softmax_model.accuracy(holdout_y, valid_label_onehot)\n",
    "        holdout_accuracy_record.append(holdout_accuracy)\n",
    "\n",
    "        if holdout_accuracy >= max(holdout_accuracy_record[cur_fold * num_epochs:]):\n",
    "            best_w = softmax_model.W\n",
    "\n",
    "        \n",
    "        # if (epoch + 1) in epochs_print:\n",
    "        print(f' epoch: {epoch + 1}, train accuracy: {train_accuracy:.4f}, train_loss_norm:{train_loss_norm:.4f}, '\\\n",
    "            f'valid_acc: {holdout_accuracy:.4f}, valid_loss_norm: {holdout_loss_norm:.4f}')\n",
    "\n",
    "    # Run on Test Dataset\n",
    "    test_y = softmax_model.model_w(test_d, best_w)\n",
    "\n",
    "    test_accuracy = softmax_model.accuracy(test_y, test_label_onehot)\n",
    "\n",
    "    print(f'Test accuracy: {test_accuracy:.4f}')\n",
    "\n",
    "    test_accuracy_record.append(test_accuracy)\n",
    "\n",
    "    raw_test_loss = softmax_model.cross_entropy(test_label_onehot, test_y)\n",
    "    test_loss_norm = raw_test_loss / len(test_d) / num_classes\n",
    "    total_test_loss += test_loss_norm\n",
    "    print(f\"Test loss norm: {test_loss_norm:.4f}\")\n",
    "\n",
    "    cur_fold += 1\n",
    "\n",
    "print(f'Average test accuracy over {k} folds: {np.mean(test_accuracy_record):.4f} (+/- {np.std(test_accuracy_record):.4f})')\n",
    "print(f'Average test loss per example and class over {k} folds: {total_test_loss / k}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Victor\\AppData\\Local\\Temp/ipykernel_33668/1695772060.py:20: UserWarning: linestyle is redundantly defined by the 'linestyle' keyword argument and the fmt string \"-b\" (-> linestyle='-'). The keyword argument will take precedence.\n",
      "  axs[0].errorbar(x=epochs_error_bar_0, y=train_loss_error_bar_y, yerr=train_loss_error_bar_yerr, label='Training loss error', fmt='-b', linestyle='')\n",
      "C:\\Users\\Victor\\AppData\\Local\\Temp/ipykernel_33668/1695772060.py:23: UserWarning: linestyle is redundantly defined by the 'linestyle' keyword argument and the fmt string \"--r\" (-> linestyle='--'). The keyword argument will take precedence.\n",
      "  axs[0].errorbar(x=epochs_error_bar_0, y=valid_loss_error_bar_y, yerr=valid_loss_error_bar_yerr, label='Validation loss error', fmt='--r', linestyle='')\n",
      "C:\\Users\\Victor\\AppData\\Local\\Temp/ipykernel_33668/1695772060.py:40: UserWarning: linestyle is redundantly defined by the 'linestyle' keyword argument and the fmt string \"-b\" (-> linestyle='-'). The keyword argument will take precedence.\n",
      "  axs[1].errorbar(x=epochs_error_bar_0, y=train_acc_error_bar_y, yerr=train_acc_error_bar_yerr, label='Training accuracy error', fmt='-b', linestyle='')\n",
      "C:\\Users\\Victor\\AppData\\Local\\Temp/ipykernel_33668/1695772060.py:43: UserWarning: linestyle is redundantly defined by the 'linestyle' keyword argument and the fmt string \"--r\" (-> linestyle='--'). The keyword argument will take precedence.\n",
      "  axs[1].errorbar(x=epochs_error_bar_0, y=valid_acc_error_bar_y, yerr=valid_acc_error_bar_yerr, label='Validation accuracy error', fmt='--r', linestyle='')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()\n",
    "\n",
    "fig, axs = plt.subplots(2, 1, constrained_layout=True)\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "\n",
    "epochs_error_bar = [50, 100, 150, 200, 250, 300] # 1-indexed\n",
    "epochs_error_bar_0 = [epoch - 1 for epoch in epochs_error_bar] # 0-indexed\n",
    "\n",
    "# Plot Loss\n",
    "average_train_loss = average_out_data_k(train_loss_record)\n",
    "train_loss_error_bar_y = [average_train_loss[epoch] for epoch in epochs_error_bar_0]\n",
    "train_loss_error_bar_yerr = [np.std(get_data_at_epoch_fold(train_loss_record, epoch)) for epoch in epochs_error_bar_0]\n",
    "\n",
    "\n",
    "average_valid_loss = average_out_data_k(holdout_loss_record)\n",
    "valid_loss_error_bar_y = [average_valid_loss[epoch] for epoch in epochs_error_bar_0]\n",
    "valid_loss_error_bar_yerr = [np.std(get_data_at_epoch_fold(holdout_loss_record, epoch)) for epoch in epochs_error_bar_0]\n",
    "\n",
    "axs[0].plot(average_train_loss, '-b', label='Training loss')\n",
    "axs[0].errorbar(x=epochs_error_bar_0, y=train_loss_error_bar_y, yerr=train_loss_error_bar_yerr, label='Training loss error', fmt='-b', linestyle='')\n",
    "\n",
    "axs[0].plot(average_valid_loss, '--r', label='Validation loss')\n",
    "axs[0].errorbar(x=epochs_error_bar_0, y=valid_loss_error_bar_y, yerr=valid_loss_error_bar_yerr, label='Validation loss error', fmt='--r', linestyle='')\n",
    "\n",
    "axs[0].legend()\n",
    "axs[0].set_xlabel('Epochs')\n",
    "axs[0].set_ylabel('Normalized Loss')\n",
    "axs[0].set_title('Loss normalized per example and class vs. Epochs')\n",
    "\n",
    "# Plot Accuracy\n",
    "average_train_acc = average_out_data_k(train_accuracy_record)\n",
    "train_acc_error_bar_y = [average_train_acc[epoch] for epoch in epochs_error_bar_0]\n",
    "train_acc_error_bar_yerr = [np.std(get_data_at_epoch_fold(train_accuracy_record, epoch)) for epoch in epochs_error_bar_0]\n",
    "\n",
    "average_valid_acc = average_out_data_k(holdout_accuracy_record)\n",
    "valid_acc_error_bar_y = [average_valid_acc[epoch] for epoch in epochs_error_bar_0]\n",
    "valid_acc_error_bar_yerr = [np.std(get_data_at_epoch_fold(holdout_accuracy_record, epoch)) for epoch in epochs_error_bar_0]\n",
    "\n",
    "axs[1].plot(average_train_acc, '-b', label='Training accuracy')\n",
    "axs[1].errorbar(x=epochs_error_bar_0, y=train_acc_error_bar_y, yerr=train_acc_error_bar_yerr, label='Training accuracy error', fmt='-b', linestyle='')\n",
    "\n",
    "axs[1].plot(average_valid_acc, '--r', label='Validation accuracy')\n",
    "axs[1].errorbar(x=epochs_error_bar_0, y=valid_acc_error_bar_y, yerr=valid_acc_error_bar_yerr, label='Validation accuracy error', fmt='--r', linestyle='')\n",
    "\n",
    "axs[1].legend()\n",
    "axs[1].set_xlabel('Epochs')\n",
    "axs[1].set_ylabel('Accuracy')\n",
    "axs[1].set_title('Accuracy vs. Epochs')\n",
    "\n",
    "plt.savefig(\"plots/Q6b_i.png\")\n",
    "plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8488/2416747609.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# (ii) Plot Batch vs. Stochastic Gradient Descent\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m# plt.set_size_inches(18.5, 10.5)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mepochs_error_bar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m150\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m250\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m300\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# 1-indexed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "# (ii) Plot Batch vs. Stochastic Gradient Descent\n",
    "plt.clf()\n",
    "# plt.set_size_inches(18.5, 10.5)\n",
    "\n",
    "epochs_error_bar = [50, 100, 150, 200, 250, 300] # 1-indexed\n",
    "epochs_error_bar_0 = [epoch - 1 for epoch in epochs_error_bar] # 0-indexed\n",
    "\n",
    "# Plot Loss\n",
    "average_train_loss = average_out_data_k(train_loss_record)\n",
    "train_loss_error_bar_y = [average_train_loss[epoch] for epoch in epochs_error_bar_0]\n",
    "train_loss_error_bar_yerr = [np.std(get_data_at_epoch_fold(train_loss_record, epoch)) for epoch in epochs_error_bar_0]\n",
    "\n",
    "plt.plot(average_train_loss, '-b', label='Stochastic')\n",
    "plt.errorbar(x=epochs_error_bar_0, y=train_loss_error_bar_y, yerr=train_loss_error_bar_yerr, label='Stochastic error', fmt='-b', linestyle='')\n",
    "\n",
    "plt.plot(batch_average_train_loss, '--r', label='Batch')\n",
    "plt.errorbar(x=epochs_error_bar_0, y=batch_average_train_loss_error_bar_y, yerr=batch_average_train_loss_error_bar_yerr, label='Batch error', fmt='--r', linestyle='')\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Normalized Loss')\n",
    "plt.title('Batch vs. Stochastic Normalized Training Loss')\n",
    "\n",
    "plt.savefig(\"plots/Q6b_ii.png\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### (c) Visualize the weights\n",
    "\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "def weights2range(w, min=0, max=256):\n",
    "    # Scales weights to be between min and max\n",
    "    w /= np.max(w)\n",
    "    w *= (max)\n",
    "    w += min\n",
    "    return w\n",
    "\n",
    "# Plot image\n",
    "\n",
    "weight_visualization_weights = best_w[:-1]\n",
    "\n",
    "# Traffic sign classes to be plotted\n",
    "ts_classes = [7, 11, 21, 25]\n",
    "\n",
    "fig, axs = plt.subplots(4,1) \n",
    "fig.set_size_inches(10, 6)\n",
    "\n",
    "for i, ts_class in enumerate(ts_classes):\n",
    "    # Get weights for each class\n",
    "    class_weights = weight_visualization_weights[:,ts_class].reshape((32, 32))\n",
    "    # Scale to [0, 256]\n",
    "    img_weights = weights2range(class_weights)\n",
    "    # Plot image\n",
    "    axs[i].set_title(f'Class {ts_class}')\n",
    "    axs[i].imshow(img_weights)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/Q6c_weights.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "005f4ed24810181fa8b2266ec303702d6575bedfaa41c7848d327e7f780b3129"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
