{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pca import PCA\n",
    "import argparse\n",
    "import network\n",
    "import os, random, sys\n",
    "from data import traffic_sign, generate_k_fold_set, onehot_encode, onehot_decode, z_score_normalize, append_bias\n",
    "from model.softmax import SoftmaxRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34799, 1024)\n",
      "(34799,)\n",
      "float32\n",
      "uint8\n"
     ]
    }
   ],
   "source": [
    "### Q6(a) - Evaluate Network on all 43 traffic signs (aligned dataset)\n",
    "\n",
    "# Load aligned data\n",
    "X, y = traffic_sign(True)\n",
    "X = X.astype(np.float32) # cast to float32 as float64 running out of memory\n",
    "X = z_score_normalize(X) \n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(X.dtype)\n",
    "print(y.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Fold: 0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27841, 300)\n",
      "(3479, 300)\n",
      "(3479, 300)\n",
      " epoch: 50, train accuracy: 0.8404, train_loss_norm:0.0296, valid_acc: 0.8324, valid_loss_norm: 0.0300\n",
      " epoch: 100, train accuracy: 0.8618, train_loss_norm:0.0217, valid_acc: 0.8488, valid_loss_norm: 0.0226\n",
      " epoch: 150, train accuracy: 0.8766, train_loss_norm:0.0183, valid_acc: 0.8566, valid_loss_norm: 0.0194\n",
      " epoch: 200, train accuracy: 0.8864, train_loss_norm:0.0162, valid_acc: 0.8594, valid_loss_norm: 0.0176\n",
      " epoch: 250, train accuracy: 0.8928, train_loss_norm:0.0148, valid_acc: 0.8635, valid_loss_norm: 0.0165\n",
      " epoch: 300, train accuracy: 0.9001, train_loss_norm:0.0138, valid_acc: 0.8672, valid_loss_norm: 0.0156\n",
      "Test accuracy: 0.8500\n",
      "Test loss norm: 0.0174\n",
      "Current Fold: 1\n",
      "(27841, 300)\n",
      "(3479, 300)\n",
      "(3479, 300)\n",
      " epoch: 50, train accuracy: 0.8413, train_loss_norm:0.0295, valid_acc: 0.8066, valid_loss_norm: 0.0320\n",
      " epoch: 100, train accuracy: 0.8638, train_loss_norm:0.0216, valid_acc: 0.8232, valid_loss_norm: 0.0245\n",
      " epoch: 150, train accuracy: 0.8777, train_loss_norm:0.0182, valid_acc: 0.8324, valid_loss_norm: 0.0214\n",
      " epoch: 200, train accuracy: 0.8869, train_loss_norm:0.0162, valid_acc: 0.8393, valid_loss_norm: 0.0196\n",
      " epoch: 250, train accuracy: 0.8952, train_loss_norm:0.0148, valid_acc: 0.8465, valid_loss_norm: 0.0184\n",
      " epoch: 300, train accuracy: 0.9007, train_loss_norm:0.0137, valid_acc: 0.8508, valid_loss_norm: 0.0175\n",
      "Test accuracy: 0.8638\n",
      "Test loss norm: 0.0164\n",
      "Current Fold: 2\n",
      "(27841, 300)\n",
      "(3479, 300)\n",
      "(3479, 300)\n",
      " epoch: 50, train accuracy: 0.8410, train_loss_norm:0.0297, valid_acc: 0.8189, valid_loss_norm: 0.0310\n",
      " epoch: 100, train accuracy: 0.8613, train_loss_norm:0.0218, valid_acc: 0.8341, valid_loss_norm: 0.0236\n",
      " epoch: 150, train accuracy: 0.8739, train_loss_norm:0.0183, valid_acc: 0.8451, valid_loss_norm: 0.0204\n",
      " epoch: 200, train accuracy: 0.8832, train_loss_norm:0.0163, valid_acc: 0.8525, valid_loss_norm: 0.0186\n",
      " epoch: 250, train accuracy: 0.8924, train_loss_norm:0.0149, valid_acc: 0.8574, valid_loss_norm: 0.0174\n",
      " epoch: 300, train accuracy: 0.8989, train_loss_norm:0.0138, valid_acc: 0.8652, valid_loss_norm: 0.0165\n",
      "Test accuracy: 0.8692\n",
      "Test loss norm: 0.0161\n",
      "Current Fold: 3\n",
      "(27841, 300)\n",
      "(3479, 300)\n",
      "(3479, 300)\n",
      " epoch: 50, train accuracy: 0.8420, train_loss_norm:0.0297, valid_acc: 0.8261, valid_loss_norm: 0.0304\n",
      " epoch: 100, train accuracy: 0.8608, train_loss_norm:0.0218, valid_acc: 0.8465, valid_loss_norm: 0.0230\n",
      " epoch: 150, train accuracy: 0.8737, train_loss_norm:0.0183, valid_acc: 0.8554, valid_loss_norm: 0.0199\n",
      " epoch: 200, train accuracy: 0.8841, train_loss_norm:0.0163, valid_acc: 0.8606, valid_loss_norm: 0.0181\n",
      " epoch: 250, train accuracy: 0.8922, train_loss_norm:0.0149, valid_acc: 0.8640, valid_loss_norm: 0.0169\n",
      " epoch: 300, train accuracy: 0.8984, train_loss_norm:0.0138, valid_acc: 0.8672, valid_loss_norm: 0.0161\n",
      "Test accuracy: 0.8623\n",
      "Test loss norm: 0.0165\n",
      "Current Fold: 4\n",
      "(27841, 300)\n",
      "(3479, 300)\n",
      "(3479, 300)\n",
      " epoch: 50, train accuracy: 0.8417, train_loss_norm:0.0296, valid_acc: 0.8172, valid_loss_norm: 0.0313\n",
      " epoch: 100, train accuracy: 0.8631, train_loss_norm:0.0217, valid_acc: 0.8336, valid_loss_norm: 0.0238\n",
      " epoch: 150, train accuracy: 0.8758, train_loss_norm:0.0182, valid_acc: 0.8459, valid_loss_norm: 0.0206\n",
      " epoch: 200, train accuracy: 0.8860, train_loss_norm:0.0162, valid_acc: 0.8531, valid_loss_norm: 0.0187\n",
      " epoch: 250, train accuracy: 0.8941, train_loss_norm:0.0148, valid_acc: 0.8643, valid_loss_norm: 0.0175\n",
      " epoch: 300, train accuracy: 0.9004, train_loss_norm:0.0138, valid_acc: 0.8672, valid_loss_norm: 0.0165\n",
      "Test accuracy: 0.8658\n",
      "Test loss norm: 0.0169\n",
      "Current Fold: 5\n",
      "(27841, 300)\n",
      "(3479, 300)\n",
      "(3479, 300)\n",
      " epoch: 50, train accuracy: 0.8414, train_loss_norm:0.0295, valid_acc: 0.8255, valid_loss_norm: 0.0313\n",
      " epoch: 100, train accuracy: 0.8625, train_loss_norm:0.0216, valid_acc: 0.8413, valid_loss_norm: 0.0239\n",
      " epoch: 150, train accuracy: 0.8762, train_loss_norm:0.0181, valid_acc: 0.8523, valid_loss_norm: 0.0208\n",
      " epoch: 200, train accuracy: 0.8875, train_loss_norm:0.0161, valid_acc: 0.8574, valid_loss_norm: 0.0190\n",
      " epoch: 250, train accuracy: 0.8946, train_loss_norm:0.0147, valid_acc: 0.8617, valid_loss_norm: 0.0178\n",
      " epoch: 300, train accuracy: 0.9018, train_loss_norm:0.0136, valid_acc: 0.8652, valid_loss_norm: 0.0169\n",
      "Test accuracy: 0.8612\n",
      "Test loss norm: 0.0173\n",
      "Current Fold: 6\n",
      "(27841, 300)\n",
      "(3479, 300)\n",
      "(3479, 300)\n",
      " epoch: 50, train accuracy: 0.8407, train_loss_norm:0.0295, valid_acc: 0.8229, valid_loss_norm: 0.0319\n",
      " epoch: 100, train accuracy: 0.8616, train_loss_norm:0.0216, valid_acc: 0.8425, valid_loss_norm: 0.0244\n",
      " epoch: 150, train accuracy: 0.8754, train_loss_norm:0.0182, valid_acc: 0.8485, valid_loss_norm: 0.0212\n",
      " epoch: 200, train accuracy: 0.8856, train_loss_norm:0.0161, valid_acc: 0.8548, valid_loss_norm: 0.0194\n",
      " epoch: 250, train accuracy: 0.8948, train_loss_norm:0.0147, valid_acc: 0.8563, valid_loss_norm: 0.0182\n",
      " epoch: 300, train accuracy: 0.9012, train_loss_norm:0.0136, valid_acc: 0.8600, valid_loss_norm: 0.0174\n",
      "Test accuracy: 0.8640\n",
      "Test loss norm: 0.0167\n",
      "Current Fold: 7\n",
      "(27841, 300)\n",
      "(3479, 300)\n",
      "(3479, 300)\n",
      " epoch: 50, train accuracy: 0.8413, train_loss_norm:0.0297, valid_acc: 0.8247, valid_loss_norm: 0.0309\n",
      " epoch: 100, train accuracy: 0.8605, train_loss_norm:0.0218, valid_acc: 0.8385, valid_loss_norm: 0.0236\n",
      " epoch: 150, train accuracy: 0.8752, train_loss_norm:0.0183, valid_acc: 0.8462, valid_loss_norm: 0.0205\n",
      " epoch: 200, train accuracy: 0.8847, train_loss_norm:0.0163, valid_acc: 0.8534, valid_loss_norm: 0.0188\n",
      " epoch: 250, train accuracy: 0.8940, train_loss_norm:0.0149, valid_acc: 0.8589, valid_loss_norm: 0.0176\n",
      " epoch: 300, train accuracy: 0.9008, train_loss_norm:0.0138, valid_acc: 0.8620, valid_loss_norm: 0.0167\n",
      "Test accuracy: 0.8672\n",
      "Test loss norm: 0.0159\n",
      "Current Fold: 8\n",
      "(27841, 300)\n",
      "(3479, 300)\n",
      "(3479, 300)\n",
      " epoch: 50, train accuracy: 0.8410, train_loss_norm:0.0296, valid_acc: 0.8221, valid_loss_norm: 0.0304\n",
      " epoch: 100, train accuracy: 0.8613, train_loss_norm:0.0218, valid_acc: 0.8393, valid_loss_norm: 0.0230\n",
      " epoch: 150, train accuracy: 0.8748, train_loss_norm:0.0183, valid_acc: 0.8471, valid_loss_norm: 0.0198\n",
      " epoch: 200, train accuracy: 0.8855, train_loss_norm:0.0163, valid_acc: 0.8569, valid_loss_norm: 0.0180\n",
      " epoch: 250, train accuracy: 0.8935, train_loss_norm:0.0149, valid_acc: 0.8638, valid_loss_norm: 0.0168\n",
      " epoch: 300, train accuracy: 0.9001, train_loss_norm:0.0138, valid_acc: 0.8701, valid_loss_norm: 0.0159\n",
      "Test accuracy: 0.8681\n",
      "Test loss norm: 0.0169\n",
      "1\n",
      "Current Fold: 9\n",
      "(27841, 300)\n",
      "(3479, 300)\n",
      "(3479, 300)\n",
      " epoch: 50, train accuracy: 0.8412, train_loss_norm:0.0296, valid_acc: 0.8186, valid_loss_norm: 0.0312\n",
      " epoch: 100, train accuracy: 0.8627, train_loss_norm:0.0218, valid_acc: 0.8339, valid_loss_norm: 0.0238\n",
      " epoch: 150, train accuracy: 0.8751, train_loss_norm:0.0183, valid_acc: 0.8514, valid_loss_norm: 0.0207\n",
      " epoch: 200, train accuracy: 0.8849, train_loss_norm:0.0163, valid_acc: 0.8617, valid_loss_norm: 0.0188\n",
      " epoch: 250, train accuracy: 0.8932, train_loss_norm:0.0149, valid_acc: 0.8672, valid_loss_norm: 0.0176\n",
      " epoch: 300, train accuracy: 0.8997, train_loss_norm:0.0138, valid_acc: 0.8709, valid_loss_norm: 0.0167\n",
      "Test accuracy: 0.8675\n",
      "Test loss norm: 0.0156\n",
      "Average test accuracy over 10 folds: 0.8639 (+/- 0.0053)\n",
      "Average test loss per example and class over 10 folds: 0.0166\n"
     ]
    }
   ],
   "source": [
    "## (i) With PCA on aligned\n",
    "\n",
    "DEBUG = False\n",
    "\n",
    "# Softmax Regression Parameters\n",
    "lr = 0.5\n",
    "num_features = X.shape[1]\n",
    "num_classes = y.max() + 1\n",
    "\n",
    "train_loss_record = []\n",
    "\n",
    "train_accuracy_record = []\n",
    "\n",
    "holdout_loss_record = []\n",
    "\n",
    "holdout_accuracy_record = []\n",
    "\n",
    "test_accuracy_record = []\n",
    "\n",
    "# PCA number of principal components\n",
    "n_components = 300\n",
    "\n",
    "first_plot = True\n",
    "\n",
    "num_epochs = 300\n",
    "epochs_print = [50, 100, 150, 200, 250, 300]\n",
    "\n",
    "k = 10\n",
    "\n",
    "total_test_loss = 0.0\n",
    "\n",
    "best_w = None\n",
    "\n",
    "cur_fold = 0\n",
    "for train, valid, test in generate_k_fold_set((X, y), k):\n",
    "    print(f\"Current Fold: {cur_fold}\")\n",
    "    train_data, train_label = train\n",
    "    valid_data, valid_label = valid\n",
    "    test_data, test_label = test\n",
    "    \n",
    "    # Project data onto principal components\n",
    "    pca = PCA(n_components)\n",
    "    projected = pca.fit_transform(train_data) # len(train_data) x n_components\n",
    "    \n",
    "    # Plot principal components\n",
    "    if first_plot == True : \n",
    "        pca.plot_PC()\n",
    "        first_plot = False\n",
    "    train_d = append_bias(projected)     \n",
    "    valid_d = append_bias(pca.PCA_generate(valid_data))\n",
    "    test_d = append_bias(pca.PCA_generate(test_data))\n",
    "\n",
    "    softmax_model = SoftmaxRegression(lr, n_components, num_classes)\n",
    "    best_w = softmax_model.W\n",
    "\n",
    "    # Onehot encode labels\n",
    "    y_true = onehot_encode(train_label)\n",
    "    valid_label_onehot = onehot_encode(valid_label)\n",
    "    test_label_onehot = onehot_encode(test_label)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        y_hat = softmax_model.model(train_d)\n",
    "        \n",
    "        raw_train_loss = softmax_model.cross_entropy(y_true, y_hat)\n",
    "        train_loss_norm = raw_train_loss / len(train_d) / num_classes # train loss normalized by # examples and classes\n",
    "        \n",
    "        train_loss_record.append(train_loss_norm)\n",
    "        \n",
    "        train_accuracy = softmax_model.accuracy(y_true, y_hat)\n",
    "        train_accuracy_record.append(train_accuracy)\n",
    "        \n",
    "        holdout_y = softmax_model.model(valid_d)\n",
    "\n",
    "        holdout_loss = softmax_model.cross_entropy(valid_label_onehot, holdout_y)\n",
    "        holdout_loss_norm = holdout_loss / len(valid_d) / num_classes # holdout loss normalized by # examples and classes\n",
    "        holdout_loss_record.append(holdout_loss_norm)\n",
    "\n",
    "        holdout_accuracy = softmax_model.accuracy(holdout_y, valid_label_onehot)\n",
    "        holdout_accuracy_record.append(holdout_accuracy)\n",
    "\n",
    "        if holdout_accuracy >= max(holdout_accuracy_record[cur_fold * num_epochs:]):\n",
    "            best_w = softmax_model.W\n",
    "\n",
    "        # Update Weights\n",
    "        softmax_model.update_weights(train_d, y_true, y_hat)\n",
    "\n",
    "        if (epoch + 1) in epochs_print:\n",
    "            print(f' epoch: {epoch + 1}, train accuracy: {train_accuracy:.4f}, train_loss_norm:{train_loss_norm:.4f}, '\\\n",
    "                f'valid_acc: {holdout_accuracy:.4f}, valid_loss_norm: {holdout_loss_norm:.4f}')\n",
    "            if DEBUG:\n",
    "                test_y = softmax_model.model_w(test_d, best_w)\n",
    "                test_y_1 = softmax_model.model(test_d)\n",
    "\n",
    "                test_accuracy = softmax_model.accuracy(test_y, test_label_onehot)\n",
    "                test_accuracy_1 = softmax_model.accuracy(test_y_1, test_label_onehot)\n",
    "\n",
    "                raw_test_loss = softmax_model.cross_entropy(test_y, test_label_onehot)\n",
    "                test_loss_norm = raw_test_loss / len(test_d) / num_classes\n",
    "\n",
    "                print(f'MODEL_W: Test accuracy: {test_accuracy:.4f}', f'Test loss norm: {test_loss_norm:.4f}')\n",
    "                print(f'MODEL: Test accuracy: {test_accuracy_1:.4f}')\n",
    "\n",
    "    # Run on Test Dataset\n",
    "    test_y = softmax_model.model_w(test_d, best_w)\n",
    "\n",
    "    test_accuracy = softmax_model.accuracy(test_y, test_label_onehot)\n",
    "\n",
    "    print(f'Test accuracy: {test_accuracy:.4f}')\n",
    "\n",
    "    test_accuracy_record.append(test_accuracy)\n",
    "\n",
    "    raw_test_loss = softmax_model.cross_entropy(test_label_onehot, test_y)\n",
    "    test_loss_norm = raw_test_loss / len(test_d) / num_classes\n",
    "    total_test_loss += test_loss_norm\n",
    "    print(f\"Test loss norm: {test_loss_norm:.4f}\")\n",
    "\n",
    "    cur_fold += 1\n",
    "\n",
    "print(f'Average test accuracy over {k} folds: {np.mean(test_accuracy_record):.4f} (+/- {np.std(test_accuracy_record):.4f})')\n",
    "print(f'Average test loss per example and class over {k} folds: {total_test_loss / k:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_out_data_k(data, k=10):\n",
    "    total_count = len(data)\n",
    "    count_per_fold = total_count // k # Assumes cleanly divisble number\n",
    "    new_data = [0.0 for i in range(count_per_fold)]\n",
    "    for i in range(k):\n",
    "        for j in range(count_per_fold):\n",
    "            new_data[j] += data[i * count_per_fold + j]\n",
    "    new_data = [d / k for d in new_data]\n",
    "    return new_data\n",
    "\n",
    "def get_data_at_epoch_fold(data, epoch, total_num_folds=10):\n",
    "    # Returns a new list of data points at a specified epoch from all folds\n",
    "    # data = [fold1....fold10]\n",
    "    # epoch is 0-indexed\n",
    "    epoch_per_fold = len(data) // total_num_folds\n",
    "    new_data = [data[f * (epoch_per_fold) + epoch] for f in range(total_num_folds)]\n",
    "    return new_data # [epoch n from fold1, epoch n from fold2, ..., epoch n from fold10]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q6(b) - Stochastic Gradient Descent\n",
      "Cur fold: 0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27841, 300)\n",
      "(3479, 300)\n",
      "(3479, 300)\n",
      " epoch: 1, train accuracy: 0.7920, train_loss_norm:0.0867, valid_acc: 0.7686, valid_loss_norm: 0.0867\n",
      " epoch: 2, train accuracy: 0.7920, train_loss_norm:0.0859, valid_acc: 0.7689, valid_loss_norm: 0.0859\n",
      " epoch: 3, train accuracy: 0.7920, train_loss_norm:0.0852, valid_acc: 0.7689, valid_loss_norm: 0.0852\n",
      " epoch: 4, train accuracy: 0.7920, train_loss_norm:0.0844, valid_acc: 0.7689, valid_loss_norm: 0.0845\n",
      " epoch: 5, train accuracy: 0.7921, train_loss_norm:0.0836, valid_acc: 0.7689, valid_loss_norm: 0.0837\n",
      " epoch: 6, train accuracy: 0.7921, train_loss_norm:0.0829, valid_acc: 0.7689, valid_loss_norm: 0.0830\n",
      " epoch: 7, train accuracy: 0.7921, train_loss_norm:0.0821, valid_acc: 0.7689, valid_loss_norm: 0.0822\n",
      " epoch: 8, train accuracy: 0.7921, train_loss_norm:0.0814, valid_acc: 0.7689, valid_loss_norm: 0.0815\n",
      " epoch: 9, train accuracy: 0.7920, train_loss_norm:0.0807, valid_acc: 0.7689, valid_loss_norm: 0.0808\n",
      " epoch: 10, train accuracy: 0.7920, train_loss_norm:0.0799, valid_acc: 0.7689, valid_loss_norm: 0.0801\n",
      " epoch: 11, train accuracy: 0.7921, train_loss_norm:0.0792, valid_acc: 0.7689, valid_loss_norm: 0.0794\n",
      " epoch: 12, train accuracy: 0.7921, train_loss_norm:0.0785, valid_acc: 0.7689, valid_loss_norm: 0.0787\n",
      " epoch: 13, train accuracy: 0.7923, train_loss_norm:0.0778, valid_acc: 0.7689, valid_loss_norm: 0.0779\n",
      " epoch: 14, train accuracy: 0.7923, train_loss_norm:0.0770, valid_acc: 0.7686, valid_loss_norm: 0.0773\n",
      " epoch: 15, train accuracy: 0.7924, train_loss_norm:0.0763, valid_acc: 0.7689, valid_loss_norm: 0.0766\n",
      " epoch: 16, train accuracy: 0.7924, train_loss_norm:0.0756, valid_acc: 0.7689, valid_loss_norm: 0.0759\n",
      " epoch: 17, train accuracy: 0.7924, train_loss_norm:0.0750, valid_acc: 0.7689, valid_loss_norm: 0.0752\n",
      " epoch: 18, train accuracy: 0.7925, train_loss_norm:0.0743, valid_acc: 0.7689, valid_loss_norm: 0.0745\n",
      " epoch: 19, train accuracy: 0.7926, train_loss_norm:0.0736, valid_acc: 0.7692, valid_loss_norm: 0.0739\n",
      " epoch: 20, train accuracy: 0.7929, train_loss_norm:0.0729, valid_acc: 0.7695, valid_loss_norm: 0.0732\n",
      " epoch: 21, train accuracy: 0.7931, train_loss_norm:0.0723, valid_acc: 0.7695, valid_loss_norm: 0.0726\n",
      " epoch: 22, train accuracy: 0.7933, train_loss_norm:0.0716, valid_acc: 0.7695, valid_loss_norm: 0.0719\n",
      " epoch: 23, train accuracy: 0.7933, train_loss_norm:0.0710, valid_acc: 0.7695, valid_loss_norm: 0.0713\n",
      " epoch: 24, train accuracy: 0.7934, train_loss_norm:0.0703, valid_acc: 0.7689, valid_loss_norm: 0.0707\n",
      " epoch: 25, train accuracy: 0.7935, train_loss_norm:0.0697, valid_acc: 0.7686, valid_loss_norm: 0.0701\n",
      " epoch: 26, train accuracy: 0.7937, train_loss_norm:0.0691, valid_acc: 0.7686, valid_loss_norm: 0.0695\n",
      " epoch: 27, train accuracy: 0.7938, train_loss_norm:0.0685, valid_acc: 0.7683, valid_loss_norm: 0.0689\n",
      " epoch: 28, train accuracy: 0.7939, train_loss_norm:0.0679, valid_acc: 0.7686, valid_loss_norm: 0.0683\n",
      " epoch: 29, train accuracy: 0.7942, train_loss_norm:0.0673, valid_acc: 0.7683, valid_loss_norm: 0.0677\n",
      " epoch: 30, train accuracy: 0.7943, train_loss_norm:0.0667, valid_acc: 0.7689, valid_loss_norm: 0.0672\n",
      " epoch: 31, train accuracy: 0.7945, train_loss_norm:0.0662, valid_acc: 0.7689, valid_loss_norm: 0.0666\n",
      " epoch: 32, train accuracy: 0.7948, train_loss_norm:0.0656, valid_acc: 0.7692, valid_loss_norm: 0.0661\n",
      " epoch: 33, train accuracy: 0.7952, train_loss_norm:0.0651, valid_acc: 0.7689, valid_loss_norm: 0.0655\n",
      " epoch: 34, train accuracy: 0.7954, train_loss_norm:0.0645, valid_acc: 0.7686, valid_loss_norm: 0.0650\n",
      " epoch: 35, train accuracy: 0.7958, train_loss_norm:0.0640, valid_acc: 0.7686, valid_loss_norm: 0.0645\n",
      " epoch: 36, train accuracy: 0.7960, train_loss_norm:0.0635, valid_acc: 0.7686, valid_loss_norm: 0.0640\n",
      " epoch: 37, train accuracy: 0.7964, train_loss_norm:0.0630, valid_acc: 0.7683, valid_loss_norm: 0.0635\n",
      " epoch: 38, train accuracy: 0.7965, train_loss_norm:0.0625, valid_acc: 0.7692, valid_loss_norm: 0.0630\n",
      " epoch: 39, train accuracy: 0.7968, train_loss_norm:0.0620, valid_acc: 0.7689, valid_loss_norm: 0.0625\n",
      " epoch: 40, train accuracy: 0.7971, train_loss_norm:0.0615, valid_acc: 0.7695, valid_loss_norm: 0.0621\n",
      " epoch: 41, train accuracy: 0.7973, train_loss_norm:0.0610, valid_acc: 0.7695, valid_loss_norm: 0.0616\n",
      " epoch: 42, train accuracy: 0.7974, train_loss_norm:0.0606, valid_acc: 0.7698, valid_loss_norm: 0.0612\n",
      " epoch: 43, train accuracy: 0.7977, train_loss_norm:0.0601, valid_acc: 0.7700, valid_loss_norm: 0.0607\n",
      " epoch: 44, train accuracy: 0.7979, train_loss_norm:0.0597, valid_acc: 0.7706, valid_loss_norm: 0.0603\n",
      " epoch: 45, train accuracy: 0.7980, train_loss_norm:0.0592, valid_acc: 0.7706, valid_loss_norm: 0.0598\n",
      " epoch: 46, train accuracy: 0.7981, train_loss_norm:0.0588, valid_acc: 0.7709, valid_loss_norm: 0.0594\n",
      " epoch: 47, train accuracy: 0.7983, train_loss_norm:0.0584, valid_acc: 0.7709, valid_loss_norm: 0.0590\n",
      " epoch: 48, train accuracy: 0.7986, train_loss_norm:0.0579, valid_acc: 0.7712, valid_loss_norm: 0.0586\n",
      " epoch: 49, train accuracy: 0.7990, train_loss_norm:0.0575, valid_acc: 0.7723, valid_loss_norm: 0.0582\n",
      " epoch: 50, train accuracy: 0.7993, train_loss_norm:0.0571, valid_acc: 0.7726, valid_loss_norm: 0.0578\n",
      " epoch: 51, train accuracy: 0.7997, train_loss_norm:0.0567, valid_acc: 0.7729, valid_loss_norm: 0.0575\n",
      " epoch: 52, train accuracy: 0.8000, train_loss_norm:0.0564, valid_acc: 0.7732, valid_loss_norm: 0.0571\n",
      " epoch: 53, train accuracy: 0.8004, train_loss_norm:0.0560, valid_acc: 0.7735, valid_loss_norm: 0.0567\n",
      " epoch: 54, train accuracy: 0.8007, train_loss_norm:0.0556, valid_acc: 0.7738, valid_loss_norm: 0.0564\n",
      " epoch: 55, train accuracy: 0.8012, train_loss_norm:0.0553, valid_acc: 0.7741, valid_loss_norm: 0.0560\n",
      " epoch: 56, train accuracy: 0.8016, train_loss_norm:0.0549, valid_acc: 0.7738, valid_loss_norm: 0.0557\n",
      " epoch: 57, train accuracy: 0.8018, train_loss_norm:0.0545, valid_acc: 0.7741, valid_loss_norm: 0.0553\n",
      " epoch: 58, train accuracy: 0.8022, train_loss_norm:0.0542, valid_acc: 0.7741, valid_loss_norm: 0.0550\n",
      " epoch: 59, train accuracy: 0.8025, train_loss_norm:0.0539, valid_acc: 0.7746, valid_loss_norm: 0.0547\n",
      " epoch: 60, train accuracy: 0.8029, train_loss_norm:0.0535, valid_acc: 0.7761, valid_loss_norm: 0.0543\n",
      " epoch: 61, train accuracy: 0.8035, train_loss_norm:0.0532, valid_acc: 0.7764, valid_loss_norm: 0.0540\n",
      " epoch: 62, train accuracy: 0.8037, train_loss_norm:0.0529, valid_acc: 0.7769, valid_loss_norm: 0.0537\n",
      " epoch: 63, train accuracy: 0.8042, train_loss_norm:0.0526, valid_acc: 0.7772, valid_loss_norm: 0.0534\n",
      " epoch: 64, train accuracy: 0.8045, train_loss_norm:0.0523, valid_acc: 0.7775, valid_loss_norm: 0.0531\n",
      " epoch: 65, train accuracy: 0.8049, train_loss_norm:0.0520, valid_acc: 0.7775, valid_loss_norm: 0.0528\n",
      " epoch: 66, train accuracy: 0.8052, train_loss_norm:0.0517, valid_acc: 0.7778, valid_loss_norm: 0.0525\n",
      " epoch: 67, train accuracy: 0.8054, train_loss_norm:0.0514, valid_acc: 0.7781, valid_loss_norm: 0.0522\n",
      " epoch: 68, train accuracy: 0.8056, train_loss_norm:0.0511, valid_acc: 0.7781, valid_loss_norm: 0.0519\n",
      " epoch: 69, train accuracy: 0.8057, train_loss_norm:0.0508, valid_acc: 0.7781, valid_loss_norm: 0.0517\n",
      " epoch: 70, train accuracy: 0.8060, train_loss_norm:0.0505, valid_acc: 0.7781, valid_loss_norm: 0.0514\n",
      " epoch: 71, train accuracy: 0.8062, train_loss_norm:0.0502, valid_acc: 0.7784, valid_loss_norm: 0.0511\n",
      " epoch: 72, train accuracy: 0.8065, train_loss_norm:0.0500, valid_acc: 0.7790, valid_loss_norm: 0.0509\n",
      " epoch: 73, train accuracy: 0.8069, train_loss_norm:0.0497, valid_acc: 0.7792, valid_loss_norm: 0.0506\n",
      " epoch: 74, train accuracy: 0.8074, train_loss_norm:0.0494, valid_acc: 0.7795, valid_loss_norm: 0.0504\n",
      " epoch: 75, train accuracy: 0.8078, train_loss_norm:0.0492, valid_acc: 0.7795, valid_loss_norm: 0.0501\n",
      " epoch: 76, train accuracy: 0.8083, train_loss_norm:0.0489, valid_acc: 0.7795, valid_loss_norm: 0.0499\n",
      " epoch: 77, train accuracy: 0.8086, train_loss_norm:0.0487, valid_acc: 0.7807, valid_loss_norm: 0.0496\n",
      " epoch: 78, train accuracy: 0.8088, train_loss_norm:0.0484, valid_acc: 0.7807, valid_loss_norm: 0.0494\n",
      " epoch: 79, train accuracy: 0.8093, train_loss_norm:0.0482, valid_acc: 0.7810, valid_loss_norm: 0.0492\n",
      " epoch: 80, train accuracy: 0.8096, train_loss_norm:0.0479, valid_acc: 0.7818, valid_loss_norm: 0.0489\n",
      " epoch: 81, train accuracy: 0.8099, train_loss_norm:0.0477, valid_acc: 0.7821, valid_loss_norm: 0.0487\n",
      " epoch: 82, train accuracy: 0.8102, train_loss_norm:0.0475, valid_acc: 0.7824, valid_loss_norm: 0.0485\n",
      " epoch: 83, train accuracy: 0.8107, train_loss_norm:0.0472, valid_acc: 0.7827, valid_loss_norm: 0.0483\n",
      " epoch: 84, train accuracy: 0.8109, train_loss_norm:0.0470, valid_acc: 0.7830, valid_loss_norm: 0.0480\n",
      " epoch: 85, train accuracy: 0.8111, train_loss_norm:0.0468, valid_acc: 0.7841, valid_loss_norm: 0.0478\n",
      " epoch: 86, train accuracy: 0.8116, train_loss_norm:0.0466, valid_acc: 0.7850, valid_loss_norm: 0.0476\n",
      " epoch: 87, train accuracy: 0.8119, train_loss_norm:0.0463, valid_acc: 0.7856, valid_loss_norm: 0.0474\n",
      " epoch: 88, train accuracy: 0.8121, train_loss_norm:0.0461, valid_acc: 0.7861, valid_loss_norm: 0.0472\n",
      " epoch: 89, train accuracy: 0.8125, train_loss_norm:0.0459, valid_acc: 0.7870, valid_loss_norm: 0.0470\n",
      " epoch: 90, train accuracy: 0.8128, train_loss_norm:0.0457, valid_acc: 0.7876, valid_loss_norm: 0.0468\n",
      " epoch: 91, train accuracy: 0.8132, train_loss_norm:0.0455, valid_acc: 0.7876, valid_loss_norm: 0.0466\n",
      " epoch: 92, train accuracy: 0.8134, train_loss_norm:0.0453, valid_acc: 0.7882, valid_loss_norm: 0.0464\n",
      " epoch: 93, train accuracy: 0.8136, train_loss_norm:0.0451, valid_acc: 0.7890, valid_loss_norm: 0.0462\n",
      " epoch: 94, train accuracy: 0.8138, train_loss_norm:0.0449, valid_acc: 0.7890, valid_loss_norm: 0.0460\n",
      " epoch: 95, train accuracy: 0.8143, train_loss_norm:0.0447, valid_acc: 0.7893, valid_loss_norm: 0.0458\n",
      " epoch: 96, train accuracy: 0.8144, train_loss_norm:0.0445, valid_acc: 0.7893, valid_loss_norm: 0.0457\n",
      " epoch: 97, train accuracy: 0.8145, train_loss_norm:0.0443, valid_acc: 0.7896, valid_loss_norm: 0.0455\n",
      " epoch: 98, train accuracy: 0.8148, train_loss_norm:0.0441, valid_acc: 0.7893, valid_loss_norm: 0.0453\n",
      " epoch: 99, train accuracy: 0.8151, train_loss_norm:0.0440, valid_acc: 0.7893, valid_loss_norm: 0.0451\n",
      " epoch: 100, train accuracy: 0.8154, train_loss_norm:0.0438, valid_acc: 0.7893, valid_loss_norm: 0.0449\n",
      " epoch: 101, train accuracy: 0.8157, train_loss_norm:0.0436, valid_acc: 0.7893, valid_loss_norm: 0.0448\n",
      " epoch: 102, train accuracy: 0.8161, train_loss_norm:0.0434, valid_acc: 0.7893, valid_loss_norm: 0.0446\n",
      " epoch: 103, train accuracy: 0.8165, train_loss_norm:0.0432, valid_acc: 0.7896, valid_loss_norm: 0.0444\n",
      " epoch: 104, train accuracy: 0.8167, train_loss_norm:0.0431, valid_acc: 0.7899, valid_loss_norm: 0.0443\n",
      " epoch: 105, train accuracy: 0.8167, train_loss_norm:0.0429, valid_acc: 0.7899, valid_loss_norm: 0.0441\n",
      " epoch: 106, train accuracy: 0.8170, train_loss_norm:0.0427, valid_acc: 0.7899, valid_loss_norm: 0.0439\n",
      " epoch: 107, train accuracy: 0.8173, train_loss_norm:0.0426, valid_acc: 0.7902, valid_loss_norm: 0.0438\n",
      " epoch: 108, train accuracy: 0.8175, train_loss_norm:0.0424, valid_acc: 0.7907, valid_loss_norm: 0.0436\n",
      " epoch: 109, train accuracy: 0.8179, train_loss_norm:0.0422, valid_acc: 0.7910, valid_loss_norm: 0.0435\n",
      " epoch: 110, train accuracy: 0.8180, train_loss_norm:0.0421, valid_acc: 0.7916, valid_loss_norm: 0.0433\n",
      " epoch: 111, train accuracy: 0.8182, train_loss_norm:0.0419, valid_acc: 0.7916, valid_loss_norm: 0.0432\n",
      " epoch: 112, train accuracy: 0.8185, train_loss_norm:0.0418, valid_acc: 0.7916, valid_loss_norm: 0.0430\n",
      " epoch: 113, train accuracy: 0.8188, train_loss_norm:0.0416, valid_acc: 0.7925, valid_loss_norm: 0.0429\n",
      " epoch: 114, train accuracy: 0.8190, train_loss_norm:0.0415, valid_acc: 0.7925, valid_loss_norm: 0.0427\n",
      " epoch: 115, train accuracy: 0.8191, train_loss_norm:0.0413, valid_acc: 0.7928, valid_loss_norm: 0.0426\n",
      " epoch: 116, train accuracy: 0.8193, train_loss_norm:0.0412, valid_acc: 0.7939, valid_loss_norm: 0.0424\n",
      " epoch: 117, train accuracy: 0.8196, train_loss_norm:0.0410, valid_acc: 0.7942, valid_loss_norm: 0.0423\n",
      " epoch: 118, train accuracy: 0.8197, train_loss_norm:0.0409, valid_acc: 0.7951, valid_loss_norm: 0.0422\n",
      " epoch: 119, train accuracy: 0.8199, train_loss_norm:0.0407, valid_acc: 0.7951, valid_loss_norm: 0.0420\n",
      " epoch: 120, train accuracy: 0.8199, train_loss_norm:0.0406, valid_acc: 0.7951, valid_loss_norm: 0.0419\n",
      " epoch: 121, train accuracy: 0.8202, train_loss_norm:0.0404, valid_acc: 0.7948, valid_loss_norm: 0.0417\n",
      " epoch: 122, train accuracy: 0.8206, train_loss_norm:0.0403, valid_acc: 0.7945, valid_loss_norm: 0.0416\n",
      " epoch: 123, train accuracy: 0.8209, train_loss_norm:0.0401, valid_acc: 0.7945, valid_loss_norm: 0.0415\n",
      " epoch: 124, train accuracy: 0.8211, train_loss_norm:0.0400, valid_acc: 0.7942, valid_loss_norm: 0.0413\n",
      " epoch: 125, train accuracy: 0.8213, train_loss_norm:0.0399, valid_acc: 0.7942, valid_loss_norm: 0.0412\n",
      " epoch: 126, train accuracy: 0.8217, train_loss_norm:0.0397, valid_acc: 0.7942, valid_loss_norm: 0.0411\n",
      " epoch: 127, train accuracy: 0.8220, train_loss_norm:0.0396, valid_acc: 0.7948, valid_loss_norm: 0.0410\n",
      " epoch: 128, train accuracy: 0.8222, train_loss_norm:0.0395, valid_acc: 0.7951, valid_loss_norm: 0.0408\n",
      " epoch: 129, train accuracy: 0.8224, train_loss_norm:0.0393, valid_acc: 0.7948, valid_loss_norm: 0.0407\n",
      " epoch: 130, train accuracy: 0.8229, train_loss_norm:0.0392, valid_acc: 0.7959, valid_loss_norm: 0.0406\n",
      " epoch: 131, train accuracy: 0.8230, train_loss_norm:0.0391, valid_acc: 0.7953, valid_loss_norm: 0.0405\n",
      " epoch: 132, train accuracy: 0.8234, train_loss_norm:0.0390, valid_acc: 0.7953, valid_loss_norm: 0.0403\n",
      " epoch: 133, train accuracy: 0.8235, train_loss_norm:0.0388, valid_acc: 0.7956, valid_loss_norm: 0.0402\n",
      " epoch: 134, train accuracy: 0.8238, train_loss_norm:0.0387, valid_acc: 0.7962, valid_loss_norm: 0.0401\n",
      " epoch: 135, train accuracy: 0.8239, train_loss_norm:0.0386, valid_acc: 0.7968, valid_loss_norm: 0.0400\n",
      " epoch: 136, train accuracy: 0.8240, train_loss_norm:0.0385, valid_acc: 0.7971, valid_loss_norm: 0.0399\n",
      " epoch: 137, train accuracy: 0.8243, train_loss_norm:0.0383, valid_acc: 0.7976, valid_loss_norm: 0.0398\n",
      " epoch: 138, train accuracy: 0.8243, train_loss_norm:0.0382, valid_acc: 0.7974, valid_loss_norm: 0.0396\n",
      " epoch: 139, train accuracy: 0.8246, train_loss_norm:0.0381, valid_acc: 0.7979, valid_loss_norm: 0.0395\n",
      " epoch: 140, train accuracy: 0.8247, train_loss_norm:0.0380, valid_acc: 0.7971, valid_loss_norm: 0.0394\n",
      " epoch: 141, train accuracy: 0.8247, train_loss_norm:0.0379, valid_acc: 0.7971, valid_loss_norm: 0.0393\n",
      " epoch: 142, train accuracy: 0.8249, train_loss_norm:0.0377, valid_acc: 0.7976, valid_loss_norm: 0.0392\n",
      " epoch: 143, train accuracy: 0.8251, train_loss_norm:0.0376, valid_acc: 0.7979, valid_loss_norm: 0.0391\n",
      " epoch: 144, train accuracy: 0.8256, train_loss_norm:0.0375, valid_acc: 0.7985, valid_loss_norm: 0.0390\n",
      " epoch: 145, train accuracy: 0.8258, train_loss_norm:0.0374, valid_acc: 0.7985, valid_loss_norm: 0.0389\n",
      " epoch: 146, train accuracy: 0.8261, train_loss_norm:0.0373, valid_acc: 0.7985, valid_loss_norm: 0.0388\n",
      " epoch: 147, train accuracy: 0.8263, train_loss_norm:0.0372, valid_acc: 0.7985, valid_loss_norm: 0.0387\n",
      " epoch: 148, train accuracy: 0.8266, train_loss_norm:0.0371, valid_acc: 0.7991, valid_loss_norm: 0.0386\n",
      " epoch: 149, train accuracy: 0.8269, train_loss_norm:0.0370, valid_acc: 0.7991, valid_loss_norm: 0.0385\n",
      " epoch: 150, train accuracy: 0.8271, train_loss_norm:0.0369, valid_acc: 0.7994, valid_loss_norm: 0.0384\n",
      " epoch: 151, train accuracy: 0.8273, train_loss_norm:0.0368, valid_acc: 0.7994, valid_loss_norm: 0.0383\n",
      " epoch: 152, train accuracy: 0.8273, train_loss_norm:0.0366, valid_acc: 0.7991, valid_loss_norm: 0.0382\n",
      " epoch: 153, train accuracy: 0.8276, train_loss_norm:0.0365, valid_acc: 0.7994, valid_loss_norm: 0.0381\n",
      " epoch: 154, train accuracy: 0.8279, train_loss_norm:0.0364, valid_acc: 0.7994, valid_loss_norm: 0.0380\n",
      " epoch: 155, train accuracy: 0.8282, train_loss_norm:0.0363, valid_acc: 0.7994, valid_loss_norm: 0.0379\n",
      " epoch: 156, train accuracy: 0.8282, train_loss_norm:0.0362, valid_acc: 0.7994, valid_loss_norm: 0.0378\n",
      " epoch: 157, train accuracy: 0.8285, train_loss_norm:0.0361, valid_acc: 0.8002, valid_loss_norm: 0.0377\n",
      " epoch: 158, train accuracy: 0.8288, train_loss_norm:0.0360, valid_acc: 0.7997, valid_loss_norm: 0.0376\n",
      " epoch: 159, train accuracy: 0.8291, train_loss_norm:0.0359, valid_acc: 0.7999, valid_loss_norm: 0.0375\n",
      " epoch: 160, train accuracy: 0.8292, train_loss_norm:0.0358, valid_acc: 0.7999, valid_loss_norm: 0.0374\n",
      " epoch: 161, train accuracy: 0.8295, train_loss_norm:0.0357, valid_acc: 0.7999, valid_loss_norm: 0.0373\n",
      " epoch: 162, train accuracy: 0.8296, train_loss_norm:0.0356, valid_acc: 0.8002, valid_loss_norm: 0.0372\n",
      " epoch: 163, train accuracy: 0.8299, train_loss_norm:0.0356, valid_acc: 0.7999, valid_loss_norm: 0.0371\n",
      " epoch: 164, train accuracy: 0.8300, train_loss_norm:0.0355, valid_acc: 0.8005, valid_loss_norm: 0.0370\n",
      " epoch: 165, train accuracy: 0.8304, train_loss_norm:0.0354, valid_acc: 0.8005, valid_loss_norm: 0.0369\n",
      " epoch: 166, train accuracy: 0.8305, train_loss_norm:0.0353, valid_acc: 0.8005, valid_loss_norm: 0.0369\n",
      " epoch: 167, train accuracy: 0.8306, train_loss_norm:0.0352, valid_acc: 0.8005, valid_loss_norm: 0.0368\n",
      " epoch: 168, train accuracy: 0.8309, train_loss_norm:0.0351, valid_acc: 0.8005, valid_loss_norm: 0.0367\n",
      " epoch: 169, train accuracy: 0.8311, train_loss_norm:0.0350, valid_acc: 0.8005, valid_loss_norm: 0.0366\n",
      " epoch: 170, train accuracy: 0.8313, train_loss_norm:0.0349, valid_acc: 0.8005, valid_loss_norm: 0.0365\n",
      " epoch: 171, train accuracy: 0.8315, train_loss_norm:0.0348, valid_acc: 0.8008, valid_loss_norm: 0.0364\n",
      " epoch: 172, train accuracy: 0.8316, train_loss_norm:0.0347, valid_acc: 0.8011, valid_loss_norm: 0.0363\n",
      " epoch: 173, train accuracy: 0.8318, train_loss_norm:0.0346, valid_acc: 0.8011, valid_loss_norm: 0.0363\n",
      " epoch: 174, train accuracy: 0.8321, train_loss_norm:0.0345, valid_acc: 0.8011, valid_loss_norm: 0.0362\n",
      " epoch: 175, train accuracy: 0.8323, train_loss_norm:0.0345, valid_acc: 0.8011, valid_loss_norm: 0.0361\n",
      " epoch: 176, train accuracy: 0.8327, train_loss_norm:0.0344, valid_acc: 0.8017, valid_loss_norm: 0.0360\n",
      " epoch: 177, train accuracy: 0.8327, train_loss_norm:0.0343, valid_acc: 0.8025, valid_loss_norm: 0.0359\n",
      " epoch: 178, train accuracy: 0.8330, train_loss_norm:0.0342, valid_acc: 0.8028, valid_loss_norm: 0.0359\n",
      " epoch: 179, train accuracy: 0.8331, train_loss_norm:0.0341, valid_acc: 0.8028, valid_loss_norm: 0.0358\n",
      " epoch: 180, train accuracy: 0.8333, train_loss_norm:0.0340, valid_acc: 0.8028, valid_loss_norm: 0.0357\n",
      " epoch: 181, train accuracy: 0.8334, train_loss_norm:0.0340, valid_acc: 0.8028, valid_loss_norm: 0.0356\n",
      " epoch: 182, train accuracy: 0.8336, train_loss_norm:0.0339, valid_acc: 0.8031, valid_loss_norm: 0.0355\n",
      " epoch: 183, train accuracy: 0.8338, train_loss_norm:0.0338, valid_acc: 0.8037, valid_loss_norm: 0.0355\n",
      " epoch: 184, train accuracy: 0.8339, train_loss_norm:0.0337, valid_acc: 0.8043, valid_loss_norm: 0.0354\n",
      " epoch: 185, train accuracy: 0.8341, train_loss_norm:0.0336, valid_acc: 0.8051, valid_loss_norm: 0.0353\n",
      " epoch: 186, train accuracy: 0.8342, train_loss_norm:0.0335, valid_acc: 0.8054, valid_loss_norm: 0.0352\n",
      " epoch: 187, train accuracy: 0.8345, train_loss_norm:0.0335, valid_acc: 0.8051, valid_loss_norm: 0.0352\n",
      " epoch: 188, train accuracy: 0.8346, train_loss_norm:0.0334, valid_acc: 0.8054, valid_loss_norm: 0.0351\n",
      " epoch: 189, train accuracy: 0.8347, train_loss_norm:0.0333, valid_acc: 0.8057, valid_loss_norm: 0.0350\n",
      " epoch: 190, train accuracy: 0.8348, train_loss_norm:0.0332, valid_acc: 0.8060, valid_loss_norm: 0.0349\n",
      " epoch: 191, train accuracy: 0.8351, train_loss_norm:0.0332, valid_acc: 0.8060, valid_loss_norm: 0.0349\n",
      " epoch: 192, train accuracy: 0.8352, train_loss_norm:0.0331, valid_acc: 0.8063, valid_loss_norm: 0.0348\n",
      " epoch: 193, train accuracy: 0.8354, train_loss_norm:0.0330, valid_acc: 0.8057, valid_loss_norm: 0.0347\n",
      " epoch: 194, train accuracy: 0.8355, train_loss_norm:0.0329, valid_acc: 0.8060, valid_loss_norm: 0.0347\n",
      " epoch: 195, train accuracy: 0.8359, train_loss_norm:0.0329, valid_acc: 0.8063, valid_loss_norm: 0.0346\n",
      " epoch: 196, train accuracy: 0.8360, train_loss_norm:0.0328, valid_acc: 0.8063, valid_loss_norm: 0.0345\n",
      " epoch: 197, train accuracy: 0.8361, train_loss_norm:0.0327, valid_acc: 0.8068, valid_loss_norm: 0.0344\n",
      " epoch: 198, train accuracy: 0.8361, train_loss_norm:0.0326, valid_acc: 0.8068, valid_loss_norm: 0.0344\n",
      " epoch: 199, train accuracy: 0.8365, train_loss_norm:0.0326, valid_acc: 0.8066, valid_loss_norm: 0.0343\n",
      " epoch: 200, train accuracy: 0.8365, train_loss_norm:0.0325, valid_acc: 0.8066, valid_loss_norm: 0.0342\n",
      " epoch: 201, train accuracy: 0.8365, train_loss_norm:0.0324, valid_acc: 0.8066, valid_loss_norm: 0.0342\n",
      " epoch: 202, train accuracy: 0.8367, train_loss_norm:0.0323, valid_acc: 0.8068, valid_loss_norm: 0.0341\n",
      " epoch: 203, train accuracy: 0.8369, train_loss_norm:0.0323, valid_acc: 0.8068, valid_loss_norm: 0.0340\n",
      " epoch: 204, train accuracy: 0.8371, train_loss_norm:0.0322, valid_acc: 0.8066, valid_loss_norm: 0.0340\n",
      " epoch: 205, train accuracy: 0.8372, train_loss_norm:0.0321, valid_acc: 0.8066, valid_loss_norm: 0.0339\n",
      " epoch: 206, train accuracy: 0.8375, train_loss_norm:0.0321, valid_acc: 0.8068, valid_loss_norm: 0.0338\n",
      " epoch: 207, train accuracy: 0.8376, train_loss_norm:0.0320, valid_acc: 0.8068, valid_loss_norm: 0.0338\n",
      " epoch: 208, train accuracy: 0.8376, train_loss_norm:0.0319, valid_acc: 0.8068, valid_loss_norm: 0.0337\n",
      " epoch: 209, train accuracy: 0.8378, train_loss_norm:0.0319, valid_acc: 0.8074, valid_loss_norm: 0.0337\n",
      " epoch: 210, train accuracy: 0.8380, train_loss_norm:0.0318, valid_acc: 0.8077, valid_loss_norm: 0.0336\n",
      " epoch: 211, train accuracy: 0.8381, train_loss_norm:0.0317, valid_acc: 0.8074, valid_loss_norm: 0.0335\n",
      " epoch: 212, train accuracy: 0.8382, train_loss_norm:0.0317, valid_acc: 0.8077, valid_loss_norm: 0.0335\n",
      " epoch: 213, train accuracy: 0.8383, train_loss_norm:0.0316, valid_acc: 0.8077, valid_loss_norm: 0.0334\n",
      " epoch: 214, train accuracy: 0.8385, train_loss_norm:0.0315, valid_acc: 0.8077, valid_loss_norm: 0.0333\n",
      " epoch: 215, train accuracy: 0.8388, train_loss_norm:0.0315, valid_acc: 0.8077, valid_loss_norm: 0.0333\n",
      " epoch: 216, train accuracy: 0.8389, train_loss_norm:0.0314, valid_acc: 0.8077, valid_loss_norm: 0.0332\n",
      " epoch: 217, train accuracy: 0.8391, train_loss_norm:0.0313, valid_acc: 0.8080, valid_loss_norm: 0.0332\n",
      " epoch: 218, train accuracy: 0.8391, train_loss_norm:0.0313, valid_acc: 0.8080, valid_loss_norm: 0.0331\n",
      " epoch: 219, train accuracy: 0.8392, train_loss_norm:0.0312, valid_acc: 0.8080, valid_loss_norm: 0.0330\n",
      " epoch: 220, train accuracy: 0.8393, train_loss_norm:0.0311, valid_acc: 0.8083, valid_loss_norm: 0.0330\n",
      " epoch: 221, train accuracy: 0.8394, train_loss_norm:0.0311, valid_acc: 0.8086, valid_loss_norm: 0.0329\n",
      " epoch: 222, train accuracy: 0.8397, train_loss_norm:0.0310, valid_acc: 0.8089, valid_loss_norm: 0.0329\n",
      " epoch: 223, train accuracy: 0.8399, train_loss_norm:0.0310, valid_acc: 0.8091, valid_loss_norm: 0.0328\n",
      " epoch: 224, train accuracy: 0.8400, train_loss_norm:0.0309, valid_acc: 0.8091, valid_loss_norm: 0.0328\n",
      " epoch: 225, train accuracy: 0.8402, train_loss_norm:0.0308, valid_acc: 0.8094, valid_loss_norm: 0.0327\n",
      " epoch: 226, train accuracy: 0.8403, train_loss_norm:0.0308, valid_acc: 0.8094, valid_loss_norm: 0.0326\n",
      " epoch: 227, train accuracy: 0.8404, train_loss_norm:0.0307, valid_acc: 0.8097, valid_loss_norm: 0.0326\n",
      " epoch: 228, train accuracy: 0.8405, train_loss_norm:0.0307, valid_acc: 0.8097, valid_loss_norm: 0.0325\n",
      " epoch: 229, train accuracy: 0.8407, train_loss_norm:0.0306, valid_acc: 0.8097, valid_loss_norm: 0.0325\n",
      " epoch: 230, train accuracy: 0.8408, train_loss_norm:0.0305, valid_acc: 0.8097, valid_loss_norm: 0.0324\n",
      " epoch: 231, train accuracy: 0.8409, train_loss_norm:0.0305, valid_acc: 0.8097, valid_loss_norm: 0.0324\n",
      " epoch: 232, train accuracy: 0.8410, train_loss_norm:0.0304, valid_acc: 0.8097, valid_loss_norm: 0.0323\n",
      " epoch: 233, train accuracy: 0.8411, train_loss_norm:0.0304, valid_acc: 0.8100, valid_loss_norm: 0.0323\n",
      " epoch: 234, train accuracy: 0.8413, train_loss_norm:0.0303, valid_acc: 0.8097, valid_loss_norm: 0.0322\n",
      " epoch: 235, train accuracy: 0.8414, train_loss_norm:0.0302, valid_acc: 0.8097, valid_loss_norm: 0.0321\n",
      " epoch: 236, train accuracy: 0.8415, train_loss_norm:0.0302, valid_acc: 0.8097, valid_loss_norm: 0.0321\n",
      " epoch: 237, train accuracy: 0.8416, train_loss_norm:0.0301, valid_acc: 0.8097, valid_loss_norm: 0.0320\n",
      " epoch: 238, train accuracy: 0.8416, train_loss_norm:0.0301, valid_acc: 0.8100, valid_loss_norm: 0.0320\n",
      " epoch: 239, train accuracy: 0.8417, train_loss_norm:0.0300, valid_acc: 0.8100, valid_loss_norm: 0.0319\n",
      " epoch: 240, train accuracy: 0.8418, train_loss_norm:0.0300, valid_acc: 0.8103, valid_loss_norm: 0.0319\n",
      " epoch: 241, train accuracy: 0.8419, train_loss_norm:0.0299, valid_acc: 0.8106, valid_loss_norm: 0.0318\n",
      " epoch: 242, train accuracy: 0.8420, train_loss_norm:0.0298, valid_acc: 0.8109, valid_loss_norm: 0.0318\n",
      " epoch: 243, train accuracy: 0.8422, train_loss_norm:0.0298, valid_acc: 0.8112, valid_loss_norm: 0.0317\n",
      " epoch: 244, train accuracy: 0.8422, train_loss_norm:0.0297, valid_acc: 0.8109, valid_loss_norm: 0.0317\n",
      " epoch: 245, train accuracy: 0.8424, train_loss_norm:0.0297, valid_acc: 0.8112, valid_loss_norm: 0.0316\n",
      " epoch: 246, train accuracy: 0.8424, train_loss_norm:0.0296, valid_acc: 0.8112, valid_loss_norm: 0.0316\n",
      " epoch: 247, train accuracy: 0.8425, train_loss_norm:0.0296, valid_acc: 0.8112, valid_loss_norm: 0.0315\n",
      " epoch: 248, train accuracy: 0.8426, train_loss_norm:0.0295, valid_acc: 0.8114, valid_loss_norm: 0.0315\n",
      " epoch: 249, train accuracy: 0.8427, train_loss_norm:0.0295, valid_acc: 0.8114, valid_loss_norm: 0.0314\n",
      " epoch: 250, train accuracy: 0.8427, train_loss_norm:0.0294, valid_acc: 0.8114, valid_loss_norm: 0.0314\n",
      " epoch: 251, train accuracy: 0.8427, train_loss_norm:0.0294, valid_acc: 0.8117, valid_loss_norm: 0.0313\n",
      " epoch: 252, train accuracy: 0.8428, train_loss_norm:0.0293, valid_acc: 0.8120, valid_loss_norm: 0.0313\n",
      " epoch: 253, train accuracy: 0.8429, train_loss_norm:0.0293, valid_acc: 0.8123, valid_loss_norm: 0.0312\n",
      " epoch: 254, train accuracy: 0.8431, train_loss_norm:0.0292, valid_acc: 0.8123, valid_loss_norm: 0.0312\n",
      " epoch: 255, train accuracy: 0.8431, train_loss_norm:0.0292, valid_acc: 0.8123, valid_loss_norm: 0.0311\n",
      " epoch: 256, train accuracy: 0.8433, train_loss_norm:0.0291, valid_acc: 0.8123, valid_loss_norm: 0.0311\n",
      " epoch: 257, train accuracy: 0.8434, train_loss_norm:0.0291, valid_acc: 0.8132, valid_loss_norm: 0.0310\n",
      " epoch: 258, train accuracy: 0.8436, train_loss_norm:0.0290, valid_acc: 0.8132, valid_loss_norm: 0.0310\n",
      " epoch: 259, train accuracy: 0.8437, train_loss_norm:0.0290, valid_acc: 0.8132, valid_loss_norm: 0.0309\n",
      " epoch: 260, train accuracy: 0.8437, train_loss_norm:0.0289, valid_acc: 0.8132, valid_loss_norm: 0.0309\n",
      " epoch: 261, train accuracy: 0.8438, train_loss_norm:0.0289, valid_acc: 0.8132, valid_loss_norm: 0.0309\n",
      " epoch: 262, train accuracy: 0.8438, train_loss_norm:0.0288, valid_acc: 0.8132, valid_loss_norm: 0.0308\n",
      " epoch: 263, train accuracy: 0.8439, train_loss_norm:0.0288, valid_acc: 0.8132, valid_loss_norm: 0.0308\n",
      " epoch: 264, train accuracy: 0.8440, train_loss_norm:0.0287, valid_acc: 0.8137, valid_loss_norm: 0.0307\n",
      " epoch: 265, train accuracy: 0.8441, train_loss_norm:0.0287, valid_acc: 0.8143, valid_loss_norm: 0.0307\n",
      " epoch: 266, train accuracy: 0.8442, train_loss_norm:0.0286, valid_acc: 0.8146, valid_loss_norm: 0.0306\n",
      " epoch: 267, train accuracy: 0.8441, train_loss_norm:0.0286, valid_acc: 0.8146, valid_loss_norm: 0.0306\n",
      " epoch: 268, train accuracy: 0.8441, train_loss_norm:0.0285, valid_acc: 0.8146, valid_loss_norm: 0.0305\n",
      " epoch: 269, train accuracy: 0.8442, train_loss_norm:0.0285, valid_acc: 0.8146, valid_loss_norm: 0.0305\n",
      " epoch: 270, train accuracy: 0.8445, train_loss_norm:0.0284, valid_acc: 0.8146, valid_loss_norm: 0.0305\n",
      " epoch: 271, train accuracy: 0.8447, train_loss_norm:0.0284, valid_acc: 0.8146, valid_loss_norm: 0.0304\n",
      " epoch: 272, train accuracy: 0.8447, train_loss_norm:0.0283, valid_acc: 0.8146, valid_loss_norm: 0.0304\n",
      " epoch: 273, train accuracy: 0.8449, train_loss_norm:0.0283, valid_acc: 0.8149, valid_loss_norm: 0.0303\n",
      " epoch: 274, train accuracy: 0.8453, train_loss_norm:0.0282, valid_acc: 0.8149, valid_loss_norm: 0.0303\n",
      " epoch: 275, train accuracy: 0.8453, train_loss_norm:0.0282, valid_acc: 0.8149, valid_loss_norm: 0.0302\n",
      " epoch: 276, train accuracy: 0.8454, train_loss_norm:0.0281, valid_acc: 0.8149, valid_loss_norm: 0.0302\n",
      " epoch: 277, train accuracy: 0.8456, train_loss_norm:0.0281, valid_acc: 0.8152, valid_loss_norm: 0.0302\n",
      " epoch: 278, train accuracy: 0.8457, train_loss_norm:0.0281, valid_acc: 0.8152, valid_loss_norm: 0.0301\n",
      " epoch: 279, train accuracy: 0.8459, train_loss_norm:0.0280, valid_acc: 0.8152, valid_loss_norm: 0.0301\n",
      " epoch: 280, train accuracy: 0.8460, train_loss_norm:0.0280, valid_acc: 0.8155, valid_loss_norm: 0.0300\n",
      " epoch: 281, train accuracy: 0.8461, train_loss_norm:0.0279, valid_acc: 0.8155, valid_loss_norm: 0.0300\n",
      " epoch: 282, train accuracy: 0.8463, train_loss_norm:0.0279, valid_acc: 0.8155, valid_loss_norm: 0.0299\n",
      " epoch: 283, train accuracy: 0.8463, train_loss_norm:0.0278, valid_acc: 0.8158, valid_loss_norm: 0.0299\n",
      " epoch: 284, train accuracy: 0.8466, train_loss_norm:0.0278, valid_acc: 0.8158, valid_loss_norm: 0.0299\n",
      " epoch: 285, train accuracy: 0.8467, train_loss_norm:0.0277, valid_acc: 0.8158, valid_loss_norm: 0.0298\n",
      " epoch: 286, train accuracy: 0.8467, train_loss_norm:0.0277, valid_acc: 0.8158, valid_loss_norm: 0.0298\n",
      " epoch: 287, train accuracy: 0.8468, train_loss_norm:0.0277, valid_acc: 0.8158, valid_loss_norm: 0.0297\n",
      " epoch: 288, train accuracy: 0.8470, train_loss_norm:0.0276, valid_acc: 0.8155, valid_loss_norm: 0.0297\n",
      " epoch: 289, train accuracy: 0.8470, train_loss_norm:0.0276, valid_acc: 0.8158, valid_loss_norm: 0.0297\n",
      " epoch: 290, train accuracy: 0.8470, train_loss_norm:0.0275, valid_acc: 0.8160, valid_loss_norm: 0.0296\n",
      " epoch: 291, train accuracy: 0.8471, train_loss_norm:0.0275, valid_acc: 0.8160, valid_loss_norm: 0.0296\n",
      " epoch: 292, train accuracy: 0.8473, train_loss_norm:0.0275, valid_acc: 0.8158, valid_loss_norm: 0.0295\n",
      " epoch: 293, train accuracy: 0.8473, train_loss_norm:0.0274, valid_acc: 0.8160, valid_loss_norm: 0.0295\n",
      " epoch: 294, train accuracy: 0.8474, train_loss_norm:0.0274, valid_acc: 0.8160, valid_loss_norm: 0.0295\n",
      " epoch: 295, train accuracy: 0.8475, train_loss_norm:0.0273, valid_acc: 0.8160, valid_loss_norm: 0.0294\n",
      " epoch: 296, train accuracy: 0.8475, train_loss_norm:0.0273, valid_acc: 0.8160, valid_loss_norm: 0.0294\n",
      " epoch: 297, train accuracy: 0.8477, train_loss_norm:0.0272, valid_acc: 0.8160, valid_loss_norm: 0.0294\n",
      " epoch: 298, train accuracy: 0.8478, train_loss_norm:0.0272, valid_acc: 0.8160, valid_loss_norm: 0.0293\n",
      " epoch: 299, train accuracy: 0.8479, train_loss_norm:0.0272, valid_acc: 0.8163, valid_loss_norm: 0.0293\n",
      " epoch: 300, train accuracy: 0.8480, train_loss_norm:0.0271, valid_acc: 0.8166, valid_loss_norm: 0.0292\n",
      "Test accuracy: 0.8284\n",
      "Test loss norm: 0.0288\n",
      "Cur fold: 1\n",
      "(27841, 300)\n",
      "(3479, 300)\n",
      "(3479, 300)\n",
      " epoch: 1, train accuracy: 0.7922, train_loss_norm:0.0867, valid_acc: 0.7787, valid_loss_norm: 0.0867\n",
      " epoch: 2, train accuracy: 0.7922, train_loss_norm:0.0859, valid_acc: 0.7787, valid_loss_norm: 0.0860\n",
      " epoch: 3, train accuracy: 0.7922, train_loss_norm:0.0851, valid_acc: 0.7787, valid_loss_norm: 0.0852\n",
      " epoch: 4, train accuracy: 0.7922, train_loss_norm:0.0844, valid_acc: 0.7787, valid_loss_norm: 0.0845\n",
      " epoch: 5, train accuracy: 0.7922, train_loss_norm:0.0836, valid_acc: 0.7787, valid_loss_norm: 0.0837\n",
      " epoch: 6, train accuracy: 0.7922, train_loss_norm:0.0829, valid_acc: 0.7787, valid_loss_norm: 0.0830\n",
      " epoch: 7, train accuracy: 0.7922, train_loss_norm:0.0821, valid_acc: 0.7787, valid_loss_norm: 0.0823\n",
      " epoch: 8, train accuracy: 0.7923, train_loss_norm:0.0814, valid_acc: 0.7784, valid_loss_norm: 0.0816\n",
      " epoch: 9, train accuracy: 0.7923, train_loss_norm:0.0806, valid_acc: 0.7784, valid_loss_norm: 0.0808\n",
      " epoch: 10, train accuracy: 0.7924, train_loss_norm:0.0799, valid_acc: 0.7784, valid_loss_norm: 0.0801\n",
      " epoch: 11, train accuracy: 0.7925, train_loss_norm:0.0792, valid_acc: 0.7781, valid_loss_norm: 0.0794\n",
      " epoch: 12, train accuracy: 0.7925, train_loss_norm:0.0785, valid_acc: 0.7781, valid_loss_norm: 0.0787\n",
      " epoch: 13, train accuracy: 0.7926, train_loss_norm:0.0777, valid_acc: 0.7787, valid_loss_norm: 0.0780\n",
      " epoch: 14, train accuracy: 0.7927, train_loss_norm:0.0770, valid_acc: 0.7790, valid_loss_norm: 0.0773\n",
      " epoch: 15, train accuracy: 0.7928, train_loss_norm:0.0763, valid_acc: 0.7792, valid_loss_norm: 0.0766\n",
      " epoch: 16, train accuracy: 0.7930, train_loss_norm:0.0756, valid_acc: 0.7795, valid_loss_norm: 0.0760\n",
      " epoch: 17, train accuracy: 0.7931, train_loss_norm:0.0749, valid_acc: 0.7795, valid_loss_norm: 0.0753\n",
      " epoch: 18, train accuracy: 0.7933, train_loss_norm:0.0743, valid_acc: 0.7795, valid_loss_norm: 0.0746\n",
      " epoch: 19, train accuracy: 0.7935, train_loss_norm:0.0736, valid_acc: 0.7795, valid_loss_norm: 0.0740\n",
      " epoch: 20, train accuracy: 0.7936, train_loss_norm:0.0729, valid_acc: 0.7801, valid_loss_norm: 0.0733\n",
      " epoch: 21, train accuracy: 0.7937, train_loss_norm:0.0723, valid_acc: 0.7807, valid_loss_norm: 0.0727\n",
      " epoch: 22, train accuracy: 0.7938, train_loss_norm:0.0716, valid_acc: 0.7804, valid_loss_norm: 0.0721\n",
      " epoch: 23, train accuracy: 0.7939, train_loss_norm:0.0710, valid_acc: 0.7804, valid_loss_norm: 0.0714\n",
      " epoch: 24, train accuracy: 0.7939, train_loss_norm:0.0703, valid_acc: 0.7807, valid_loss_norm: 0.0708\n",
      " epoch: 25, train accuracy: 0.7939, train_loss_norm:0.0697, valid_acc: 0.7807, valid_loss_norm: 0.0702\n",
      " epoch: 26, train accuracy: 0.7940, train_loss_norm:0.0691, valid_acc: 0.7810, valid_loss_norm: 0.0696\n",
      " epoch: 27, train accuracy: 0.7941, train_loss_norm:0.0685, valid_acc: 0.7810, valid_loss_norm: 0.0690\n",
      " epoch: 28, train accuracy: 0.7943, train_loss_norm:0.0679, valid_acc: 0.7810, valid_loss_norm: 0.0684\n",
      " epoch: 29, train accuracy: 0.7946, train_loss_norm:0.0673, valid_acc: 0.7815, valid_loss_norm: 0.0679\n",
      " epoch: 30, train accuracy: 0.7947, train_loss_norm:0.0667, valid_acc: 0.7818, valid_loss_norm: 0.0673\n",
      " epoch: 31, train accuracy: 0.7949, train_loss_norm:0.0661, valid_acc: 0.7818, valid_loss_norm: 0.0668\n",
      " epoch: 32, train accuracy: 0.7951, train_loss_norm:0.0656, valid_acc: 0.7827, valid_loss_norm: 0.0662\n",
      " epoch: 33, train accuracy: 0.7955, train_loss_norm:0.0650, valid_acc: 0.7827, valid_loss_norm: 0.0657\n",
      " epoch: 34, train accuracy: 0.7956, train_loss_norm:0.0645, valid_acc: 0.7830, valid_loss_norm: 0.0652\n",
      " epoch: 35, train accuracy: 0.7959, train_loss_norm:0.0640, valid_acc: 0.7827, valid_loss_norm: 0.0646\n",
      " epoch: 36, train accuracy: 0.7963, train_loss_norm:0.0635, valid_acc: 0.7827, valid_loss_norm: 0.0641\n",
      " epoch: 37, train accuracy: 0.7966, train_loss_norm:0.0629, valid_acc: 0.7830, valid_loss_norm: 0.0636\n",
      " epoch: 38, train accuracy: 0.7969, train_loss_norm:0.0624, valid_acc: 0.7836, valid_loss_norm: 0.0631\n",
      " epoch: 39, train accuracy: 0.7971, train_loss_norm:0.0620, valid_acc: 0.7836, valid_loss_norm: 0.0627\n",
      " epoch: 40, train accuracy: 0.7973, train_loss_norm:0.0615, valid_acc: 0.7836, valid_loss_norm: 0.0622\n",
      " epoch: 41, train accuracy: 0.7976, train_loss_norm:0.0610, valid_acc: 0.7833, valid_loss_norm: 0.0617\n",
      " epoch: 42, train accuracy: 0.7982, train_loss_norm:0.0605, valid_acc: 0.7833, valid_loss_norm: 0.0613\n",
      " epoch: 43, train accuracy: 0.7986, train_loss_norm:0.0601, valid_acc: 0.7836, valid_loss_norm: 0.0608\n",
      " epoch: 44, train accuracy: 0.7990, train_loss_norm:0.0596, valid_acc: 0.7841, valid_loss_norm: 0.0604\n",
      " epoch: 45, train accuracy: 0.7993, train_loss_norm:0.0592, valid_acc: 0.7847, valid_loss_norm: 0.0600\n",
      " epoch: 46, train accuracy: 0.7996, train_loss_norm:0.0588, valid_acc: 0.7847, valid_loss_norm: 0.0596\n",
      " epoch: 47, train accuracy: 0.8000, train_loss_norm:0.0583, valid_acc: 0.7850, valid_loss_norm: 0.0591\n",
      " epoch: 48, train accuracy: 0.8001, train_loss_norm:0.0579, valid_acc: 0.7856, valid_loss_norm: 0.0587\n",
      " epoch: 49, train accuracy: 0.8001, train_loss_norm:0.0575, valid_acc: 0.7859, valid_loss_norm: 0.0583\n",
      " epoch: 50, train accuracy: 0.8004, train_loss_norm:0.0571, valid_acc: 0.7859, valid_loss_norm: 0.0580\n",
      " epoch: 51, train accuracy: 0.8009, train_loss_norm:0.0567, valid_acc: 0.7864, valid_loss_norm: 0.0576\n",
      " epoch: 52, train accuracy: 0.8014, train_loss_norm:0.0563, valid_acc: 0.7867, valid_loss_norm: 0.0572\n",
      " epoch: 53, train accuracy: 0.8018, train_loss_norm:0.0560, valid_acc: 0.7867, valid_loss_norm: 0.0568\n",
      " epoch: 54, train accuracy: 0.8019, train_loss_norm:0.0556, valid_acc: 0.7867, valid_loss_norm: 0.0565\n",
      " epoch: 55, train accuracy: 0.8021, train_loss_norm:0.0552, valid_acc: 0.7873, valid_loss_norm: 0.0561\n",
      " epoch: 56, train accuracy: 0.8022, train_loss_norm:0.0549, valid_acc: 0.7873, valid_loss_norm: 0.0558\n",
      " epoch: 57, train accuracy: 0.8027, train_loss_norm:0.0545, valid_acc: 0.7873, valid_loss_norm: 0.0554\n",
      " epoch: 58, train accuracy: 0.8030, train_loss_norm:0.0542, valid_acc: 0.7873, valid_loss_norm: 0.0551\n",
      " epoch: 59, train accuracy: 0.8033, train_loss_norm:0.0538, valid_acc: 0.7876, valid_loss_norm: 0.0548\n",
      " epoch: 60, train accuracy: 0.8040, train_loss_norm:0.0535, valid_acc: 0.7882, valid_loss_norm: 0.0544\n",
      " epoch: 61, train accuracy: 0.8041, train_loss_norm:0.0532, valid_acc: 0.7884, valid_loss_norm: 0.0541\n",
      " epoch: 62, train accuracy: 0.8044, train_loss_norm:0.0529, valid_acc: 0.7882, valid_loss_norm: 0.0538\n",
      " epoch: 63, train accuracy: 0.8049, train_loss_norm:0.0526, valid_acc: 0.7884, valid_loss_norm: 0.0535\n",
      " epoch: 64, train accuracy: 0.8053, train_loss_norm:0.0522, valid_acc: 0.7893, valid_loss_norm: 0.0532\n",
      " epoch: 65, train accuracy: 0.8057, train_loss_norm:0.0519, valid_acc: 0.7890, valid_loss_norm: 0.0529\n",
      " epoch: 66, train accuracy: 0.8063, train_loss_norm:0.0516, valid_acc: 0.7893, valid_loss_norm: 0.0526\n",
      " epoch: 67, train accuracy: 0.8067, train_loss_norm:0.0513, valid_acc: 0.7893, valid_loss_norm: 0.0523\n",
      " epoch: 68, train accuracy: 0.8070, train_loss_norm:0.0511, valid_acc: 0.7899, valid_loss_norm: 0.0520\n",
      " epoch: 69, train accuracy: 0.8072, train_loss_norm:0.0508, valid_acc: 0.7899, valid_loss_norm: 0.0518\n",
      " epoch: 70, train accuracy: 0.8074, train_loss_norm:0.0505, valid_acc: 0.7899, valid_loss_norm: 0.0515\n",
      " epoch: 71, train accuracy: 0.8078, train_loss_norm:0.0502, valid_acc: 0.7907, valid_loss_norm: 0.0512\n",
      " epoch: 72, train accuracy: 0.8079, train_loss_norm:0.0499, valid_acc: 0.7913, valid_loss_norm: 0.0510\n",
      " epoch: 73, train accuracy: 0.8084, train_loss_norm:0.0497, valid_acc: 0.7913, valid_loss_norm: 0.0507\n",
      " epoch: 74, train accuracy: 0.8090, train_loss_norm:0.0494, valid_acc: 0.7916, valid_loss_norm: 0.0504\n",
      " epoch: 75, train accuracy: 0.8094, train_loss_norm:0.0492, valid_acc: 0.7919, valid_loss_norm: 0.0502\n",
      " epoch: 76, train accuracy: 0.8096, train_loss_norm:0.0489, valid_acc: 0.7922, valid_loss_norm: 0.0499\n",
      " epoch: 77, train accuracy: 0.8100, train_loss_norm:0.0487, valid_acc: 0.7925, valid_loss_norm: 0.0497\n",
      " epoch: 78, train accuracy: 0.8104, train_loss_norm:0.0484, valid_acc: 0.7930, valid_loss_norm: 0.0494\n",
      " epoch: 79, train accuracy: 0.8105, train_loss_norm:0.0482, valid_acc: 0.7928, valid_loss_norm: 0.0492\n",
      " epoch: 80, train accuracy: 0.8106, train_loss_norm:0.0479, valid_acc: 0.7936, valid_loss_norm: 0.0490\n",
      " epoch: 81, train accuracy: 0.8110, train_loss_norm:0.0477, valid_acc: 0.7939, valid_loss_norm: 0.0487\n",
      " epoch: 82, train accuracy: 0.8112, train_loss_norm:0.0475, valid_acc: 0.7945, valid_loss_norm: 0.0485\n",
      " epoch: 83, train accuracy: 0.8115, train_loss_norm:0.0472, valid_acc: 0.7951, valid_loss_norm: 0.0483\n",
      " epoch: 84, train accuracy: 0.8119, train_loss_norm:0.0470, valid_acc: 0.7959, valid_loss_norm: 0.0481\n",
      " epoch: 85, train accuracy: 0.8121, train_loss_norm:0.0468, valid_acc: 0.7965, valid_loss_norm: 0.0479\n",
      " epoch: 86, train accuracy: 0.8123, train_loss_norm:0.0466, valid_acc: 0.7971, valid_loss_norm: 0.0476\n",
      " epoch: 87, train accuracy: 0.8127, train_loss_norm:0.0463, valid_acc: 0.7976, valid_loss_norm: 0.0474\n",
      " epoch: 88, train accuracy: 0.8131, train_loss_norm:0.0461, valid_acc: 0.7982, valid_loss_norm: 0.0472\n",
      " epoch: 89, train accuracy: 0.8136, train_loss_norm:0.0459, valid_acc: 0.7985, valid_loss_norm: 0.0470\n",
      " epoch: 90, train accuracy: 0.8137, train_loss_norm:0.0457, valid_acc: 0.7985, valid_loss_norm: 0.0468\n",
      " epoch: 91, train accuracy: 0.8142, train_loss_norm:0.0455, valid_acc: 0.7985, valid_loss_norm: 0.0466\n",
      " epoch: 92, train accuracy: 0.8143, train_loss_norm:0.0453, valid_acc: 0.7985, valid_loss_norm: 0.0464\n",
      " epoch: 93, train accuracy: 0.8145, train_loss_norm:0.0451, valid_acc: 0.7985, valid_loss_norm: 0.0462\n",
      " epoch: 94, train accuracy: 0.8148, train_loss_norm:0.0449, valid_acc: 0.7985, valid_loss_norm: 0.0460\n",
      " epoch: 95, train accuracy: 0.8151, train_loss_norm:0.0447, valid_acc: 0.7988, valid_loss_norm: 0.0458\n",
      " epoch: 96, train accuracy: 0.8153, train_loss_norm:0.0445, valid_acc: 0.7994, valid_loss_norm: 0.0456\n",
      " epoch: 97, train accuracy: 0.8157, train_loss_norm:0.0443, valid_acc: 0.7991, valid_loss_norm: 0.0455\n",
      " epoch: 98, train accuracy: 0.8158, train_loss_norm:0.0442, valid_acc: 0.7991, valid_loss_norm: 0.0453\n",
      " epoch: 99, train accuracy: 0.8159, train_loss_norm:0.0440, valid_acc: 0.8002, valid_loss_norm: 0.0451\n",
      " epoch: 100, train accuracy: 0.8162, train_loss_norm:0.0438, valid_acc: 0.8020, valid_loss_norm: 0.0449\n",
      " epoch: 101, train accuracy: 0.8165, train_loss_norm:0.0436, valid_acc: 0.8020, valid_loss_norm: 0.0447\n",
      " epoch: 102, train accuracy: 0.8165, train_loss_norm:0.0434, valid_acc: 0.8020, valid_loss_norm: 0.0446\n",
      " epoch: 103, train accuracy: 0.8168, train_loss_norm:0.0433, valid_acc: 0.8025, valid_loss_norm: 0.0444\n",
      " epoch: 104, train accuracy: 0.8170, train_loss_norm:0.0431, valid_acc: 0.8025, valid_loss_norm: 0.0442\n",
      " epoch: 105, train accuracy: 0.8172, train_loss_norm:0.0429, valid_acc: 0.8028, valid_loss_norm: 0.0441\n",
      " epoch: 106, train accuracy: 0.8175, train_loss_norm:0.0427, valid_acc: 0.8028, valid_loss_norm: 0.0439\n",
      " epoch: 107, train accuracy: 0.8176, train_loss_norm:0.0426, valid_acc: 0.8028, valid_loss_norm: 0.0437\n",
      " epoch: 108, train accuracy: 0.8178, train_loss_norm:0.0424, valid_acc: 0.8037, valid_loss_norm: 0.0436\n",
      " epoch: 109, train accuracy: 0.8180, train_loss_norm:0.0423, valid_acc: 0.8037, valid_loss_norm: 0.0434\n",
      " epoch: 110, train accuracy: 0.8182, train_loss_norm:0.0421, valid_acc: 0.8037, valid_loss_norm: 0.0433\n",
      " epoch: 111, train accuracy: 0.8185, train_loss_norm:0.0419, valid_acc: 0.8034, valid_loss_norm: 0.0431\n",
      " epoch: 112, train accuracy: 0.8187, train_loss_norm:0.0418, valid_acc: 0.8037, valid_loss_norm: 0.0430\n",
      " epoch: 113, train accuracy: 0.8189, train_loss_norm:0.0416, valid_acc: 0.8040, valid_loss_norm: 0.0428\n",
      " epoch: 114, train accuracy: 0.8192, train_loss_norm:0.0415, valid_acc: 0.8048, valid_loss_norm: 0.0426\n",
      " epoch: 115, train accuracy: 0.8194, train_loss_norm:0.0413, valid_acc: 0.8051, valid_loss_norm: 0.0425\n",
      " epoch: 116, train accuracy: 0.8195, train_loss_norm:0.0412, valid_acc: 0.8051, valid_loss_norm: 0.0424\n",
      " epoch: 117, train accuracy: 0.8198, train_loss_norm:0.0410, valid_acc: 0.8051, valid_loss_norm: 0.0422\n",
      " epoch: 118, train accuracy: 0.8199, train_loss_norm:0.0409, valid_acc: 0.8066, valid_loss_norm: 0.0421\n",
      " epoch: 119, train accuracy: 0.8202, train_loss_norm:0.0407, valid_acc: 0.8074, valid_loss_norm: 0.0419\n",
      " epoch: 120, train accuracy: 0.8204, train_loss_norm:0.0406, valid_acc: 0.8077, valid_loss_norm: 0.0418\n",
      " epoch: 121, train accuracy: 0.8207, train_loss_norm:0.0404, valid_acc: 0.8080, valid_loss_norm: 0.0416\n",
      " epoch: 122, train accuracy: 0.8212, train_loss_norm:0.0403, valid_acc: 0.8080, valid_loss_norm: 0.0415\n",
      " epoch: 123, train accuracy: 0.8214, train_loss_norm:0.0402, valid_acc: 0.8077, valid_loss_norm: 0.0414\n",
      " epoch: 124, train accuracy: 0.8217, train_loss_norm:0.0400, valid_acc: 0.8083, valid_loss_norm: 0.0412\n",
      " epoch: 125, train accuracy: 0.8221, train_loss_norm:0.0399, valid_acc: 0.8083, valid_loss_norm: 0.0411\n",
      " epoch: 126, train accuracy: 0.8224, train_loss_norm:0.0398, valid_acc: 0.8083, valid_loss_norm: 0.0410\n",
      " epoch: 127, train accuracy: 0.8227, train_loss_norm:0.0396, valid_acc: 0.8086, valid_loss_norm: 0.0408\n",
      " epoch: 128, train accuracy: 0.8230, train_loss_norm:0.0395, valid_acc: 0.8086, valid_loss_norm: 0.0407\n",
      " epoch: 129, train accuracy: 0.8232, train_loss_norm:0.0394, valid_acc: 0.8089, valid_loss_norm: 0.0406\n",
      " epoch: 130, train accuracy: 0.8233, train_loss_norm:0.0392, valid_acc: 0.8086, valid_loss_norm: 0.0405\n",
      " epoch: 131, train accuracy: 0.8236, train_loss_norm:0.0391, valid_acc: 0.8089, valid_loss_norm: 0.0403\n",
      " epoch: 132, train accuracy: 0.8238, train_loss_norm:0.0390, valid_acc: 0.8094, valid_loss_norm: 0.0402\n",
      " epoch: 133, train accuracy: 0.8242, train_loss_norm:0.0388, valid_acc: 0.8097, valid_loss_norm: 0.0401\n",
      " epoch: 134, train accuracy: 0.8245, train_loss_norm:0.0387, valid_acc: 0.8097, valid_loss_norm: 0.0400\n",
      " epoch: 135, train accuracy: 0.8249, train_loss_norm:0.0386, valid_acc: 0.8100, valid_loss_norm: 0.0398\n",
      " epoch: 136, train accuracy: 0.8251, train_loss_norm:0.0385, valid_acc: 0.8106, valid_loss_norm: 0.0397\n",
      " epoch: 137, train accuracy: 0.8254, train_loss_norm:0.0384, valid_acc: 0.8106, valid_loss_norm: 0.0396\n",
      " epoch: 138, train accuracy: 0.8256, train_loss_norm:0.0382, valid_acc: 0.8106, valid_loss_norm: 0.0395\n",
      " epoch: 139, train accuracy: 0.8258, train_loss_norm:0.0381, valid_acc: 0.8109, valid_loss_norm: 0.0394\n",
      " epoch: 140, train accuracy: 0.8258, train_loss_norm:0.0380, valid_acc: 0.8112, valid_loss_norm: 0.0393\n",
      " epoch: 141, train accuracy: 0.8258, train_loss_norm:0.0379, valid_acc: 0.8114, valid_loss_norm: 0.0391\n",
      " epoch: 142, train accuracy: 0.8259, train_loss_norm:0.0378, valid_acc: 0.8117, valid_loss_norm: 0.0390\n",
      " epoch: 143, train accuracy: 0.8261, train_loss_norm:0.0377, valid_acc: 0.8126, valid_loss_norm: 0.0389\n",
      " epoch: 144, train accuracy: 0.8263, train_loss_norm:0.0375, valid_acc: 0.8126, valid_loss_norm: 0.0388\n",
      " epoch: 145, train accuracy: 0.8268, train_loss_norm:0.0374, valid_acc: 0.8137, valid_loss_norm: 0.0387\n",
      " epoch: 146, train accuracy: 0.8271, train_loss_norm:0.0373, valid_acc: 0.8140, valid_loss_norm: 0.0386\n",
      " epoch: 147, train accuracy: 0.8273, train_loss_norm:0.0372, valid_acc: 0.8143, valid_loss_norm: 0.0385\n",
      " epoch: 148, train accuracy: 0.8274, train_loss_norm:0.0371, valid_acc: 0.8143, valid_loss_norm: 0.0384\n",
      " epoch: 149, train accuracy: 0.8275, train_loss_norm:0.0370, valid_acc: 0.8143, valid_loss_norm: 0.0383\n",
      " epoch: 150, train accuracy: 0.8276, train_loss_norm:0.0369, valid_acc: 0.8140, valid_loss_norm: 0.0382\n",
      " epoch: 151, train accuracy: 0.8279, train_loss_norm:0.0368, valid_acc: 0.8143, valid_loss_norm: 0.0381\n",
      " epoch: 152, train accuracy: 0.8281, train_loss_norm:0.0367, valid_acc: 0.8140, valid_loss_norm: 0.0380\n",
      " epoch: 153, train accuracy: 0.8284, train_loss_norm:0.0366, valid_acc: 0.8140, valid_loss_norm: 0.0379\n",
      " epoch: 154, train accuracy: 0.8288, train_loss_norm:0.0365, valid_acc: 0.8137, valid_loss_norm: 0.0378\n",
      " epoch: 155, train accuracy: 0.8288, train_loss_norm:0.0364, valid_acc: 0.8137, valid_loss_norm: 0.0377\n",
      " epoch: 156, train accuracy: 0.8289, train_loss_norm:0.0363, valid_acc: 0.8140, valid_loss_norm: 0.0376\n",
      " epoch: 157, train accuracy: 0.8289, train_loss_norm:0.0362, valid_acc: 0.8146, valid_loss_norm: 0.0375\n",
      " epoch: 158, train accuracy: 0.8289, train_loss_norm:0.0361, valid_acc: 0.8146, valid_loss_norm: 0.0374\n",
      " epoch: 159, train accuracy: 0.8290, train_loss_norm:0.0360, valid_acc: 0.8146, valid_loss_norm: 0.0373\n",
      " epoch: 160, train accuracy: 0.8292, train_loss_norm:0.0359, valid_acc: 0.8158, valid_loss_norm: 0.0372\n",
      " epoch: 161, train accuracy: 0.8293, train_loss_norm:0.0358, valid_acc: 0.8158, valid_loss_norm: 0.0371\n",
      " epoch: 162, train accuracy: 0.8294, train_loss_norm:0.0357, valid_acc: 0.8160, valid_loss_norm: 0.0370\n",
      " epoch: 163, train accuracy: 0.8297, train_loss_norm:0.0356, valid_acc: 0.8166, valid_loss_norm: 0.0369\n",
      " epoch: 164, train accuracy: 0.8300, train_loss_norm:0.0355, valid_acc: 0.8163, valid_loss_norm: 0.0368\n",
      " epoch: 165, train accuracy: 0.8303, train_loss_norm:0.0354, valid_acc: 0.8166, valid_loss_norm: 0.0367\n",
      " epoch: 166, train accuracy: 0.8304, train_loss_norm:0.0353, valid_acc: 0.8169, valid_loss_norm: 0.0366\n",
      " epoch: 167, train accuracy: 0.8306, train_loss_norm:0.0352, valid_acc: 0.8169, valid_loss_norm: 0.0365\n",
      " epoch: 168, train accuracy: 0.8309, train_loss_norm:0.0351, valid_acc: 0.8169, valid_loss_norm: 0.0364\n",
      " epoch: 169, train accuracy: 0.8311, train_loss_norm:0.0350, valid_acc: 0.8169, valid_loss_norm: 0.0363\n",
      " epoch: 170, train accuracy: 0.8311, train_loss_norm:0.0349, valid_acc: 0.8172, valid_loss_norm: 0.0363\n",
      " epoch: 171, train accuracy: 0.8313, train_loss_norm:0.0348, valid_acc: 0.8178, valid_loss_norm: 0.0362\n",
      " epoch: 172, train accuracy: 0.8314, train_loss_norm:0.0348, valid_acc: 0.8181, valid_loss_norm: 0.0361\n",
      " epoch: 173, train accuracy: 0.8318, train_loss_norm:0.0347, valid_acc: 0.8186, valid_loss_norm: 0.0360\n",
      " epoch: 174, train accuracy: 0.8319, train_loss_norm:0.0346, valid_acc: 0.8189, valid_loss_norm: 0.0359\n",
      " epoch: 175, train accuracy: 0.8321, train_loss_norm:0.0345, valid_acc: 0.8189, valid_loss_norm: 0.0358\n",
      " epoch: 176, train accuracy: 0.8324, train_loss_norm:0.0344, valid_acc: 0.8189, valid_loss_norm: 0.0357\n",
      " epoch: 177, train accuracy: 0.8327, train_loss_norm:0.0343, valid_acc: 0.8189, valid_loss_norm: 0.0357\n",
      " epoch: 178, train accuracy: 0.8328, train_loss_norm:0.0342, valid_acc: 0.8192, valid_loss_norm: 0.0356\n",
      " epoch: 179, train accuracy: 0.8329, train_loss_norm:0.0342, valid_acc: 0.8198, valid_loss_norm: 0.0355\n",
      " epoch: 180, train accuracy: 0.8333, train_loss_norm:0.0341, valid_acc: 0.8198, valid_loss_norm: 0.0354\n",
      " epoch: 181, train accuracy: 0.8335, train_loss_norm:0.0340, valid_acc: 0.8201, valid_loss_norm: 0.0353\n",
      " epoch: 182, train accuracy: 0.8336, train_loss_norm:0.0339, valid_acc: 0.8201, valid_loss_norm: 0.0352\n",
      " epoch: 183, train accuracy: 0.8338, train_loss_norm:0.0338, valid_acc: 0.8201, valid_loss_norm: 0.0352\n",
      " epoch: 184, train accuracy: 0.8342, train_loss_norm:0.0337, valid_acc: 0.8201, valid_loss_norm: 0.0351\n",
      " epoch: 185, train accuracy: 0.8343, train_loss_norm:0.0337, valid_acc: 0.8201, valid_loss_norm: 0.0350\n",
      " epoch: 186, train accuracy: 0.8346, train_loss_norm:0.0336, valid_acc: 0.8201, valid_loss_norm: 0.0349\n",
      " epoch: 187, train accuracy: 0.8349, train_loss_norm:0.0335, valid_acc: 0.8204, valid_loss_norm: 0.0349\n",
      " epoch: 188, train accuracy: 0.8351, train_loss_norm:0.0334, valid_acc: 0.8206, valid_loss_norm: 0.0348\n",
      " epoch: 189, train accuracy: 0.8353, train_loss_norm:0.0333, valid_acc: 0.8204, valid_loss_norm: 0.0347\n",
      " epoch: 190, train accuracy: 0.8355, train_loss_norm:0.0333, valid_acc: 0.8201, valid_loss_norm: 0.0346\n",
      " epoch: 191, train accuracy: 0.8356, train_loss_norm:0.0332, valid_acc: 0.8215, valid_loss_norm: 0.0346\n",
      " epoch: 192, train accuracy: 0.8358, train_loss_norm:0.0331, valid_acc: 0.8221, valid_loss_norm: 0.0345\n",
      " epoch: 193, train accuracy: 0.8360, train_loss_norm:0.0330, valid_acc: 0.8224, valid_loss_norm: 0.0344\n",
      " epoch: 194, train accuracy: 0.8363, train_loss_norm:0.0330, valid_acc: 0.8224, valid_loss_norm: 0.0343\n",
      " epoch: 195, train accuracy: 0.8365, train_loss_norm:0.0329, valid_acc: 0.8221, valid_loss_norm: 0.0343\n",
      " epoch: 196, train accuracy: 0.8369, train_loss_norm:0.0328, valid_acc: 0.8221, valid_loss_norm: 0.0342\n",
      " epoch: 197, train accuracy: 0.8370, train_loss_norm:0.0327, valid_acc: 0.8229, valid_loss_norm: 0.0341\n",
      " epoch: 198, train accuracy: 0.8371, train_loss_norm:0.0327, valid_acc: 0.8232, valid_loss_norm: 0.0340\n",
      " epoch: 199, train accuracy: 0.8372, train_loss_norm:0.0326, valid_acc: 0.8232, valid_loss_norm: 0.0340\n",
      " epoch: 200, train accuracy: 0.8374, train_loss_norm:0.0325, valid_acc: 0.8232, valid_loss_norm: 0.0339\n",
      " epoch: 201, train accuracy: 0.8377, train_loss_norm:0.0325, valid_acc: 0.8235, valid_loss_norm: 0.0338\n",
      " epoch: 202, train accuracy: 0.8380, train_loss_norm:0.0324, valid_acc: 0.8241, valid_loss_norm: 0.0338\n",
      " epoch: 203, train accuracy: 0.8383, train_loss_norm:0.0323, valid_acc: 0.8241, valid_loss_norm: 0.0337\n",
      " epoch: 204, train accuracy: 0.8384, train_loss_norm:0.0322, valid_acc: 0.8241, valid_loss_norm: 0.0336\n",
      " epoch: 205, train accuracy: 0.8385, train_loss_norm:0.0322, valid_acc: 0.8241, valid_loss_norm: 0.0336\n",
      " epoch: 206, train accuracy: 0.8387, train_loss_norm:0.0321, valid_acc: 0.8244, valid_loss_norm: 0.0335\n",
      " epoch: 207, train accuracy: 0.8388, train_loss_norm:0.0320, valid_acc: 0.8247, valid_loss_norm: 0.0334\n",
      " epoch: 208, train accuracy: 0.8388, train_loss_norm:0.0320, valid_acc: 0.8247, valid_loss_norm: 0.0334\n",
      " epoch: 209, train accuracy: 0.8390, train_loss_norm:0.0319, valid_acc: 0.8247, valid_loss_norm: 0.0333\n",
      " epoch: 210, train accuracy: 0.8393, train_loss_norm:0.0318, valid_acc: 0.8249, valid_loss_norm: 0.0332\n",
      " epoch: 211, train accuracy: 0.8394, train_loss_norm:0.0318, valid_acc: 0.8249, valid_loss_norm: 0.0332\n",
      " epoch: 212, train accuracy: 0.8396, train_loss_norm:0.0317, valid_acc: 0.8249, valid_loss_norm: 0.0331\n",
      " epoch: 213, train accuracy: 0.8397, train_loss_norm:0.0316, valid_acc: 0.8249, valid_loss_norm: 0.0330\n",
      " epoch: 214, train accuracy: 0.8399, train_loss_norm:0.0316, valid_acc: 0.8249, valid_loss_norm: 0.0330\n",
      " epoch: 215, train accuracy: 0.8401, train_loss_norm:0.0315, valid_acc: 0.8252, valid_loss_norm: 0.0329\n",
      " epoch: 216, train accuracy: 0.8401, train_loss_norm:0.0314, valid_acc: 0.8258, valid_loss_norm: 0.0328\n",
      " epoch: 217, train accuracy: 0.8401, train_loss_norm:0.0314, valid_acc: 0.8264, valid_loss_norm: 0.0328\n",
      " epoch: 218, train accuracy: 0.8403, train_loss_norm:0.0313, valid_acc: 0.8267, valid_loss_norm: 0.0327\n",
      " epoch: 219, train accuracy: 0.8405, train_loss_norm:0.0312, valid_acc: 0.8267, valid_loss_norm: 0.0327\n",
      " epoch: 220, train accuracy: 0.8405, train_loss_norm:0.0312, valid_acc: 0.8272, valid_loss_norm: 0.0326\n",
      " epoch: 221, train accuracy: 0.8407, train_loss_norm:0.0311, valid_acc: 0.8272, valid_loss_norm: 0.0325\n",
      " epoch: 222, train accuracy: 0.8409, train_loss_norm:0.0311, valid_acc: 0.8272, valid_loss_norm: 0.0325\n",
      " epoch: 223, train accuracy: 0.8411, train_loss_norm:0.0310, valid_acc: 0.8272, valid_loss_norm: 0.0324\n",
      " epoch: 224, train accuracy: 0.8413, train_loss_norm:0.0309, valid_acc: 0.8272, valid_loss_norm: 0.0323\n",
      " epoch: 225, train accuracy: 0.8412, train_loss_norm:0.0309, valid_acc: 0.8272, valid_loss_norm: 0.0323\n",
      " epoch: 226, train accuracy: 0.8413, train_loss_norm:0.0308, valid_acc: 0.8275, valid_loss_norm: 0.0322\n",
      " epoch: 227, train accuracy: 0.8413, train_loss_norm:0.0308, valid_acc: 0.8275, valid_loss_norm: 0.0322\n",
      " epoch: 228, train accuracy: 0.8413, train_loss_norm:0.0307, valid_acc: 0.8275, valid_loss_norm: 0.0321\n",
      " epoch: 229, train accuracy: 0.8414, train_loss_norm:0.0306, valid_acc: 0.8275, valid_loss_norm: 0.0321\n",
      " epoch: 230, train accuracy: 0.8415, train_loss_norm:0.0306, valid_acc: 0.8275, valid_loss_norm: 0.0320\n",
      " epoch: 231, train accuracy: 0.8415, train_loss_norm:0.0305, valid_acc: 0.8275, valid_loss_norm: 0.0319\n",
      " epoch: 232, train accuracy: 0.8416, train_loss_norm:0.0305, valid_acc: 0.8278, valid_loss_norm: 0.0319\n",
      " epoch: 233, train accuracy: 0.8416, train_loss_norm:0.0304, valid_acc: 0.8278, valid_loss_norm: 0.0318\n",
      " epoch: 234, train accuracy: 0.8417, train_loss_norm:0.0303, valid_acc: 0.8275, valid_loss_norm: 0.0318\n",
      " epoch: 235, train accuracy: 0.8418, train_loss_norm:0.0303, valid_acc: 0.8278, valid_loss_norm: 0.0317\n",
      " epoch: 236, train accuracy: 0.8418, train_loss_norm:0.0302, valid_acc: 0.8278, valid_loss_norm: 0.0317\n",
      " epoch: 237, train accuracy: 0.8419, train_loss_norm:0.0302, valid_acc: 0.8278, valid_loss_norm: 0.0316\n",
      " epoch: 238, train accuracy: 0.8420, train_loss_norm:0.0301, valid_acc: 0.8275, valid_loss_norm: 0.0315\n",
      " epoch: 239, train accuracy: 0.8421, train_loss_norm:0.0301, valid_acc: 0.8278, valid_loss_norm: 0.0315\n",
      " epoch: 240, train accuracy: 0.8422, train_loss_norm:0.0300, valid_acc: 0.8281, valid_loss_norm: 0.0314\n",
      " epoch: 241, train accuracy: 0.8422, train_loss_norm:0.0299, valid_acc: 0.8284, valid_loss_norm: 0.0314\n",
      " epoch: 242, train accuracy: 0.8424, train_loss_norm:0.0299, valid_acc: 0.8284, valid_loss_norm: 0.0313\n",
      " epoch: 243, train accuracy: 0.8425, train_loss_norm:0.0298, valid_acc: 0.8284, valid_loss_norm: 0.0313\n",
      " epoch: 244, train accuracy: 0.8426, train_loss_norm:0.0298, valid_acc: 0.8281, valid_loss_norm: 0.0312\n",
      " epoch: 245, train accuracy: 0.8428, train_loss_norm:0.0297, valid_acc: 0.8281, valid_loss_norm: 0.0312\n",
      " epoch: 246, train accuracy: 0.8430, train_loss_norm:0.0297, valid_acc: 0.8287, valid_loss_norm: 0.0311\n",
      " epoch: 247, train accuracy: 0.8432, train_loss_norm:0.0296, valid_acc: 0.8287, valid_loss_norm: 0.0311\n",
      " epoch: 248, train accuracy: 0.8433, train_loss_norm:0.0296, valid_acc: 0.8293, valid_loss_norm: 0.0310\n",
      " epoch: 249, train accuracy: 0.8434, train_loss_norm:0.0295, valid_acc: 0.8287, valid_loss_norm: 0.0310\n",
      " epoch: 250, train accuracy: 0.8434, train_loss_norm:0.0295, valid_acc: 0.8287, valid_loss_norm: 0.0309\n",
      " epoch: 251, train accuracy: 0.8436, train_loss_norm:0.0294, valid_acc: 0.8290, valid_loss_norm: 0.0309\n",
      " epoch: 252, train accuracy: 0.8436, train_loss_norm:0.0294, valid_acc: 0.8290, valid_loss_norm: 0.0308\n",
      " epoch: 253, train accuracy: 0.8438, train_loss_norm:0.0293, valid_acc: 0.8287, valid_loss_norm: 0.0308\n",
      " epoch: 254, train accuracy: 0.8438, train_loss_norm:0.0293, valid_acc: 0.8290, valid_loss_norm: 0.0307\n",
      " epoch: 255, train accuracy: 0.8440, train_loss_norm:0.0292, valid_acc: 0.8293, valid_loss_norm: 0.0307\n",
      " epoch: 256, train accuracy: 0.8441, train_loss_norm:0.0292, valid_acc: 0.8293, valid_loss_norm: 0.0306\n",
      " epoch: 257, train accuracy: 0.8443, train_loss_norm:0.0291, valid_acc: 0.8293, valid_loss_norm: 0.0306\n",
      " epoch: 258, train accuracy: 0.8443, train_loss_norm:0.0291, valid_acc: 0.8293, valid_loss_norm: 0.0305\n",
      " epoch: 259, train accuracy: 0.8445, train_loss_norm:0.0290, valid_acc: 0.8293, valid_loss_norm: 0.0305\n",
      " epoch: 260, train accuracy: 0.8445, train_loss_norm:0.0290, valid_acc: 0.8293, valid_loss_norm: 0.0304\n",
      " epoch: 261, train accuracy: 0.8444, train_loss_norm:0.0289, valid_acc: 0.8293, valid_loss_norm: 0.0304\n",
      " epoch: 262, train accuracy: 0.8447, train_loss_norm:0.0289, valid_acc: 0.8293, valid_loss_norm: 0.0303\n",
      " epoch: 263, train accuracy: 0.8448, train_loss_norm:0.0288, valid_acc: 0.8293, valid_loss_norm: 0.0303\n",
      " epoch: 264, train accuracy: 0.8448, train_loss_norm:0.0288, valid_acc: 0.8293, valid_loss_norm: 0.0302\n",
      " epoch: 265, train accuracy: 0.8448, train_loss_norm:0.0287, valid_acc: 0.8298, valid_loss_norm: 0.0302\n",
      " epoch: 266, train accuracy: 0.8448, train_loss_norm:0.0287, valid_acc: 0.8301, valid_loss_norm: 0.0301\n",
      " epoch: 267, train accuracy: 0.8450, train_loss_norm:0.0286, valid_acc: 0.8301, valid_loss_norm: 0.0301\n",
      " epoch: 268, train accuracy: 0.8451, train_loss_norm:0.0286, valid_acc: 0.8301, valid_loss_norm: 0.0300\n",
      " epoch: 269, train accuracy: 0.8451, train_loss_norm:0.0285, valid_acc: 0.8307, valid_loss_norm: 0.0300\n",
      " epoch: 270, train accuracy: 0.8452, train_loss_norm:0.0285, valid_acc: 0.8304, valid_loss_norm: 0.0299\n",
      " epoch: 271, train accuracy: 0.8452, train_loss_norm:0.0284, valid_acc: 0.8307, valid_loss_norm: 0.0299\n",
      " epoch: 272, train accuracy: 0.8453, train_loss_norm:0.0284, valid_acc: 0.8307, valid_loss_norm: 0.0299\n",
      " epoch: 273, train accuracy: 0.8454, train_loss_norm:0.0283, valid_acc: 0.8310, valid_loss_norm: 0.0298\n",
      " epoch: 274, train accuracy: 0.8455, train_loss_norm:0.0283, valid_acc: 0.8313, valid_loss_norm: 0.0298\n",
      " epoch: 275, train accuracy: 0.8456, train_loss_norm:0.0282, valid_acc: 0.8318, valid_loss_norm: 0.0297\n",
      " epoch: 276, train accuracy: 0.8456, train_loss_norm:0.0282, valid_acc: 0.8316, valid_loss_norm: 0.0297\n",
      " epoch: 277, train accuracy: 0.8458, train_loss_norm:0.0281, valid_acc: 0.8321, valid_loss_norm: 0.0296\n",
      " epoch: 278, train accuracy: 0.8458, train_loss_norm:0.0281, valid_acc: 0.8318, valid_loss_norm: 0.0296\n",
      " epoch: 279, train accuracy: 0.8458, train_loss_norm:0.0281, valid_acc: 0.8316, valid_loss_norm: 0.0295\n",
      " epoch: 280, train accuracy: 0.8458, train_loss_norm:0.0280, valid_acc: 0.8318, valid_loss_norm: 0.0295\n",
      " epoch: 281, train accuracy: 0.8459, train_loss_norm:0.0280, valid_acc: 0.8321, valid_loss_norm: 0.0295\n",
      " epoch: 282, train accuracy: 0.8459, train_loss_norm:0.0279, valid_acc: 0.8324, valid_loss_norm: 0.0294\n",
      " epoch: 283, train accuracy: 0.8459, train_loss_norm:0.0279, valid_acc: 0.8324, valid_loss_norm: 0.0294\n",
      " epoch: 284, train accuracy: 0.8461, train_loss_norm:0.0278, valid_acc: 0.8324, valid_loss_norm: 0.0293\n",
      " epoch: 285, train accuracy: 0.8462, train_loss_norm:0.0278, valid_acc: 0.8327, valid_loss_norm: 0.0293\n",
      " epoch: 286, train accuracy: 0.8462, train_loss_norm:0.0278, valid_acc: 0.8327, valid_loss_norm: 0.0293\n",
      " epoch: 287, train accuracy: 0.8462, train_loss_norm:0.0277, valid_acc: 0.8330, valid_loss_norm: 0.0292\n",
      " epoch: 288, train accuracy: 0.8463, train_loss_norm:0.0277, valid_acc: 0.8336, valid_loss_norm: 0.0292\n",
      " epoch: 289, train accuracy: 0.8464, train_loss_norm:0.0276, valid_acc: 0.8339, valid_loss_norm: 0.0291\n",
      " epoch: 290, train accuracy: 0.8466, train_loss_norm:0.0276, valid_acc: 0.8341, valid_loss_norm: 0.0291\n",
      " epoch: 291, train accuracy: 0.8467, train_loss_norm:0.0275, valid_acc: 0.8347, valid_loss_norm: 0.0290\n",
      " epoch: 292, train accuracy: 0.8467, train_loss_norm:0.0275, valid_acc: 0.8347, valid_loss_norm: 0.0290\n",
      " epoch: 293, train accuracy: 0.8469, train_loss_norm:0.0275, valid_acc: 0.8353, valid_loss_norm: 0.0290\n",
      " epoch: 294, train accuracy: 0.8469, train_loss_norm:0.0274, valid_acc: 0.8359, valid_loss_norm: 0.0289\n",
      " epoch: 295, train accuracy: 0.8469, train_loss_norm:0.0274, valid_acc: 0.8359, valid_loss_norm: 0.0289\n",
      " epoch: 296, train accuracy: 0.8470, train_loss_norm:0.0273, valid_acc: 0.8359, valid_loss_norm: 0.0288\n",
      " epoch: 297, train accuracy: 0.8471, train_loss_norm:0.0273, valid_acc: 0.8359, valid_loss_norm: 0.0288\n",
      " epoch: 298, train accuracy: 0.8471, train_loss_norm:0.0272, valid_acc: 0.8359, valid_loss_norm: 0.0288\n",
      " epoch: 299, train accuracy: 0.8472, train_loss_norm:0.0272, valid_acc: 0.8359, valid_loss_norm: 0.0287\n",
      " epoch: 300, train accuracy: 0.8472, train_loss_norm:0.0272, valid_acc: 0.8359, valid_loss_norm: 0.0287\n",
      "Test accuracy: 0.8238\n",
      "Test loss norm: 0.0290\n",
      "Cur fold: 2\n",
      "(27841, 300)\n",
      "(3479, 300)\n",
      "(3479, 300)\n",
      " epoch: 1, train accuracy: 0.7934, train_loss_norm:0.0867, valid_acc: 0.7775, valid_loss_norm: 0.0867\n",
      " epoch: 2, train accuracy: 0.7934, train_loss_norm:0.0859, valid_acc: 0.7775, valid_loss_norm: 0.0860\n",
      " epoch: 3, train accuracy: 0.7934, train_loss_norm:0.0852, valid_acc: 0.7775, valid_loss_norm: 0.0852\n",
      " epoch: 4, train accuracy: 0.7934, train_loss_norm:0.0844, valid_acc: 0.7775, valid_loss_norm: 0.0845\n",
      " epoch: 5, train accuracy: 0.7934, train_loss_norm:0.0836, valid_acc: 0.7775, valid_loss_norm: 0.0838\n",
      " epoch: 6, train accuracy: 0.7934, train_loss_norm:0.0829, valid_acc: 0.7775, valid_loss_norm: 0.0831\n",
      " epoch: 7, train accuracy: 0.7935, train_loss_norm:0.0821, valid_acc: 0.7775, valid_loss_norm: 0.0823\n",
      " epoch: 8, train accuracy: 0.7935, train_loss_norm:0.0814, valid_acc: 0.7775, valid_loss_norm: 0.0816\n",
      " epoch: 9, train accuracy: 0.7936, train_loss_norm:0.0806, valid_acc: 0.7775, valid_loss_norm: 0.0809\n",
      " epoch: 10, train accuracy: 0.7936, train_loss_norm:0.0799, valid_acc: 0.7775, valid_loss_norm: 0.0802\n",
      " epoch: 11, train accuracy: 0.7936, train_loss_norm:0.0792, valid_acc: 0.7775, valid_loss_norm: 0.0795\n",
      " epoch: 12, train accuracy: 0.7937, train_loss_norm:0.0785, valid_acc: 0.7775, valid_loss_norm: 0.0788\n",
      " epoch: 13, train accuracy: 0.7938, train_loss_norm:0.0777, valid_acc: 0.7775, valid_loss_norm: 0.0781\n",
      " epoch: 14, train accuracy: 0.7938, train_loss_norm:0.0770, valid_acc: 0.7775, valid_loss_norm: 0.0774\n",
      " epoch: 15, train accuracy: 0.7938, train_loss_norm:0.0763, valid_acc: 0.7775, valid_loss_norm: 0.0768\n",
      " epoch: 16, train accuracy: 0.7938, train_loss_norm:0.0756, valid_acc: 0.7775, valid_loss_norm: 0.0761\n",
      " epoch: 17, train accuracy: 0.7939, train_loss_norm:0.0749, valid_acc: 0.7775, valid_loss_norm: 0.0754\n",
      " epoch: 18, train accuracy: 0.7940, train_loss_norm:0.0743, valid_acc: 0.7775, valid_loss_norm: 0.0748\n",
      " epoch: 19, train accuracy: 0.7940, train_loss_norm:0.0736, valid_acc: 0.7772, valid_loss_norm: 0.0741\n",
      " epoch: 20, train accuracy: 0.7942, train_loss_norm:0.0729, valid_acc: 0.7772, valid_loss_norm: 0.0735\n",
      " epoch: 21, train accuracy: 0.7943, train_loss_norm:0.0723, valid_acc: 0.7772, valid_loss_norm: 0.0728\n",
      " epoch: 22, train accuracy: 0.7944, train_loss_norm:0.0716, valid_acc: 0.7775, valid_loss_norm: 0.0722\n",
      " epoch: 23, train accuracy: 0.7945, train_loss_norm:0.0710, valid_acc: 0.7775, valid_loss_norm: 0.0716\n",
      " epoch: 24, train accuracy: 0.7945, train_loss_norm:0.0703, valid_acc: 0.7781, valid_loss_norm: 0.0710\n",
      " epoch: 25, train accuracy: 0.7947, train_loss_norm:0.0697, valid_acc: 0.7784, valid_loss_norm: 0.0704\n",
      " epoch: 26, train accuracy: 0.7947, train_loss_norm:0.0691, valid_acc: 0.7787, valid_loss_norm: 0.0698\n",
      " epoch: 27, train accuracy: 0.7949, train_loss_norm:0.0685, valid_acc: 0.7792, valid_loss_norm: 0.0692\n",
      " epoch: 28, train accuracy: 0.7951, train_loss_norm:0.0679, valid_acc: 0.7795, valid_loss_norm: 0.0686\n",
      " epoch: 29, train accuracy: 0.7953, train_loss_norm:0.0673, valid_acc: 0.7795, valid_loss_norm: 0.0681\n",
      " epoch: 30, train accuracy: 0.7956, train_loss_norm:0.0667, valid_acc: 0.7798, valid_loss_norm: 0.0675\n",
      " epoch: 31, train accuracy: 0.7958, train_loss_norm:0.0662, valid_acc: 0.7798, valid_loss_norm: 0.0670\n",
      " epoch: 32, train accuracy: 0.7962, train_loss_norm:0.0656, valid_acc: 0.7801, valid_loss_norm: 0.0664\n",
      " epoch: 33, train accuracy: 0.7965, train_loss_norm:0.0651, valid_acc: 0.7801, valid_loss_norm: 0.0659\n",
      " epoch: 34, train accuracy: 0.7966, train_loss_norm:0.0645, valid_acc: 0.7801, valid_loss_norm: 0.0654\n",
      " epoch: 35, train accuracy: 0.7969, train_loss_norm:0.0640, valid_acc: 0.7801, valid_loss_norm: 0.0649\n",
      " epoch: 36, train accuracy: 0.7972, train_loss_norm:0.0635, valid_acc: 0.7801, valid_loss_norm: 0.0643\n",
      " epoch: 37, train accuracy: 0.7972, train_loss_norm:0.0630, valid_acc: 0.7801, valid_loss_norm: 0.0639\n",
      " epoch: 38, train accuracy: 0.7974, train_loss_norm:0.0625, valid_acc: 0.7801, valid_loss_norm: 0.0634\n",
      " epoch: 39, train accuracy: 0.7975, train_loss_norm:0.0620, valid_acc: 0.7801, valid_loss_norm: 0.0629\n",
      " epoch: 40, train accuracy: 0.7979, train_loss_norm:0.0615, valid_acc: 0.7804, valid_loss_norm: 0.0624\n",
      " epoch: 41, train accuracy: 0.7981, train_loss_norm:0.0610, valid_acc: 0.7804, valid_loss_norm: 0.0620\n",
      " epoch: 42, train accuracy: 0.7984, train_loss_norm:0.0605, valid_acc: 0.7810, valid_loss_norm: 0.0615\n",
      " epoch: 43, train accuracy: 0.7988, train_loss_norm:0.0601, valid_acc: 0.7815, valid_loss_norm: 0.0611\n",
      " epoch: 44, train accuracy: 0.7991, train_loss_norm:0.0596, valid_acc: 0.7821, valid_loss_norm: 0.0606\n",
      " epoch: 45, train accuracy: 0.7994, train_loss_norm:0.0592, valid_acc: 0.7827, valid_loss_norm: 0.0602\n",
      " epoch: 46, train accuracy: 0.7997, train_loss_norm:0.0588, valid_acc: 0.7830, valid_loss_norm: 0.0598\n",
      " epoch: 47, train accuracy: 0.7999, train_loss_norm:0.0583, valid_acc: 0.7830, valid_loss_norm: 0.0594\n",
      " epoch: 48, train accuracy: 0.8002, train_loss_norm:0.0579, valid_acc: 0.7830, valid_loss_norm: 0.0590\n",
      " epoch: 49, train accuracy: 0.8005, train_loss_norm:0.0575, valid_acc: 0.7833, valid_loss_norm: 0.0586\n",
      " epoch: 50, train accuracy: 0.8009, train_loss_norm:0.0571, valid_acc: 0.7838, valid_loss_norm: 0.0582\n",
      " epoch: 51, train accuracy: 0.8011, train_loss_norm:0.0567, valid_acc: 0.7844, valid_loss_norm: 0.0578\n",
      " epoch: 52, train accuracy: 0.8014, train_loss_norm:0.0563, valid_acc: 0.7850, valid_loss_norm: 0.0574\n",
      " epoch: 53, train accuracy: 0.8021, train_loss_norm:0.0560, valid_acc: 0.7856, valid_loss_norm: 0.0570\n",
      " epoch: 54, train accuracy: 0.8023, train_loss_norm:0.0556, valid_acc: 0.7856, valid_loss_norm: 0.0567\n",
      " epoch: 55, train accuracy: 0.8025, train_loss_norm:0.0552, valid_acc: 0.7861, valid_loss_norm: 0.0563\n",
      " epoch: 56, train accuracy: 0.8029, train_loss_norm:0.0549, valid_acc: 0.7867, valid_loss_norm: 0.0560\n",
      " epoch: 57, train accuracy: 0.8031, train_loss_norm:0.0545, valid_acc: 0.7873, valid_loss_norm: 0.0556\n",
      " epoch: 58, train accuracy: 0.8033, train_loss_norm:0.0542, valid_acc: 0.7873, valid_loss_norm: 0.0553\n",
      " epoch: 59, train accuracy: 0.8035, train_loss_norm:0.0538, valid_acc: 0.7879, valid_loss_norm: 0.0550\n",
      " epoch: 60, train accuracy: 0.8037, train_loss_norm:0.0535, valid_acc: 0.7884, valid_loss_norm: 0.0546\n",
      " epoch: 61, train accuracy: 0.8041, train_loss_norm:0.0532, valid_acc: 0.7884, valid_loss_norm: 0.0543\n",
      " epoch: 62, train accuracy: 0.8045, train_loss_norm:0.0529, valid_acc: 0.7884, valid_loss_norm: 0.0540\n",
      " epoch: 63, train accuracy: 0.8049, train_loss_norm:0.0525, valid_acc: 0.7884, valid_loss_norm: 0.0537\n",
      " epoch: 64, train accuracy: 0.8055, train_loss_norm:0.0522, valid_acc: 0.7884, valid_loss_norm: 0.0534\n",
      " epoch: 65, train accuracy: 0.8057, train_loss_norm:0.0519, valid_acc: 0.7882, valid_loss_norm: 0.0531\n",
      " epoch: 66, train accuracy: 0.8061, train_loss_norm:0.0516, valid_acc: 0.7887, valid_loss_norm: 0.0528\n",
      " epoch: 67, train accuracy: 0.8065, train_loss_norm:0.0513, valid_acc: 0.7890, valid_loss_norm: 0.0525\n",
      " epoch: 68, train accuracy: 0.8069, train_loss_norm:0.0511, valid_acc: 0.7899, valid_loss_norm: 0.0522\n",
      " epoch: 69, train accuracy: 0.8073, train_loss_norm:0.0508, valid_acc: 0.7902, valid_loss_norm: 0.0520\n",
      " epoch: 70, train accuracy: 0.8076, train_loss_norm:0.0505, valid_acc: 0.7905, valid_loss_norm: 0.0517\n",
      " epoch: 71, train accuracy: 0.8078, train_loss_norm:0.0502, valid_acc: 0.7910, valid_loss_norm: 0.0514\n",
      " epoch: 72, train accuracy: 0.8084, train_loss_norm:0.0499, valid_acc: 0.7913, valid_loss_norm: 0.0512\n",
      " epoch: 73, train accuracy: 0.8088, train_loss_norm:0.0497, valid_acc: 0.7925, valid_loss_norm: 0.0509\n",
      " epoch: 74, train accuracy: 0.8090, train_loss_norm:0.0494, valid_acc: 0.7928, valid_loss_norm: 0.0506\n",
      " epoch: 75, train accuracy: 0.8090, train_loss_norm:0.0492, valid_acc: 0.7928, valid_loss_norm: 0.0504\n",
      " epoch: 76, train accuracy: 0.8093, train_loss_norm:0.0489, valid_acc: 0.7928, valid_loss_norm: 0.0501\n",
      " epoch: 77, train accuracy: 0.8096, train_loss_norm:0.0486, valid_acc: 0.7925, valid_loss_norm: 0.0499\n",
      " epoch: 78, train accuracy: 0.8098, train_loss_norm:0.0484, valid_acc: 0.7928, valid_loss_norm: 0.0496\n",
      " epoch: 79, train accuracy: 0.8103, train_loss_norm:0.0482, valid_acc: 0.7930, valid_loss_norm: 0.0494\n",
      " epoch: 80, train accuracy: 0.8106, train_loss_norm:0.0479, valid_acc: 0.7939, valid_loss_norm: 0.0492\n",
      " epoch: 81, train accuracy: 0.8111, train_loss_norm:0.0477, valid_acc: 0.7942, valid_loss_norm: 0.0489\n",
      " epoch: 82, train accuracy: 0.8115, train_loss_norm:0.0474, valid_acc: 0.7945, valid_loss_norm: 0.0487\n",
      " epoch: 83, train accuracy: 0.8118, train_loss_norm:0.0472, valid_acc: 0.7948, valid_loss_norm: 0.0485\n",
      " epoch: 84, train accuracy: 0.8122, train_loss_norm:0.0470, valid_acc: 0.7948, valid_loss_norm: 0.0483\n",
      " epoch: 85, train accuracy: 0.8124, train_loss_norm:0.0468, valid_acc: 0.7951, valid_loss_norm: 0.0481\n",
      " epoch: 86, train accuracy: 0.8127, train_loss_norm:0.0466, valid_acc: 0.7953, valid_loss_norm: 0.0478\n",
      " epoch: 87, train accuracy: 0.8128, train_loss_norm:0.0463, valid_acc: 0.7953, valid_loss_norm: 0.0476\n",
      " epoch: 88, train accuracy: 0.8133, train_loss_norm:0.0461, valid_acc: 0.7959, valid_loss_norm: 0.0474\n",
      " epoch: 89, train accuracy: 0.8135, train_loss_norm:0.0459, valid_acc: 0.7965, valid_loss_norm: 0.0472\n",
      " epoch: 90, train accuracy: 0.8137, train_loss_norm:0.0457, valid_acc: 0.7968, valid_loss_norm: 0.0470\n",
      " epoch: 91, train accuracy: 0.8138, train_loss_norm:0.0455, valid_acc: 0.7974, valid_loss_norm: 0.0468\n",
      " epoch: 92, train accuracy: 0.8140, train_loss_norm:0.0453, valid_acc: 0.7976, valid_loss_norm: 0.0466\n",
      " epoch: 93, train accuracy: 0.8142, train_loss_norm:0.0451, valid_acc: 0.7979, valid_loss_norm: 0.0464\n",
      " epoch: 94, train accuracy: 0.8144, train_loss_norm:0.0449, valid_acc: 0.7979, valid_loss_norm: 0.0462\n",
      " epoch: 95, train accuracy: 0.8146, train_loss_norm:0.0447, valid_acc: 0.7982, valid_loss_norm: 0.0460\n",
      " epoch: 96, train accuracy: 0.8147, train_loss_norm:0.0445, valid_acc: 0.7985, valid_loss_norm: 0.0458\n",
      " epoch: 97, train accuracy: 0.8150, train_loss_norm:0.0443, valid_acc: 0.7994, valid_loss_norm: 0.0457\n",
      " epoch: 98, train accuracy: 0.8154, train_loss_norm:0.0441, valid_acc: 0.7994, valid_loss_norm: 0.0455\n",
      " epoch: 99, train accuracy: 0.8156, train_loss_norm:0.0440, valid_acc: 0.8002, valid_loss_norm: 0.0453\n",
      " epoch: 100, train accuracy: 0.8161, train_loss_norm:0.0438, valid_acc: 0.8002, valid_loss_norm: 0.0451\n",
      " epoch: 101, train accuracy: 0.8164, train_loss_norm:0.0436, valid_acc: 0.8008, valid_loss_norm: 0.0449\n",
      " epoch: 102, train accuracy: 0.8169, train_loss_norm:0.0434, valid_acc: 0.8008, valid_loss_norm: 0.0448\n",
      " epoch: 103, train accuracy: 0.8170, train_loss_norm:0.0432, valid_acc: 0.8014, valid_loss_norm: 0.0446\n",
      " epoch: 104, train accuracy: 0.8170, train_loss_norm:0.0431, valid_acc: 0.8014, valid_loss_norm: 0.0444\n",
      " epoch: 105, train accuracy: 0.8173, train_loss_norm:0.0429, valid_acc: 0.8017, valid_loss_norm: 0.0443\n",
      " epoch: 106, train accuracy: 0.8175, train_loss_norm:0.0427, valid_acc: 0.8022, valid_loss_norm: 0.0441\n",
      " epoch: 107, train accuracy: 0.8176, train_loss_norm:0.0426, valid_acc: 0.8022, valid_loss_norm: 0.0439\n",
      " epoch: 108, train accuracy: 0.8177, train_loss_norm:0.0424, valid_acc: 0.8022, valid_loss_norm: 0.0438\n",
      " epoch: 109, train accuracy: 0.8179, train_loss_norm:0.0422, valid_acc: 0.8031, valid_loss_norm: 0.0436\n",
      " epoch: 110, train accuracy: 0.8184, train_loss_norm:0.0421, valid_acc: 0.8031, valid_loss_norm: 0.0435\n",
      " epoch: 111, train accuracy: 0.8186, train_loss_norm:0.0419, valid_acc: 0.8031, valid_loss_norm: 0.0433\n",
      " epoch: 112, train accuracy: 0.8188, train_loss_norm:0.0418, valid_acc: 0.8034, valid_loss_norm: 0.0432\n",
      " epoch: 113, train accuracy: 0.8190, train_loss_norm:0.0416, valid_acc: 0.8034, valid_loss_norm: 0.0430\n",
      " epoch: 114, train accuracy: 0.8191, train_loss_norm:0.0414, valid_acc: 0.8040, valid_loss_norm: 0.0429\n",
      " epoch: 115, train accuracy: 0.8195, train_loss_norm:0.0413, valid_acc: 0.8043, valid_loss_norm: 0.0427\n",
      " epoch: 116, train accuracy: 0.8201, train_loss_norm:0.0411, valid_acc: 0.8045, valid_loss_norm: 0.0426\n",
      " epoch: 117, train accuracy: 0.8203, train_loss_norm:0.0410, valid_acc: 0.8040, valid_loss_norm: 0.0424\n",
      " epoch: 118, train accuracy: 0.8206, train_loss_norm:0.0409, valid_acc: 0.8045, valid_loss_norm: 0.0423\n",
      " epoch: 119, train accuracy: 0.8207, train_loss_norm:0.0407, valid_acc: 0.8051, valid_loss_norm: 0.0421\n",
      " epoch: 120, train accuracy: 0.8207, train_loss_norm:0.0406, valid_acc: 0.8051, valid_loss_norm: 0.0420\n",
      " epoch: 121, train accuracy: 0.8211, train_loss_norm:0.0404, valid_acc: 0.8048, valid_loss_norm: 0.0419\n",
      " epoch: 122, train accuracy: 0.8213, train_loss_norm:0.0403, valid_acc: 0.8048, valid_loss_norm: 0.0417\n",
      " epoch: 123, train accuracy: 0.8215, train_loss_norm:0.0401, valid_acc: 0.8054, valid_loss_norm: 0.0416\n",
      " epoch: 124, train accuracy: 0.8218, train_loss_norm:0.0400, valid_acc: 0.8060, valid_loss_norm: 0.0414\n",
      " epoch: 125, train accuracy: 0.8221, train_loss_norm:0.0399, valid_acc: 0.8060, valid_loss_norm: 0.0413\n",
      " epoch: 126, train accuracy: 0.8223, train_loss_norm:0.0397, valid_acc: 0.8060, valid_loss_norm: 0.0412\n",
      " epoch: 127, train accuracy: 0.8226, train_loss_norm:0.0396, valid_acc: 0.8060, valid_loss_norm: 0.0411\n",
      " epoch: 128, train accuracy: 0.8229, train_loss_norm:0.0395, valid_acc: 0.8063, valid_loss_norm: 0.0409\n",
      " epoch: 129, train accuracy: 0.8231, train_loss_norm:0.0393, valid_acc: 0.8063, valid_loss_norm: 0.0408\n",
      " epoch: 130, train accuracy: 0.8233, train_loss_norm:0.0392, valid_acc: 0.8060, valid_loss_norm: 0.0407\n",
      " epoch: 131, train accuracy: 0.8235, train_loss_norm:0.0391, valid_acc: 0.8057, valid_loss_norm: 0.0405\n",
      " epoch: 132, train accuracy: 0.8236, train_loss_norm:0.0389, valid_acc: 0.8068, valid_loss_norm: 0.0404\n",
      " epoch: 133, train accuracy: 0.8238, train_loss_norm:0.0388, valid_acc: 0.8071, valid_loss_norm: 0.0403\n",
      " epoch: 134, train accuracy: 0.8239, train_loss_norm:0.0387, valid_acc: 0.8074, valid_loss_norm: 0.0402\n",
      " epoch: 135, train accuracy: 0.8241, train_loss_norm:0.0386, valid_acc: 0.8077, valid_loss_norm: 0.0401\n",
      " epoch: 136, train accuracy: 0.8243, train_loss_norm:0.0385, valid_acc: 0.8077, valid_loss_norm: 0.0399\n",
      " epoch: 137, train accuracy: 0.8246, train_loss_norm:0.0383, valid_acc: 0.8080, valid_loss_norm: 0.0398\n",
      " epoch: 138, train accuracy: 0.8249, train_loss_norm:0.0382, valid_acc: 0.8077, valid_loss_norm: 0.0397\n",
      " epoch: 139, train accuracy: 0.8251, train_loss_norm:0.0381, valid_acc: 0.8083, valid_loss_norm: 0.0396\n",
      " epoch: 140, train accuracy: 0.8254, train_loss_norm:0.0380, valid_acc: 0.8083, valid_loss_norm: 0.0395\n",
      " epoch: 141, train accuracy: 0.8255, train_loss_norm:0.0379, valid_acc: 0.8083, valid_loss_norm: 0.0394\n",
      " epoch: 142, train accuracy: 0.8257, train_loss_norm:0.0377, valid_acc: 0.8080, valid_loss_norm: 0.0393\n",
      " epoch: 143, train accuracy: 0.8260, train_loss_norm:0.0376, valid_acc: 0.8083, valid_loss_norm: 0.0391\n",
      " epoch: 144, train accuracy: 0.8262, train_loss_norm:0.0375, valid_acc: 0.8089, valid_loss_norm: 0.0390\n",
      " epoch: 145, train accuracy: 0.8266, train_loss_norm:0.0374, valid_acc: 0.8089, valid_loss_norm: 0.0389\n",
      " epoch: 146, train accuracy: 0.8269, train_loss_norm:0.0373, valid_acc: 0.8089, valid_loss_norm: 0.0388\n",
      " epoch: 147, train accuracy: 0.8271, train_loss_norm:0.0372, valid_acc: 0.8089, valid_loss_norm: 0.0387\n",
      " epoch: 148, train accuracy: 0.8273, train_loss_norm:0.0371, valid_acc: 0.8086, valid_loss_norm: 0.0386\n",
      " epoch: 149, train accuracy: 0.8273, train_loss_norm:0.0370, valid_acc: 0.8086, valid_loss_norm: 0.0385\n",
      " epoch: 150, train accuracy: 0.8273, train_loss_norm:0.0369, valid_acc: 0.8089, valid_loss_norm: 0.0384\n",
      " epoch: 151, train accuracy: 0.8276, train_loss_norm:0.0368, valid_acc: 0.8097, valid_loss_norm: 0.0383\n",
      " epoch: 152, train accuracy: 0.8278, train_loss_norm:0.0367, valid_acc: 0.8100, valid_loss_norm: 0.0382\n",
      " epoch: 153, train accuracy: 0.8279, train_loss_norm:0.0365, valid_acc: 0.8100, valid_loss_norm: 0.0381\n",
      " epoch: 154, train accuracy: 0.8281, train_loss_norm:0.0364, valid_acc: 0.8103, valid_loss_norm: 0.0380\n",
      " epoch: 155, train accuracy: 0.8283, train_loss_norm:0.0363, valid_acc: 0.8103, valid_loss_norm: 0.0379\n",
      " epoch: 156, train accuracy: 0.8284, train_loss_norm:0.0362, valid_acc: 0.8109, valid_loss_norm: 0.0378\n",
      " epoch: 157, train accuracy: 0.8287, train_loss_norm:0.0361, valid_acc: 0.8109, valid_loss_norm: 0.0377\n",
      " epoch: 158, train accuracy: 0.8290, train_loss_norm:0.0360, valid_acc: 0.8112, valid_loss_norm: 0.0376\n",
      " epoch: 159, train accuracy: 0.8292, train_loss_norm:0.0359, valid_acc: 0.8112, valid_loss_norm: 0.0375\n",
      " epoch: 160, train accuracy: 0.8295, train_loss_norm:0.0358, valid_acc: 0.8112, valid_loss_norm: 0.0374\n",
      " epoch: 161, train accuracy: 0.8295, train_loss_norm:0.0357, valid_acc: 0.8109, valid_loss_norm: 0.0373\n",
      " epoch: 162, train accuracy: 0.8297, train_loss_norm:0.0357, valid_acc: 0.8112, valid_loss_norm: 0.0372\n",
      " epoch: 163, train accuracy: 0.8299, train_loss_norm:0.0356, valid_acc: 0.8117, valid_loss_norm: 0.0371\n",
      " epoch: 164, train accuracy: 0.8302, train_loss_norm:0.0355, valid_acc: 0.8112, valid_loss_norm: 0.0370\n",
      " epoch: 165, train accuracy: 0.8303, train_loss_norm:0.0354, valid_acc: 0.8112, valid_loss_norm: 0.0369\n",
      " epoch: 166, train accuracy: 0.8304, train_loss_norm:0.0353, valid_acc: 0.8114, valid_loss_norm: 0.0369\n",
      " epoch: 167, train accuracy: 0.8305, train_loss_norm:0.0352, valid_acc: 0.8114, valid_loss_norm: 0.0368\n",
      " epoch: 168, train accuracy: 0.8307, train_loss_norm:0.0351, valid_acc: 0.8117, valid_loss_norm: 0.0367\n",
      " epoch: 169, train accuracy: 0.8308, train_loss_norm:0.0350, valid_acc: 0.8117, valid_loss_norm: 0.0366\n",
      " epoch: 170, train accuracy: 0.8309, train_loss_norm:0.0349, valid_acc: 0.8112, valid_loss_norm: 0.0365\n",
      " epoch: 171, train accuracy: 0.8311, train_loss_norm:0.0348, valid_acc: 0.8112, valid_loss_norm: 0.0364\n",
      " epoch: 172, train accuracy: 0.8311, train_loss_norm:0.0347, valid_acc: 0.8109, valid_loss_norm: 0.0363\n",
      " epoch: 173, train accuracy: 0.8313, train_loss_norm:0.0346, valid_acc: 0.8112, valid_loss_norm: 0.0362\n",
      " epoch: 174, train accuracy: 0.8316, train_loss_norm:0.0346, valid_acc: 0.8112, valid_loss_norm: 0.0362\n",
      " epoch: 175, train accuracy: 0.8318, train_loss_norm:0.0345, valid_acc: 0.8114, valid_loss_norm: 0.0361\n",
      " epoch: 176, train accuracy: 0.8320, train_loss_norm:0.0344, valid_acc: 0.8117, valid_loss_norm: 0.0360\n",
      " epoch: 177, train accuracy: 0.8321, train_loss_norm:0.0343, valid_acc: 0.8117, valid_loss_norm: 0.0359\n",
      " epoch: 178, train accuracy: 0.8321, train_loss_norm:0.0342, valid_acc: 0.8117, valid_loss_norm: 0.0358\n",
      " epoch: 179, train accuracy: 0.8322, train_loss_norm:0.0341, valid_acc: 0.8117, valid_loss_norm: 0.0357\n",
      " epoch: 180, train accuracy: 0.8324, train_loss_norm:0.0340, valid_acc: 0.8117, valid_loss_norm: 0.0357\n",
      " epoch: 181, train accuracy: 0.8326, train_loss_norm:0.0340, valid_acc: 0.8123, valid_loss_norm: 0.0356\n",
      " epoch: 182, train accuracy: 0.8328, train_loss_norm:0.0339, valid_acc: 0.8126, valid_loss_norm: 0.0355\n",
      " epoch: 183, train accuracy: 0.8332, train_loss_norm:0.0338, valid_acc: 0.8132, valid_loss_norm: 0.0354\n",
      " epoch: 184, train accuracy: 0.8334, train_loss_norm:0.0337, valid_acc: 0.8129, valid_loss_norm: 0.0354\n",
      " epoch: 185, train accuracy: 0.8336, train_loss_norm:0.0336, valid_acc: 0.8129, valid_loss_norm: 0.0353\n",
      " epoch: 186, train accuracy: 0.8337, train_loss_norm:0.0336, valid_acc: 0.8132, valid_loss_norm: 0.0352\n",
      " epoch: 187, train accuracy: 0.8338, train_loss_norm:0.0335, valid_acc: 0.8135, valid_loss_norm: 0.0351\n",
      " epoch: 188, train accuracy: 0.8340, train_loss_norm:0.0334, valid_acc: 0.8137, valid_loss_norm: 0.0350\n",
      " epoch: 189, train accuracy: 0.8341, train_loss_norm:0.0333, valid_acc: 0.8140, valid_loss_norm: 0.0350\n",
      " epoch: 190, train accuracy: 0.8343, train_loss_norm:0.0332, valid_acc: 0.8143, valid_loss_norm: 0.0349\n",
      " epoch: 191, train accuracy: 0.8344, train_loss_norm:0.0332, valid_acc: 0.8146, valid_loss_norm: 0.0348\n",
      " epoch: 192, train accuracy: 0.8346, train_loss_norm:0.0331, valid_acc: 0.8146, valid_loss_norm: 0.0347\n",
      " epoch: 193, train accuracy: 0.8348, train_loss_norm:0.0330, valid_acc: 0.8149, valid_loss_norm: 0.0347\n",
      " epoch: 194, train accuracy: 0.8349, train_loss_norm:0.0329, valid_acc: 0.8149, valid_loss_norm: 0.0346\n",
      " epoch: 195, train accuracy: 0.8350, train_loss_norm:0.0329, valid_acc: 0.8149, valid_loss_norm: 0.0345\n",
      " epoch: 196, train accuracy: 0.8351, train_loss_norm:0.0328, valid_acc: 0.8152, valid_loss_norm: 0.0345\n",
      " epoch: 197, train accuracy: 0.8352, train_loss_norm:0.0327, valid_acc: 0.8152, valid_loss_norm: 0.0344\n",
      " epoch: 198, train accuracy: 0.8354, train_loss_norm:0.0326, valid_acc: 0.8152, valid_loss_norm: 0.0343\n",
      " epoch: 199, train accuracy: 0.8354, train_loss_norm:0.0326, valid_acc: 0.8152, valid_loss_norm: 0.0342\n",
      " epoch: 200, train accuracy: 0.8356, train_loss_norm:0.0325, valid_acc: 0.8149, valid_loss_norm: 0.0342\n",
      " epoch: 201, train accuracy: 0.8357, train_loss_norm:0.0324, valid_acc: 0.8146, valid_loss_norm: 0.0341\n",
      " epoch: 202, train accuracy: 0.8358, train_loss_norm:0.0324, valid_acc: 0.8149, valid_loss_norm: 0.0340\n",
      " epoch: 203, train accuracy: 0.8359, train_loss_norm:0.0323, valid_acc: 0.8149, valid_loss_norm: 0.0340\n",
      " epoch: 204, train accuracy: 0.8361, train_loss_norm:0.0322, valid_acc: 0.8152, valid_loss_norm: 0.0339\n",
      " epoch: 205, train accuracy: 0.8362, train_loss_norm:0.0321, valid_acc: 0.8152, valid_loss_norm: 0.0338\n",
      " epoch: 206, train accuracy: 0.8364, train_loss_norm:0.0321, valid_acc: 0.8152, valid_loss_norm: 0.0338\n",
      " epoch: 207, train accuracy: 0.8365, train_loss_norm:0.0320, valid_acc: 0.8158, valid_loss_norm: 0.0337\n",
      " epoch: 208, train accuracy: 0.8367, train_loss_norm:0.0319, valid_acc: 0.8158, valid_loss_norm: 0.0336\n",
      " epoch: 209, train accuracy: 0.8367, train_loss_norm:0.0319, valid_acc: 0.8158, valid_loss_norm: 0.0336\n",
      " epoch: 210, train accuracy: 0.8371, train_loss_norm:0.0318, valid_acc: 0.8163, valid_loss_norm: 0.0335\n",
      " epoch: 211, train accuracy: 0.8373, train_loss_norm:0.0317, valid_acc: 0.8163, valid_loss_norm: 0.0334\n",
      " epoch: 212, train accuracy: 0.8375, train_loss_norm:0.0317, valid_acc: 0.8166, valid_loss_norm: 0.0334\n",
      " epoch: 213, train accuracy: 0.8377, train_loss_norm:0.0316, valid_acc: 0.8166, valid_loss_norm: 0.0333\n",
      " epoch: 214, train accuracy: 0.8378, train_loss_norm:0.0315, valid_acc: 0.8166, valid_loss_norm: 0.0333\n",
      " epoch: 215, train accuracy: 0.8379, train_loss_norm:0.0315, valid_acc: 0.8169, valid_loss_norm: 0.0332\n",
      " epoch: 216, train accuracy: 0.8380, train_loss_norm:0.0314, valid_acc: 0.8172, valid_loss_norm: 0.0331\n",
      " epoch: 217, train accuracy: 0.8381, train_loss_norm:0.0313, valid_acc: 0.8172, valid_loss_norm: 0.0331\n",
      " epoch: 218, train accuracy: 0.8382, train_loss_norm:0.0313, valid_acc: 0.8178, valid_loss_norm: 0.0330\n",
      " epoch: 219, train accuracy: 0.8384, train_loss_norm:0.0312, valid_acc: 0.8175, valid_loss_norm: 0.0329\n",
      " epoch: 220, train accuracy: 0.8386, train_loss_norm:0.0312, valid_acc: 0.8175, valid_loss_norm: 0.0329\n",
      " epoch: 221, train accuracy: 0.8387, train_loss_norm:0.0311, valid_acc: 0.8175, valid_loss_norm: 0.0328\n",
      " epoch: 222, train accuracy: 0.8387, train_loss_norm:0.0310, valid_acc: 0.8175, valid_loss_norm: 0.0328\n",
      " epoch: 223, train accuracy: 0.8387, train_loss_norm:0.0310, valid_acc: 0.8181, valid_loss_norm: 0.0327\n",
      " epoch: 224, train accuracy: 0.8388, train_loss_norm:0.0309, valid_acc: 0.8181, valid_loss_norm: 0.0326\n",
      " epoch: 225, train accuracy: 0.8388, train_loss_norm:0.0308, valid_acc: 0.8181, valid_loss_norm: 0.0326\n",
      " epoch: 226, train accuracy: 0.8390, train_loss_norm:0.0308, valid_acc: 0.8183, valid_loss_norm: 0.0325\n",
      " epoch: 227, train accuracy: 0.8390, train_loss_norm:0.0307, valid_acc: 0.8183, valid_loss_norm: 0.0325\n",
      " epoch: 228, train accuracy: 0.8391, train_loss_norm:0.0307, valid_acc: 0.8183, valid_loss_norm: 0.0324\n",
      " epoch: 229, train accuracy: 0.8391, train_loss_norm:0.0306, valid_acc: 0.8183, valid_loss_norm: 0.0324\n",
      " epoch: 230, train accuracy: 0.8392, train_loss_norm:0.0305, valid_acc: 0.8183, valid_loss_norm: 0.0323\n",
      " epoch: 231, train accuracy: 0.8394, train_loss_norm:0.0305, valid_acc: 0.8183, valid_loss_norm: 0.0322\n",
      " epoch: 232, train accuracy: 0.8394, train_loss_norm:0.0304, valid_acc: 0.8183, valid_loss_norm: 0.0322\n",
      " epoch: 233, train accuracy: 0.8395, train_loss_norm:0.0304, valid_acc: 0.8186, valid_loss_norm: 0.0321\n",
      " epoch: 234, train accuracy: 0.8397, train_loss_norm:0.0303, valid_acc: 0.8192, valid_loss_norm: 0.0321\n",
      " epoch: 235, train accuracy: 0.8397, train_loss_norm:0.0303, valid_acc: 0.8195, valid_loss_norm: 0.0320\n",
      " epoch: 236, train accuracy: 0.8398, train_loss_norm:0.0302, valid_acc: 0.8198, valid_loss_norm: 0.0320\n",
      " epoch: 237, train accuracy: 0.8399, train_loss_norm:0.0301, valid_acc: 0.8195, valid_loss_norm: 0.0319\n",
      " epoch: 238, train accuracy: 0.8399, train_loss_norm:0.0301, valid_acc: 0.8198, valid_loss_norm: 0.0319\n",
      " epoch: 239, train accuracy: 0.8401, train_loss_norm:0.0300, valid_acc: 0.8198, valid_loss_norm: 0.0318\n",
      " epoch: 240, train accuracy: 0.8402, train_loss_norm:0.0300, valid_acc: 0.8198, valid_loss_norm: 0.0318\n",
      " epoch: 241, train accuracy: 0.8403, train_loss_norm:0.0299, valid_acc: 0.8198, valid_loss_norm: 0.0317\n",
      " epoch: 242, train accuracy: 0.8404, train_loss_norm:0.0299, valid_acc: 0.8198, valid_loss_norm: 0.0316\n",
      " epoch: 243, train accuracy: 0.8406, train_loss_norm:0.0298, valid_acc: 0.8198, valid_loss_norm: 0.0316\n",
      " epoch: 244, train accuracy: 0.8408, train_loss_norm:0.0298, valid_acc: 0.8195, valid_loss_norm: 0.0315\n",
      " epoch: 245, train accuracy: 0.8409, train_loss_norm:0.0297, valid_acc: 0.8195, valid_loss_norm: 0.0315\n",
      " epoch: 246, train accuracy: 0.8409, train_loss_norm:0.0297, valid_acc: 0.8195, valid_loss_norm: 0.0314\n",
      " epoch: 247, train accuracy: 0.8411, train_loss_norm:0.0296, valid_acc: 0.8195, valid_loss_norm: 0.0314\n",
      " epoch: 248, train accuracy: 0.8411, train_loss_norm:0.0295, valid_acc: 0.8195, valid_loss_norm: 0.0313\n",
      " epoch: 249, train accuracy: 0.8411, train_loss_norm:0.0295, valid_acc: 0.8195, valid_loss_norm: 0.0313\n",
      " epoch: 250, train accuracy: 0.8412, train_loss_norm:0.0294, valid_acc: 0.8195, valid_loss_norm: 0.0312\n",
      " epoch: 251, train accuracy: 0.8412, train_loss_norm:0.0294, valid_acc: 0.8195, valid_loss_norm: 0.0312\n",
      " epoch: 252, train accuracy: 0.8414, train_loss_norm:0.0293, valid_acc: 0.8195, valid_loss_norm: 0.0311\n",
      " epoch: 253, train accuracy: 0.8416, train_loss_norm:0.0293, valid_acc: 0.8201, valid_loss_norm: 0.0311\n",
      " epoch: 254, train accuracy: 0.8416, train_loss_norm:0.0292, valid_acc: 0.8198, valid_loss_norm: 0.0310\n",
      " epoch: 255, train accuracy: 0.8418, train_loss_norm:0.0292, valid_acc: 0.8201, valid_loss_norm: 0.0310\n",
      " epoch: 256, train accuracy: 0.8419, train_loss_norm:0.0291, valid_acc: 0.8201, valid_loss_norm: 0.0309\n",
      " epoch: 257, train accuracy: 0.8420, train_loss_norm:0.0291, valid_acc: 0.8201, valid_loss_norm: 0.0309\n",
      " epoch: 258, train accuracy: 0.8421, train_loss_norm:0.0290, valid_acc: 0.8201, valid_loss_norm: 0.0308\n",
      " epoch: 259, train accuracy: 0.8422, train_loss_norm:0.0290, valid_acc: 0.8204, valid_loss_norm: 0.0308\n",
      " epoch: 260, train accuracy: 0.8421, train_loss_norm:0.0289, valid_acc: 0.8204, valid_loss_norm: 0.0308\n",
      " epoch: 261, train accuracy: 0.8423, train_loss_norm:0.0289, valid_acc: 0.8204, valid_loss_norm: 0.0307\n",
      " epoch: 262, train accuracy: 0.8422, train_loss_norm:0.0288, valid_acc: 0.8206, valid_loss_norm: 0.0307\n",
      " epoch: 263, train accuracy: 0.8425, train_loss_norm:0.0288, valid_acc: 0.8201, valid_loss_norm: 0.0306\n",
      " epoch: 264, train accuracy: 0.8426, train_loss_norm:0.0287, valid_acc: 0.8201, valid_loss_norm: 0.0306\n",
      " epoch: 265, train accuracy: 0.8428, train_loss_norm:0.0287, valid_acc: 0.8201, valid_loss_norm: 0.0305\n",
      " epoch: 266, train accuracy: 0.8429, train_loss_norm:0.0286, valid_acc: 0.8201, valid_loss_norm: 0.0305\n",
      " epoch: 267, train accuracy: 0.8430, train_loss_norm:0.0286, valid_acc: 0.8198, valid_loss_norm: 0.0304\n",
      " epoch: 268, train accuracy: 0.8430, train_loss_norm:0.0285, valid_acc: 0.8198, valid_loss_norm: 0.0304\n",
      " epoch: 269, train accuracy: 0.8430, train_loss_norm:0.0285, valid_acc: 0.8198, valid_loss_norm: 0.0303\n",
      " epoch: 270, train accuracy: 0.8432, train_loss_norm:0.0284, valid_acc: 0.8198, valid_loss_norm: 0.0303\n",
      " epoch: 271, train accuracy: 0.8433, train_loss_norm:0.0284, valid_acc: 0.8198, valid_loss_norm: 0.0302\n",
      " epoch: 272, train accuracy: 0.8434, train_loss_norm:0.0284, valid_acc: 0.8198, valid_loss_norm: 0.0302\n",
      " epoch: 273, train accuracy: 0.8435, train_loss_norm:0.0283, valid_acc: 0.8195, valid_loss_norm: 0.0302\n",
      " epoch: 274, train accuracy: 0.8437, train_loss_norm:0.0283, valid_acc: 0.8195, valid_loss_norm: 0.0301\n",
      " epoch: 275, train accuracy: 0.8438, train_loss_norm:0.0282, valid_acc: 0.8195, valid_loss_norm: 0.0301\n",
      " epoch: 276, train accuracy: 0.8438, train_loss_norm:0.0282, valid_acc: 0.8195, valid_loss_norm: 0.0300\n",
      " epoch: 277, train accuracy: 0.8440, train_loss_norm:0.0281, valid_acc: 0.8195, valid_loss_norm: 0.0300\n",
      " epoch: 278, train accuracy: 0.8442, train_loss_norm:0.0281, valid_acc: 0.8195, valid_loss_norm: 0.0299\n",
      " epoch: 279, train accuracy: 0.8441, train_loss_norm:0.0280, valid_acc: 0.8195, valid_loss_norm: 0.0299\n",
      " epoch: 280, train accuracy: 0.8442, train_loss_norm:0.0280, valid_acc: 0.8195, valid_loss_norm: 0.0299\n",
      " epoch: 281, train accuracy: 0.8443, train_loss_norm:0.0279, valid_acc: 0.8198, valid_loss_norm: 0.0298\n",
      " epoch: 282, train accuracy: 0.8445, train_loss_norm:0.0279, valid_acc: 0.8201, valid_loss_norm: 0.0298\n",
      " epoch: 283, train accuracy: 0.8446, train_loss_norm:0.0279, valid_acc: 0.8201, valid_loss_norm: 0.0297\n",
      " epoch: 284, train accuracy: 0.8447, train_loss_norm:0.0278, valid_acc: 0.8201, valid_loss_norm: 0.0297\n",
      " epoch: 285, train accuracy: 0.8447, train_loss_norm:0.0278, valid_acc: 0.8201, valid_loss_norm: 0.0296\n",
      " epoch: 286, train accuracy: 0.8447, train_loss_norm:0.0277, valid_acc: 0.8204, valid_loss_norm: 0.0296\n",
      " epoch: 287, train accuracy: 0.8448, train_loss_norm:0.0277, valid_acc: 0.8204, valid_loss_norm: 0.0296\n",
      " epoch: 288, train accuracy: 0.8448, train_loss_norm:0.0276, valid_acc: 0.8204, valid_loss_norm: 0.0295\n",
      " epoch: 289, train accuracy: 0.8448, train_loss_norm:0.0276, valid_acc: 0.8206, valid_loss_norm: 0.0295\n",
      " epoch: 290, train accuracy: 0.8449, train_loss_norm:0.0276, valid_acc: 0.8209, valid_loss_norm: 0.0294\n",
      " epoch: 291, train accuracy: 0.8451, train_loss_norm:0.0275, valid_acc: 0.8209, valid_loss_norm: 0.0294\n",
      " epoch: 292, train accuracy: 0.8452, train_loss_norm:0.0275, valid_acc: 0.8209, valid_loss_norm: 0.0294\n",
      " epoch: 293, train accuracy: 0.8452, train_loss_norm:0.0274, valid_acc: 0.8209, valid_loss_norm: 0.0293\n",
      " epoch: 294, train accuracy: 0.8454, train_loss_norm:0.0274, valid_acc: 0.8206, valid_loss_norm: 0.0293\n",
      " epoch: 295, train accuracy: 0.8456, train_loss_norm:0.0274, valid_acc: 0.8209, valid_loss_norm: 0.0292\n",
      " epoch: 296, train accuracy: 0.8456, train_loss_norm:0.0273, valid_acc: 0.8204, valid_loss_norm: 0.0292\n",
      " epoch: 297, train accuracy: 0.8457, train_loss_norm:0.0273, valid_acc: 0.8201, valid_loss_norm: 0.0292\n",
      " epoch: 298, train accuracy: 0.8460, train_loss_norm:0.0272, valid_acc: 0.8204, valid_loss_norm: 0.0291\n",
      " epoch: 299, train accuracy: 0.8461, train_loss_norm:0.0272, valid_acc: 0.8204, valid_loss_norm: 0.0291\n",
      " epoch: 300, train accuracy: 0.8462, train_loss_norm:0.0271, valid_acc: 0.8204, valid_loss_norm: 0.0291\n",
      "Test accuracy: 0.8275\n",
      "Test loss norm: 0.0291\n",
      "Cur fold: 3\n",
      "(27841, 300)\n",
      "(3479, 300)\n",
      "(3479, 300)\n",
      " epoch: 1, train accuracy: 0.7920, train_loss_norm:0.0867, valid_acc: 0.7790, valid_loss_norm: 0.0867\n",
      " epoch: 2, train accuracy: 0.7920, train_loss_norm:0.0859, valid_acc: 0.7790, valid_loss_norm: 0.0860\n",
      " epoch: 3, train accuracy: 0.7921, train_loss_norm:0.0852, valid_acc: 0.7790, valid_loss_norm: 0.0852\n",
      " epoch: 4, train accuracy: 0.7921, train_loss_norm:0.0844, valid_acc: 0.7790, valid_loss_norm: 0.0845\n",
      " epoch: 5, train accuracy: 0.7921, train_loss_norm:0.0836, valid_acc: 0.7790, valid_loss_norm: 0.0838\n",
      " epoch: 6, train accuracy: 0.7921, train_loss_norm:0.0829, valid_acc: 0.7790, valid_loss_norm: 0.0831\n",
      " epoch: 7, train accuracy: 0.7922, train_loss_norm:0.0821, valid_acc: 0.7790, valid_loss_norm: 0.0823\n",
      " epoch: 8, train accuracy: 0.7922, train_loss_norm:0.0814, valid_acc: 0.7790, valid_loss_norm: 0.0816\n",
      " epoch: 9, train accuracy: 0.7923, train_loss_norm:0.0807, valid_acc: 0.7790, valid_loss_norm: 0.0809\n",
      " epoch: 10, train accuracy: 0.7925, train_loss_norm:0.0799, valid_acc: 0.7790, valid_loss_norm: 0.0802\n",
      " epoch: 11, train accuracy: 0.7925, train_loss_norm:0.0792, valid_acc: 0.7790, valid_loss_norm: 0.0795\n",
      " epoch: 12, train accuracy: 0.7927, train_loss_norm:0.0785, valid_acc: 0.7790, valid_loss_norm: 0.0788\n",
      " epoch: 13, train accuracy: 0.7929, train_loss_norm:0.0778, valid_acc: 0.7790, valid_loss_norm: 0.0781\n",
      " epoch: 14, train accuracy: 0.7929, train_loss_norm:0.0770, valid_acc: 0.7790, valid_loss_norm: 0.0774\n",
      " epoch: 15, train accuracy: 0.7930, train_loss_norm:0.0763, valid_acc: 0.7790, valid_loss_norm: 0.0768\n",
      " epoch: 16, train accuracy: 0.7931, train_loss_norm:0.0756, valid_acc: 0.7790, valid_loss_norm: 0.0761\n",
      " epoch: 17, train accuracy: 0.7932, train_loss_norm:0.0750, valid_acc: 0.7790, valid_loss_norm: 0.0754\n",
      " epoch: 18, train accuracy: 0.7931, train_loss_norm:0.0743, valid_acc: 0.7790, valid_loss_norm: 0.0748\n",
      " epoch: 19, train accuracy: 0.7934, train_loss_norm:0.0736, valid_acc: 0.7790, valid_loss_norm: 0.0741\n",
      " epoch: 20, train accuracy: 0.7936, train_loss_norm:0.0729, valid_acc: 0.7790, valid_loss_norm: 0.0735\n",
      " epoch: 21, train accuracy: 0.7938, train_loss_norm:0.0723, valid_acc: 0.7792, valid_loss_norm: 0.0729\n",
      " epoch: 22, train accuracy: 0.7937, train_loss_norm:0.0716, valid_acc: 0.7792, valid_loss_norm: 0.0722\n",
      " epoch: 23, train accuracy: 0.7938, train_loss_norm:0.0710, valid_acc: 0.7792, valid_loss_norm: 0.0716\n",
      " epoch: 24, train accuracy: 0.7940, train_loss_norm:0.0703, valid_acc: 0.7792, valid_loss_norm: 0.0710\n",
      " epoch: 25, train accuracy: 0.7942, train_loss_norm:0.0697, valid_acc: 0.7792, valid_loss_norm: 0.0704\n",
      " epoch: 26, train accuracy: 0.7942, train_loss_norm:0.0691, valid_acc: 0.7792, valid_loss_norm: 0.0698\n",
      " epoch: 27, train accuracy: 0.7944, train_loss_norm:0.0685, valid_acc: 0.7795, valid_loss_norm: 0.0692\n",
      " epoch: 28, train accuracy: 0.7948, train_loss_norm:0.0679, valid_acc: 0.7795, valid_loss_norm: 0.0687\n",
      " epoch: 29, train accuracy: 0.7949, train_loss_norm:0.0673, valid_acc: 0.7795, valid_loss_norm: 0.0681\n",
      " epoch: 30, train accuracy: 0.7949, train_loss_norm:0.0667, valid_acc: 0.7798, valid_loss_norm: 0.0675\n",
      " epoch: 31, train accuracy: 0.7952, train_loss_norm:0.0662, valid_acc: 0.7795, valid_loss_norm: 0.0670\n",
      " epoch: 32, train accuracy: 0.7954, train_loss_norm:0.0656, valid_acc: 0.7795, valid_loss_norm: 0.0664\n",
      " epoch: 33, train accuracy: 0.7955, train_loss_norm:0.0651, valid_acc: 0.7795, valid_loss_norm: 0.0659\n",
      " epoch: 34, train accuracy: 0.7955, train_loss_norm:0.0645, valid_acc: 0.7795, valid_loss_norm: 0.0654\n",
      " epoch: 35, train accuracy: 0.7958, train_loss_norm:0.0640, valid_acc: 0.7798, valid_loss_norm: 0.0649\n",
      " epoch: 36, train accuracy: 0.7961, train_loss_norm:0.0635, valid_acc: 0.7804, valid_loss_norm: 0.0644\n",
      " epoch: 37, train accuracy: 0.7963, train_loss_norm:0.0630, valid_acc: 0.7813, valid_loss_norm: 0.0639\n",
      " epoch: 38, train accuracy: 0.7964, train_loss_norm:0.0625, valid_acc: 0.7813, valid_loss_norm: 0.0634\n",
      " epoch: 39, train accuracy: 0.7967, train_loss_norm:0.0620, valid_acc: 0.7813, valid_loss_norm: 0.0629\n",
      " epoch: 40, train accuracy: 0.7970, train_loss_norm:0.0615, valid_acc: 0.7813, valid_loss_norm: 0.0625\n",
      " epoch: 41, train accuracy: 0.7975, train_loss_norm:0.0610, valid_acc: 0.7813, valid_loss_norm: 0.0620\n",
      " epoch: 42, train accuracy: 0.7977, train_loss_norm:0.0605, valid_acc: 0.7815, valid_loss_norm: 0.0616\n",
      " epoch: 43, train accuracy: 0.7981, train_loss_norm:0.0601, valid_acc: 0.7821, valid_loss_norm: 0.0611\n",
      " epoch: 44, train accuracy: 0.7984, train_loss_norm:0.0596, valid_acc: 0.7824, valid_loss_norm: 0.0607\n",
      " epoch: 45, train accuracy: 0.7986, train_loss_norm:0.0592, valid_acc: 0.7830, valid_loss_norm: 0.0603\n",
      " epoch: 46, train accuracy: 0.7989, train_loss_norm:0.0588, valid_acc: 0.7838, valid_loss_norm: 0.0598\n",
      " epoch: 47, train accuracy: 0.7992, train_loss_norm:0.0583, valid_acc: 0.7844, valid_loss_norm: 0.0594\n",
      " epoch: 48, train accuracy: 0.7996, train_loss_norm:0.0579, valid_acc: 0.7847, valid_loss_norm: 0.0590\n",
      " epoch: 49, train accuracy: 0.7999, train_loss_norm:0.0575, valid_acc: 0.7859, valid_loss_norm: 0.0586\n",
      " epoch: 50, train accuracy: 0.8001, train_loss_norm:0.0571, valid_acc: 0.7859, valid_loss_norm: 0.0583\n",
      " epoch: 51, train accuracy: 0.8003, train_loss_norm:0.0567, valid_acc: 0.7861, valid_loss_norm: 0.0579\n",
      " epoch: 52, train accuracy: 0.8006, train_loss_norm:0.0563, valid_acc: 0.7873, valid_loss_norm: 0.0575\n",
      " epoch: 53, train accuracy: 0.8010, train_loss_norm:0.0560, valid_acc: 0.7876, valid_loss_norm: 0.0571\n",
      " epoch: 54, train accuracy: 0.8016, train_loss_norm:0.0556, valid_acc: 0.7873, valid_loss_norm: 0.0568\n",
      " epoch: 55, train accuracy: 0.8018, train_loss_norm:0.0552, valid_acc: 0.7873, valid_loss_norm: 0.0564\n",
      " epoch: 56, train accuracy: 0.8023, train_loss_norm:0.0549, valid_acc: 0.7879, valid_loss_norm: 0.0561\n",
      " epoch: 57, train accuracy: 0.8026, train_loss_norm:0.0545, valid_acc: 0.7882, valid_loss_norm: 0.0557\n",
      " epoch: 58, train accuracy: 0.8029, train_loss_norm:0.0542, valid_acc: 0.7882, valid_loss_norm: 0.0554\n",
      " epoch: 59, train accuracy: 0.8031, train_loss_norm:0.0538, valid_acc: 0.7882, valid_loss_norm: 0.0551\n",
      " epoch: 60, train accuracy: 0.8033, train_loss_norm:0.0535, valid_acc: 0.7890, valid_loss_norm: 0.0548\n",
      " epoch: 61, train accuracy: 0.8037, train_loss_norm:0.0532, valid_acc: 0.7896, valid_loss_norm: 0.0545\n",
      " epoch: 62, train accuracy: 0.8039, train_loss_norm:0.0529, valid_acc: 0.7899, valid_loss_norm: 0.0541\n",
      " epoch: 63, train accuracy: 0.8042, train_loss_norm:0.0525, valid_acc: 0.7902, valid_loss_norm: 0.0538\n",
      " epoch: 64, train accuracy: 0.8044, train_loss_norm:0.0522, valid_acc: 0.7902, valid_loss_norm: 0.0535\n",
      " epoch: 65, train accuracy: 0.8048, train_loss_norm:0.0519, valid_acc: 0.7902, valid_loss_norm: 0.0532\n",
      " epoch: 66, train accuracy: 0.8052, train_loss_norm:0.0516, valid_acc: 0.7907, valid_loss_norm: 0.0530\n",
      " epoch: 67, train accuracy: 0.8054, train_loss_norm:0.0513, valid_acc: 0.7913, valid_loss_norm: 0.0527\n",
      " epoch: 68, train accuracy: 0.8057, train_loss_norm:0.0511, valid_acc: 0.7907, valid_loss_norm: 0.0524\n",
      " epoch: 69, train accuracy: 0.8060, train_loss_norm:0.0508, valid_acc: 0.7910, valid_loss_norm: 0.0521\n",
      " epoch: 70, train accuracy: 0.8065, train_loss_norm:0.0505, valid_acc: 0.7922, valid_loss_norm: 0.0518\n",
      " epoch: 71, train accuracy: 0.8069, train_loss_norm:0.0502, valid_acc: 0.7925, valid_loss_norm: 0.0516\n",
      " epoch: 72, train accuracy: 0.8071, train_loss_norm:0.0499, valid_acc: 0.7930, valid_loss_norm: 0.0513\n",
      " epoch: 73, train accuracy: 0.8073, train_loss_norm:0.0497, valid_acc: 0.7936, valid_loss_norm: 0.0510\n",
      " epoch: 74, train accuracy: 0.8078, train_loss_norm:0.0494, valid_acc: 0.7942, valid_loss_norm: 0.0508\n",
      " epoch: 75, train accuracy: 0.8082, train_loss_norm:0.0492, valid_acc: 0.7942, valid_loss_norm: 0.0505\n",
      " epoch: 76, train accuracy: 0.8086, train_loss_norm:0.0489, valid_acc: 0.7945, valid_loss_norm: 0.0503\n",
      " epoch: 77, train accuracy: 0.8089, train_loss_norm:0.0486, valid_acc: 0.7951, valid_loss_norm: 0.0501\n",
      " epoch: 78, train accuracy: 0.8092, train_loss_norm:0.0484, valid_acc: 0.7951, valid_loss_norm: 0.0498\n",
      " epoch: 79, train accuracy: 0.8098, train_loss_norm:0.0482, valid_acc: 0.7962, valid_loss_norm: 0.0496\n",
      " epoch: 80, train accuracy: 0.8102, train_loss_norm:0.0479, valid_acc: 0.7965, valid_loss_norm: 0.0493\n",
      " epoch: 81, train accuracy: 0.8106, train_loss_norm:0.0477, valid_acc: 0.7971, valid_loss_norm: 0.0491\n",
      " epoch: 82, train accuracy: 0.8110, train_loss_norm:0.0474, valid_acc: 0.7971, valid_loss_norm: 0.0489\n",
      " epoch: 83, train accuracy: 0.8114, train_loss_norm:0.0472, valid_acc: 0.7971, valid_loss_norm: 0.0487\n",
      " epoch: 84, train accuracy: 0.8118, train_loss_norm:0.0470, valid_acc: 0.7968, valid_loss_norm: 0.0484\n",
      " epoch: 85, train accuracy: 0.8123, train_loss_norm:0.0468, valid_acc: 0.7971, valid_loss_norm: 0.0482\n",
      " epoch: 86, train accuracy: 0.8127, train_loss_norm:0.0466, valid_acc: 0.7974, valid_loss_norm: 0.0480\n",
      " epoch: 87, train accuracy: 0.8129, train_loss_norm:0.0463, valid_acc: 0.7979, valid_loss_norm: 0.0478\n",
      " epoch: 88, train accuracy: 0.8129, train_loss_norm:0.0461, valid_acc: 0.7985, valid_loss_norm: 0.0476\n",
      " epoch: 89, train accuracy: 0.8132, train_loss_norm:0.0459, valid_acc: 0.7985, valid_loss_norm: 0.0474\n",
      " epoch: 90, train accuracy: 0.8132, train_loss_norm:0.0457, valid_acc: 0.7991, valid_loss_norm: 0.0472\n",
      " epoch: 91, train accuracy: 0.8137, train_loss_norm:0.0455, valid_acc: 0.7997, valid_loss_norm: 0.0470\n",
      " epoch: 92, train accuracy: 0.8138, train_loss_norm:0.0453, valid_acc: 0.7997, valid_loss_norm: 0.0468\n",
      " epoch: 93, train accuracy: 0.8141, train_loss_norm:0.0451, valid_acc: 0.7999, valid_loss_norm: 0.0466\n",
      " epoch: 94, train accuracy: 0.8143, train_loss_norm:0.0449, valid_acc: 0.8005, valid_loss_norm: 0.0464\n",
      " epoch: 95, train accuracy: 0.8144, train_loss_norm:0.0447, valid_acc: 0.8005, valid_loss_norm: 0.0462\n",
      " epoch: 96, train accuracy: 0.8147, train_loss_norm:0.0445, valid_acc: 0.8008, valid_loss_norm: 0.0460\n",
      " epoch: 97, train accuracy: 0.8149, train_loss_norm:0.0443, valid_acc: 0.8002, valid_loss_norm: 0.0459\n",
      " epoch: 98, train accuracy: 0.8152, train_loss_norm:0.0441, valid_acc: 0.8005, valid_loss_norm: 0.0457\n",
      " epoch: 99, train accuracy: 0.8154, train_loss_norm:0.0440, valid_acc: 0.8017, valid_loss_norm: 0.0455\n",
      " epoch: 100, train accuracy: 0.8157, train_loss_norm:0.0438, valid_acc: 0.8014, valid_loss_norm: 0.0453\n",
      " epoch: 101, train accuracy: 0.8160, train_loss_norm:0.0436, valid_acc: 0.8017, valid_loss_norm: 0.0451\n",
      " epoch: 102, train accuracy: 0.8162, train_loss_norm:0.0434, valid_acc: 0.8014, valid_loss_norm: 0.0450\n",
      " epoch: 103, train accuracy: 0.8167, train_loss_norm:0.0432, valid_acc: 0.8022, valid_loss_norm: 0.0448\n",
      " epoch: 104, train accuracy: 0.8170, train_loss_norm:0.0431, valid_acc: 0.8025, valid_loss_norm: 0.0446\n",
      " epoch: 105, train accuracy: 0.8172, train_loss_norm:0.0429, valid_acc: 0.8028, valid_loss_norm: 0.0445\n",
      " epoch: 106, train accuracy: 0.8175, train_loss_norm:0.0427, valid_acc: 0.8031, valid_loss_norm: 0.0443\n",
      " epoch: 107, train accuracy: 0.8178, train_loss_norm:0.0426, valid_acc: 0.8031, valid_loss_norm: 0.0441\n",
      " epoch: 108, train accuracy: 0.8179, train_loss_norm:0.0424, valid_acc: 0.8028, valid_loss_norm: 0.0440\n",
      " epoch: 109, train accuracy: 0.8183, train_loss_norm:0.0422, valid_acc: 0.8037, valid_loss_norm: 0.0438\n",
      " epoch: 110, train accuracy: 0.8185, train_loss_norm:0.0421, valid_acc: 0.8040, valid_loss_norm: 0.0437\n",
      " epoch: 111, train accuracy: 0.8187, train_loss_norm:0.0419, valid_acc: 0.8037, valid_loss_norm: 0.0435\n",
      " epoch: 112, train accuracy: 0.8190, train_loss_norm:0.0418, valid_acc: 0.8040, valid_loss_norm: 0.0434\n",
      " epoch: 113, train accuracy: 0.8193, train_loss_norm:0.0416, valid_acc: 0.8037, valid_loss_norm: 0.0432\n",
      " epoch: 114, train accuracy: 0.8196, train_loss_norm:0.0415, valid_acc: 0.8043, valid_loss_norm: 0.0431\n",
      " epoch: 115, train accuracy: 0.8199, train_loss_norm:0.0413, valid_acc: 0.8051, valid_loss_norm: 0.0429\n",
      " epoch: 116, train accuracy: 0.8203, train_loss_norm:0.0412, valid_acc: 0.8051, valid_loss_norm: 0.0428\n",
      " epoch: 117, train accuracy: 0.8206, train_loss_norm:0.0410, valid_acc: 0.8051, valid_loss_norm: 0.0426\n",
      " epoch: 118, train accuracy: 0.8208, train_loss_norm:0.0409, valid_acc: 0.8051, valid_loss_norm: 0.0425\n",
      " epoch: 119, train accuracy: 0.8209, train_loss_norm:0.0407, valid_acc: 0.8051, valid_loss_norm: 0.0423\n",
      " epoch: 120, train accuracy: 0.8211, train_loss_norm:0.0406, valid_acc: 0.8051, valid_loss_norm: 0.0422\n",
      " epoch: 121, train accuracy: 0.8213, train_loss_norm:0.0404, valid_acc: 0.8051, valid_loss_norm: 0.0421\n",
      " epoch: 122, train accuracy: 0.8215, train_loss_norm:0.0403, valid_acc: 0.8054, valid_loss_norm: 0.0419\n",
      " epoch: 123, train accuracy: 0.8218, train_loss_norm:0.0401, valid_acc: 0.8060, valid_loss_norm: 0.0418\n",
      " epoch: 124, train accuracy: 0.8221, train_loss_norm:0.0400, valid_acc: 0.8057, valid_loss_norm: 0.0416\n",
      " epoch: 125, train accuracy: 0.8224, train_loss_norm:0.0399, valid_acc: 0.8060, valid_loss_norm: 0.0415\n",
      " epoch: 126, train accuracy: 0.8226, train_loss_norm:0.0397, valid_acc: 0.8054, valid_loss_norm: 0.0414\n",
      " epoch: 127, train accuracy: 0.8228, train_loss_norm:0.0396, valid_acc: 0.8060, valid_loss_norm: 0.0412\n",
      " epoch: 128, train accuracy: 0.8229, train_loss_norm:0.0395, valid_acc: 0.8063, valid_loss_norm: 0.0411\n",
      " epoch: 129, train accuracy: 0.8232, train_loss_norm:0.0393, valid_acc: 0.8068, valid_loss_norm: 0.0410\n",
      " epoch: 130, train accuracy: 0.8236, train_loss_norm:0.0392, valid_acc: 0.8068, valid_loss_norm: 0.0409\n",
      " epoch: 131, train accuracy: 0.8237, train_loss_norm:0.0391, valid_acc: 0.8068, valid_loss_norm: 0.0407\n",
      " epoch: 132, train accuracy: 0.8239, train_loss_norm:0.0390, valid_acc: 0.8074, valid_loss_norm: 0.0406\n",
      " epoch: 133, train accuracy: 0.8242, train_loss_norm:0.0388, valid_acc: 0.8074, valid_loss_norm: 0.0405\n",
      " epoch: 134, train accuracy: 0.8245, train_loss_norm:0.0387, valid_acc: 0.8083, valid_loss_norm: 0.0404\n",
      " epoch: 135, train accuracy: 0.8248, train_loss_norm:0.0386, valid_acc: 0.8086, valid_loss_norm: 0.0403\n",
      " epoch: 136, train accuracy: 0.8248, train_loss_norm:0.0385, valid_acc: 0.8086, valid_loss_norm: 0.0401\n",
      " epoch: 137, train accuracy: 0.8250, train_loss_norm:0.0383, valid_acc: 0.8094, valid_loss_norm: 0.0400\n",
      " epoch: 138, train accuracy: 0.8251, train_loss_norm:0.0382, valid_acc: 0.8091, valid_loss_norm: 0.0399\n",
      " epoch: 139, train accuracy: 0.8253, train_loss_norm:0.0381, valid_acc: 0.8094, valid_loss_norm: 0.0398\n",
      " epoch: 140, train accuracy: 0.8255, train_loss_norm:0.0380, valid_acc: 0.8094, valid_loss_norm: 0.0397\n",
      " epoch: 141, train accuracy: 0.8258, train_loss_norm:0.0379, valid_acc: 0.8103, valid_loss_norm: 0.0396\n",
      " epoch: 142, train accuracy: 0.8260, train_loss_norm:0.0378, valid_acc: 0.8100, valid_loss_norm: 0.0394\n",
      " epoch: 143, train accuracy: 0.8263, train_loss_norm:0.0376, valid_acc: 0.8103, valid_loss_norm: 0.0393\n",
      " epoch: 144, train accuracy: 0.8265, train_loss_norm:0.0375, valid_acc: 0.8100, valid_loss_norm: 0.0392\n",
      " epoch: 145, train accuracy: 0.8267, train_loss_norm:0.0374, valid_acc: 0.8100, valid_loss_norm: 0.0391\n",
      " epoch: 146, train accuracy: 0.8267, train_loss_norm:0.0373, valid_acc: 0.8100, valid_loss_norm: 0.0390\n",
      " epoch: 147, train accuracy: 0.8269, train_loss_norm:0.0372, valid_acc: 0.8100, valid_loss_norm: 0.0389\n",
      " epoch: 148, train accuracy: 0.8271, train_loss_norm:0.0371, valid_acc: 0.8106, valid_loss_norm: 0.0388\n",
      " epoch: 149, train accuracy: 0.8273, train_loss_norm:0.0370, valid_acc: 0.8112, valid_loss_norm: 0.0387\n",
      " epoch: 150, train accuracy: 0.8277, train_loss_norm:0.0369, valid_acc: 0.8117, valid_loss_norm: 0.0386\n",
      " epoch: 151, train accuracy: 0.8279, train_loss_norm:0.0368, valid_acc: 0.8120, valid_loss_norm: 0.0385\n",
      " epoch: 152, train accuracy: 0.8281, train_loss_norm:0.0367, valid_acc: 0.8120, valid_loss_norm: 0.0384\n",
      " epoch: 153, train accuracy: 0.8285, train_loss_norm:0.0366, valid_acc: 0.8126, valid_loss_norm: 0.0383\n",
      " epoch: 154, train accuracy: 0.8286, train_loss_norm:0.0365, valid_acc: 0.8132, valid_loss_norm: 0.0382\n",
      " epoch: 155, train accuracy: 0.8287, train_loss_norm:0.0364, valid_acc: 0.8135, valid_loss_norm: 0.0381\n",
      " epoch: 156, train accuracy: 0.8288, train_loss_norm:0.0363, valid_acc: 0.8135, valid_loss_norm: 0.0380\n",
      " epoch: 157, train accuracy: 0.8290, train_loss_norm:0.0362, valid_acc: 0.8135, valid_loss_norm: 0.0379\n",
      " epoch: 158, train accuracy: 0.8293, train_loss_norm:0.0361, valid_acc: 0.8137, valid_loss_norm: 0.0378\n",
      " epoch: 159, train accuracy: 0.8295, train_loss_norm:0.0360, valid_acc: 0.8135, valid_loss_norm: 0.0377\n",
      " epoch: 160, train accuracy: 0.8296, train_loss_norm:0.0359, valid_acc: 0.8135, valid_loss_norm: 0.0376\n",
      " epoch: 161, train accuracy: 0.8298, train_loss_norm:0.0358, valid_acc: 0.8135, valid_loss_norm: 0.0375\n",
      " epoch: 162, train accuracy: 0.8300, train_loss_norm:0.0357, valid_acc: 0.8135, valid_loss_norm: 0.0374\n",
      " epoch: 163, train accuracy: 0.8300, train_loss_norm:0.0356, valid_acc: 0.8137, valid_loss_norm: 0.0373\n",
      " epoch: 164, train accuracy: 0.8302, train_loss_norm:0.0355, valid_acc: 0.8140, valid_loss_norm: 0.0372\n",
      " epoch: 165, train accuracy: 0.8303, train_loss_norm:0.0354, valid_acc: 0.8143, valid_loss_norm: 0.0371\n",
      " epoch: 166, train accuracy: 0.8306, train_loss_norm:0.0353, valid_acc: 0.8146, valid_loss_norm: 0.0370\n",
      " epoch: 167, train accuracy: 0.8308, train_loss_norm:0.0352, valid_acc: 0.8146, valid_loss_norm: 0.0369\n",
      " epoch: 168, train accuracy: 0.8309, train_loss_norm:0.0351, valid_acc: 0.8143, valid_loss_norm: 0.0368\n",
      " epoch: 169, train accuracy: 0.8311, train_loss_norm:0.0350, valid_acc: 0.8143, valid_loss_norm: 0.0368\n",
      " epoch: 170, train accuracy: 0.8314, train_loss_norm:0.0349, valid_acc: 0.8143, valid_loss_norm: 0.0367\n",
      " epoch: 171, train accuracy: 0.8316, train_loss_norm:0.0348, valid_acc: 0.8146, valid_loss_norm: 0.0366\n",
      " epoch: 172, train accuracy: 0.8319, train_loss_norm:0.0348, valid_acc: 0.8146, valid_loss_norm: 0.0365\n",
      " epoch: 173, train accuracy: 0.8320, train_loss_norm:0.0347, valid_acc: 0.8140, valid_loss_norm: 0.0364\n",
      " epoch: 174, train accuracy: 0.8322, train_loss_norm:0.0346, valid_acc: 0.8137, valid_loss_norm: 0.0363\n",
      " epoch: 175, train accuracy: 0.8322, train_loss_norm:0.0345, valid_acc: 0.8140, valid_loss_norm: 0.0362\n",
      " epoch: 176, train accuracy: 0.8323, train_loss_norm:0.0344, valid_acc: 0.8143, valid_loss_norm: 0.0362\n",
      " epoch: 177, train accuracy: 0.8325, train_loss_norm:0.0343, valid_acc: 0.8143, valid_loss_norm: 0.0361\n",
      " epoch: 178, train accuracy: 0.8328, train_loss_norm:0.0342, valid_acc: 0.8143, valid_loss_norm: 0.0360\n",
      " epoch: 179, train accuracy: 0.8330, train_loss_norm:0.0342, valid_acc: 0.8140, valid_loss_norm: 0.0359\n",
      " epoch: 180, train accuracy: 0.8332, train_loss_norm:0.0341, valid_acc: 0.8140, valid_loss_norm: 0.0358\n",
      " epoch: 181, train accuracy: 0.8333, train_loss_norm:0.0340, valid_acc: 0.8143, valid_loss_norm: 0.0357\n",
      " epoch: 182, train accuracy: 0.8334, train_loss_norm:0.0339, valid_acc: 0.8143, valid_loss_norm: 0.0357\n",
      " epoch: 183, train accuracy: 0.8335, train_loss_norm:0.0338, valid_acc: 0.8143, valid_loss_norm: 0.0356\n",
      " epoch: 184, train accuracy: 0.8337, train_loss_norm:0.0337, valid_acc: 0.8149, valid_loss_norm: 0.0355\n",
      " epoch: 185, train accuracy: 0.8338, train_loss_norm:0.0337, valid_acc: 0.8149, valid_loss_norm: 0.0354\n",
      " epoch: 186, train accuracy: 0.8338, train_loss_norm:0.0336, valid_acc: 0.8149, valid_loss_norm: 0.0353\n",
      " epoch: 187, train accuracy: 0.8339, train_loss_norm:0.0335, valid_acc: 0.8152, valid_loss_norm: 0.0353\n",
      " epoch: 188, train accuracy: 0.8342, train_loss_norm:0.0334, valid_acc: 0.8149, valid_loss_norm: 0.0352\n",
      " epoch: 189, train accuracy: 0.8345, train_loss_norm:0.0333, valid_acc: 0.8149, valid_loss_norm: 0.0351\n",
      " epoch: 190, train accuracy: 0.8346, train_loss_norm:0.0333, valid_acc: 0.8160, valid_loss_norm: 0.0350\n",
      " epoch: 191, train accuracy: 0.8346, train_loss_norm:0.0332, valid_acc: 0.8158, valid_loss_norm: 0.0350\n",
      " epoch: 192, train accuracy: 0.8347, train_loss_norm:0.0331, valid_acc: 0.8158, valid_loss_norm: 0.0349\n",
      " epoch: 193, train accuracy: 0.8348, train_loss_norm:0.0330, valid_acc: 0.8155, valid_loss_norm: 0.0348\n",
      " epoch: 194, train accuracy: 0.8351, train_loss_norm:0.0330, valid_acc: 0.8160, valid_loss_norm: 0.0347\n",
      " epoch: 195, train accuracy: 0.8350, train_loss_norm:0.0329, valid_acc: 0.8169, valid_loss_norm: 0.0347\n",
      " epoch: 196, train accuracy: 0.8353, train_loss_norm:0.0328, valid_acc: 0.8169, valid_loss_norm: 0.0346\n",
      " epoch: 197, train accuracy: 0.8354, train_loss_norm:0.0327, valid_acc: 0.8172, valid_loss_norm: 0.0345\n",
      " epoch: 198, train accuracy: 0.8357, train_loss_norm:0.0327, valid_acc: 0.8178, valid_loss_norm: 0.0345\n",
      " epoch: 199, train accuracy: 0.8358, train_loss_norm:0.0326, valid_acc: 0.8189, valid_loss_norm: 0.0344\n",
      " epoch: 200, train accuracy: 0.8361, train_loss_norm:0.0325, valid_acc: 0.8189, valid_loss_norm: 0.0343\n",
      " epoch: 201, train accuracy: 0.8361, train_loss_norm:0.0325, valid_acc: 0.8189, valid_loss_norm: 0.0342\n",
      " epoch: 202, train accuracy: 0.8362, train_loss_norm:0.0324, valid_acc: 0.8183, valid_loss_norm: 0.0342\n",
      " epoch: 203, train accuracy: 0.8363, train_loss_norm:0.0323, valid_acc: 0.8186, valid_loss_norm: 0.0341\n",
      " epoch: 204, train accuracy: 0.8365, train_loss_norm:0.0322, valid_acc: 0.8189, valid_loss_norm: 0.0340\n",
      " epoch: 205, train accuracy: 0.8367, train_loss_norm:0.0322, valid_acc: 0.8192, valid_loss_norm: 0.0340\n",
      " epoch: 206, train accuracy: 0.8367, train_loss_norm:0.0321, valid_acc: 0.8192, valid_loss_norm: 0.0339\n",
      " epoch: 207, train accuracy: 0.8368, train_loss_norm:0.0320, valid_acc: 0.8195, valid_loss_norm: 0.0338\n",
      " epoch: 208, train accuracy: 0.8370, train_loss_norm:0.0320, valid_acc: 0.8195, valid_loss_norm: 0.0338\n",
      " epoch: 209, train accuracy: 0.8370, train_loss_norm:0.0319, valid_acc: 0.8198, valid_loss_norm: 0.0337\n",
      " epoch: 210, train accuracy: 0.8372, train_loss_norm:0.0318, valid_acc: 0.8198, valid_loss_norm: 0.0336\n",
      " epoch: 211, train accuracy: 0.8373, train_loss_norm:0.0318, valid_acc: 0.8198, valid_loss_norm: 0.0336\n",
      " epoch: 212, train accuracy: 0.8373, train_loss_norm:0.0317, valid_acc: 0.8206, valid_loss_norm: 0.0335\n",
      " epoch: 213, train accuracy: 0.8376, train_loss_norm:0.0316, valid_acc: 0.8206, valid_loss_norm: 0.0334\n",
      " epoch: 214, train accuracy: 0.8377, train_loss_norm:0.0316, valid_acc: 0.8209, valid_loss_norm: 0.0334\n",
      " epoch: 215, train accuracy: 0.8378, train_loss_norm:0.0315, valid_acc: 0.8206, valid_loss_norm: 0.0333\n",
      " epoch: 216, train accuracy: 0.8378, train_loss_norm:0.0314, valid_acc: 0.8212, valid_loss_norm: 0.0333\n",
      " epoch: 217, train accuracy: 0.8379, train_loss_norm:0.0314, valid_acc: 0.8212, valid_loss_norm: 0.0332\n",
      " epoch: 218, train accuracy: 0.8379, train_loss_norm:0.0313, valid_acc: 0.8212, valid_loss_norm: 0.0331\n",
      " epoch: 219, train accuracy: 0.8382, train_loss_norm:0.0312, valid_acc: 0.8215, valid_loss_norm: 0.0331\n",
      " epoch: 220, train accuracy: 0.8383, train_loss_norm:0.0312, valid_acc: 0.8224, valid_loss_norm: 0.0330\n",
      " epoch: 221, train accuracy: 0.8384, train_loss_norm:0.0311, valid_acc: 0.8221, valid_loss_norm: 0.0329\n",
      " epoch: 222, train accuracy: 0.8386, train_loss_norm:0.0311, valid_acc: 0.8218, valid_loss_norm: 0.0329\n",
      " epoch: 223, train accuracy: 0.8386, train_loss_norm:0.0310, valid_acc: 0.8221, valid_loss_norm: 0.0328\n",
      " epoch: 224, train accuracy: 0.8388, train_loss_norm:0.0309, valid_acc: 0.8215, valid_loss_norm: 0.0328\n",
      " epoch: 225, train accuracy: 0.8389, train_loss_norm:0.0309, valid_acc: 0.8215, valid_loss_norm: 0.0327\n",
      " epoch: 226, train accuracy: 0.8391, train_loss_norm:0.0308, valid_acc: 0.8212, valid_loss_norm: 0.0326\n",
      " epoch: 227, train accuracy: 0.8392, train_loss_norm:0.0308, valid_acc: 0.8215, valid_loss_norm: 0.0326\n",
      " epoch: 228, train accuracy: 0.8394, train_loss_norm:0.0307, valid_acc: 0.8224, valid_loss_norm: 0.0325\n",
      " epoch: 229, train accuracy: 0.8395, train_loss_norm:0.0306, valid_acc: 0.8221, valid_loss_norm: 0.0325\n",
      " epoch: 230, train accuracy: 0.8395, train_loss_norm:0.0306, valid_acc: 0.8221, valid_loss_norm: 0.0324\n",
      " epoch: 231, train accuracy: 0.8395, train_loss_norm:0.0305, valid_acc: 0.8227, valid_loss_norm: 0.0324\n",
      " epoch: 232, train accuracy: 0.8397, train_loss_norm:0.0305, valid_acc: 0.8227, valid_loss_norm: 0.0323\n",
      " epoch: 233, train accuracy: 0.8397, train_loss_norm:0.0304, valid_acc: 0.8227, valid_loss_norm: 0.0322\n",
      " epoch: 234, train accuracy: 0.8398, train_loss_norm:0.0303, valid_acc: 0.8229, valid_loss_norm: 0.0322\n",
      " epoch: 235, train accuracy: 0.8399, train_loss_norm:0.0303, valid_acc: 0.8235, valid_loss_norm: 0.0321\n",
      " epoch: 236, train accuracy: 0.8399, train_loss_norm:0.0302, valid_acc: 0.8235, valid_loss_norm: 0.0321\n",
      " epoch: 237, train accuracy: 0.8401, train_loss_norm:0.0302, valid_acc: 0.8235, valid_loss_norm: 0.0320\n",
      " epoch: 238, train accuracy: 0.8400, train_loss_norm:0.0301, valid_acc: 0.8235, valid_loss_norm: 0.0320\n",
      " epoch: 239, train accuracy: 0.8401, train_loss_norm:0.0301, valid_acc: 0.8235, valid_loss_norm: 0.0319\n",
      " epoch: 240, train accuracy: 0.8402, train_loss_norm:0.0300, valid_acc: 0.8238, valid_loss_norm: 0.0318\n",
      " epoch: 241, train accuracy: 0.8403, train_loss_norm:0.0300, valid_acc: 0.8238, valid_loss_norm: 0.0318\n",
      " epoch: 242, train accuracy: 0.8405, train_loss_norm:0.0299, valid_acc: 0.8238, valid_loss_norm: 0.0317\n",
      " epoch: 243, train accuracy: 0.8406, train_loss_norm:0.0298, valid_acc: 0.8238, valid_loss_norm: 0.0317\n",
      " epoch: 244, train accuracy: 0.8408, train_loss_norm:0.0298, valid_acc: 0.8238, valid_loss_norm: 0.0316\n",
      " epoch: 245, train accuracy: 0.8410, train_loss_norm:0.0297, valid_acc: 0.8238, valid_loss_norm: 0.0316\n",
      " epoch: 246, train accuracy: 0.8411, train_loss_norm:0.0297, valid_acc: 0.8238, valid_loss_norm: 0.0315\n",
      " epoch: 247, train accuracy: 0.8413, train_loss_norm:0.0296, valid_acc: 0.8238, valid_loss_norm: 0.0315\n",
      " epoch: 248, train accuracy: 0.8413, train_loss_norm:0.0296, valid_acc: 0.8238, valid_loss_norm: 0.0314\n",
      " epoch: 249, train accuracy: 0.8415, train_loss_norm:0.0295, valid_acc: 0.8238, valid_loss_norm: 0.0314\n",
      " epoch: 250, train accuracy: 0.8417, train_loss_norm:0.0295, valid_acc: 0.8238, valid_loss_norm: 0.0313\n",
      " epoch: 251, train accuracy: 0.8416, train_loss_norm:0.0294, valid_acc: 0.8241, valid_loss_norm: 0.0313\n",
      " epoch: 252, train accuracy: 0.8416, train_loss_norm:0.0294, valid_acc: 0.8241, valid_loss_norm: 0.0312\n",
      " epoch: 253, train accuracy: 0.8417, train_loss_norm:0.0293, valid_acc: 0.8241, valid_loss_norm: 0.0312\n",
      " epoch: 254, train accuracy: 0.8417, train_loss_norm:0.0293, valid_acc: 0.8241, valid_loss_norm: 0.0311\n",
      " epoch: 255, train accuracy: 0.8418, train_loss_norm:0.0292, valid_acc: 0.8241, valid_loss_norm: 0.0311\n",
      " epoch: 256, train accuracy: 0.8419, train_loss_norm:0.0292, valid_acc: 0.8241, valid_loss_norm: 0.0310\n",
      " epoch: 257, train accuracy: 0.8421, train_loss_norm:0.0291, valid_acc: 0.8241, valid_loss_norm: 0.0310\n",
      " epoch: 258, train accuracy: 0.8421, train_loss_norm:0.0291, valid_acc: 0.8235, valid_loss_norm: 0.0309\n",
      " epoch: 259, train accuracy: 0.8422, train_loss_norm:0.0290, valid_acc: 0.8235, valid_loss_norm: 0.0309\n",
      " epoch: 260, train accuracy: 0.8424, train_loss_norm:0.0290, valid_acc: 0.8235, valid_loss_norm: 0.0308\n",
      " epoch: 261, train accuracy: 0.8424, train_loss_norm:0.0289, valid_acc: 0.8235, valid_loss_norm: 0.0308\n",
      " epoch: 262, train accuracy: 0.8424, train_loss_norm:0.0289, valid_acc: 0.8238, valid_loss_norm: 0.0307\n",
      " epoch: 263, train accuracy: 0.8425, train_loss_norm:0.0288, valid_acc: 0.8238, valid_loss_norm: 0.0307\n",
      " epoch: 264, train accuracy: 0.8425, train_loss_norm:0.0288, valid_acc: 0.8238, valid_loss_norm: 0.0306\n",
      " epoch: 265, train accuracy: 0.8427, train_loss_norm:0.0287, valid_acc: 0.8241, valid_loss_norm: 0.0306\n",
      " epoch: 266, train accuracy: 0.8427, train_loss_norm:0.0287, valid_acc: 0.8244, valid_loss_norm: 0.0305\n",
      " epoch: 267, train accuracy: 0.8429, train_loss_norm:0.0286, valid_acc: 0.8247, valid_loss_norm: 0.0305\n",
      " epoch: 268, train accuracy: 0.8429, train_loss_norm:0.0286, valid_acc: 0.8249, valid_loss_norm: 0.0304\n",
      " epoch: 269, train accuracy: 0.8433, train_loss_norm:0.0285, valid_acc: 0.8247, valid_loss_norm: 0.0304\n",
      " epoch: 270, train accuracy: 0.8433, train_loss_norm:0.0285, valid_acc: 0.8247, valid_loss_norm: 0.0304\n",
      " epoch: 271, train accuracy: 0.8434, train_loss_norm:0.0284, valid_acc: 0.8249, valid_loss_norm: 0.0303\n",
      " epoch: 272, train accuracy: 0.8435, train_loss_norm:0.0284, valid_acc: 0.8249, valid_loss_norm: 0.0303\n",
      " epoch: 273, train accuracy: 0.8436, train_loss_norm:0.0283, valid_acc: 0.8255, valid_loss_norm: 0.0302\n",
      " epoch: 274, train accuracy: 0.8437, train_loss_norm:0.0283, valid_acc: 0.8255, valid_loss_norm: 0.0302\n",
      " epoch: 275, train accuracy: 0.8437, train_loss_norm:0.0282, valid_acc: 0.8255, valid_loss_norm: 0.0301\n",
      " epoch: 276, train accuracy: 0.8437, train_loss_norm:0.0282, valid_acc: 0.8255, valid_loss_norm: 0.0301\n",
      " epoch: 277, train accuracy: 0.8436, train_loss_norm:0.0282, valid_acc: 0.8255, valid_loss_norm: 0.0300\n",
      " epoch: 278, train accuracy: 0.8438, train_loss_norm:0.0281, valid_acc: 0.8258, valid_loss_norm: 0.0300\n",
      " epoch: 279, train accuracy: 0.8439, train_loss_norm:0.0281, valid_acc: 0.8255, valid_loss_norm: 0.0300\n",
      " epoch: 280, train accuracy: 0.8439, train_loss_norm:0.0280, valid_acc: 0.8258, valid_loss_norm: 0.0299\n",
      " epoch: 281, train accuracy: 0.8440, train_loss_norm:0.0280, valid_acc: 0.8258, valid_loss_norm: 0.0299\n",
      " epoch: 282, train accuracy: 0.8442, train_loss_norm:0.0279, valid_acc: 0.8261, valid_loss_norm: 0.0298\n",
      " epoch: 283, train accuracy: 0.8443, train_loss_norm:0.0279, valid_acc: 0.8264, valid_loss_norm: 0.0298\n",
      " epoch: 284, train accuracy: 0.8443, train_loss_norm:0.0278, valid_acc: 0.8264, valid_loss_norm: 0.0297\n",
      " epoch: 285, train accuracy: 0.8445, train_loss_norm:0.0278, valid_acc: 0.8264, valid_loss_norm: 0.0297\n",
      " epoch: 286, train accuracy: 0.8445, train_loss_norm:0.0278, valid_acc: 0.8264, valid_loss_norm: 0.0297\n",
      " epoch: 287, train accuracy: 0.8445, train_loss_norm:0.0277, valid_acc: 0.8267, valid_loss_norm: 0.0296\n",
      " epoch: 288, train accuracy: 0.8447, train_loss_norm:0.0277, valid_acc: 0.8267, valid_loss_norm: 0.0296\n",
      " epoch: 289, train accuracy: 0.8449, train_loss_norm:0.0276, valid_acc: 0.8267, valid_loss_norm: 0.0295\n",
      " epoch: 290, train accuracy: 0.8449, train_loss_norm:0.0276, valid_acc: 0.8267, valid_loss_norm: 0.0295\n",
      " epoch: 291, train accuracy: 0.8450, train_loss_norm:0.0275, valid_acc: 0.8267, valid_loss_norm: 0.0294\n",
      " epoch: 292, train accuracy: 0.8451, train_loss_norm:0.0275, valid_acc: 0.8267, valid_loss_norm: 0.0294\n",
      " epoch: 293, train accuracy: 0.8451, train_loss_norm:0.0275, valid_acc: 0.8267, valid_loss_norm: 0.0294\n",
      " epoch: 294, train accuracy: 0.8452, train_loss_norm:0.0274, valid_acc: 0.8267, valid_loss_norm: 0.0293\n",
      " epoch: 295, train accuracy: 0.8451, train_loss_norm:0.0274, valid_acc: 0.8267, valid_loss_norm: 0.0293\n",
      " epoch: 296, train accuracy: 0.8453, train_loss_norm:0.0273, valid_acc: 0.8264, valid_loss_norm: 0.0292\n",
      " epoch: 297, train accuracy: 0.8454, train_loss_norm:0.0273, valid_acc: 0.8267, valid_loss_norm: 0.0292\n",
      " epoch: 298, train accuracy: 0.8454, train_loss_norm:0.0273, valid_acc: 0.8270, valid_loss_norm: 0.0292\n",
      " epoch: 299, train accuracy: 0.8455, train_loss_norm:0.0272, valid_acc: 0.8270, valid_loss_norm: 0.0291\n",
      " epoch: 300, train accuracy: 0.8457, train_loss_norm:0.0272, valid_acc: 0.8272, valid_loss_norm: 0.0291\n",
      "Test accuracy: 0.8227\n",
      "Test loss norm: 0.0289\n",
      "Cur fold: 4\n",
      "(27841, 300)\n",
      "(3479, 300)\n",
      "(3479, 300)\n",
      " epoch: 1, train accuracy: 0.7944, train_loss_norm:0.0867, valid_acc: 0.7749, valid_loss_norm: 0.0867\n",
      " epoch: 2, train accuracy: 0.7944, train_loss_norm:0.0859, valid_acc: 0.7749, valid_loss_norm: 0.0860\n",
      " epoch: 3, train accuracy: 0.7944, train_loss_norm:0.0852, valid_acc: 0.7749, valid_loss_norm: 0.0852\n",
      " epoch: 4, train accuracy: 0.7944, train_loss_norm:0.0844, valid_acc: 0.7749, valid_loss_norm: 0.0845\n",
      " epoch: 5, train accuracy: 0.7944, train_loss_norm:0.0836, valid_acc: 0.7749, valid_loss_norm: 0.0837\n",
      " epoch: 6, train accuracy: 0.7944, train_loss_norm:0.0829, valid_acc: 0.7749, valid_loss_norm: 0.0830\n",
      " epoch: 7, train accuracy: 0.7945, train_loss_norm:0.0821, valid_acc: 0.7749, valid_loss_norm: 0.0822\n",
      " epoch: 8, train accuracy: 0.7945, train_loss_norm:0.0814, valid_acc: 0.7749, valid_loss_norm: 0.0815\n",
      " epoch: 9, train accuracy: 0.7945, train_loss_norm:0.0807, valid_acc: 0.7749, valid_loss_norm: 0.0808\n",
      " epoch: 10, train accuracy: 0.7946, train_loss_norm:0.0799, valid_acc: 0.7749, valid_loss_norm: 0.0801\n",
      " epoch: 11, train accuracy: 0.7946, train_loss_norm:0.0792, valid_acc: 0.7749, valid_loss_norm: 0.0794\n",
      " epoch: 12, train accuracy: 0.7946, train_loss_norm:0.0785, valid_acc: 0.7749, valid_loss_norm: 0.0787\n",
      " epoch: 13, train accuracy: 0.7947, train_loss_norm:0.0778, valid_acc: 0.7749, valid_loss_norm: 0.0780\n",
      " epoch: 14, train accuracy: 0.7947, train_loss_norm:0.0771, valid_acc: 0.7749, valid_loss_norm: 0.0773\n",
      " epoch: 15, train accuracy: 0.7948, train_loss_norm:0.0764, valid_acc: 0.7749, valid_loss_norm: 0.0766\n",
      " epoch: 16, train accuracy: 0.7948, train_loss_norm:0.0757, valid_acc: 0.7755, valid_loss_norm: 0.0759\n",
      " epoch: 17, train accuracy: 0.7948, train_loss_norm:0.0750, valid_acc: 0.7755, valid_loss_norm: 0.0752\n",
      " epoch: 18, train accuracy: 0.7949, train_loss_norm:0.0743, valid_acc: 0.7755, valid_loss_norm: 0.0746\n",
      " epoch: 19, train accuracy: 0.7950, train_loss_norm:0.0736, valid_acc: 0.7755, valid_loss_norm: 0.0739\n",
      " epoch: 20, train accuracy: 0.7950, train_loss_norm:0.0730, valid_acc: 0.7755, valid_loss_norm: 0.0733\n",
      " epoch: 21, train accuracy: 0.7952, train_loss_norm:0.0723, valid_acc: 0.7755, valid_loss_norm: 0.0726\n",
      " epoch: 22, train accuracy: 0.7954, train_loss_norm:0.0716, valid_acc: 0.7758, valid_loss_norm: 0.0720\n",
      " epoch: 23, train accuracy: 0.7954, train_loss_norm:0.0710, valid_acc: 0.7761, valid_loss_norm: 0.0714\n",
      " epoch: 24, train accuracy: 0.7955, train_loss_norm:0.0704, valid_acc: 0.7767, valid_loss_norm: 0.0707\n",
      " epoch: 25, train accuracy: 0.7957, train_loss_norm:0.0697, valid_acc: 0.7767, valid_loss_norm: 0.0701\n",
      " epoch: 26, train accuracy: 0.7960, train_loss_norm:0.0691, valid_acc: 0.7767, valid_loss_norm: 0.0695\n",
      " epoch: 27, train accuracy: 0.7961, train_loss_norm:0.0685, valid_acc: 0.7764, valid_loss_norm: 0.0689\n",
      " epoch: 28, train accuracy: 0.7961, train_loss_norm:0.0679, valid_acc: 0.7767, valid_loss_norm: 0.0684\n",
      " epoch: 29, train accuracy: 0.7962, train_loss_norm:0.0673, valid_acc: 0.7772, valid_loss_norm: 0.0678\n",
      " epoch: 30, train accuracy: 0.7963, train_loss_norm:0.0668, valid_acc: 0.7775, valid_loss_norm: 0.0672\n",
      " epoch: 31, train accuracy: 0.7965, train_loss_norm:0.0662, valid_acc: 0.7781, valid_loss_norm: 0.0667\n",
      " epoch: 32, train accuracy: 0.7968, train_loss_norm:0.0656, valid_acc: 0.7790, valid_loss_norm: 0.0661\n",
      " epoch: 33, train accuracy: 0.7969, train_loss_norm:0.0651, valid_acc: 0.7790, valid_loss_norm: 0.0656\n",
      " epoch: 34, train accuracy: 0.7969, train_loss_norm:0.0646, valid_acc: 0.7790, valid_loss_norm: 0.0651\n",
      " epoch: 35, train accuracy: 0.7972, train_loss_norm:0.0640, valid_acc: 0.7795, valid_loss_norm: 0.0646\n",
      " epoch: 36, train accuracy: 0.7974, train_loss_norm:0.0635, valid_acc: 0.7798, valid_loss_norm: 0.0640\n",
      " epoch: 37, train accuracy: 0.7974, train_loss_norm:0.0630, valid_acc: 0.7801, valid_loss_norm: 0.0636\n",
      " epoch: 38, train accuracy: 0.7976, train_loss_norm:0.0625, valid_acc: 0.7801, valid_loss_norm: 0.0631\n",
      " epoch: 39, train accuracy: 0.7980, train_loss_norm:0.0620, valid_acc: 0.7804, valid_loss_norm: 0.0626\n",
      " epoch: 40, train accuracy: 0.7980, train_loss_norm:0.0615, valid_acc: 0.7804, valid_loss_norm: 0.0621\n",
      " epoch: 41, train accuracy: 0.7981, train_loss_norm:0.0611, valid_acc: 0.7807, valid_loss_norm: 0.0617\n",
      " epoch: 42, train accuracy: 0.7985, train_loss_norm:0.0606, valid_acc: 0.7810, valid_loss_norm: 0.0612\n",
      " epoch: 43, train accuracy: 0.7989, train_loss_norm:0.0601, valid_acc: 0.7810, valid_loss_norm: 0.0608\n",
      " epoch: 44, train accuracy: 0.7989, train_loss_norm:0.0597, valid_acc: 0.7810, valid_loss_norm: 0.0603\n",
      " epoch: 45, train accuracy: 0.7992, train_loss_norm:0.0592, valid_acc: 0.7813, valid_loss_norm: 0.0599\n",
      " epoch: 46, train accuracy: 0.7994, train_loss_norm:0.0588, valid_acc: 0.7818, valid_loss_norm: 0.0595\n",
      " epoch: 47, train accuracy: 0.7996, train_loss_norm:0.0584, valid_acc: 0.7821, valid_loss_norm: 0.0591\n",
      " epoch: 48, train accuracy: 0.8000, train_loss_norm:0.0580, valid_acc: 0.7824, valid_loss_norm: 0.0587\n",
      " epoch: 49, train accuracy: 0.8005, train_loss_norm:0.0576, valid_acc: 0.7827, valid_loss_norm: 0.0583\n",
      " epoch: 50, train accuracy: 0.8008, train_loss_norm:0.0572, valid_acc: 0.7827, valid_loss_norm: 0.0579\n",
      " epoch: 51, train accuracy: 0.8009, train_loss_norm:0.0568, valid_acc: 0.7833, valid_loss_norm: 0.0575\n",
      " epoch: 52, train accuracy: 0.8014, train_loss_norm:0.0564, valid_acc: 0.7833, valid_loss_norm: 0.0571\n",
      " epoch: 53, train accuracy: 0.8015, train_loss_norm:0.0560, valid_acc: 0.7836, valid_loss_norm: 0.0568\n",
      " epoch: 54, train accuracy: 0.8019, train_loss_norm:0.0556, valid_acc: 0.7833, valid_loss_norm: 0.0564\n",
      " epoch: 55, train accuracy: 0.8021, train_loss_norm:0.0553, valid_acc: 0.7833, valid_loss_norm: 0.0561\n",
      " epoch: 56, train accuracy: 0.8025, train_loss_norm:0.0549, valid_acc: 0.7836, valid_loss_norm: 0.0557\n",
      " epoch: 57, train accuracy: 0.8029, train_loss_norm:0.0546, valid_acc: 0.7836, valid_loss_norm: 0.0554\n",
      " epoch: 58, train accuracy: 0.8033, train_loss_norm:0.0542, valid_acc: 0.7847, valid_loss_norm: 0.0550\n",
      " epoch: 59, train accuracy: 0.8035, train_loss_norm:0.0539, valid_acc: 0.7853, valid_loss_norm: 0.0547\n",
      " epoch: 60, train accuracy: 0.8038, train_loss_norm:0.0536, valid_acc: 0.7856, valid_loss_norm: 0.0544\n",
      " epoch: 61, train accuracy: 0.8042, train_loss_norm:0.0532, valid_acc: 0.7856, valid_loss_norm: 0.0541\n",
      " epoch: 62, train accuracy: 0.8045, train_loss_norm:0.0529, valid_acc: 0.7864, valid_loss_norm: 0.0538\n",
      " epoch: 63, train accuracy: 0.8047, train_loss_norm:0.0526, valid_acc: 0.7870, valid_loss_norm: 0.0534\n",
      " epoch: 64, train accuracy: 0.8048, train_loss_norm:0.0523, valid_acc: 0.7873, valid_loss_norm: 0.0531\n",
      " epoch: 65, train accuracy: 0.8051, train_loss_norm:0.0520, valid_acc: 0.7873, valid_loss_norm: 0.0529\n",
      " epoch: 66, train accuracy: 0.8056, train_loss_norm:0.0517, valid_acc: 0.7876, valid_loss_norm: 0.0526\n",
      " epoch: 67, train accuracy: 0.8061, train_loss_norm:0.0514, valid_acc: 0.7882, valid_loss_norm: 0.0523\n",
      " epoch: 68, train accuracy: 0.8065, train_loss_norm:0.0511, valid_acc: 0.7884, valid_loss_norm: 0.0520\n",
      " epoch: 69, train accuracy: 0.8069, train_loss_norm:0.0508, valid_acc: 0.7884, valid_loss_norm: 0.0517\n",
      " epoch: 70, train accuracy: 0.8073, train_loss_norm:0.0505, valid_acc: 0.7890, valid_loss_norm: 0.0514\n",
      " epoch: 71, train accuracy: 0.8075, train_loss_norm:0.0503, valid_acc: 0.7893, valid_loss_norm: 0.0512\n",
      " epoch: 72, train accuracy: 0.8077, train_loss_norm:0.0500, valid_acc: 0.7893, valid_loss_norm: 0.0509\n",
      " epoch: 73, train accuracy: 0.8080, train_loss_norm:0.0497, valid_acc: 0.7896, valid_loss_norm: 0.0507\n",
      " epoch: 74, train accuracy: 0.8082, train_loss_norm:0.0495, valid_acc: 0.7899, valid_loss_norm: 0.0504\n",
      " epoch: 75, train accuracy: 0.8085, train_loss_norm:0.0492, valid_acc: 0.7905, valid_loss_norm: 0.0502\n",
      " epoch: 76, train accuracy: 0.8091, train_loss_norm:0.0489, valid_acc: 0.7905, valid_loss_norm: 0.0499\n",
      " epoch: 77, train accuracy: 0.8096, train_loss_norm:0.0487, valid_acc: 0.7905, valid_loss_norm: 0.0497\n",
      " epoch: 78, train accuracy: 0.8101, train_loss_norm:0.0485, valid_acc: 0.7910, valid_loss_norm: 0.0494\n",
      " epoch: 79, train accuracy: 0.8102, train_loss_norm:0.0482, valid_acc: 0.7913, valid_loss_norm: 0.0492\n",
      " epoch: 80, train accuracy: 0.8107, train_loss_norm:0.0480, valid_acc: 0.7913, valid_loss_norm: 0.0490\n",
      " epoch: 81, train accuracy: 0.8112, train_loss_norm:0.0477, valid_acc: 0.7922, valid_loss_norm: 0.0487\n",
      " epoch: 82, train accuracy: 0.8115, train_loss_norm:0.0475, valid_acc: 0.7928, valid_loss_norm: 0.0485\n",
      " epoch: 83, train accuracy: 0.8116, train_loss_norm:0.0473, valid_acc: 0.7928, valid_loss_norm: 0.0483\n",
      " epoch: 84, train accuracy: 0.8120, train_loss_norm:0.0470, valid_acc: 0.7939, valid_loss_norm: 0.0481\n",
      " epoch: 85, train accuracy: 0.8122, train_loss_norm:0.0468, valid_acc: 0.7942, valid_loss_norm: 0.0478\n",
      " epoch: 86, train accuracy: 0.8125, train_loss_norm:0.0466, valid_acc: 0.7942, valid_loss_norm: 0.0476\n",
      " epoch: 87, train accuracy: 0.8128, train_loss_norm:0.0464, valid_acc: 0.7945, valid_loss_norm: 0.0474\n",
      " epoch: 88, train accuracy: 0.8132, train_loss_norm:0.0462, valid_acc: 0.7948, valid_loss_norm: 0.0472\n",
      " epoch: 89, train accuracy: 0.8135, train_loss_norm:0.0460, valid_acc: 0.7948, valid_loss_norm: 0.0470\n",
      " epoch: 90, train accuracy: 0.8140, train_loss_norm:0.0458, valid_acc: 0.7953, valid_loss_norm: 0.0468\n",
      " epoch: 91, train accuracy: 0.8144, train_loss_norm:0.0456, valid_acc: 0.7951, valid_loss_norm: 0.0466\n",
      " epoch: 92, train accuracy: 0.8149, train_loss_norm:0.0454, valid_acc: 0.7953, valid_loss_norm: 0.0464\n",
      " epoch: 93, train accuracy: 0.8152, train_loss_norm:0.0452, valid_acc: 0.7953, valid_loss_norm: 0.0462\n",
      " epoch: 94, train accuracy: 0.8156, train_loss_norm:0.0450, valid_acc: 0.7951, valid_loss_norm: 0.0460\n",
      " epoch: 95, train accuracy: 0.8160, train_loss_norm:0.0448, valid_acc: 0.7951, valid_loss_norm: 0.0458\n",
      " epoch: 96, train accuracy: 0.8162, train_loss_norm:0.0446, valid_acc: 0.7951, valid_loss_norm: 0.0457\n",
      " epoch: 97, train accuracy: 0.8166, train_loss_norm:0.0444, valid_acc: 0.7953, valid_loss_norm: 0.0455\n",
      " epoch: 98, train accuracy: 0.8168, train_loss_norm:0.0442, valid_acc: 0.7956, valid_loss_norm: 0.0453\n",
      " epoch: 99, train accuracy: 0.8172, train_loss_norm:0.0440, valid_acc: 0.7956, valid_loss_norm: 0.0451\n",
      " epoch: 100, train accuracy: 0.8175, train_loss_norm:0.0438, valid_acc: 0.7959, valid_loss_norm: 0.0449\n",
      " epoch: 101, train accuracy: 0.8176, train_loss_norm:0.0436, valid_acc: 0.7965, valid_loss_norm: 0.0448\n",
      " epoch: 102, train accuracy: 0.8181, train_loss_norm:0.0435, valid_acc: 0.7965, valid_loss_norm: 0.0446\n",
      " epoch: 103, train accuracy: 0.8182, train_loss_norm:0.0433, valid_acc: 0.7971, valid_loss_norm: 0.0444\n",
      " epoch: 104, train accuracy: 0.8184, train_loss_norm:0.0431, valid_acc: 0.7971, valid_loss_norm: 0.0443\n",
      " epoch: 105, train accuracy: 0.8188, train_loss_norm:0.0430, valid_acc: 0.7976, valid_loss_norm: 0.0441\n",
      " epoch: 106, train accuracy: 0.8190, train_loss_norm:0.0428, valid_acc: 0.7982, valid_loss_norm: 0.0439\n",
      " epoch: 107, train accuracy: 0.8191, train_loss_norm:0.0426, valid_acc: 0.7985, valid_loss_norm: 0.0438\n",
      " epoch: 108, train accuracy: 0.8195, train_loss_norm:0.0425, valid_acc: 0.7988, valid_loss_norm: 0.0436\n",
      " epoch: 109, train accuracy: 0.8198, train_loss_norm:0.0423, valid_acc: 0.7994, valid_loss_norm: 0.0435\n",
      " epoch: 110, train accuracy: 0.8202, train_loss_norm:0.0421, valid_acc: 0.7991, valid_loss_norm: 0.0433\n",
      " epoch: 111, train accuracy: 0.8204, train_loss_norm:0.0420, valid_acc: 0.7994, valid_loss_norm: 0.0431\n",
      " epoch: 112, train accuracy: 0.8206, train_loss_norm:0.0418, valid_acc: 0.7994, valid_loss_norm: 0.0430\n",
      " epoch: 113, train accuracy: 0.8211, train_loss_norm:0.0417, valid_acc: 0.7994, valid_loss_norm: 0.0428\n",
      " epoch: 114, train accuracy: 0.8213, train_loss_norm:0.0415, valid_acc: 0.7991, valid_loss_norm: 0.0427\n",
      " epoch: 115, train accuracy: 0.8213, train_loss_norm:0.0414, valid_acc: 0.7988, valid_loss_norm: 0.0425\n",
      " epoch: 116, train accuracy: 0.8217, train_loss_norm:0.0412, valid_acc: 0.7994, valid_loss_norm: 0.0424\n",
      " epoch: 117, train accuracy: 0.8220, train_loss_norm:0.0411, valid_acc: 0.7999, valid_loss_norm: 0.0423\n",
      " epoch: 118, train accuracy: 0.8223, train_loss_norm:0.0409, valid_acc: 0.7997, valid_loss_norm: 0.0421\n",
      " epoch: 119, train accuracy: 0.8224, train_loss_norm:0.0408, valid_acc: 0.7999, valid_loss_norm: 0.0420\n",
      " epoch: 120, train accuracy: 0.8227, train_loss_norm:0.0406, valid_acc: 0.7999, valid_loss_norm: 0.0418\n",
      " epoch: 121, train accuracy: 0.8229, train_loss_norm:0.0405, valid_acc: 0.7999, valid_loss_norm: 0.0417\n",
      " epoch: 122, train accuracy: 0.8232, train_loss_norm:0.0403, valid_acc: 0.8005, valid_loss_norm: 0.0416\n",
      " epoch: 123, train accuracy: 0.8234, train_loss_norm:0.0402, valid_acc: 0.8014, valid_loss_norm: 0.0414\n",
      " epoch: 124, train accuracy: 0.8234, train_loss_norm:0.0401, valid_acc: 0.8014, valid_loss_norm: 0.0413\n",
      " epoch: 125, train accuracy: 0.8235, train_loss_norm:0.0399, valid_acc: 0.8017, valid_loss_norm: 0.0412\n",
      " epoch: 126, train accuracy: 0.8237, train_loss_norm:0.0398, valid_acc: 0.8020, valid_loss_norm: 0.0410\n",
      " epoch: 127, train accuracy: 0.8241, train_loss_norm:0.0397, valid_acc: 0.8017, valid_loss_norm: 0.0409\n",
      " epoch: 128, train accuracy: 0.8244, train_loss_norm:0.0395, valid_acc: 0.8022, valid_loss_norm: 0.0408\n",
      " epoch: 129, train accuracy: 0.8246, train_loss_norm:0.0394, valid_acc: 0.8025, valid_loss_norm: 0.0407\n",
      " epoch: 130, train accuracy: 0.8248, train_loss_norm:0.0393, valid_acc: 0.8025, valid_loss_norm: 0.0405\n",
      " epoch: 131, train accuracy: 0.8250, train_loss_norm:0.0391, valid_acc: 0.8034, valid_loss_norm: 0.0404\n",
      " epoch: 132, train accuracy: 0.8251, train_loss_norm:0.0390, valid_acc: 0.8034, valid_loss_norm: 0.0403\n",
      " epoch: 133, train accuracy: 0.8253, train_loss_norm:0.0389, valid_acc: 0.8043, valid_loss_norm: 0.0402\n",
      " epoch: 134, train accuracy: 0.8255, train_loss_norm:0.0388, valid_acc: 0.8043, valid_loss_norm: 0.0400\n",
      " epoch: 135, train accuracy: 0.8256, train_loss_norm:0.0386, valid_acc: 0.8043, valid_loss_norm: 0.0399\n",
      " epoch: 136, train accuracy: 0.8258, train_loss_norm:0.0385, valid_acc: 0.8043, valid_loss_norm: 0.0398\n",
      " epoch: 137, train accuracy: 0.8260, train_loss_norm:0.0384, valid_acc: 0.8045, valid_loss_norm: 0.0397\n",
      " epoch: 138, train accuracy: 0.8263, train_loss_norm:0.0383, valid_acc: 0.8054, valid_loss_norm: 0.0396\n",
      " epoch: 139, train accuracy: 0.8264, train_loss_norm:0.0382, valid_acc: 0.8051, valid_loss_norm: 0.0395\n",
      " epoch: 140, train accuracy: 0.8267, train_loss_norm:0.0380, valid_acc: 0.8054, valid_loss_norm: 0.0393\n",
      " epoch: 141, train accuracy: 0.8268, train_loss_norm:0.0379, valid_acc: 0.8057, valid_loss_norm: 0.0392\n",
      " epoch: 142, train accuracy: 0.8269, train_loss_norm:0.0378, valid_acc: 0.8063, valid_loss_norm: 0.0391\n",
      " epoch: 143, train accuracy: 0.8271, train_loss_norm:0.0377, valid_acc: 0.8063, valid_loss_norm: 0.0390\n",
      " epoch: 144, train accuracy: 0.8273, train_loss_norm:0.0376, valid_acc: 0.8066, valid_loss_norm: 0.0389\n",
      " epoch: 145, train accuracy: 0.8276, train_loss_norm:0.0375, valid_acc: 0.8068, valid_loss_norm: 0.0388\n",
      " epoch: 146, train accuracy: 0.8277, train_loss_norm:0.0374, valid_acc: 0.8068, valid_loss_norm: 0.0387\n",
      " epoch: 147, train accuracy: 0.8281, train_loss_norm:0.0372, valid_acc: 0.8066, valid_loss_norm: 0.0386\n",
      " epoch: 148, train accuracy: 0.8282, train_loss_norm:0.0371, valid_acc: 0.8068, valid_loss_norm: 0.0385\n",
      " epoch: 149, train accuracy: 0.8285, train_loss_norm:0.0370, valid_acc: 0.8068, valid_loss_norm: 0.0384\n",
      " epoch: 150, train accuracy: 0.8287, train_loss_norm:0.0369, valid_acc: 0.8066, valid_loss_norm: 0.0383\n",
      " epoch: 151, train accuracy: 0.8289, train_loss_norm:0.0368, valid_acc: 0.8066, valid_loss_norm: 0.0382\n",
      " epoch: 152, train accuracy: 0.8291, train_loss_norm:0.0367, valid_acc: 0.8074, valid_loss_norm: 0.0381\n",
      " epoch: 153, train accuracy: 0.8292, train_loss_norm:0.0366, valid_acc: 0.8074, valid_loss_norm: 0.0380\n",
      " epoch: 154, train accuracy: 0.8293, train_loss_norm:0.0365, valid_acc: 0.8077, valid_loss_norm: 0.0379\n",
      " epoch: 155, train accuracy: 0.8297, train_loss_norm:0.0364, valid_acc: 0.8083, valid_loss_norm: 0.0378\n",
      " epoch: 156, train accuracy: 0.8296, train_loss_norm:0.0363, valid_acc: 0.8086, valid_loss_norm: 0.0377\n",
      " epoch: 157, train accuracy: 0.8300, train_loss_norm:0.0362, valid_acc: 0.8086, valid_loss_norm: 0.0376\n",
      " epoch: 158, train accuracy: 0.8299, train_loss_norm:0.0361, valid_acc: 0.8083, valid_loss_norm: 0.0375\n",
      " epoch: 159, train accuracy: 0.8301, train_loss_norm:0.0360, valid_acc: 0.8083, valid_loss_norm: 0.0374\n",
      " epoch: 160, train accuracy: 0.8303, train_loss_norm:0.0359, valid_acc: 0.8083, valid_loss_norm: 0.0373\n",
      " epoch: 161, train accuracy: 0.8303, train_loss_norm:0.0358, valid_acc: 0.8086, valid_loss_norm: 0.0372\n",
      " epoch: 162, train accuracy: 0.8306, train_loss_norm:0.0357, valid_acc: 0.8091, valid_loss_norm: 0.0371\n",
      " epoch: 163, train accuracy: 0.8306, train_loss_norm:0.0356, valid_acc: 0.8091, valid_loss_norm: 0.0370\n",
      " epoch: 164, train accuracy: 0.8309, train_loss_norm:0.0355, valid_acc: 0.8097, valid_loss_norm: 0.0369\n",
      " epoch: 165, train accuracy: 0.8312, train_loss_norm:0.0354, valid_acc: 0.8097, valid_loss_norm: 0.0368\n",
      " epoch: 166, train accuracy: 0.8313, train_loss_norm:0.0353, valid_acc: 0.8097, valid_loss_norm: 0.0367\n",
      " epoch: 167, train accuracy: 0.8316, train_loss_norm:0.0352, valid_acc: 0.8097, valid_loss_norm: 0.0366\n",
      " epoch: 168, train accuracy: 0.8317, train_loss_norm:0.0351, valid_acc: 0.8097, valid_loss_norm: 0.0366\n",
      " epoch: 169, train accuracy: 0.8320, train_loss_norm:0.0351, valid_acc: 0.8097, valid_loss_norm: 0.0365\n",
      " epoch: 170, train accuracy: 0.8322, train_loss_norm:0.0350, valid_acc: 0.8103, valid_loss_norm: 0.0364\n",
      " epoch: 171, train accuracy: 0.8324, train_loss_norm:0.0349, valid_acc: 0.8112, valid_loss_norm: 0.0363\n",
      " epoch: 172, train accuracy: 0.8327, train_loss_norm:0.0348, valid_acc: 0.8112, valid_loss_norm: 0.0362\n",
      " epoch: 173, train accuracy: 0.8329, train_loss_norm:0.0347, valid_acc: 0.8114, valid_loss_norm: 0.0361\n",
      " epoch: 174, train accuracy: 0.8331, train_loss_norm:0.0346, valid_acc: 0.8117, valid_loss_norm: 0.0360\n",
      " epoch: 175, train accuracy: 0.8333, train_loss_norm:0.0345, valid_acc: 0.8120, valid_loss_norm: 0.0360\n",
      " epoch: 176, train accuracy: 0.8334, train_loss_norm:0.0344, valid_acc: 0.8123, valid_loss_norm: 0.0359\n",
      " epoch: 177, train accuracy: 0.8336, train_loss_norm:0.0344, valid_acc: 0.8120, valid_loss_norm: 0.0358\n",
      " epoch: 178, train accuracy: 0.8337, train_loss_norm:0.0343, valid_acc: 0.8120, valid_loss_norm: 0.0357\n",
      " epoch: 179, train accuracy: 0.8339, train_loss_norm:0.0342, valid_acc: 0.8120, valid_loss_norm: 0.0356\n",
      " epoch: 180, train accuracy: 0.8342, train_loss_norm:0.0341, valid_acc: 0.8123, valid_loss_norm: 0.0355\n",
      " epoch: 181, train accuracy: 0.8343, train_loss_norm:0.0340, valid_acc: 0.8126, valid_loss_norm: 0.0355\n",
      " epoch: 182, train accuracy: 0.8344, train_loss_norm:0.0339, valid_acc: 0.8129, valid_loss_norm: 0.0354\n",
      " epoch: 183, train accuracy: 0.8344, train_loss_norm:0.0339, valid_acc: 0.8132, valid_loss_norm: 0.0353\n",
      " epoch: 184, train accuracy: 0.8346, train_loss_norm:0.0338, valid_acc: 0.8135, valid_loss_norm: 0.0352\n",
      " epoch: 185, train accuracy: 0.8347, train_loss_norm:0.0337, valid_acc: 0.8140, valid_loss_norm: 0.0351\n",
      " epoch: 186, train accuracy: 0.8350, train_loss_norm:0.0336, valid_acc: 0.8143, valid_loss_norm: 0.0351\n",
      " epoch: 187, train accuracy: 0.8352, train_loss_norm:0.0335, valid_acc: 0.8140, valid_loss_norm: 0.0350\n",
      " epoch: 188, train accuracy: 0.8352, train_loss_norm:0.0335, valid_acc: 0.8135, valid_loss_norm: 0.0349\n",
      " epoch: 189, train accuracy: 0.8354, train_loss_norm:0.0334, valid_acc: 0.8129, valid_loss_norm: 0.0348\n",
      " epoch: 190, train accuracy: 0.8356, train_loss_norm:0.0333, valid_acc: 0.8129, valid_loss_norm: 0.0348\n",
      " epoch: 191, train accuracy: 0.8359, train_loss_norm:0.0332, valid_acc: 0.8126, valid_loss_norm: 0.0347\n",
      " epoch: 192, train accuracy: 0.8360, train_loss_norm:0.0331, valid_acc: 0.8126, valid_loss_norm: 0.0346\n",
      " epoch: 193, train accuracy: 0.8360, train_loss_norm:0.0331, valid_acc: 0.8126, valid_loss_norm: 0.0345\n",
      " epoch: 194, train accuracy: 0.8363, train_loss_norm:0.0330, valid_acc: 0.8126, valid_loss_norm: 0.0345\n",
      " epoch: 195, train accuracy: 0.8365, train_loss_norm:0.0329, valid_acc: 0.8126, valid_loss_norm: 0.0344\n",
      " epoch: 196, train accuracy: 0.8368, train_loss_norm:0.0328, valid_acc: 0.8129, valid_loss_norm: 0.0343\n",
      " epoch: 197, train accuracy: 0.8370, train_loss_norm:0.0328, valid_acc: 0.8129, valid_loss_norm: 0.0343\n",
      " epoch: 198, train accuracy: 0.8372, train_loss_norm:0.0327, valid_acc: 0.8129, valid_loss_norm: 0.0342\n",
      " epoch: 199, train accuracy: 0.8373, train_loss_norm:0.0326, valid_acc: 0.8132, valid_loss_norm: 0.0341\n",
      " epoch: 200, train accuracy: 0.8374, train_loss_norm:0.0326, valid_acc: 0.8135, valid_loss_norm: 0.0341\n",
      " epoch: 201, train accuracy: 0.8377, train_loss_norm:0.0325, valid_acc: 0.8135, valid_loss_norm: 0.0340\n",
      " epoch: 202, train accuracy: 0.8378, train_loss_norm:0.0324, valid_acc: 0.8143, valid_loss_norm: 0.0339\n",
      " epoch: 203, train accuracy: 0.8379, train_loss_norm:0.0323, valid_acc: 0.8143, valid_loss_norm: 0.0338\n",
      " epoch: 204, train accuracy: 0.8381, train_loss_norm:0.0323, valid_acc: 0.8146, valid_loss_norm: 0.0338\n",
      " epoch: 205, train accuracy: 0.8382, train_loss_norm:0.0322, valid_acc: 0.8152, valid_loss_norm: 0.0337\n",
      " epoch: 206, train accuracy: 0.8383, train_loss_norm:0.0321, valid_acc: 0.8158, valid_loss_norm: 0.0336\n",
      " epoch: 207, train accuracy: 0.8384, train_loss_norm:0.0321, valid_acc: 0.8160, valid_loss_norm: 0.0336\n",
      " epoch: 208, train accuracy: 0.8387, train_loss_norm:0.0320, valid_acc: 0.8160, valid_loss_norm: 0.0335\n",
      " epoch: 209, train accuracy: 0.8388, train_loss_norm:0.0319, valid_acc: 0.8160, valid_loss_norm: 0.0334\n",
      " epoch: 210, train accuracy: 0.8388, train_loss_norm:0.0319, valid_acc: 0.8160, valid_loss_norm: 0.0334\n",
      " epoch: 211, train accuracy: 0.8388, train_loss_norm:0.0318, valid_acc: 0.8166, valid_loss_norm: 0.0333\n",
      " epoch: 212, train accuracy: 0.8389, train_loss_norm:0.0317, valid_acc: 0.8166, valid_loss_norm: 0.0333\n",
      " epoch: 213, train accuracy: 0.8390, train_loss_norm:0.0317, valid_acc: 0.8169, valid_loss_norm: 0.0332\n",
      " epoch: 214, train accuracy: 0.8391, train_loss_norm:0.0316, valid_acc: 0.8175, valid_loss_norm: 0.0331\n",
      " epoch: 215, train accuracy: 0.8392, train_loss_norm:0.0315, valid_acc: 0.8178, valid_loss_norm: 0.0331\n",
      " epoch: 216, train accuracy: 0.8394, train_loss_norm:0.0315, valid_acc: 0.8178, valid_loss_norm: 0.0330\n",
      " epoch: 217, train accuracy: 0.8396, train_loss_norm:0.0314, valid_acc: 0.8175, valid_loss_norm: 0.0329\n",
      " epoch: 218, train accuracy: 0.8397, train_loss_norm:0.0313, valid_acc: 0.8178, valid_loss_norm: 0.0329\n",
      " epoch: 219, train accuracy: 0.8398, train_loss_norm:0.0313, valid_acc: 0.8178, valid_loss_norm: 0.0328\n",
      " epoch: 220, train accuracy: 0.8399, train_loss_norm:0.0312, valid_acc: 0.8181, valid_loss_norm: 0.0328\n",
      " epoch: 221, train accuracy: 0.8399, train_loss_norm:0.0311, valid_acc: 0.8181, valid_loss_norm: 0.0327\n",
      " epoch: 222, train accuracy: 0.8399, train_loss_norm:0.0311, valid_acc: 0.8183, valid_loss_norm: 0.0326\n",
      " epoch: 223, train accuracy: 0.8399, train_loss_norm:0.0310, valid_acc: 0.8183, valid_loss_norm: 0.0326\n",
      " epoch: 224, train accuracy: 0.8401, train_loss_norm:0.0310, valid_acc: 0.8186, valid_loss_norm: 0.0325\n",
      " epoch: 225, train accuracy: 0.8402, train_loss_norm:0.0309, valid_acc: 0.8186, valid_loss_norm: 0.0325\n",
      " epoch: 226, train accuracy: 0.8404, train_loss_norm:0.0308, valid_acc: 0.8189, valid_loss_norm: 0.0324\n",
      " epoch: 227, train accuracy: 0.8406, train_loss_norm:0.0308, valid_acc: 0.8189, valid_loss_norm: 0.0323\n",
      " epoch: 228, train accuracy: 0.8406, train_loss_norm:0.0307, valid_acc: 0.8189, valid_loss_norm: 0.0323\n",
      " epoch: 229, train accuracy: 0.8409, train_loss_norm:0.0307, valid_acc: 0.8189, valid_loss_norm: 0.0322\n",
      " epoch: 230, train accuracy: 0.8409, train_loss_norm:0.0306, valid_acc: 0.8186, valid_loss_norm: 0.0322\n",
      " epoch: 231, train accuracy: 0.8409, train_loss_norm:0.0305, valid_acc: 0.8189, valid_loss_norm: 0.0321\n",
      " epoch: 232, train accuracy: 0.8410, train_loss_norm:0.0305, valid_acc: 0.8192, valid_loss_norm: 0.0321\n",
      " epoch: 233, train accuracy: 0.8411, train_loss_norm:0.0304, valid_acc: 0.8195, valid_loss_norm: 0.0320\n",
      " epoch: 234, train accuracy: 0.8412, train_loss_norm:0.0304, valid_acc: 0.8195, valid_loss_norm: 0.0319\n",
      " epoch: 235, train accuracy: 0.8414, train_loss_norm:0.0303, valid_acc: 0.8198, valid_loss_norm: 0.0319\n",
      " epoch: 236, train accuracy: 0.8415, train_loss_norm:0.0303, valid_acc: 0.8198, valid_loss_norm: 0.0318\n",
      " epoch: 237, train accuracy: 0.8415, train_loss_norm:0.0302, valid_acc: 0.8195, valid_loss_norm: 0.0318\n",
      " epoch: 238, train accuracy: 0.8416, train_loss_norm:0.0301, valid_acc: 0.8192, valid_loss_norm: 0.0317\n",
      " epoch: 239, train accuracy: 0.8417, train_loss_norm:0.0301, valid_acc: 0.8195, valid_loss_norm: 0.0317\n",
      " epoch: 240, train accuracy: 0.8418, train_loss_norm:0.0300, valid_acc: 0.8195, valid_loss_norm: 0.0316\n",
      " epoch: 241, train accuracy: 0.8420, train_loss_norm:0.0300, valid_acc: 0.8195, valid_loss_norm: 0.0316\n",
      " epoch: 242, train accuracy: 0.8421, train_loss_norm:0.0299, valid_acc: 0.8201, valid_loss_norm: 0.0315\n",
      " epoch: 243, train accuracy: 0.8422, train_loss_norm:0.0299, valid_acc: 0.8204, valid_loss_norm: 0.0315\n",
      " epoch: 244, train accuracy: 0.8424, train_loss_norm:0.0298, valid_acc: 0.8204, valid_loss_norm: 0.0314\n",
      " epoch: 245, train accuracy: 0.8425, train_loss_norm:0.0298, valid_acc: 0.8204, valid_loss_norm: 0.0314\n",
      " epoch: 246, train accuracy: 0.8425, train_loss_norm:0.0297, valid_acc: 0.8204, valid_loss_norm: 0.0313\n",
      " epoch: 247, train accuracy: 0.8426, train_loss_norm:0.0296, valid_acc: 0.8206, valid_loss_norm: 0.0313\n",
      " epoch: 248, train accuracy: 0.8426, train_loss_norm:0.0296, valid_acc: 0.8206, valid_loss_norm: 0.0312\n",
      " epoch: 249, train accuracy: 0.8427, train_loss_norm:0.0295, valid_acc: 0.8209, valid_loss_norm: 0.0312\n",
      " epoch: 250, train accuracy: 0.8428, train_loss_norm:0.0295, valid_acc: 0.8209, valid_loss_norm: 0.0311\n",
      " epoch: 251, train accuracy: 0.8428, train_loss_norm:0.0294, valid_acc: 0.8209, valid_loss_norm: 0.0311\n",
      " epoch: 252, train accuracy: 0.8429, train_loss_norm:0.0294, valid_acc: 0.8209, valid_loss_norm: 0.0310\n",
      " epoch: 253, train accuracy: 0.8430, train_loss_norm:0.0293, valid_acc: 0.8212, valid_loss_norm: 0.0310\n",
      " epoch: 254, train accuracy: 0.8431, train_loss_norm:0.0293, valid_acc: 0.8215, valid_loss_norm: 0.0309\n",
      " epoch: 255, train accuracy: 0.8432, train_loss_norm:0.0292, valid_acc: 0.8218, valid_loss_norm: 0.0309\n",
      " epoch: 256, train accuracy: 0.8433, train_loss_norm:0.0292, valid_acc: 0.8218, valid_loss_norm: 0.0308\n",
      " epoch: 257, train accuracy: 0.8434, train_loss_norm:0.0291, valid_acc: 0.8224, valid_loss_norm: 0.0308\n",
      " epoch: 258, train accuracy: 0.8434, train_loss_norm:0.0291, valid_acc: 0.8221, valid_loss_norm: 0.0307\n",
      " epoch: 259, train accuracy: 0.8434, train_loss_norm:0.0290, valid_acc: 0.8221, valid_loss_norm: 0.0307\n",
      " epoch: 260, train accuracy: 0.8434, train_loss_norm:0.0290, valid_acc: 0.8218, valid_loss_norm: 0.0306\n",
      " epoch: 261, train accuracy: 0.8435, train_loss_norm:0.0289, valid_acc: 0.8221, valid_loss_norm: 0.0306\n",
      " epoch: 262, train accuracy: 0.8436, train_loss_norm:0.0289, valid_acc: 0.8221, valid_loss_norm: 0.0305\n",
      " epoch: 263, train accuracy: 0.8437, train_loss_norm:0.0288, valid_acc: 0.8221, valid_loss_norm: 0.0305\n",
      " epoch: 264, train accuracy: 0.8439, train_loss_norm:0.0288, valid_acc: 0.8224, valid_loss_norm: 0.0304\n",
      " epoch: 265, train accuracy: 0.8440, train_loss_norm:0.0287, valid_acc: 0.8224, valid_loss_norm: 0.0304\n",
      " epoch: 266, train accuracy: 0.8440, train_loss_norm:0.0287, valid_acc: 0.8227, valid_loss_norm: 0.0303\n",
      " epoch: 267, train accuracy: 0.8440, train_loss_norm:0.0286, valid_acc: 0.8227, valid_loss_norm: 0.0303\n",
      " epoch: 268, train accuracy: 0.8443, train_loss_norm:0.0286, valid_acc: 0.8229, valid_loss_norm: 0.0302\n",
      " epoch: 269, train accuracy: 0.8445, train_loss_norm:0.0285, valid_acc: 0.8232, valid_loss_norm: 0.0302\n",
      " epoch: 270, train accuracy: 0.8446, train_loss_norm:0.0285, valid_acc: 0.8232, valid_loss_norm: 0.0302\n",
      " epoch: 271, train accuracy: 0.8448, train_loss_norm:0.0284, valid_acc: 0.8232, valid_loss_norm: 0.0301\n",
      " epoch: 272, train accuracy: 0.8448, train_loss_norm:0.0284, valid_acc: 0.8238, valid_loss_norm: 0.0301\n",
      " epoch: 273, train accuracy: 0.8449, train_loss_norm:0.0284, valid_acc: 0.8238, valid_loss_norm: 0.0300\n",
      " epoch: 274, train accuracy: 0.8452, train_loss_norm:0.0283, valid_acc: 0.8241, valid_loss_norm: 0.0300\n",
      " epoch: 275, train accuracy: 0.8453, train_loss_norm:0.0283, valid_acc: 0.8241, valid_loss_norm: 0.0299\n",
      " epoch: 276, train accuracy: 0.8454, train_loss_norm:0.0282, valid_acc: 0.8241, valid_loss_norm: 0.0299\n",
      " epoch: 277, train accuracy: 0.8453, train_loss_norm:0.0282, valid_acc: 0.8241, valid_loss_norm: 0.0298\n",
      " epoch: 278, train accuracy: 0.8453, train_loss_norm:0.0281, valid_acc: 0.8238, valid_loss_norm: 0.0298\n",
      " epoch: 279, train accuracy: 0.8453, train_loss_norm:0.0281, valid_acc: 0.8238, valid_loss_norm: 0.0298\n",
      " epoch: 280, train accuracy: 0.8453, train_loss_norm:0.0280, valid_acc: 0.8235, valid_loss_norm: 0.0297\n",
      " epoch: 281, train accuracy: 0.8455, train_loss_norm:0.0280, valid_acc: 0.8235, valid_loss_norm: 0.0297\n",
      " epoch: 282, train accuracy: 0.8456, train_loss_norm:0.0279, valid_acc: 0.8238, valid_loss_norm: 0.0296\n",
      " epoch: 283, train accuracy: 0.8457, train_loss_norm:0.0279, valid_acc: 0.8235, valid_loss_norm: 0.0296\n",
      " epoch: 284, train accuracy: 0.8457, train_loss_norm:0.0279, valid_acc: 0.8238, valid_loss_norm: 0.0295\n",
      " epoch: 285, train accuracy: 0.8458, train_loss_norm:0.0278, valid_acc: 0.8238, valid_loss_norm: 0.0295\n",
      " epoch: 286, train accuracy: 0.8458, train_loss_norm:0.0278, valid_acc: 0.8241, valid_loss_norm: 0.0295\n",
      " epoch: 287, train accuracy: 0.8461, train_loss_norm:0.0277, valid_acc: 0.8241, valid_loss_norm: 0.0294\n",
      " epoch: 288, train accuracy: 0.8462, train_loss_norm:0.0277, valid_acc: 0.8241, valid_loss_norm: 0.0294\n",
      " epoch: 289, train accuracy: 0.8463, train_loss_norm:0.0276, valid_acc: 0.8241, valid_loss_norm: 0.0293\n",
      " epoch: 290, train accuracy: 0.8463, train_loss_norm:0.0276, valid_acc: 0.8241, valid_loss_norm: 0.0293\n",
      " epoch: 291, train accuracy: 0.8463, train_loss_norm:0.0276, valid_acc: 0.8244, valid_loss_norm: 0.0293\n",
      " epoch: 292, train accuracy: 0.8463, train_loss_norm:0.0275, valid_acc: 0.8247, valid_loss_norm: 0.0292\n",
      " epoch: 293, train accuracy: 0.8465, train_loss_norm:0.0275, valid_acc: 0.8252, valid_loss_norm: 0.0292\n",
      " epoch: 294, train accuracy: 0.8467, train_loss_norm:0.0274, valid_acc: 0.8252, valid_loss_norm: 0.0291\n",
      " epoch: 295, train accuracy: 0.8467, train_loss_norm:0.0274, valid_acc: 0.8255, valid_loss_norm: 0.0291\n",
      " epoch: 296, train accuracy: 0.8468, train_loss_norm:0.0273, valid_acc: 0.8258, valid_loss_norm: 0.0291\n",
      " epoch: 297, train accuracy: 0.8470, train_loss_norm:0.0273, valid_acc: 0.8258, valid_loss_norm: 0.0290\n",
      " epoch: 298, train accuracy: 0.8470, train_loss_norm:0.0273, valid_acc: 0.8258, valid_loss_norm: 0.0290\n",
      " epoch: 299, train accuracy: 0.8471, train_loss_norm:0.0272, valid_acc: 0.8258, valid_loss_norm: 0.0289\n",
      " epoch: 300, train accuracy: 0.8472, train_loss_norm:0.0272, valid_acc: 0.8261, valid_loss_norm: 0.0289\n",
      "Test accuracy: 0.8356\n",
      "Test loss norm: 0.0283\n",
      "Cur fold: 5\n",
      "(27841, 300)\n",
      "(3479, 300)\n",
      "(3479, 300)\n",
      " epoch: 1, train accuracy: 0.7915, train_loss_norm:0.0867, valid_acc: 0.7873, valid_loss_norm: 0.0867\n",
      " epoch: 2, train accuracy: 0.7915, train_loss_norm:0.0859, valid_acc: 0.7873, valid_loss_norm: 0.0859\n",
      " epoch: 3, train accuracy: 0.7915, train_loss_norm:0.0852, valid_acc: 0.7873, valid_loss_norm: 0.0852\n",
      " epoch: 4, train accuracy: 0.7915, train_loss_norm:0.0844, valid_acc: 0.7873, valid_loss_norm: 0.0844\n",
      " epoch: 5, train accuracy: 0.7915, train_loss_norm:0.0837, valid_acc: 0.7873, valid_loss_norm: 0.0837\n",
      " epoch: 6, train accuracy: 0.7915, train_loss_norm:0.0829, valid_acc: 0.7873, valid_loss_norm: 0.0829\n",
      " epoch: 7, train accuracy: 0.7915, train_loss_norm:0.0822, valid_acc: 0.7873, valid_loss_norm: 0.0822\n",
      " epoch: 8, train accuracy: 0.7915, train_loss_norm:0.0814, valid_acc: 0.7873, valid_loss_norm: 0.0815\n",
      " epoch: 9, train accuracy: 0.7915, train_loss_norm:0.0807, valid_acc: 0.7876, valid_loss_norm: 0.0807\n",
      " epoch: 10, train accuracy: 0.7915, train_loss_norm:0.0800, valid_acc: 0.7876, valid_loss_norm: 0.0800\n",
      " epoch: 11, train accuracy: 0.7915, train_loss_norm:0.0792, valid_acc: 0.7876, valid_loss_norm: 0.0793\n",
      " epoch: 12, train accuracy: 0.7915, train_loss_norm:0.0785, valid_acc: 0.7876, valid_loss_norm: 0.0786\n",
      " epoch: 13, train accuracy: 0.7917, train_loss_norm:0.0778, valid_acc: 0.7876, valid_loss_norm: 0.0779\n",
      " epoch: 14, train accuracy: 0.7917, train_loss_norm:0.0771, valid_acc: 0.7876, valid_loss_norm: 0.0772\n",
      " epoch: 15, train accuracy: 0.7918, train_loss_norm:0.0764, valid_acc: 0.7879, valid_loss_norm: 0.0765\n",
      " epoch: 16, train accuracy: 0.7919, train_loss_norm:0.0757, valid_acc: 0.7882, valid_loss_norm: 0.0758\n",
      " epoch: 17, train accuracy: 0.7919, train_loss_norm:0.0750, valid_acc: 0.7882, valid_loss_norm: 0.0751\n",
      " epoch: 18, train accuracy: 0.7920, train_loss_norm:0.0743, valid_acc: 0.7882, valid_loss_norm: 0.0745\n",
      " epoch: 19, train accuracy: 0.7921, train_loss_norm:0.0737, valid_acc: 0.7879, valid_loss_norm: 0.0738\n",
      " epoch: 20, train accuracy: 0.7925, train_loss_norm:0.0730, valid_acc: 0.7879, valid_loss_norm: 0.0731\n",
      " epoch: 21, train accuracy: 0.7926, train_loss_norm:0.0724, valid_acc: 0.7882, valid_loss_norm: 0.0725\n",
      " epoch: 22, train accuracy: 0.7926, train_loss_norm:0.0717, valid_acc: 0.7884, valid_loss_norm: 0.0718\n",
      " epoch: 23, train accuracy: 0.7928, train_loss_norm:0.0711, valid_acc: 0.7887, valid_loss_norm: 0.0712\n",
      " epoch: 24, train accuracy: 0.7929, train_loss_norm:0.0704, valid_acc: 0.7884, valid_loss_norm: 0.0706\n",
      " epoch: 25, train accuracy: 0.7929, train_loss_norm:0.0698, valid_acc: 0.7882, valid_loss_norm: 0.0700\n",
      " epoch: 26, train accuracy: 0.7931, train_loss_norm:0.0692, valid_acc: 0.7887, valid_loss_norm: 0.0694\n",
      " epoch: 27, train accuracy: 0.7931, train_loss_norm:0.0686, valid_acc: 0.7890, valid_loss_norm: 0.0688\n",
      " epoch: 28, train accuracy: 0.7931, train_loss_norm:0.0680, valid_acc: 0.7887, valid_loss_norm: 0.0682\n",
      " epoch: 29, train accuracy: 0.7932, train_loss_norm:0.0674, valid_acc: 0.7887, valid_loss_norm: 0.0676\n",
      " epoch: 30, train accuracy: 0.7932, train_loss_norm:0.0668, valid_acc: 0.7890, valid_loss_norm: 0.0670\n",
      " epoch: 31, train accuracy: 0.7934, train_loss_norm:0.0663, valid_acc: 0.7890, valid_loss_norm: 0.0665\n",
      " epoch: 32, train accuracy: 0.7935, train_loss_norm:0.0657, valid_acc: 0.7890, valid_loss_norm: 0.0659\n",
      " epoch: 33, train accuracy: 0.7935, train_loss_norm:0.0652, valid_acc: 0.7890, valid_loss_norm: 0.0654\n",
      " epoch: 34, train accuracy: 0.7938, train_loss_norm:0.0646, valid_acc: 0.7893, valid_loss_norm: 0.0648\n",
      " epoch: 35, train accuracy: 0.7942, train_loss_norm:0.0641, valid_acc: 0.7893, valid_loss_norm: 0.0643\n",
      " epoch: 36, train accuracy: 0.7942, train_loss_norm:0.0636, valid_acc: 0.7896, valid_loss_norm: 0.0638\n",
      " epoch: 37, train accuracy: 0.7945, train_loss_norm:0.0631, valid_acc: 0.7905, valid_loss_norm: 0.0633\n",
      " epoch: 38, train accuracy: 0.7949, train_loss_norm:0.0626, valid_acc: 0.7905, valid_loss_norm: 0.0628\n",
      " epoch: 39, train accuracy: 0.7952, train_loss_norm:0.0621, valid_acc: 0.7905, valid_loss_norm: 0.0623\n",
      " epoch: 40, train accuracy: 0.7954, train_loss_norm:0.0616, valid_acc: 0.7910, valid_loss_norm: 0.0619\n",
      " epoch: 41, train accuracy: 0.7956, train_loss_norm:0.0611, valid_acc: 0.7916, valid_loss_norm: 0.0614\n",
      " epoch: 42, train accuracy: 0.7961, train_loss_norm:0.0607, valid_acc: 0.7922, valid_loss_norm: 0.0609\n",
      " epoch: 43, train accuracy: 0.7964, train_loss_norm:0.0602, valid_acc: 0.7925, valid_loss_norm: 0.0605\n",
      " epoch: 44, train accuracy: 0.7968, train_loss_norm:0.0598, valid_acc: 0.7925, valid_loss_norm: 0.0600\n",
      " epoch: 45, train accuracy: 0.7972, train_loss_norm:0.0593, valid_acc: 0.7930, valid_loss_norm: 0.0596\n",
      " epoch: 46, train accuracy: 0.7977, train_loss_norm:0.0589, valid_acc: 0.7936, valid_loss_norm: 0.0592\n",
      " epoch: 47, train accuracy: 0.7981, train_loss_norm:0.0585, valid_acc: 0.7942, valid_loss_norm: 0.0588\n",
      " epoch: 48, train accuracy: 0.7983, train_loss_norm:0.0581, valid_acc: 0.7945, valid_loss_norm: 0.0584\n",
      " epoch: 49, train accuracy: 0.7985, train_loss_norm:0.0577, valid_acc: 0.7948, valid_loss_norm: 0.0580\n",
      " epoch: 50, train accuracy: 0.7987, train_loss_norm:0.0573, valid_acc: 0.7948, valid_loss_norm: 0.0576\n",
      " epoch: 51, train accuracy: 0.7991, train_loss_norm:0.0569, valid_acc: 0.7948, valid_loss_norm: 0.0572\n",
      " epoch: 52, train accuracy: 0.7994, train_loss_norm:0.0565, valid_acc: 0.7951, valid_loss_norm: 0.0568\n",
      " epoch: 53, train accuracy: 0.7999, train_loss_norm:0.0561, valid_acc: 0.7951, valid_loss_norm: 0.0564\n",
      " epoch: 54, train accuracy: 0.8000, train_loss_norm:0.0558, valid_acc: 0.7953, valid_loss_norm: 0.0561\n",
      " epoch: 55, train accuracy: 0.8003, train_loss_norm:0.0554, valid_acc: 0.7959, valid_loss_norm: 0.0557\n",
      " epoch: 56, train accuracy: 0.8005, train_loss_norm:0.0550, valid_acc: 0.7959, valid_loss_norm: 0.0554\n",
      " epoch: 57, train accuracy: 0.8009, train_loss_norm:0.0547, valid_acc: 0.7959, valid_loss_norm: 0.0550\n",
      " epoch: 58, train accuracy: 0.8013, train_loss_norm:0.0543, valid_acc: 0.7965, valid_loss_norm: 0.0547\n",
      " epoch: 59, train accuracy: 0.8016, train_loss_norm:0.0540, valid_acc: 0.7965, valid_loss_norm: 0.0543\n",
      " epoch: 60, train accuracy: 0.8020, train_loss_norm:0.0537, valid_acc: 0.7976, valid_loss_norm: 0.0540\n",
      " epoch: 61, train accuracy: 0.8024, train_loss_norm:0.0533, valid_acc: 0.7985, valid_loss_norm: 0.0537\n",
      " epoch: 62, train accuracy: 0.8028, train_loss_norm:0.0530, valid_acc: 0.7991, valid_loss_norm: 0.0534\n",
      " epoch: 63, train accuracy: 0.8032, train_loss_norm:0.0527, valid_acc: 0.7991, valid_loss_norm: 0.0531\n",
      " epoch: 64, train accuracy: 0.8035, train_loss_norm:0.0524, valid_acc: 0.7994, valid_loss_norm: 0.0528\n",
      " epoch: 65, train accuracy: 0.8038, train_loss_norm:0.0521, valid_acc: 0.7999, valid_loss_norm: 0.0525\n",
      " epoch: 66, train accuracy: 0.8042, train_loss_norm:0.0518, valid_acc: 0.7999, valid_loss_norm: 0.0522\n",
      " epoch: 67, train accuracy: 0.8044, train_loss_norm:0.0515, valid_acc: 0.7999, valid_loss_norm: 0.0519\n",
      " epoch: 68, train accuracy: 0.8048, train_loss_norm:0.0512, valid_acc: 0.7997, valid_loss_norm: 0.0516\n",
      " epoch: 69, train accuracy: 0.8053, train_loss_norm:0.0509, valid_acc: 0.7999, valid_loss_norm: 0.0513\n",
      " epoch: 70, train accuracy: 0.8056, train_loss_norm:0.0507, valid_acc: 0.8002, valid_loss_norm: 0.0510\n",
      " epoch: 71, train accuracy: 0.8059, train_loss_norm:0.0504, valid_acc: 0.8002, valid_loss_norm: 0.0508\n",
      " epoch: 72, train accuracy: 0.8063, train_loss_norm:0.0501, valid_acc: 0.8005, valid_loss_norm: 0.0505\n",
      " epoch: 73, train accuracy: 0.8065, train_loss_norm:0.0498, valid_acc: 0.8002, valid_loss_norm: 0.0502\n",
      " epoch: 74, train accuracy: 0.8069, train_loss_norm:0.0496, valid_acc: 0.8002, valid_loss_norm: 0.0500\n",
      " epoch: 75, train accuracy: 0.8069, train_loss_norm:0.0493, valid_acc: 0.8008, valid_loss_norm: 0.0497\n",
      " epoch: 76, train accuracy: 0.8072, train_loss_norm:0.0491, valid_acc: 0.8008, valid_loss_norm: 0.0495\n",
      " epoch: 77, train accuracy: 0.8076, train_loss_norm:0.0488, valid_acc: 0.8011, valid_loss_norm: 0.0492\n",
      " epoch: 78, train accuracy: 0.8079, train_loss_norm:0.0486, valid_acc: 0.8014, valid_loss_norm: 0.0490\n",
      " epoch: 79, train accuracy: 0.8083, train_loss_norm:0.0483, valid_acc: 0.8014, valid_loss_norm: 0.0487\n",
      " epoch: 80, train accuracy: 0.8087, train_loss_norm:0.0481, valid_acc: 0.8014, valid_loss_norm: 0.0485\n",
      " epoch: 81, train accuracy: 0.8089, train_loss_norm:0.0479, valid_acc: 0.8014, valid_loss_norm: 0.0483\n",
      " epoch: 82, train accuracy: 0.8092, train_loss_norm:0.0476, valid_acc: 0.8014, valid_loss_norm: 0.0480\n",
      " epoch: 83, train accuracy: 0.8099, train_loss_norm:0.0474, valid_acc: 0.8017, valid_loss_norm: 0.0478\n",
      " epoch: 84, train accuracy: 0.8102, train_loss_norm:0.0472, valid_acc: 0.8017, valid_loss_norm: 0.0476\n",
      " epoch: 85, train accuracy: 0.8106, train_loss_norm:0.0469, valid_acc: 0.8028, valid_loss_norm: 0.0474\n",
      " epoch: 86, train accuracy: 0.8109, train_loss_norm:0.0467, valid_acc: 0.8037, valid_loss_norm: 0.0472\n",
      " epoch: 87, train accuracy: 0.8113, train_loss_norm:0.0465, valid_acc: 0.8037, valid_loss_norm: 0.0469\n",
      " epoch: 88, train accuracy: 0.8119, train_loss_norm:0.0463, valid_acc: 0.8040, valid_loss_norm: 0.0467\n",
      " epoch: 89, train accuracy: 0.8121, train_loss_norm:0.0461, valid_acc: 0.8037, valid_loss_norm: 0.0465\n",
      " epoch: 90, train accuracy: 0.8122, train_loss_norm:0.0459, valid_acc: 0.8045, valid_loss_norm: 0.0463\n",
      " epoch: 91, train accuracy: 0.8126, train_loss_norm:0.0457, valid_acc: 0.8048, valid_loss_norm: 0.0461\n",
      " epoch: 92, train accuracy: 0.8130, train_loss_norm:0.0455, valid_acc: 0.8051, valid_loss_norm: 0.0459\n",
      " epoch: 93, train accuracy: 0.8134, train_loss_norm:0.0453, valid_acc: 0.8043, valid_loss_norm: 0.0457\n",
      " epoch: 94, train accuracy: 0.8137, train_loss_norm:0.0451, valid_acc: 0.8043, valid_loss_norm: 0.0455\n",
      " epoch: 95, train accuracy: 0.8140, train_loss_norm:0.0449, valid_acc: 0.8043, valid_loss_norm: 0.0453\n",
      " epoch: 96, train accuracy: 0.8143, train_loss_norm:0.0447, valid_acc: 0.8043, valid_loss_norm: 0.0451\n",
      " epoch: 97, train accuracy: 0.8147, train_loss_norm:0.0445, valid_acc: 0.8048, valid_loss_norm: 0.0450\n",
      " epoch: 98, train accuracy: 0.8150, train_loss_norm:0.0443, valid_acc: 0.8045, valid_loss_norm: 0.0448\n",
      " epoch: 99, train accuracy: 0.8153, train_loss_norm:0.0441, valid_acc: 0.8051, valid_loss_norm: 0.0446\n",
      " epoch: 100, train accuracy: 0.8158, train_loss_norm:0.0440, valid_acc: 0.8054, valid_loss_norm: 0.0444\n",
      " epoch: 101, train accuracy: 0.8162, train_loss_norm:0.0438, valid_acc: 0.8060, valid_loss_norm: 0.0442\n",
      " epoch: 102, train accuracy: 0.8165, train_loss_norm:0.0436, valid_acc: 0.8060, valid_loss_norm: 0.0441\n",
      " epoch: 103, train accuracy: 0.8167, train_loss_norm:0.0434, valid_acc: 0.8063, valid_loss_norm: 0.0439\n",
      " epoch: 104, train accuracy: 0.8172, train_loss_norm:0.0432, valid_acc: 0.8066, valid_loss_norm: 0.0437\n",
      " epoch: 105, train accuracy: 0.8177, train_loss_norm:0.0431, valid_acc: 0.8066, valid_loss_norm: 0.0436\n",
      " epoch: 106, train accuracy: 0.8180, train_loss_norm:0.0429, valid_acc: 0.8071, valid_loss_norm: 0.0434\n",
      " epoch: 107, train accuracy: 0.8182, train_loss_norm:0.0427, valid_acc: 0.8074, valid_loss_norm: 0.0432\n",
      " epoch: 108, train accuracy: 0.8183, train_loss_norm:0.0426, valid_acc: 0.8074, valid_loss_norm: 0.0431\n",
      " epoch: 109, train accuracy: 0.8186, train_loss_norm:0.0424, valid_acc: 0.8074, valid_loss_norm: 0.0429\n",
      " epoch: 110, train accuracy: 0.8190, train_loss_norm:0.0423, valid_acc: 0.8074, valid_loss_norm: 0.0428\n",
      " epoch: 111, train accuracy: 0.8191, train_loss_norm:0.0421, valid_acc: 0.8077, valid_loss_norm: 0.0426\n",
      " epoch: 112, train accuracy: 0.8194, train_loss_norm:0.0419, valid_acc: 0.8080, valid_loss_norm: 0.0424\n",
      " epoch: 113, train accuracy: 0.8197, train_loss_norm:0.0418, valid_acc: 0.8083, valid_loss_norm: 0.0423\n",
      " epoch: 114, train accuracy: 0.8197, train_loss_norm:0.0416, valid_acc: 0.8083, valid_loss_norm: 0.0421\n",
      " epoch: 115, train accuracy: 0.8199, train_loss_norm:0.0415, valid_acc: 0.8083, valid_loss_norm: 0.0420\n",
      " epoch: 116, train accuracy: 0.8202, train_loss_norm:0.0413, valid_acc: 0.8077, valid_loss_norm: 0.0418\n",
      " epoch: 117, train accuracy: 0.8203, train_loss_norm:0.0412, valid_acc: 0.8077, valid_loss_norm: 0.0417\n",
      " epoch: 118, train accuracy: 0.8204, train_loss_norm:0.0410, valid_acc: 0.8077, valid_loss_norm: 0.0416\n",
      " epoch: 119, train accuracy: 0.8206, train_loss_norm:0.0409, valid_acc: 0.8077, valid_loss_norm: 0.0414\n",
      " epoch: 120, train accuracy: 0.8207, train_loss_norm:0.0407, valid_acc: 0.8083, valid_loss_norm: 0.0413\n",
      " epoch: 121, train accuracy: 0.8208, train_loss_norm:0.0406, valid_acc: 0.8089, valid_loss_norm: 0.0411\n",
      " epoch: 122, train accuracy: 0.8211, train_loss_norm:0.0405, valid_acc: 0.8094, valid_loss_norm: 0.0410\n",
      " epoch: 123, train accuracy: 0.8214, train_loss_norm:0.0403, valid_acc: 0.8094, valid_loss_norm: 0.0409\n",
      " epoch: 124, train accuracy: 0.8217, train_loss_norm:0.0402, valid_acc: 0.8097, valid_loss_norm: 0.0407\n",
      " epoch: 125, train accuracy: 0.8219, train_loss_norm:0.0400, valid_acc: 0.8109, valid_loss_norm: 0.0406\n",
      " epoch: 126, train accuracy: 0.8221, train_loss_norm:0.0399, valid_acc: 0.8112, valid_loss_norm: 0.0405\n",
      " epoch: 127, train accuracy: 0.8223, train_loss_norm:0.0398, valid_acc: 0.8112, valid_loss_norm: 0.0403\n",
      " epoch: 128, train accuracy: 0.8225, train_loss_norm:0.0396, valid_acc: 0.8117, valid_loss_norm: 0.0402\n",
      " epoch: 129, train accuracy: 0.8229, train_loss_norm:0.0395, valid_acc: 0.8120, valid_loss_norm: 0.0401\n",
      " epoch: 130, train accuracy: 0.8229, train_loss_norm:0.0394, valid_acc: 0.8120, valid_loss_norm: 0.0399\n",
      " epoch: 131, train accuracy: 0.8230, train_loss_norm:0.0393, valid_acc: 0.8123, valid_loss_norm: 0.0398\n",
      " epoch: 132, train accuracy: 0.8232, train_loss_norm:0.0391, valid_acc: 0.8129, valid_loss_norm: 0.0397\n",
      " epoch: 133, train accuracy: 0.8235, train_loss_norm:0.0390, valid_acc: 0.8126, valid_loss_norm: 0.0396\n",
      " epoch: 134, train accuracy: 0.8238, train_loss_norm:0.0389, valid_acc: 0.8123, valid_loss_norm: 0.0394\n",
      " epoch: 135, train accuracy: 0.8240, train_loss_norm:0.0388, valid_acc: 0.8129, valid_loss_norm: 0.0393\n",
      " epoch: 136, train accuracy: 0.8241, train_loss_norm:0.0386, valid_acc: 0.8132, valid_loss_norm: 0.0392\n",
      " epoch: 137, train accuracy: 0.8242, train_loss_norm:0.0385, valid_acc: 0.8132, valid_loss_norm: 0.0391\n",
      " epoch: 138, train accuracy: 0.8245, train_loss_norm:0.0384, valid_acc: 0.8132, valid_loss_norm: 0.0390\n",
      " epoch: 139, train accuracy: 0.8247, train_loss_norm:0.0383, valid_acc: 0.8132, valid_loss_norm: 0.0389\n",
      " epoch: 140, train accuracy: 0.8250, train_loss_norm:0.0382, valid_acc: 0.8135, valid_loss_norm: 0.0387\n",
      " epoch: 141, train accuracy: 0.8252, train_loss_norm:0.0380, valid_acc: 0.8143, valid_loss_norm: 0.0386\n",
      " epoch: 142, train accuracy: 0.8254, train_loss_norm:0.0379, valid_acc: 0.8143, valid_loss_norm: 0.0385\n",
      " epoch: 143, train accuracy: 0.8257, train_loss_norm:0.0378, valid_acc: 0.8143, valid_loss_norm: 0.0384\n",
      " epoch: 144, train accuracy: 0.8260, train_loss_norm:0.0377, valid_acc: 0.8140, valid_loss_norm: 0.0383\n",
      " epoch: 145, train accuracy: 0.8262, train_loss_norm:0.0376, valid_acc: 0.8140, valid_loss_norm: 0.0382\n",
      " epoch: 146, train accuracy: 0.8264, train_loss_norm:0.0375, valid_acc: 0.8143, valid_loss_norm: 0.0381\n",
      " epoch: 147, train accuracy: 0.8264, train_loss_norm:0.0374, valid_acc: 0.8149, valid_loss_norm: 0.0380\n",
      " epoch: 148, train accuracy: 0.8266, train_loss_norm:0.0373, valid_acc: 0.8158, valid_loss_norm: 0.0379\n",
      " epoch: 149, train accuracy: 0.8268, train_loss_norm:0.0372, valid_acc: 0.8163, valid_loss_norm: 0.0377\n",
      " epoch: 150, train accuracy: 0.8270, train_loss_norm:0.0370, valid_acc: 0.8172, valid_loss_norm: 0.0376\n",
      " epoch: 151, train accuracy: 0.8273, train_loss_norm:0.0369, valid_acc: 0.8175, valid_loss_norm: 0.0375\n",
      " epoch: 152, train accuracy: 0.8276, train_loss_norm:0.0368, valid_acc: 0.8175, valid_loss_norm: 0.0374\n",
      " epoch: 153, train accuracy: 0.8279, train_loss_norm:0.0367, valid_acc: 0.8175, valid_loss_norm: 0.0373\n",
      " epoch: 154, train accuracy: 0.8279, train_loss_norm:0.0366, valid_acc: 0.8175, valid_loss_norm: 0.0372\n",
      " epoch: 155, train accuracy: 0.8281, train_loss_norm:0.0365, valid_acc: 0.8175, valid_loss_norm: 0.0371\n",
      " epoch: 156, train accuracy: 0.8284, train_loss_norm:0.0364, valid_acc: 0.8181, valid_loss_norm: 0.0370\n",
      " epoch: 157, train accuracy: 0.8285, train_loss_norm:0.0363, valid_acc: 0.8181, valid_loss_norm: 0.0369\n",
      " epoch: 158, train accuracy: 0.8288, train_loss_norm:0.0362, valid_acc: 0.8183, valid_loss_norm: 0.0368\n",
      " epoch: 159, train accuracy: 0.8289, train_loss_norm:0.0361, valid_acc: 0.8186, valid_loss_norm: 0.0367\n",
      " epoch: 160, train accuracy: 0.8292, train_loss_norm:0.0360, valid_acc: 0.8186, valid_loss_norm: 0.0366\n",
      " epoch: 161, train accuracy: 0.8293, train_loss_norm:0.0359, valid_acc: 0.8186, valid_loss_norm: 0.0366\n",
      " epoch: 162, train accuracy: 0.8295, train_loss_norm:0.0358, valid_acc: 0.8186, valid_loss_norm: 0.0365\n",
      " epoch: 163, train accuracy: 0.8299, train_loss_norm:0.0357, valid_acc: 0.8186, valid_loss_norm: 0.0364\n",
      " epoch: 164, train accuracy: 0.8299, train_loss_norm:0.0356, valid_acc: 0.8189, valid_loss_norm: 0.0363\n",
      " epoch: 165, train accuracy: 0.8299, train_loss_norm:0.0355, valid_acc: 0.8186, valid_loss_norm: 0.0362\n",
      " epoch: 166, train accuracy: 0.8301, train_loss_norm:0.0355, valid_acc: 0.8189, valid_loss_norm: 0.0361\n",
      " epoch: 167, train accuracy: 0.8304, train_loss_norm:0.0354, valid_acc: 0.8189, valid_loss_norm: 0.0360\n",
      " epoch: 168, train accuracy: 0.8306, train_loss_norm:0.0353, valid_acc: 0.8192, valid_loss_norm: 0.0359\n",
      " epoch: 169, train accuracy: 0.8309, train_loss_norm:0.0352, valid_acc: 0.8195, valid_loss_norm: 0.0358\n",
      " epoch: 170, train accuracy: 0.8310, train_loss_norm:0.0351, valid_acc: 0.8195, valid_loss_norm: 0.0357\n",
      " epoch: 171, train accuracy: 0.8311, train_loss_norm:0.0350, valid_acc: 0.8195, valid_loss_norm: 0.0356\n",
      " epoch: 172, train accuracy: 0.8313, train_loss_norm:0.0349, valid_acc: 0.8198, valid_loss_norm: 0.0356\n",
      " epoch: 173, train accuracy: 0.8314, train_loss_norm:0.0348, valid_acc: 0.8198, valid_loss_norm: 0.0355\n",
      " epoch: 174, train accuracy: 0.8316, train_loss_norm:0.0347, valid_acc: 0.8204, valid_loss_norm: 0.0354\n",
      " epoch: 175, train accuracy: 0.8318, train_loss_norm:0.0346, valid_acc: 0.8206, valid_loss_norm: 0.0353\n",
      " epoch: 176, train accuracy: 0.8319, train_loss_norm:0.0346, valid_acc: 0.8206, valid_loss_norm: 0.0352\n",
      " epoch: 177, train accuracy: 0.8321, train_loss_norm:0.0345, valid_acc: 0.8209, valid_loss_norm: 0.0351\n",
      " epoch: 178, train accuracy: 0.8322, train_loss_norm:0.0344, valid_acc: 0.8212, valid_loss_norm: 0.0351\n",
      " epoch: 179, train accuracy: 0.8324, train_loss_norm:0.0343, valid_acc: 0.8218, valid_loss_norm: 0.0350\n",
      " epoch: 180, train accuracy: 0.8326, train_loss_norm:0.0342, valid_acc: 0.8229, valid_loss_norm: 0.0349\n",
      " epoch: 181, train accuracy: 0.8327, train_loss_norm:0.0341, valid_acc: 0.8229, valid_loss_norm: 0.0348\n",
      " epoch: 182, train accuracy: 0.8328, train_loss_norm:0.0341, valid_acc: 0.8229, valid_loss_norm: 0.0347\n",
      " epoch: 183, train accuracy: 0.8331, train_loss_norm:0.0340, valid_acc: 0.8229, valid_loss_norm: 0.0347\n",
      " epoch: 184, train accuracy: 0.8332, train_loss_norm:0.0339, valid_acc: 0.8229, valid_loss_norm: 0.0346\n",
      " epoch: 185, train accuracy: 0.8333, train_loss_norm:0.0338, valid_acc: 0.8235, valid_loss_norm: 0.0345\n",
      " epoch: 186, train accuracy: 0.8335, train_loss_norm:0.0337, valid_acc: 0.8235, valid_loss_norm: 0.0344\n",
      " epoch: 187, train accuracy: 0.8337, train_loss_norm:0.0337, valid_acc: 0.8238, valid_loss_norm: 0.0343\n",
      " epoch: 188, train accuracy: 0.8337, train_loss_norm:0.0336, valid_acc: 0.8241, valid_loss_norm: 0.0343\n",
      " epoch: 189, train accuracy: 0.8338, train_loss_norm:0.0335, valid_acc: 0.8241, valid_loss_norm: 0.0342\n",
      " epoch: 190, train accuracy: 0.8339, train_loss_norm:0.0334, valid_acc: 0.8235, valid_loss_norm: 0.0341\n",
      " epoch: 191, train accuracy: 0.8342, train_loss_norm:0.0333, valid_acc: 0.8235, valid_loss_norm: 0.0340\n",
      " epoch: 192, train accuracy: 0.8344, train_loss_norm:0.0333, valid_acc: 0.8238, valid_loss_norm: 0.0340\n",
      " epoch: 193, train accuracy: 0.8343, train_loss_norm:0.0332, valid_acc: 0.8238, valid_loss_norm: 0.0339\n",
      " epoch: 194, train accuracy: 0.8345, train_loss_norm:0.0331, valid_acc: 0.8238, valid_loss_norm: 0.0338\n",
      " epoch: 195, train accuracy: 0.8346, train_loss_norm:0.0330, valid_acc: 0.8244, valid_loss_norm: 0.0337\n",
      " epoch: 196, train accuracy: 0.8349, train_loss_norm:0.0330, valid_acc: 0.8244, valid_loss_norm: 0.0337\n",
      " epoch: 197, train accuracy: 0.8350, train_loss_norm:0.0329, valid_acc: 0.8249, valid_loss_norm: 0.0336\n",
      " epoch: 198, train accuracy: 0.8351, train_loss_norm:0.0328, valid_acc: 0.8249, valid_loss_norm: 0.0335\n",
      " epoch: 199, train accuracy: 0.8353, train_loss_norm:0.0327, valid_acc: 0.8249, valid_loss_norm: 0.0335\n",
      " epoch: 200, train accuracy: 0.8353, train_loss_norm:0.0327, valid_acc: 0.8249, valid_loss_norm: 0.0334\n",
      " epoch: 201, train accuracy: 0.8353, train_loss_norm:0.0326, valid_acc: 0.8252, valid_loss_norm: 0.0333\n",
      " epoch: 202, train accuracy: 0.8354, train_loss_norm:0.0325, valid_acc: 0.8255, valid_loss_norm: 0.0332\n",
      " epoch: 203, train accuracy: 0.8355, train_loss_norm:0.0325, valid_acc: 0.8255, valid_loss_norm: 0.0332\n",
      " epoch: 204, train accuracy: 0.8357, train_loss_norm:0.0324, valid_acc: 0.8258, valid_loss_norm: 0.0331\n",
      " epoch: 205, train accuracy: 0.8360, train_loss_norm:0.0323, valid_acc: 0.8261, valid_loss_norm: 0.0330\n",
      " epoch: 206, train accuracy: 0.8361, train_loss_norm:0.0323, valid_acc: 0.8258, valid_loss_norm: 0.0330\n",
      " epoch: 207, train accuracy: 0.8363, train_loss_norm:0.0322, valid_acc: 0.8255, valid_loss_norm: 0.0329\n",
      " epoch: 208, train accuracy: 0.8363, train_loss_norm:0.0321, valid_acc: 0.8255, valid_loss_norm: 0.0328\n",
      " epoch: 209, train accuracy: 0.8364, train_loss_norm:0.0320, valid_acc: 0.8264, valid_loss_norm: 0.0328\n",
      " epoch: 210, train accuracy: 0.8366, train_loss_norm:0.0320, valid_acc: 0.8264, valid_loss_norm: 0.0327\n",
      " epoch: 211, train accuracy: 0.8365, train_loss_norm:0.0319, valid_acc: 0.8264, valid_loss_norm: 0.0326\n",
      " epoch: 212, train accuracy: 0.8366, train_loss_norm:0.0318, valid_acc: 0.8267, valid_loss_norm: 0.0326\n",
      " epoch: 213, train accuracy: 0.8368, train_loss_norm:0.0318, valid_acc: 0.8267, valid_loss_norm: 0.0325\n",
      " epoch: 214, train accuracy: 0.8368, train_loss_norm:0.0317, valid_acc: 0.8267, valid_loss_norm: 0.0325\n",
      " epoch: 215, train accuracy: 0.8369, train_loss_norm:0.0317, valid_acc: 0.8272, valid_loss_norm: 0.0324\n",
      " epoch: 216, train accuracy: 0.8369, train_loss_norm:0.0316, valid_acc: 0.8270, valid_loss_norm: 0.0323\n",
      " epoch: 217, train accuracy: 0.8371, train_loss_norm:0.0315, valid_acc: 0.8272, valid_loss_norm: 0.0323\n",
      " epoch: 218, train accuracy: 0.8372, train_loss_norm:0.0315, valid_acc: 0.8275, valid_loss_norm: 0.0322\n",
      " epoch: 219, train accuracy: 0.8373, train_loss_norm:0.0314, valid_acc: 0.8275, valid_loss_norm: 0.0321\n",
      " epoch: 220, train accuracy: 0.8374, train_loss_norm:0.0313, valid_acc: 0.8275, valid_loss_norm: 0.0321\n",
      " epoch: 221, train accuracy: 0.8376, train_loss_norm:0.0313, valid_acc: 0.8272, valid_loss_norm: 0.0320\n",
      " epoch: 222, train accuracy: 0.8377, train_loss_norm:0.0312, valid_acc: 0.8275, valid_loss_norm: 0.0320\n",
      " epoch: 223, train accuracy: 0.8378, train_loss_norm:0.0311, valid_acc: 0.8275, valid_loss_norm: 0.0319\n",
      " epoch: 224, train accuracy: 0.8379, train_loss_norm:0.0311, valid_acc: 0.8278, valid_loss_norm: 0.0318\n",
      " epoch: 225, train accuracy: 0.8379, train_loss_norm:0.0310, valid_acc: 0.8278, valid_loss_norm: 0.0318\n",
      " epoch: 226, train accuracy: 0.8380, train_loss_norm:0.0310, valid_acc: 0.8278, valid_loss_norm: 0.0317\n",
      " epoch: 227, train accuracy: 0.8382, train_loss_norm:0.0309, valid_acc: 0.8278, valid_loss_norm: 0.0317\n",
      " epoch: 228, train accuracy: 0.8384, train_loss_norm:0.0308, valid_acc: 0.8281, valid_loss_norm: 0.0316\n",
      " epoch: 229, train accuracy: 0.8384, train_loss_norm:0.0308, valid_acc: 0.8287, valid_loss_norm: 0.0315\n",
      " epoch: 230, train accuracy: 0.8385, train_loss_norm:0.0307, valid_acc: 0.8290, valid_loss_norm: 0.0315\n",
      " epoch: 231, train accuracy: 0.8387, train_loss_norm:0.0307, valid_acc: 0.8293, valid_loss_norm: 0.0314\n",
      " epoch: 232, train accuracy: 0.8388, train_loss_norm:0.0306, valid_acc: 0.8293, valid_loss_norm: 0.0314\n",
      " epoch: 233, train accuracy: 0.8387, train_loss_norm:0.0305, valid_acc: 0.8298, valid_loss_norm: 0.0313\n",
      " epoch: 234, train accuracy: 0.8388, train_loss_norm:0.0305, valid_acc: 0.8295, valid_loss_norm: 0.0313\n",
      " epoch: 235, train accuracy: 0.8389, train_loss_norm:0.0304, valid_acc: 0.8301, valid_loss_norm: 0.0312\n",
      " epoch: 236, train accuracy: 0.8390, train_loss_norm:0.0304, valid_acc: 0.8301, valid_loss_norm: 0.0312\n",
      " epoch: 237, train accuracy: 0.8391, train_loss_norm:0.0303, valid_acc: 0.8301, valid_loss_norm: 0.0311\n",
      " epoch: 238, train accuracy: 0.8391, train_loss_norm:0.0303, valid_acc: 0.8298, valid_loss_norm: 0.0310\n",
      " epoch: 239, train accuracy: 0.8391, train_loss_norm:0.0302, valid_acc: 0.8298, valid_loss_norm: 0.0310\n",
      " epoch: 240, train accuracy: 0.8393, train_loss_norm:0.0301, valid_acc: 0.8301, valid_loss_norm: 0.0309\n",
      " epoch: 241, train accuracy: 0.8394, train_loss_norm:0.0301, valid_acc: 0.8301, valid_loss_norm: 0.0309\n",
      " epoch: 242, train accuracy: 0.8393, train_loss_norm:0.0300, valid_acc: 0.8304, valid_loss_norm: 0.0308\n",
      " epoch: 243, train accuracy: 0.8394, train_loss_norm:0.0300, valid_acc: 0.8307, valid_loss_norm: 0.0308\n",
      " epoch: 244, train accuracy: 0.8396, train_loss_norm:0.0299, valid_acc: 0.8310, valid_loss_norm: 0.0307\n",
      " epoch: 245, train accuracy: 0.8397, train_loss_norm:0.0299, valid_acc: 0.8310, valid_loss_norm: 0.0307\n",
      " epoch: 246, train accuracy: 0.8397, train_loss_norm:0.0298, valid_acc: 0.8313, valid_loss_norm: 0.0306\n",
      " epoch: 247, train accuracy: 0.8398, train_loss_norm:0.0298, valid_acc: 0.8313, valid_loss_norm: 0.0306\n",
      " epoch: 248, train accuracy: 0.8399, train_loss_norm:0.0297, valid_acc: 0.8316, valid_loss_norm: 0.0305\n",
      " epoch: 249, train accuracy: 0.8399, train_loss_norm:0.0297, valid_acc: 0.8316, valid_loss_norm: 0.0305\n",
      " epoch: 250, train accuracy: 0.8401, train_loss_norm:0.0296, valid_acc: 0.8316, valid_loss_norm: 0.0304\n",
      " epoch: 251, train accuracy: 0.8401, train_loss_norm:0.0296, valid_acc: 0.8316, valid_loss_norm: 0.0304\n",
      " epoch: 252, train accuracy: 0.8403, train_loss_norm:0.0295, valid_acc: 0.8316, valid_loss_norm: 0.0303\n",
      " epoch: 253, train accuracy: 0.8405, train_loss_norm:0.0294, valid_acc: 0.8327, valid_loss_norm: 0.0303\n",
      " epoch: 254, train accuracy: 0.8406, train_loss_norm:0.0294, valid_acc: 0.8330, valid_loss_norm: 0.0302\n",
      " epoch: 255, train accuracy: 0.8406, train_loss_norm:0.0293, valid_acc: 0.8330, valid_loss_norm: 0.0302\n",
      " epoch: 256, train accuracy: 0.8407, train_loss_norm:0.0293, valid_acc: 0.8330, valid_loss_norm: 0.0301\n",
      " epoch: 257, train accuracy: 0.8407, train_loss_norm:0.0292, valid_acc: 0.8330, valid_loss_norm: 0.0301\n",
      " epoch: 258, train accuracy: 0.8408, train_loss_norm:0.0292, valid_acc: 0.8330, valid_loss_norm: 0.0300\n",
      " epoch: 259, train accuracy: 0.8410, train_loss_norm:0.0291, valid_acc: 0.8330, valid_loss_norm: 0.0300\n",
      " epoch: 260, train accuracy: 0.8411, train_loss_norm:0.0291, valid_acc: 0.8333, valid_loss_norm: 0.0299\n",
      " epoch: 261, train accuracy: 0.8412, train_loss_norm:0.0290, valid_acc: 0.8333, valid_loss_norm: 0.0299\n",
      " epoch: 262, train accuracy: 0.8413, train_loss_norm:0.0290, valid_acc: 0.8333, valid_loss_norm: 0.0298\n",
      " epoch: 263, train accuracy: 0.8412, train_loss_norm:0.0289, valid_acc: 0.8333, valid_loss_norm: 0.0298\n",
      " epoch: 264, train accuracy: 0.8413, train_loss_norm:0.0289, valid_acc: 0.8333, valid_loss_norm: 0.0297\n",
      " epoch: 265, train accuracy: 0.8416, train_loss_norm:0.0288, valid_acc: 0.8336, valid_loss_norm: 0.0297\n",
      " epoch: 266, train accuracy: 0.8417, train_loss_norm:0.0288, valid_acc: 0.8336, valid_loss_norm: 0.0296\n",
      " epoch: 267, train accuracy: 0.8419, train_loss_norm:0.0288, valid_acc: 0.8344, valid_loss_norm: 0.0296\n",
      " epoch: 268, train accuracy: 0.8421, train_loss_norm:0.0287, valid_acc: 0.8347, valid_loss_norm: 0.0295\n",
      " epoch: 269, train accuracy: 0.8422, train_loss_norm:0.0287, valid_acc: 0.8347, valid_loss_norm: 0.0295\n",
      " epoch: 270, train accuracy: 0.8423, train_loss_norm:0.0286, valid_acc: 0.8347, valid_loss_norm: 0.0295\n",
      " epoch: 271, train accuracy: 0.8424, train_loss_norm:0.0286, valid_acc: 0.8347, valid_loss_norm: 0.0294\n",
      " epoch: 272, train accuracy: 0.8425, train_loss_norm:0.0285, valid_acc: 0.8347, valid_loss_norm: 0.0294\n",
      " epoch: 273, train accuracy: 0.8427, train_loss_norm:0.0285, valid_acc: 0.8350, valid_loss_norm: 0.0293\n",
      " epoch: 274, train accuracy: 0.8428, train_loss_norm:0.0284, valid_acc: 0.8350, valid_loss_norm: 0.0293\n",
      " epoch: 275, train accuracy: 0.8430, train_loss_norm:0.0284, valid_acc: 0.8350, valid_loss_norm: 0.0292\n",
      " epoch: 276, train accuracy: 0.8430, train_loss_norm:0.0283, valid_acc: 0.8356, valid_loss_norm: 0.0292\n",
      " epoch: 277, train accuracy: 0.8431, train_loss_norm:0.0283, valid_acc: 0.8356, valid_loss_norm: 0.0291\n",
      " epoch: 278, train accuracy: 0.8431, train_loss_norm:0.0282, valid_acc: 0.8356, valid_loss_norm: 0.0291\n",
      " epoch: 279, train accuracy: 0.8431, train_loss_norm:0.0282, valid_acc: 0.8362, valid_loss_norm: 0.0291\n",
      " epoch: 280, train accuracy: 0.8432, train_loss_norm:0.0282, valid_acc: 0.8370, valid_loss_norm: 0.0290\n",
      " epoch: 281, train accuracy: 0.8434, train_loss_norm:0.0281, valid_acc: 0.8373, valid_loss_norm: 0.0290\n",
      " epoch: 282, train accuracy: 0.8434, train_loss_norm:0.0281, valid_acc: 0.8376, valid_loss_norm: 0.0289\n",
      " epoch: 283, train accuracy: 0.8434, train_loss_norm:0.0280, valid_acc: 0.8376, valid_loss_norm: 0.0289\n",
      " epoch: 284, train accuracy: 0.8435, train_loss_norm:0.0280, valid_acc: 0.8376, valid_loss_norm: 0.0288\n",
      " epoch: 285, train accuracy: 0.8435, train_loss_norm:0.0279, valid_acc: 0.8373, valid_loss_norm: 0.0288\n",
      " epoch: 286, train accuracy: 0.8435, train_loss_norm:0.0279, valid_acc: 0.8370, valid_loss_norm: 0.0288\n",
      " epoch: 287, train accuracy: 0.8436, train_loss_norm:0.0278, valid_acc: 0.8370, valid_loss_norm: 0.0287\n",
      " epoch: 288, train accuracy: 0.8438, train_loss_norm:0.0278, valid_acc: 0.8370, valid_loss_norm: 0.0287\n",
      " epoch: 289, train accuracy: 0.8438, train_loss_norm:0.0278, valid_acc: 0.8367, valid_loss_norm: 0.0286\n",
      " epoch: 290, train accuracy: 0.8440, train_loss_norm:0.0277, valid_acc: 0.8367, valid_loss_norm: 0.0286\n",
      " epoch: 291, train accuracy: 0.8441, train_loss_norm:0.0277, valid_acc: 0.8367, valid_loss_norm: 0.0286\n",
      " epoch: 292, train accuracy: 0.8441, train_loss_norm:0.0276, valid_acc: 0.8367, valid_loss_norm: 0.0285\n",
      " epoch: 293, train accuracy: 0.8443, train_loss_norm:0.0276, valid_acc: 0.8367, valid_loss_norm: 0.0285\n",
      " epoch: 294, train accuracy: 0.8443, train_loss_norm:0.0275, valid_acc: 0.8367, valid_loss_norm: 0.0284\n",
      " epoch: 295, train accuracy: 0.8444, train_loss_norm:0.0275, valid_acc: 0.8367, valid_loss_norm: 0.0284\n",
      " epoch: 296, train accuracy: 0.8444, train_loss_norm:0.0275, valid_acc: 0.8370, valid_loss_norm: 0.0284\n",
      " epoch: 297, train accuracy: 0.8445, train_loss_norm:0.0274, valid_acc: 0.8370, valid_loss_norm: 0.0283\n",
      " epoch: 298, train accuracy: 0.8448, train_loss_norm:0.0274, valid_acc: 0.8370, valid_loss_norm: 0.0283\n",
      " epoch: 299, train accuracy: 0.8449, train_loss_norm:0.0273, valid_acc: 0.8370, valid_loss_norm: 0.0282\n",
      " epoch: 300, train accuracy: 0.8449, train_loss_norm:0.0273, valid_acc: 0.8370, valid_loss_norm: 0.0282\n",
      "Test accuracy: 0.8330\n",
      "Test loss norm: 0.0278\n",
      "Cur fold: 6\n",
      "(27841, 300)\n",
      "(3479, 300)\n",
      "(3479, 300)\n",
      " epoch: 1, train accuracy: 0.7913, train_loss_norm:0.0867, valid_acc: 0.7867, valid_loss_norm: 0.0867\n",
      " epoch: 2, train accuracy: 0.7913, train_loss_norm:0.0859, valid_acc: 0.7867, valid_loss_norm: 0.0859\n",
      " epoch: 3, train accuracy: 0.7914, train_loss_norm:0.0852, valid_acc: 0.7867, valid_loss_norm: 0.0851\n",
      " epoch: 4, train accuracy: 0.7914, train_loss_norm:0.0844, valid_acc: 0.7867, valid_loss_norm: 0.0843\n",
      " epoch: 5, train accuracy: 0.7914, train_loss_norm:0.0837, valid_acc: 0.7867, valid_loss_norm: 0.0836\n",
      " epoch: 6, train accuracy: 0.7915, train_loss_norm:0.0829, valid_acc: 0.7867, valid_loss_norm: 0.0828\n",
      " epoch: 7, train accuracy: 0.7916, train_loss_norm:0.0822, valid_acc: 0.7867, valid_loss_norm: 0.0821\n",
      " epoch: 8, train accuracy: 0.7917, train_loss_norm:0.0814, valid_acc: 0.7867, valid_loss_norm: 0.0813\n",
      " epoch: 9, train accuracy: 0.7917, train_loss_norm:0.0807, valid_acc: 0.7867, valid_loss_norm: 0.0805\n",
      " epoch: 10, train accuracy: 0.7918, train_loss_norm:0.0800, valid_acc: 0.7867, valid_loss_norm: 0.0798\n",
      " epoch: 11, train accuracy: 0.7918, train_loss_norm:0.0792, valid_acc: 0.7867, valid_loss_norm: 0.0791\n",
      " epoch: 12, train accuracy: 0.7919, train_loss_norm:0.0785, valid_acc: 0.7867, valid_loss_norm: 0.0783\n",
      " epoch: 13, train accuracy: 0.7919, train_loss_norm:0.0778, valid_acc: 0.7867, valid_loss_norm: 0.0776\n",
      " epoch: 14, train accuracy: 0.7920, train_loss_norm:0.0771, valid_acc: 0.7867, valid_loss_norm: 0.0769\n",
      " epoch: 15, train accuracy: 0.7920, train_loss_norm:0.0764, valid_acc: 0.7867, valid_loss_norm: 0.0762\n",
      " epoch: 16, train accuracy: 0.7920, train_loss_norm:0.0757, valid_acc: 0.7870, valid_loss_norm: 0.0755\n",
      " epoch: 17, train accuracy: 0.7921, train_loss_norm:0.0750, valid_acc: 0.7873, valid_loss_norm: 0.0748\n",
      " epoch: 18, train accuracy: 0.7922, train_loss_norm:0.0743, valid_acc: 0.7873, valid_loss_norm: 0.0741\n",
      " epoch: 19, train accuracy: 0.7924, train_loss_norm:0.0737, valid_acc: 0.7876, valid_loss_norm: 0.0734\n",
      " epoch: 20, train accuracy: 0.7926, train_loss_norm:0.0730, valid_acc: 0.7876, valid_loss_norm: 0.0727\n",
      " epoch: 21, train accuracy: 0.7927, train_loss_norm:0.0723, valid_acc: 0.7879, valid_loss_norm: 0.0721\n",
      " epoch: 22, train accuracy: 0.7929, train_loss_norm:0.0717, valid_acc: 0.7879, valid_loss_norm: 0.0714\n",
      " epoch: 23, train accuracy: 0.7930, train_loss_norm:0.0710, valid_acc: 0.7879, valid_loss_norm: 0.0708\n",
      " epoch: 24, train accuracy: 0.7931, train_loss_norm:0.0704, valid_acc: 0.7882, valid_loss_norm: 0.0701\n",
      " epoch: 25, train accuracy: 0.7933, train_loss_norm:0.0698, valid_acc: 0.7884, valid_loss_norm: 0.0695\n",
      " epoch: 26, train accuracy: 0.7935, train_loss_norm:0.0692, valid_acc: 0.7884, valid_loss_norm: 0.0689\n",
      " epoch: 27, train accuracy: 0.7936, train_loss_norm:0.0686, valid_acc: 0.7882, valid_loss_norm: 0.0683\n",
      " epoch: 28, train accuracy: 0.7936, train_loss_norm:0.0680, valid_acc: 0.7884, valid_loss_norm: 0.0677\n",
      " epoch: 29, train accuracy: 0.7938, train_loss_norm:0.0674, valid_acc: 0.7890, valid_loss_norm: 0.0671\n",
      " epoch: 30, train accuracy: 0.7940, train_loss_norm:0.0668, valid_acc: 0.7887, valid_loss_norm: 0.0665\n",
      " epoch: 31, train accuracy: 0.7941, train_loss_norm:0.0663, valid_acc: 0.7896, valid_loss_norm: 0.0659\n",
      " epoch: 32, train accuracy: 0.7944, train_loss_norm:0.0657, valid_acc: 0.7896, valid_loss_norm: 0.0654\n",
      " epoch: 33, train accuracy: 0.7947, train_loss_norm:0.0652, valid_acc: 0.7899, valid_loss_norm: 0.0648\n",
      " epoch: 34, train accuracy: 0.7950, train_loss_norm:0.0646, valid_acc: 0.7902, valid_loss_norm: 0.0643\n",
      " epoch: 35, train accuracy: 0.7951, train_loss_norm:0.0641, valid_acc: 0.7902, valid_loss_norm: 0.0637\n",
      " epoch: 36, train accuracy: 0.7954, train_loss_norm:0.0636, valid_acc: 0.7905, valid_loss_norm: 0.0632\n",
      " epoch: 37, train accuracy: 0.7955, train_loss_norm:0.0631, valid_acc: 0.7910, valid_loss_norm: 0.0627\n",
      " epoch: 38, train accuracy: 0.7955, train_loss_norm:0.0626, valid_acc: 0.7907, valid_loss_norm: 0.0622\n",
      " epoch: 39, train accuracy: 0.7957, train_loss_norm:0.0621, valid_acc: 0.7913, valid_loss_norm: 0.0617\n",
      " epoch: 40, train accuracy: 0.7962, train_loss_norm:0.0616, valid_acc: 0.7913, valid_loss_norm: 0.0612\n",
      " epoch: 41, train accuracy: 0.7968, train_loss_norm:0.0611, valid_acc: 0.7913, valid_loss_norm: 0.0608\n",
      " epoch: 42, train accuracy: 0.7972, train_loss_norm:0.0606, valid_acc: 0.7910, valid_loss_norm: 0.0603\n",
      " epoch: 43, train accuracy: 0.7976, train_loss_norm:0.0602, valid_acc: 0.7907, valid_loss_norm: 0.0598\n",
      " epoch: 44, train accuracy: 0.7977, train_loss_norm:0.0597, valid_acc: 0.7902, valid_loss_norm: 0.0594\n",
      " epoch: 45, train accuracy: 0.7979, train_loss_norm:0.0593, valid_acc: 0.7902, valid_loss_norm: 0.0590\n",
      " epoch: 46, train accuracy: 0.7981, train_loss_norm:0.0589, valid_acc: 0.7905, valid_loss_norm: 0.0585\n",
      " epoch: 47, train accuracy: 0.7984, train_loss_norm:0.0585, valid_acc: 0.7905, valid_loss_norm: 0.0581\n",
      " epoch: 48, train accuracy: 0.7989, train_loss_norm:0.0580, valid_acc: 0.7907, valid_loss_norm: 0.0577\n",
      " epoch: 49, train accuracy: 0.7991, train_loss_norm:0.0576, valid_acc: 0.7910, valid_loss_norm: 0.0573\n",
      " epoch: 50, train accuracy: 0.7996, train_loss_norm:0.0572, valid_acc: 0.7910, valid_loss_norm: 0.0569\n",
      " epoch: 51, train accuracy: 0.7999, train_loss_norm:0.0568, valid_acc: 0.7916, valid_loss_norm: 0.0565\n",
      " epoch: 52, train accuracy: 0.8005, train_loss_norm:0.0565, valid_acc: 0.7916, valid_loss_norm: 0.0561\n",
      " epoch: 53, train accuracy: 0.8008, train_loss_norm:0.0561, valid_acc: 0.7919, valid_loss_norm: 0.0557\n",
      " epoch: 54, train accuracy: 0.8011, train_loss_norm:0.0557, valid_acc: 0.7925, valid_loss_norm: 0.0554\n",
      " epoch: 55, train accuracy: 0.8014, train_loss_norm:0.0553, valid_acc: 0.7928, valid_loss_norm: 0.0550\n",
      " epoch: 56, train accuracy: 0.8016, train_loss_norm:0.0550, valid_acc: 0.7933, valid_loss_norm: 0.0547\n",
      " epoch: 57, train accuracy: 0.8018, train_loss_norm:0.0546, valid_acc: 0.7942, valid_loss_norm: 0.0543\n",
      " epoch: 58, train accuracy: 0.8021, train_loss_norm:0.0543, valid_acc: 0.7948, valid_loss_norm: 0.0540\n",
      " epoch: 59, train accuracy: 0.8026, train_loss_norm:0.0540, valid_acc: 0.7956, valid_loss_norm: 0.0536\n",
      " epoch: 60, train accuracy: 0.8028, train_loss_norm:0.0536, valid_acc: 0.7959, valid_loss_norm: 0.0533\n",
      " epoch: 61, train accuracy: 0.8032, train_loss_norm:0.0533, valid_acc: 0.7962, valid_loss_norm: 0.0530\n",
      " epoch: 62, train accuracy: 0.8034, train_loss_norm:0.0530, valid_acc: 0.7959, valid_loss_norm: 0.0527\n",
      " epoch: 63, train accuracy: 0.8039, train_loss_norm:0.0527, valid_acc: 0.7962, valid_loss_norm: 0.0524\n",
      " epoch: 64, train accuracy: 0.8042, train_loss_norm:0.0523, valid_acc: 0.7962, valid_loss_norm: 0.0521\n",
      " epoch: 65, train accuracy: 0.8046, train_loss_norm:0.0520, valid_acc: 0.7962, valid_loss_norm: 0.0518\n",
      " epoch: 66, train accuracy: 0.8048, train_loss_norm:0.0517, valid_acc: 0.7965, valid_loss_norm: 0.0515\n",
      " epoch: 67, train accuracy: 0.8054, train_loss_norm:0.0514, valid_acc: 0.7965, valid_loss_norm: 0.0512\n",
      " epoch: 68, train accuracy: 0.8059, train_loss_norm:0.0512, valid_acc: 0.7968, valid_loss_norm: 0.0509\n",
      " epoch: 69, train accuracy: 0.8064, train_loss_norm:0.0509, valid_acc: 0.7974, valid_loss_norm: 0.0506\n",
      " epoch: 70, train accuracy: 0.8067, train_loss_norm:0.0506, valid_acc: 0.7976, valid_loss_norm: 0.0503\n",
      " epoch: 71, train accuracy: 0.8069, train_loss_norm:0.0503, valid_acc: 0.7976, valid_loss_norm: 0.0501\n",
      " epoch: 72, train accuracy: 0.8072, train_loss_norm:0.0500, valid_acc: 0.7976, valid_loss_norm: 0.0498\n",
      " epoch: 73, train accuracy: 0.8074, train_loss_norm:0.0498, valid_acc: 0.7976, valid_loss_norm: 0.0495\n",
      " epoch: 74, train accuracy: 0.8078, train_loss_norm:0.0495, valid_acc: 0.7979, valid_loss_norm: 0.0493\n",
      " epoch: 75, train accuracy: 0.8082, train_loss_norm:0.0493, valid_acc: 0.7982, valid_loss_norm: 0.0490\n",
      " epoch: 76, train accuracy: 0.8084, train_loss_norm:0.0490, valid_acc: 0.7985, valid_loss_norm: 0.0488\n",
      " epoch: 77, train accuracy: 0.8086, train_loss_norm:0.0488, valid_acc: 0.7988, valid_loss_norm: 0.0485\n",
      " epoch: 78, train accuracy: 0.8091, train_loss_norm:0.0485, valid_acc: 0.7985, valid_loss_norm: 0.0483\n",
      " epoch: 79, train accuracy: 0.8092, train_loss_norm:0.0483, valid_acc: 0.7985, valid_loss_norm: 0.0481\n",
      " epoch: 80, train accuracy: 0.8095, train_loss_norm:0.0480, valid_acc: 0.7985, valid_loss_norm: 0.0478\n",
      " epoch: 81, train accuracy: 0.8098, train_loss_norm:0.0478, valid_acc: 0.7988, valid_loss_norm: 0.0476\n",
      " epoch: 82, train accuracy: 0.8098, train_loss_norm:0.0476, valid_acc: 0.7988, valid_loss_norm: 0.0474\n",
      " epoch: 83, train accuracy: 0.8104, train_loss_norm:0.0473, valid_acc: 0.7991, valid_loss_norm: 0.0471\n",
      " epoch: 84, train accuracy: 0.8106, train_loss_norm:0.0471, valid_acc: 0.7991, valid_loss_norm: 0.0469\n",
      " epoch: 85, train accuracy: 0.8108, train_loss_norm:0.0469, valid_acc: 0.7988, valid_loss_norm: 0.0467\n",
      " epoch: 86, train accuracy: 0.8111, train_loss_norm:0.0467, valid_acc: 0.7991, valid_loss_norm: 0.0465\n",
      " epoch: 87, train accuracy: 0.8112, train_loss_norm:0.0464, valid_acc: 0.7991, valid_loss_norm: 0.0463\n",
      " epoch: 88, train accuracy: 0.8115, train_loss_norm:0.0462, valid_acc: 0.7991, valid_loss_norm: 0.0461\n",
      " epoch: 89, train accuracy: 0.8117, train_loss_norm:0.0460, valid_acc: 0.7997, valid_loss_norm: 0.0459\n",
      " epoch: 90, train accuracy: 0.8120, train_loss_norm:0.0458, valid_acc: 0.7999, valid_loss_norm: 0.0457\n",
      " epoch: 91, train accuracy: 0.8124, train_loss_norm:0.0456, valid_acc: 0.7999, valid_loss_norm: 0.0455\n",
      " epoch: 92, train accuracy: 0.8128, train_loss_norm:0.0454, valid_acc: 0.8002, valid_loss_norm: 0.0453\n",
      " epoch: 93, train accuracy: 0.8131, train_loss_norm:0.0452, valid_acc: 0.8008, valid_loss_norm: 0.0451\n",
      " epoch: 94, train accuracy: 0.8135, train_loss_norm:0.0450, valid_acc: 0.8008, valid_loss_norm: 0.0449\n",
      " epoch: 95, train accuracy: 0.8138, train_loss_norm:0.0448, valid_acc: 0.8014, valid_loss_norm: 0.0447\n",
      " epoch: 96, train accuracy: 0.8141, train_loss_norm:0.0446, valid_acc: 0.8022, valid_loss_norm: 0.0445\n",
      " epoch: 97, train accuracy: 0.8142, train_loss_norm:0.0444, valid_acc: 0.8025, valid_loss_norm: 0.0443\n",
      " epoch: 98, train accuracy: 0.8144, train_loss_norm:0.0442, valid_acc: 0.8025, valid_loss_norm: 0.0441\n",
      " epoch: 99, train accuracy: 0.8148, train_loss_norm:0.0441, valid_acc: 0.8031, valid_loss_norm: 0.0440\n",
      " epoch: 100, train accuracy: 0.8152, train_loss_norm:0.0439, valid_acc: 0.8040, valid_loss_norm: 0.0438\n",
      " epoch: 101, train accuracy: 0.8154, train_loss_norm:0.0437, valid_acc: 0.8048, valid_loss_norm: 0.0436\n",
      " epoch: 102, train accuracy: 0.8156, train_loss_norm:0.0435, valid_acc: 0.8054, valid_loss_norm: 0.0434\n",
      " epoch: 103, train accuracy: 0.8161, train_loss_norm:0.0433, valid_acc: 0.8060, valid_loss_norm: 0.0433\n",
      " epoch: 104, train accuracy: 0.8165, train_loss_norm:0.0432, valid_acc: 0.8066, valid_loss_norm: 0.0431\n",
      " epoch: 105, train accuracy: 0.8169, train_loss_norm:0.0430, valid_acc: 0.8066, valid_loss_norm: 0.0429\n",
      " epoch: 106, train accuracy: 0.8171, train_loss_norm:0.0428, valid_acc: 0.8068, valid_loss_norm: 0.0428\n",
      " epoch: 107, train accuracy: 0.8172, train_loss_norm:0.0427, valid_acc: 0.8077, valid_loss_norm: 0.0426\n",
      " epoch: 108, train accuracy: 0.8172, train_loss_norm:0.0425, valid_acc: 0.8077, valid_loss_norm: 0.0424\n",
      " epoch: 109, train accuracy: 0.8176, train_loss_norm:0.0423, valid_acc: 0.8080, valid_loss_norm: 0.0423\n",
      " epoch: 110, train accuracy: 0.8180, train_loss_norm:0.0422, valid_acc: 0.8080, valid_loss_norm: 0.0421\n",
      " epoch: 111, train accuracy: 0.8184, train_loss_norm:0.0420, valid_acc: 0.8080, valid_loss_norm: 0.0420\n",
      " epoch: 112, train accuracy: 0.8188, train_loss_norm:0.0419, valid_acc: 0.8083, valid_loss_norm: 0.0418\n",
      " epoch: 113, train accuracy: 0.8189, train_loss_norm:0.0417, valid_acc: 0.8083, valid_loss_norm: 0.0417\n",
      " epoch: 114, train accuracy: 0.8191, train_loss_norm:0.0416, valid_acc: 0.8080, valid_loss_norm: 0.0415\n",
      " epoch: 115, train accuracy: 0.8193, train_loss_norm:0.0414, valid_acc: 0.8077, valid_loss_norm: 0.0414\n",
      " epoch: 116, train accuracy: 0.8194, train_loss_norm:0.0412, valid_acc: 0.8077, valid_loss_norm: 0.0412\n",
      " epoch: 117, train accuracy: 0.8195, train_loss_norm:0.0411, valid_acc: 0.8077, valid_loss_norm: 0.0411\n",
      " epoch: 118, train accuracy: 0.8198, train_loss_norm:0.0410, valid_acc: 0.8080, valid_loss_norm: 0.0409\n",
      " epoch: 119, train accuracy: 0.8201, train_loss_norm:0.0408, valid_acc: 0.8080, valid_loss_norm: 0.0408\n",
      " epoch: 120, train accuracy: 0.8202, train_loss_norm:0.0407, valid_acc: 0.8083, valid_loss_norm: 0.0407\n",
      " epoch: 121, train accuracy: 0.8204, train_loss_norm:0.0405, valid_acc: 0.8083, valid_loss_norm: 0.0405\n",
      " epoch: 122, train accuracy: 0.8205, train_loss_norm:0.0404, valid_acc: 0.8086, valid_loss_norm: 0.0404\n",
      " epoch: 123, train accuracy: 0.8208, train_loss_norm:0.0402, valid_acc: 0.8086, valid_loss_norm: 0.0403\n",
      " epoch: 124, train accuracy: 0.8209, train_loss_norm:0.0401, valid_acc: 0.8089, valid_loss_norm: 0.0401\n",
      " epoch: 125, train accuracy: 0.8212, train_loss_norm:0.0400, valid_acc: 0.8091, valid_loss_norm: 0.0400\n",
      " epoch: 126, train accuracy: 0.8213, train_loss_norm:0.0398, valid_acc: 0.8091, valid_loss_norm: 0.0399\n",
      " epoch: 127, train accuracy: 0.8213, train_loss_norm:0.0397, valid_acc: 0.8091, valid_loss_norm: 0.0397\n",
      " epoch: 128, train accuracy: 0.8214, train_loss_norm:0.0396, valid_acc: 0.8091, valid_loss_norm: 0.0396\n",
      " epoch: 129, train accuracy: 0.8216, train_loss_norm:0.0394, valid_acc: 0.8089, valid_loss_norm: 0.0395\n",
      " epoch: 130, train accuracy: 0.8220, train_loss_norm:0.0393, valid_acc: 0.8089, valid_loss_norm: 0.0394\n",
      " epoch: 131, train accuracy: 0.8221, train_loss_norm:0.0392, valid_acc: 0.8089, valid_loss_norm: 0.0392\n",
      " epoch: 132, train accuracy: 0.8223, train_loss_norm:0.0391, valid_acc: 0.8094, valid_loss_norm: 0.0391\n",
      " epoch: 133, train accuracy: 0.8223, train_loss_norm:0.0389, valid_acc: 0.8094, valid_loss_norm: 0.0390\n",
      " epoch: 134, train accuracy: 0.8225, train_loss_norm:0.0388, valid_acc: 0.8094, valid_loss_norm: 0.0389\n",
      " epoch: 135, train accuracy: 0.8226, train_loss_norm:0.0387, valid_acc: 0.8100, valid_loss_norm: 0.0387\n",
      " epoch: 136, train accuracy: 0.8229, train_loss_norm:0.0386, valid_acc: 0.8103, valid_loss_norm: 0.0386\n",
      " epoch: 137, train accuracy: 0.8232, train_loss_norm:0.0384, valid_acc: 0.8103, valid_loss_norm: 0.0385\n",
      " epoch: 138, train accuracy: 0.8234, train_loss_norm:0.0383, valid_acc: 0.8109, valid_loss_norm: 0.0384\n",
      " epoch: 139, train accuracy: 0.8235, train_loss_norm:0.0382, valid_acc: 0.8114, valid_loss_norm: 0.0383\n",
      " epoch: 140, train accuracy: 0.8237, train_loss_norm:0.0381, valid_acc: 0.8117, valid_loss_norm: 0.0382\n",
      " epoch: 141, train accuracy: 0.8240, train_loss_norm:0.0380, valid_acc: 0.8129, valid_loss_norm: 0.0381\n",
      " epoch: 142, train accuracy: 0.8242, train_loss_norm:0.0378, valid_acc: 0.8135, valid_loss_norm: 0.0379\n",
      " epoch: 143, train accuracy: 0.8243, train_loss_norm:0.0377, valid_acc: 0.8135, valid_loss_norm: 0.0378\n",
      " epoch: 144, train accuracy: 0.8244, train_loss_norm:0.0376, valid_acc: 0.8137, valid_loss_norm: 0.0377\n",
      " epoch: 145, train accuracy: 0.8247, train_loss_norm:0.0375, valid_acc: 0.8137, valid_loss_norm: 0.0376\n",
      " epoch: 146, train accuracy: 0.8249, train_loss_norm:0.0374, valid_acc: 0.8137, valid_loss_norm: 0.0375\n",
      " epoch: 147, train accuracy: 0.8250, train_loss_norm:0.0373, valid_acc: 0.8137, valid_loss_norm: 0.0374\n",
      " epoch: 148, train accuracy: 0.8254, train_loss_norm:0.0372, valid_acc: 0.8143, valid_loss_norm: 0.0373\n",
      " epoch: 149, train accuracy: 0.8255, train_loss_norm:0.0371, valid_acc: 0.8143, valid_loss_norm: 0.0372\n",
      " epoch: 150, train accuracy: 0.8257, train_loss_norm:0.0370, valid_acc: 0.8146, valid_loss_norm: 0.0371\n",
      " epoch: 151, train accuracy: 0.8259, train_loss_norm:0.0369, valid_acc: 0.8146, valid_loss_norm: 0.0370\n",
      " epoch: 152, train accuracy: 0.8262, train_loss_norm:0.0368, valid_acc: 0.8146, valid_loss_norm: 0.0369\n",
      " epoch: 153, train accuracy: 0.8264, train_loss_norm:0.0366, valid_acc: 0.8152, valid_loss_norm: 0.0368\n",
      " epoch: 154, train accuracy: 0.8265, train_loss_norm:0.0365, valid_acc: 0.8149, valid_loss_norm: 0.0367\n",
      " epoch: 155, train accuracy: 0.8266, train_loss_norm:0.0364, valid_acc: 0.8149, valid_loss_norm: 0.0366\n",
      " epoch: 156, train accuracy: 0.8268, train_loss_norm:0.0363, valid_acc: 0.8149, valid_loss_norm: 0.0365\n",
      " epoch: 157, train accuracy: 0.8270, train_loss_norm:0.0362, valid_acc: 0.8143, valid_loss_norm: 0.0364\n",
      " epoch: 158, train accuracy: 0.8273, train_loss_norm:0.0361, valid_acc: 0.8143, valid_loss_norm: 0.0363\n",
      " epoch: 159, train accuracy: 0.8277, train_loss_norm:0.0360, valid_acc: 0.8149, valid_loss_norm: 0.0362\n",
      " epoch: 160, train accuracy: 0.8278, train_loss_norm:0.0359, valid_acc: 0.8152, valid_loss_norm: 0.0361\n",
      " epoch: 161, train accuracy: 0.8280, train_loss_norm:0.0358, valid_acc: 0.8152, valid_loss_norm: 0.0360\n",
      " epoch: 162, train accuracy: 0.8283, train_loss_norm:0.0358, valid_acc: 0.8152, valid_loss_norm: 0.0359\n",
      " epoch: 163, train accuracy: 0.8286, train_loss_norm:0.0357, valid_acc: 0.8160, valid_loss_norm: 0.0358\n",
      " epoch: 164, train accuracy: 0.8288, train_loss_norm:0.0356, valid_acc: 0.8160, valid_loss_norm: 0.0357\n",
      " epoch: 165, train accuracy: 0.8291, train_loss_norm:0.0355, valid_acc: 0.8163, valid_loss_norm: 0.0357\n",
      " epoch: 166, train accuracy: 0.8291, train_loss_norm:0.0354, valid_acc: 0.8163, valid_loss_norm: 0.0356\n",
      " epoch: 167, train accuracy: 0.8293, train_loss_norm:0.0353, valid_acc: 0.8166, valid_loss_norm: 0.0355\n",
      " epoch: 168, train accuracy: 0.8296, train_loss_norm:0.0352, valid_acc: 0.8166, valid_loss_norm: 0.0354\n",
      " epoch: 169, train accuracy: 0.8297, train_loss_norm:0.0351, valid_acc: 0.8166, valid_loss_norm: 0.0353\n",
      " epoch: 170, train accuracy: 0.8300, train_loss_norm:0.0350, valid_acc: 0.8166, valid_loss_norm: 0.0352\n",
      " epoch: 171, train accuracy: 0.8300, train_loss_norm:0.0349, valid_acc: 0.8166, valid_loss_norm: 0.0351\n",
      " epoch: 172, train accuracy: 0.8301, train_loss_norm:0.0348, valid_acc: 0.8166, valid_loss_norm: 0.0350\n",
      " epoch: 173, train accuracy: 0.8303, train_loss_norm:0.0347, valid_acc: 0.8166, valid_loss_norm: 0.0350\n",
      " epoch: 174, train accuracy: 0.8307, train_loss_norm:0.0347, valid_acc: 0.8166, valid_loss_norm: 0.0349\n",
      " epoch: 175, train accuracy: 0.8309, train_loss_norm:0.0346, valid_acc: 0.8166, valid_loss_norm: 0.0348\n",
      " epoch: 176, train accuracy: 0.8310, train_loss_norm:0.0345, valid_acc: 0.8166, valid_loss_norm: 0.0347\n",
      " epoch: 177, train accuracy: 0.8313, train_loss_norm:0.0344, valid_acc: 0.8169, valid_loss_norm: 0.0346\n",
      " epoch: 178, train accuracy: 0.8314, train_loss_norm:0.0343, valid_acc: 0.8169, valid_loss_norm: 0.0346\n",
      " epoch: 179, train accuracy: 0.8315, train_loss_norm:0.0342, valid_acc: 0.8169, valid_loss_norm: 0.0345\n",
      " epoch: 180, train accuracy: 0.8317, train_loss_norm:0.0341, valid_acc: 0.8169, valid_loss_norm: 0.0344\n",
      " epoch: 181, train accuracy: 0.8320, train_loss_norm:0.0341, valid_acc: 0.8172, valid_loss_norm: 0.0343\n",
      " epoch: 182, train accuracy: 0.8324, train_loss_norm:0.0340, valid_acc: 0.8172, valid_loss_norm: 0.0342\n",
      " epoch: 183, train accuracy: 0.8324, train_loss_norm:0.0339, valid_acc: 0.8172, valid_loss_norm: 0.0342\n",
      " epoch: 184, train accuracy: 0.8326, train_loss_norm:0.0338, valid_acc: 0.8172, valid_loss_norm: 0.0341\n",
      " epoch: 185, train accuracy: 0.8327, train_loss_norm:0.0337, valid_acc: 0.8175, valid_loss_norm: 0.0340\n",
      " epoch: 186, train accuracy: 0.8329, train_loss_norm:0.0337, valid_acc: 0.8181, valid_loss_norm: 0.0339\n",
      " epoch: 187, train accuracy: 0.8332, train_loss_norm:0.0336, valid_acc: 0.8181, valid_loss_norm: 0.0338\n",
      " epoch: 188, train accuracy: 0.8333, train_loss_norm:0.0335, valid_acc: 0.8181, valid_loss_norm: 0.0338\n",
      " epoch: 189, train accuracy: 0.8334, train_loss_norm:0.0334, valid_acc: 0.8186, valid_loss_norm: 0.0337\n",
      " epoch: 190, train accuracy: 0.8337, train_loss_norm:0.0333, valid_acc: 0.8189, valid_loss_norm: 0.0336\n",
      " epoch: 191, train accuracy: 0.8337, train_loss_norm:0.0333, valid_acc: 0.8189, valid_loss_norm: 0.0336\n",
      " epoch: 192, train accuracy: 0.8339, train_loss_norm:0.0332, valid_acc: 0.8195, valid_loss_norm: 0.0335\n",
      " epoch: 193, train accuracy: 0.8339, train_loss_norm:0.0331, valid_acc: 0.8198, valid_loss_norm: 0.0334\n",
      " epoch: 194, train accuracy: 0.8343, train_loss_norm:0.0330, valid_acc: 0.8201, valid_loss_norm: 0.0333\n",
      " epoch: 195, train accuracy: 0.8345, train_loss_norm:0.0330, valid_acc: 0.8195, valid_loss_norm: 0.0333\n",
      " epoch: 196, train accuracy: 0.8347, train_loss_norm:0.0329, valid_acc: 0.8201, valid_loss_norm: 0.0332\n",
      " epoch: 197, train accuracy: 0.8347, train_loss_norm:0.0328, valid_acc: 0.8201, valid_loss_norm: 0.0331\n",
      " epoch: 198, train accuracy: 0.8348, train_loss_norm:0.0327, valid_acc: 0.8204, valid_loss_norm: 0.0331\n",
      " epoch: 199, train accuracy: 0.8350, train_loss_norm:0.0327, valid_acc: 0.8204, valid_loss_norm: 0.0330\n",
      " epoch: 200, train accuracy: 0.8352, train_loss_norm:0.0326, valid_acc: 0.8206, valid_loss_norm: 0.0329\n",
      " epoch: 201, train accuracy: 0.8356, train_loss_norm:0.0325, valid_acc: 0.8206, valid_loss_norm: 0.0328\n",
      " epoch: 202, train accuracy: 0.8357, train_loss_norm:0.0325, valid_acc: 0.8206, valid_loss_norm: 0.0328\n",
      " epoch: 203, train accuracy: 0.8359, train_loss_norm:0.0324, valid_acc: 0.8206, valid_loss_norm: 0.0327\n",
      " epoch: 204, train accuracy: 0.8361, train_loss_norm:0.0323, valid_acc: 0.8209, valid_loss_norm: 0.0326\n",
      " epoch: 205, train accuracy: 0.8362, train_loss_norm:0.0322, valid_acc: 0.8212, valid_loss_norm: 0.0326\n",
      " epoch: 206, train accuracy: 0.8363, train_loss_norm:0.0322, valid_acc: 0.8215, valid_loss_norm: 0.0325\n",
      " epoch: 207, train accuracy: 0.8365, train_loss_norm:0.0321, valid_acc: 0.8215, valid_loss_norm: 0.0324\n",
      " epoch: 208, train accuracy: 0.8366, train_loss_norm:0.0320, valid_acc: 0.8215, valid_loss_norm: 0.0324\n",
      " epoch: 209, train accuracy: 0.8367, train_loss_norm:0.0320, valid_acc: 0.8215, valid_loss_norm: 0.0323\n",
      " epoch: 210, train accuracy: 0.8368, train_loss_norm:0.0319, valid_acc: 0.8215, valid_loss_norm: 0.0322\n",
      " epoch: 211, train accuracy: 0.8371, train_loss_norm:0.0318, valid_acc: 0.8218, valid_loss_norm: 0.0322\n",
      " epoch: 212, train accuracy: 0.8373, train_loss_norm:0.0318, valid_acc: 0.8218, valid_loss_norm: 0.0321\n",
      " epoch: 213, train accuracy: 0.8374, train_loss_norm:0.0317, valid_acc: 0.8224, valid_loss_norm: 0.0321\n",
      " epoch: 214, train accuracy: 0.8375, train_loss_norm:0.0316, valid_acc: 0.8224, valid_loss_norm: 0.0320\n",
      " epoch: 215, train accuracy: 0.8375, train_loss_norm:0.0316, valid_acc: 0.8224, valid_loss_norm: 0.0319\n",
      " epoch: 216, train accuracy: 0.8376, train_loss_norm:0.0315, valid_acc: 0.8221, valid_loss_norm: 0.0319\n",
      " epoch: 217, train accuracy: 0.8378, train_loss_norm:0.0314, valid_acc: 0.8221, valid_loss_norm: 0.0318\n",
      " epoch: 218, train accuracy: 0.8380, train_loss_norm:0.0314, valid_acc: 0.8224, valid_loss_norm: 0.0317\n",
      " epoch: 219, train accuracy: 0.8383, train_loss_norm:0.0313, valid_acc: 0.8227, valid_loss_norm: 0.0317\n",
      " epoch: 220, train accuracy: 0.8383, train_loss_norm:0.0313, valid_acc: 0.8227, valid_loss_norm: 0.0316\n",
      " epoch: 221, train accuracy: 0.8383, train_loss_norm:0.0312, valid_acc: 0.8229, valid_loss_norm: 0.0316\n",
      " epoch: 222, train accuracy: 0.8384, train_loss_norm:0.0311, valid_acc: 0.8235, valid_loss_norm: 0.0315\n",
      " epoch: 223, train accuracy: 0.8386, train_loss_norm:0.0311, valid_acc: 0.8238, valid_loss_norm: 0.0315\n",
      " epoch: 224, train accuracy: 0.8387, train_loss_norm:0.0310, valid_acc: 0.8241, valid_loss_norm: 0.0314\n",
      " epoch: 225, train accuracy: 0.8388, train_loss_norm:0.0309, valid_acc: 0.8241, valid_loss_norm: 0.0313\n",
      " epoch: 226, train accuracy: 0.8389, train_loss_norm:0.0309, valid_acc: 0.8241, valid_loss_norm: 0.0313\n",
      " epoch: 227, train accuracy: 0.8391, train_loss_norm:0.0308, valid_acc: 0.8241, valid_loss_norm: 0.0312\n",
      " epoch: 228, train accuracy: 0.8392, train_loss_norm:0.0308, valid_acc: 0.8241, valid_loss_norm: 0.0312\n",
      " epoch: 229, train accuracy: 0.8393, train_loss_norm:0.0307, valid_acc: 0.8241, valid_loss_norm: 0.0311\n",
      " epoch: 230, train accuracy: 0.8396, train_loss_norm:0.0306, valid_acc: 0.8244, valid_loss_norm: 0.0310\n",
      " epoch: 231, train accuracy: 0.8398, train_loss_norm:0.0306, valid_acc: 0.8247, valid_loss_norm: 0.0310\n",
      " epoch: 232, train accuracy: 0.8399, train_loss_norm:0.0305, valid_acc: 0.8249, valid_loss_norm: 0.0309\n",
      " epoch: 233, train accuracy: 0.8400, train_loss_norm:0.0305, valid_acc: 0.8252, valid_loss_norm: 0.0309\n",
      " epoch: 234, train accuracy: 0.8401, train_loss_norm:0.0304, valid_acc: 0.8258, valid_loss_norm: 0.0308\n",
      " epoch: 235, train accuracy: 0.8401, train_loss_norm:0.0303, valid_acc: 0.8258, valid_loss_norm: 0.0308\n",
      " epoch: 236, train accuracy: 0.8401, train_loss_norm:0.0303, valid_acc: 0.8261, valid_loss_norm: 0.0307\n",
      " epoch: 237, train accuracy: 0.8403, train_loss_norm:0.0302, valid_acc: 0.8261, valid_loss_norm: 0.0307\n",
      " epoch: 238, train accuracy: 0.8404, train_loss_norm:0.0302, valid_acc: 0.8261, valid_loss_norm: 0.0306\n",
      " epoch: 239, train accuracy: 0.8404, train_loss_norm:0.0301, valid_acc: 0.8261, valid_loss_norm: 0.0306\n",
      " epoch: 240, train accuracy: 0.8407, train_loss_norm:0.0301, valid_acc: 0.8264, valid_loss_norm: 0.0305\n",
      " epoch: 241, train accuracy: 0.8408, train_loss_norm:0.0300, valid_acc: 0.8264, valid_loss_norm: 0.0304\n",
      " epoch: 242, train accuracy: 0.8410, train_loss_norm:0.0300, valid_acc: 0.8264, valid_loss_norm: 0.0304\n",
      " epoch: 243, train accuracy: 0.8411, train_loss_norm:0.0299, valid_acc: 0.8264, valid_loss_norm: 0.0303\n",
      " epoch: 244, train accuracy: 0.8412, train_loss_norm:0.0298, valid_acc: 0.8264, valid_loss_norm: 0.0303\n",
      " epoch: 245, train accuracy: 0.8413, train_loss_norm:0.0298, valid_acc: 0.8264, valid_loss_norm: 0.0302\n",
      " epoch: 246, train accuracy: 0.8413, train_loss_norm:0.0297, valid_acc: 0.8264, valid_loss_norm: 0.0302\n",
      " epoch: 247, train accuracy: 0.8414, train_loss_norm:0.0297, valid_acc: 0.8272, valid_loss_norm: 0.0301\n",
      " epoch: 248, train accuracy: 0.8415, train_loss_norm:0.0296, valid_acc: 0.8272, valid_loss_norm: 0.0301\n",
      " epoch: 249, train accuracy: 0.8416, train_loss_norm:0.0296, valid_acc: 0.8275, valid_loss_norm: 0.0300\n",
      " epoch: 250, train accuracy: 0.8416, train_loss_norm:0.0295, valid_acc: 0.8278, valid_loss_norm: 0.0300\n",
      " epoch: 251, train accuracy: 0.8418, train_loss_norm:0.0295, valid_acc: 0.8281, valid_loss_norm: 0.0299\n",
      " epoch: 252, train accuracy: 0.8419, train_loss_norm:0.0294, valid_acc: 0.8284, valid_loss_norm: 0.0299\n",
      " epoch: 253, train accuracy: 0.8421, train_loss_norm:0.0294, valid_acc: 0.8290, valid_loss_norm: 0.0298\n",
      " epoch: 254, train accuracy: 0.8422, train_loss_norm:0.0293, valid_acc: 0.8295, valid_loss_norm: 0.0298\n",
      " epoch: 255, train accuracy: 0.8424, train_loss_norm:0.0293, valid_acc: 0.8301, valid_loss_norm: 0.0297\n",
      " epoch: 256, train accuracy: 0.8424, train_loss_norm:0.0292, valid_acc: 0.8304, valid_loss_norm: 0.0297\n",
      " epoch: 257, train accuracy: 0.8424, train_loss_norm:0.0292, valid_acc: 0.8304, valid_loss_norm: 0.0296\n",
      " epoch: 258, train accuracy: 0.8427, train_loss_norm:0.0291, valid_acc: 0.8304, valid_loss_norm: 0.0296\n",
      " epoch: 259, train accuracy: 0.8427, train_loss_norm:0.0291, valid_acc: 0.8304, valid_loss_norm: 0.0296\n",
      " epoch: 260, train accuracy: 0.8429, train_loss_norm:0.0290, valid_acc: 0.8307, valid_loss_norm: 0.0295\n",
      " epoch: 261, train accuracy: 0.8430, train_loss_norm:0.0290, valid_acc: 0.8307, valid_loss_norm: 0.0295\n",
      " epoch: 262, train accuracy: 0.8431, train_loss_norm:0.0289, valid_acc: 0.8304, valid_loss_norm: 0.0294\n",
      " epoch: 263, train accuracy: 0.8432, train_loss_norm:0.0289, valid_acc: 0.8307, valid_loss_norm: 0.0294\n",
      " epoch: 264, train accuracy: 0.8433, train_loss_norm:0.0288, valid_acc: 0.8307, valid_loss_norm: 0.0293\n",
      " epoch: 265, train accuracy: 0.8434, train_loss_norm:0.0288, valid_acc: 0.8304, valid_loss_norm: 0.0293\n",
      " epoch: 266, train accuracy: 0.8435, train_loss_norm:0.0287, valid_acc: 0.8307, valid_loss_norm: 0.0292\n",
      " epoch: 267, train accuracy: 0.8435, train_loss_norm:0.0287, valid_acc: 0.8307, valid_loss_norm: 0.0292\n",
      " epoch: 268, train accuracy: 0.8436, train_loss_norm:0.0286, valid_acc: 0.8304, valid_loss_norm: 0.0291\n",
      " epoch: 269, train accuracy: 0.8438, train_loss_norm:0.0286, valid_acc: 0.8307, valid_loss_norm: 0.0291\n",
      " epoch: 270, train accuracy: 0.8438, train_loss_norm:0.0285, valid_acc: 0.8307, valid_loss_norm: 0.0290\n",
      " epoch: 271, train accuracy: 0.8438, train_loss_norm:0.0285, valid_acc: 0.8310, valid_loss_norm: 0.0290\n",
      " epoch: 272, train accuracy: 0.8439, train_loss_norm:0.0284, valid_acc: 0.8310, valid_loss_norm: 0.0290\n",
      " epoch: 273, train accuracy: 0.8439, train_loss_norm:0.0284, valid_acc: 0.8310, valid_loss_norm: 0.0289\n",
      " epoch: 274, train accuracy: 0.8440, train_loss_norm:0.0283, valid_acc: 0.8313, valid_loss_norm: 0.0289\n",
      " epoch: 275, train accuracy: 0.8443, train_loss_norm:0.0283, valid_acc: 0.8313, valid_loss_norm: 0.0288\n",
      " epoch: 276, train accuracy: 0.8443, train_loss_norm:0.0283, valid_acc: 0.8313, valid_loss_norm: 0.0288\n",
      " epoch: 277, train accuracy: 0.8444, train_loss_norm:0.0282, valid_acc: 0.8316, valid_loss_norm: 0.0287\n",
      " epoch: 278, train accuracy: 0.8446, train_loss_norm:0.0282, valid_acc: 0.8318, valid_loss_norm: 0.0287\n",
      " epoch: 279, train accuracy: 0.8446, train_loss_norm:0.0281, valid_acc: 0.8321, valid_loss_norm: 0.0287\n",
      " epoch: 280, train accuracy: 0.8447, train_loss_norm:0.0281, valid_acc: 0.8321, valid_loss_norm: 0.0286\n",
      " epoch: 281, train accuracy: 0.8446, train_loss_norm:0.0280, valid_acc: 0.8324, valid_loss_norm: 0.0286\n",
      " epoch: 282, train accuracy: 0.8448, train_loss_norm:0.0280, valid_acc: 0.8324, valid_loss_norm: 0.0285\n",
      " epoch: 283, train accuracy: 0.8447, train_loss_norm:0.0279, valid_acc: 0.8324, valid_loss_norm: 0.0285\n",
      " epoch: 284, train accuracy: 0.8448, train_loss_norm:0.0279, valid_acc: 0.8324, valid_loss_norm: 0.0284\n",
      " epoch: 285, train accuracy: 0.8448, train_loss_norm:0.0279, valid_acc: 0.8327, valid_loss_norm: 0.0284\n",
      " epoch: 286, train accuracy: 0.8450, train_loss_norm:0.0278, valid_acc: 0.8330, valid_loss_norm: 0.0284\n",
      " epoch: 287, train accuracy: 0.8450, train_loss_norm:0.0278, valid_acc: 0.8330, valid_loss_norm: 0.0283\n",
      " epoch: 288, train accuracy: 0.8451, train_loss_norm:0.0277, valid_acc: 0.8330, valid_loss_norm: 0.0283\n",
      " epoch: 289, train accuracy: 0.8452, train_loss_norm:0.0277, valid_acc: 0.8333, valid_loss_norm: 0.0282\n",
      " epoch: 290, train accuracy: 0.8452, train_loss_norm:0.0276, valid_acc: 0.8339, valid_loss_norm: 0.0282\n",
      " epoch: 291, train accuracy: 0.8453, train_loss_norm:0.0276, valid_acc: 0.8339, valid_loss_norm: 0.0282\n",
      " epoch: 292, train accuracy: 0.8454, train_loss_norm:0.0276, valid_acc: 0.8339, valid_loss_norm: 0.0281\n",
      " epoch: 293, train accuracy: 0.8453, train_loss_norm:0.0275, valid_acc: 0.8339, valid_loss_norm: 0.0281\n",
      " epoch: 294, train accuracy: 0.8454, train_loss_norm:0.0275, valid_acc: 0.8339, valid_loss_norm: 0.0280\n",
      " epoch: 295, train accuracy: 0.8455, train_loss_norm:0.0274, valid_acc: 0.8341, valid_loss_norm: 0.0280\n",
      " epoch: 296, train accuracy: 0.8456, train_loss_norm:0.0274, valid_acc: 0.8341, valid_loss_norm: 0.0280\n",
      " epoch: 297, train accuracy: 0.8456, train_loss_norm:0.0273, valid_acc: 0.8341, valid_loss_norm: 0.0279\n",
      " epoch: 298, train accuracy: 0.8456, train_loss_norm:0.0273, valid_acc: 0.8344, valid_loss_norm: 0.0279\n",
      " epoch: 299, train accuracy: 0.8458, train_loss_norm:0.0273, valid_acc: 0.8344, valid_loss_norm: 0.0279\n",
      " epoch: 300, train accuracy: 0.8458, train_loss_norm:0.0272, valid_acc: 0.8347, valid_loss_norm: 0.0278\n",
      "Test accuracy: 0.8244\n",
      "Test loss norm: 0.0287\n",
      "Cur fold: 7\n",
      "(27841, 300)\n",
      "(3479, 300)\n",
      "(3479, 300)\n",
      " epoch: 1, train accuracy: 0.7907, train_loss_norm:0.0867, valid_acc: 0.7732, valid_loss_norm: 0.0867\n",
      " epoch: 2, train accuracy: 0.7907, train_loss_norm:0.0859, valid_acc: 0.7732, valid_loss_norm: 0.0859\n",
      " epoch: 3, train accuracy: 0.7908, train_loss_norm:0.0852, valid_acc: 0.7732, valid_loss_norm: 0.0852\n",
      " epoch: 4, train accuracy: 0.7908, train_loss_norm:0.0844, valid_acc: 0.7732, valid_loss_norm: 0.0844\n",
      " epoch: 5, train accuracy: 0.7908, train_loss_norm:0.0836, valid_acc: 0.7732, valid_loss_norm: 0.0837\n",
      " epoch: 6, train accuracy: 0.7908, train_loss_norm:0.0829, valid_acc: 0.7732, valid_loss_norm: 0.0829\n",
      " epoch: 7, train accuracy: 0.7908, train_loss_norm:0.0821, valid_acc: 0.7732, valid_loss_norm: 0.0822\n",
      " epoch: 8, train accuracy: 0.7908, train_loss_norm:0.0814, valid_acc: 0.7732, valid_loss_norm: 0.0815\n",
      " epoch: 9, train accuracy: 0.7910, train_loss_norm:0.0807, valid_acc: 0.7732, valid_loss_norm: 0.0808\n",
      " epoch: 10, train accuracy: 0.7910, train_loss_norm:0.0799, valid_acc: 0.7732, valid_loss_norm: 0.0800\n",
      " epoch: 11, train accuracy: 0.7911, train_loss_norm:0.0792, valid_acc: 0.7732, valid_loss_norm: 0.0793\n",
      " epoch: 12, train accuracy: 0.7911, train_loss_norm:0.0785, valid_acc: 0.7732, valid_loss_norm: 0.0786\n",
      " epoch: 13, train accuracy: 0.7911, train_loss_norm:0.0778, valid_acc: 0.7732, valid_loss_norm: 0.0779\n",
      " epoch: 14, train accuracy: 0.7913, train_loss_norm:0.0771, valid_acc: 0.7732, valid_loss_norm: 0.0772\n",
      " epoch: 15, train accuracy: 0.7914, train_loss_norm:0.0764, valid_acc: 0.7732, valid_loss_norm: 0.0765\n",
      " epoch: 16, train accuracy: 0.7917, train_loss_norm:0.0757, valid_acc: 0.7732, valid_loss_norm: 0.0758\n",
      " epoch: 17, train accuracy: 0.7916, train_loss_norm:0.0750, valid_acc: 0.7735, valid_loss_norm: 0.0751\n",
      " epoch: 18, train accuracy: 0.7917, train_loss_norm:0.0743, valid_acc: 0.7738, valid_loss_norm: 0.0745\n",
      " epoch: 19, train accuracy: 0.7917, train_loss_norm:0.0736, valid_acc: 0.7738, valid_loss_norm: 0.0738\n",
      " epoch: 20, train accuracy: 0.7917, train_loss_norm:0.0730, valid_acc: 0.7738, valid_loss_norm: 0.0731\n",
      " epoch: 21, train accuracy: 0.7918, train_loss_norm:0.0723, valid_acc: 0.7738, valid_loss_norm: 0.0725\n",
      " epoch: 22, train accuracy: 0.7920, train_loss_norm:0.0717, valid_acc: 0.7732, valid_loss_norm: 0.0719\n",
      " epoch: 23, train accuracy: 0.7921, train_loss_norm:0.0710, valid_acc: 0.7732, valid_loss_norm: 0.0712\n",
      " epoch: 24, train accuracy: 0.7923, train_loss_norm:0.0704, valid_acc: 0.7729, valid_loss_norm: 0.0706\n",
      " epoch: 25, train accuracy: 0.7925, train_loss_norm:0.0698, valid_acc: 0.7729, valid_loss_norm: 0.0700\n",
      " epoch: 26, train accuracy: 0.7926, train_loss_norm:0.0692, valid_acc: 0.7732, valid_loss_norm: 0.0694\n",
      " epoch: 27, train accuracy: 0.7928, train_loss_norm:0.0686, valid_acc: 0.7729, valid_loss_norm: 0.0688\n",
      " epoch: 28, train accuracy: 0.7930, train_loss_norm:0.0680, valid_acc: 0.7729, valid_loss_norm: 0.0682\n",
      " epoch: 29, train accuracy: 0.7930, train_loss_norm:0.0674, valid_acc: 0.7729, valid_loss_norm: 0.0676\n",
      " epoch: 30, train accuracy: 0.7932, train_loss_norm:0.0668, valid_acc: 0.7732, valid_loss_norm: 0.0671\n",
      " epoch: 31, train accuracy: 0.7932, train_loss_norm:0.0662, valid_acc: 0.7729, valid_loss_norm: 0.0665\n",
      " epoch: 32, train accuracy: 0.7934, train_loss_norm:0.0657, valid_acc: 0.7729, valid_loss_norm: 0.0659\n",
      " epoch: 33, train accuracy: 0.7938, train_loss_norm:0.0651, valid_acc: 0.7732, valid_loss_norm: 0.0654\n",
      " epoch: 34, train accuracy: 0.7941, train_loss_norm:0.0646, valid_acc: 0.7732, valid_loss_norm: 0.0649\n",
      " epoch: 35, train accuracy: 0.7942, train_loss_norm:0.0641, valid_acc: 0.7735, valid_loss_norm: 0.0644\n",
      " epoch: 36, train accuracy: 0.7943, train_loss_norm:0.0635, valid_acc: 0.7738, valid_loss_norm: 0.0639\n",
      " epoch: 37, train accuracy: 0.7944, train_loss_norm:0.0630, valid_acc: 0.7741, valid_loss_norm: 0.0634\n",
      " epoch: 38, train accuracy: 0.7949, train_loss_norm:0.0625, valid_acc: 0.7744, valid_loss_norm: 0.0629\n",
      " epoch: 39, train accuracy: 0.7952, train_loss_norm:0.0620, valid_acc: 0.7746, valid_loss_norm: 0.0624\n",
      " epoch: 40, train accuracy: 0.7953, train_loss_norm:0.0616, valid_acc: 0.7752, valid_loss_norm: 0.0619\n",
      " epoch: 41, train accuracy: 0.7956, train_loss_norm:0.0611, valid_acc: 0.7761, valid_loss_norm: 0.0614\n",
      " epoch: 42, train accuracy: 0.7958, train_loss_norm:0.0606, valid_acc: 0.7761, valid_loss_norm: 0.0610\n",
      " epoch: 43, train accuracy: 0.7959, train_loss_norm:0.0602, valid_acc: 0.7755, valid_loss_norm: 0.0605\n",
      " epoch: 44, train accuracy: 0.7961, train_loss_norm:0.0597, valid_acc: 0.7758, valid_loss_norm: 0.0601\n",
      " epoch: 45, train accuracy: 0.7965, train_loss_norm:0.0593, valid_acc: 0.7761, valid_loss_norm: 0.0597\n",
      " epoch: 46, train accuracy: 0.7968, train_loss_norm:0.0588, valid_acc: 0.7761, valid_loss_norm: 0.0592\n",
      " epoch: 47, train accuracy: 0.7972, train_loss_norm:0.0584, valid_acc: 0.7755, valid_loss_norm: 0.0588\n",
      " epoch: 48, train accuracy: 0.7974, train_loss_norm:0.0580, valid_acc: 0.7752, valid_loss_norm: 0.0584\n",
      " epoch: 49, train accuracy: 0.7976, train_loss_norm:0.0576, valid_acc: 0.7755, valid_loss_norm: 0.0580\n",
      " epoch: 50, train accuracy: 0.7980, train_loss_norm:0.0572, valid_acc: 0.7758, valid_loss_norm: 0.0576\n",
      " epoch: 51, train accuracy: 0.7981, train_loss_norm:0.0568, valid_acc: 0.7758, valid_loss_norm: 0.0573\n",
      " epoch: 52, train accuracy: 0.7984, train_loss_norm:0.0564, valid_acc: 0.7761, valid_loss_norm: 0.0569\n",
      " epoch: 53, train accuracy: 0.7988, train_loss_norm:0.0561, valid_acc: 0.7764, valid_loss_norm: 0.0565\n",
      " epoch: 54, train accuracy: 0.7993, train_loss_norm:0.0557, valid_acc: 0.7764, valid_loss_norm: 0.0562\n",
      " epoch: 55, train accuracy: 0.7995, train_loss_norm:0.0553, valid_acc: 0.7764, valid_loss_norm: 0.0558\n",
      " epoch: 56, train accuracy: 0.8000, train_loss_norm:0.0550, valid_acc: 0.7772, valid_loss_norm: 0.0555\n",
      " epoch: 57, train accuracy: 0.8002, train_loss_norm:0.0546, valid_acc: 0.7781, valid_loss_norm: 0.0551\n",
      " epoch: 58, train accuracy: 0.8006, train_loss_norm:0.0543, valid_acc: 0.7787, valid_loss_norm: 0.0548\n",
      " epoch: 59, train accuracy: 0.8008, train_loss_norm:0.0539, valid_acc: 0.7790, valid_loss_norm: 0.0544\n",
      " epoch: 60, train accuracy: 0.8011, train_loss_norm:0.0536, valid_acc: 0.7792, valid_loss_norm: 0.0541\n",
      " epoch: 61, train accuracy: 0.8017, train_loss_norm:0.0533, valid_acc: 0.7798, valid_loss_norm: 0.0538\n",
      " epoch: 62, train accuracy: 0.8021, train_loss_norm:0.0529, valid_acc: 0.7807, valid_loss_norm: 0.0535\n",
      " epoch: 63, train accuracy: 0.8023, train_loss_norm:0.0526, valid_acc: 0.7810, valid_loss_norm: 0.0532\n",
      " epoch: 64, train accuracy: 0.8027, train_loss_norm:0.0523, valid_acc: 0.7810, valid_loss_norm: 0.0529\n",
      " epoch: 65, train accuracy: 0.8032, train_loss_norm:0.0520, valid_acc: 0.7813, valid_loss_norm: 0.0526\n",
      " epoch: 66, train accuracy: 0.8035, train_loss_norm:0.0517, valid_acc: 0.7821, valid_loss_norm: 0.0523\n",
      " epoch: 67, train accuracy: 0.8040, train_loss_norm:0.0514, valid_acc: 0.7827, valid_loss_norm: 0.0520\n",
      " epoch: 68, train accuracy: 0.8045, train_loss_norm:0.0511, valid_acc: 0.7833, valid_loss_norm: 0.0517\n",
      " epoch: 69, train accuracy: 0.8046, train_loss_norm:0.0509, valid_acc: 0.7836, valid_loss_norm: 0.0515\n",
      " epoch: 70, train accuracy: 0.8049, train_loss_norm:0.0506, valid_acc: 0.7838, valid_loss_norm: 0.0512\n",
      " epoch: 71, train accuracy: 0.8052, train_loss_norm:0.0503, valid_acc: 0.7844, valid_loss_norm: 0.0509\n",
      " epoch: 72, train accuracy: 0.8055, train_loss_norm:0.0500, valid_acc: 0.7853, valid_loss_norm: 0.0507\n",
      " epoch: 73, train accuracy: 0.8058, train_loss_norm:0.0498, valid_acc: 0.7853, valid_loss_norm: 0.0504\n",
      " epoch: 74, train accuracy: 0.8060, train_loss_norm:0.0495, valid_acc: 0.7859, valid_loss_norm: 0.0501\n",
      " epoch: 75, train accuracy: 0.8063, train_loss_norm:0.0492, valid_acc: 0.7861, valid_loss_norm: 0.0499\n",
      " epoch: 76, train accuracy: 0.8066, train_loss_norm:0.0490, valid_acc: 0.7861, valid_loss_norm: 0.0496\n",
      " epoch: 77, train accuracy: 0.8070, train_loss_norm:0.0487, valid_acc: 0.7864, valid_loss_norm: 0.0494\n",
      " epoch: 78, train accuracy: 0.8075, train_loss_norm:0.0485, valid_acc: 0.7867, valid_loss_norm: 0.0492\n",
      " epoch: 79, train accuracy: 0.8080, train_loss_norm:0.0482, valid_acc: 0.7873, valid_loss_norm: 0.0489\n",
      " epoch: 80, train accuracy: 0.8084, train_loss_norm:0.0480, valid_acc: 0.7876, valid_loss_norm: 0.0487\n",
      " epoch: 81, train accuracy: 0.8087, train_loss_norm:0.0478, valid_acc: 0.7884, valid_loss_norm: 0.0485\n",
      " epoch: 82, train accuracy: 0.8089, train_loss_norm:0.0475, valid_acc: 0.7890, valid_loss_norm: 0.0482\n",
      " epoch: 83, train accuracy: 0.8092, train_loss_norm:0.0473, valid_acc: 0.7896, valid_loss_norm: 0.0480\n",
      " epoch: 84, train accuracy: 0.8096, train_loss_norm:0.0471, valid_acc: 0.7902, valid_loss_norm: 0.0478\n",
      " epoch: 85, train accuracy: 0.8100, train_loss_norm:0.0469, valid_acc: 0.7905, valid_loss_norm: 0.0476\n",
      " epoch: 86, train accuracy: 0.8101, train_loss_norm:0.0466, valid_acc: 0.7907, valid_loss_norm: 0.0474\n",
      " epoch: 87, train accuracy: 0.8102, train_loss_norm:0.0464, valid_acc: 0.7910, valid_loss_norm: 0.0472\n",
      " epoch: 88, train accuracy: 0.8104, train_loss_norm:0.0462, valid_acc: 0.7907, valid_loss_norm: 0.0470\n",
      " epoch: 89, train accuracy: 0.8107, train_loss_norm:0.0460, valid_acc: 0.7910, valid_loss_norm: 0.0468\n",
      " epoch: 90, train accuracy: 0.8109, train_loss_norm:0.0458, valid_acc: 0.7907, valid_loss_norm: 0.0466\n",
      " epoch: 91, train accuracy: 0.8110, train_loss_norm:0.0456, valid_acc: 0.7913, valid_loss_norm: 0.0464\n",
      " epoch: 92, train accuracy: 0.8115, train_loss_norm:0.0454, valid_acc: 0.7916, valid_loss_norm: 0.0462\n",
      " epoch: 93, train accuracy: 0.8116, train_loss_norm:0.0452, valid_acc: 0.7922, valid_loss_norm: 0.0460\n",
      " epoch: 94, train accuracy: 0.8118, train_loss_norm:0.0450, valid_acc: 0.7928, valid_loss_norm: 0.0458\n",
      " epoch: 95, train accuracy: 0.8120, train_loss_norm:0.0448, valid_acc: 0.7928, valid_loss_norm: 0.0456\n",
      " epoch: 96, train accuracy: 0.8121, train_loss_norm:0.0446, valid_acc: 0.7930, valid_loss_norm: 0.0454\n",
      " epoch: 97, train accuracy: 0.8124, train_loss_norm:0.0444, valid_acc: 0.7930, valid_loss_norm: 0.0452\n",
      " epoch: 98, train accuracy: 0.8126, train_loss_norm:0.0442, valid_acc: 0.7928, valid_loss_norm: 0.0451\n",
      " epoch: 99, train accuracy: 0.8128, train_loss_norm:0.0440, valid_acc: 0.7936, valid_loss_norm: 0.0449\n",
      " epoch: 100, train accuracy: 0.8131, train_loss_norm:0.0439, valid_acc: 0.7942, valid_loss_norm: 0.0447\n",
      " epoch: 101, train accuracy: 0.8132, train_loss_norm:0.0437, valid_acc: 0.7942, valid_loss_norm: 0.0445\n",
      " epoch: 102, train accuracy: 0.8134, train_loss_norm:0.0435, valid_acc: 0.7945, valid_loss_norm: 0.0444\n",
      " epoch: 103, train accuracy: 0.8135, train_loss_norm:0.0433, valid_acc: 0.7945, valid_loss_norm: 0.0442\n",
      " epoch: 104, train accuracy: 0.8138, train_loss_norm:0.0432, valid_acc: 0.7948, valid_loss_norm: 0.0440\n",
      " epoch: 105, train accuracy: 0.8142, train_loss_norm:0.0430, valid_acc: 0.7951, valid_loss_norm: 0.0439\n",
      " epoch: 106, train accuracy: 0.8145, train_loss_norm:0.0428, valid_acc: 0.7951, valid_loss_norm: 0.0437\n",
      " epoch: 107, train accuracy: 0.8148, train_loss_norm:0.0427, valid_acc: 0.7953, valid_loss_norm: 0.0435\n",
      " epoch: 108, train accuracy: 0.8149, train_loss_norm:0.0425, valid_acc: 0.7953, valid_loss_norm: 0.0434\n",
      " epoch: 109, train accuracy: 0.8153, train_loss_norm:0.0423, valid_acc: 0.7956, valid_loss_norm: 0.0432\n",
      " epoch: 110, train accuracy: 0.8156, train_loss_norm:0.0422, valid_acc: 0.7953, valid_loss_norm: 0.0431\n",
      " epoch: 111, train accuracy: 0.8158, train_loss_norm:0.0420, valid_acc: 0.7953, valid_loss_norm: 0.0429\n",
      " epoch: 112, train accuracy: 0.8161, train_loss_norm:0.0419, valid_acc: 0.7951, valid_loss_norm: 0.0428\n",
      " epoch: 113, train accuracy: 0.8166, train_loss_norm:0.0417, valid_acc: 0.7953, valid_loss_norm: 0.0426\n",
      " epoch: 114, train accuracy: 0.8170, train_loss_norm:0.0415, valid_acc: 0.7956, valid_loss_norm: 0.0425\n",
      " epoch: 115, train accuracy: 0.8172, train_loss_norm:0.0414, valid_acc: 0.7956, valid_loss_norm: 0.0423\n",
      " epoch: 116, train accuracy: 0.8175, train_loss_norm:0.0412, valid_acc: 0.7959, valid_loss_norm: 0.0422\n",
      " epoch: 117, train accuracy: 0.8179, train_loss_norm:0.0411, valid_acc: 0.7965, valid_loss_norm: 0.0420\n",
      " epoch: 118, train accuracy: 0.8181, train_loss_norm:0.0409, valid_acc: 0.7965, valid_loss_norm: 0.0419\n",
      " epoch: 119, train accuracy: 0.8184, train_loss_norm:0.0408, valid_acc: 0.7968, valid_loss_norm: 0.0417\n",
      " epoch: 120, train accuracy: 0.8186, train_loss_norm:0.0407, valid_acc: 0.7974, valid_loss_norm: 0.0416\n",
      " epoch: 121, train accuracy: 0.8189, train_loss_norm:0.0405, valid_acc: 0.7976, valid_loss_norm: 0.0415\n",
      " epoch: 122, train accuracy: 0.8190, train_loss_norm:0.0404, valid_acc: 0.7979, valid_loss_norm: 0.0413\n",
      " epoch: 123, train accuracy: 0.8193, train_loss_norm:0.0402, valid_acc: 0.7979, valid_loss_norm: 0.0412\n",
      " epoch: 124, train accuracy: 0.8194, train_loss_norm:0.0401, valid_acc: 0.7979, valid_loss_norm: 0.0411\n",
      " epoch: 125, train accuracy: 0.8197, train_loss_norm:0.0400, valid_acc: 0.7976, valid_loss_norm: 0.0409\n",
      " epoch: 126, train accuracy: 0.8200, train_loss_norm:0.0398, valid_acc: 0.7985, valid_loss_norm: 0.0408\n",
      " epoch: 127, train accuracy: 0.8205, train_loss_norm:0.0397, valid_acc: 0.7988, valid_loss_norm: 0.0407\n",
      " epoch: 128, train accuracy: 0.8207, train_loss_norm:0.0396, valid_acc: 0.7988, valid_loss_norm: 0.0405\n",
      " epoch: 129, train accuracy: 0.8207, train_loss_norm:0.0394, valid_acc: 0.7988, valid_loss_norm: 0.0404\n",
      " epoch: 130, train accuracy: 0.8208, train_loss_norm:0.0393, valid_acc: 0.7988, valid_loss_norm: 0.0403\n",
      " epoch: 131, train accuracy: 0.8210, train_loss_norm:0.0392, valid_acc: 0.7991, valid_loss_norm: 0.0402\n",
      " epoch: 132, train accuracy: 0.8212, train_loss_norm:0.0390, valid_acc: 0.7991, valid_loss_norm: 0.0401\n",
      " epoch: 133, train accuracy: 0.8214, train_loss_norm:0.0389, valid_acc: 0.7997, valid_loss_norm: 0.0399\n",
      " epoch: 134, train accuracy: 0.8216, train_loss_norm:0.0388, valid_acc: 0.8002, valid_loss_norm: 0.0398\n",
      " epoch: 135, train accuracy: 0.8218, train_loss_norm:0.0387, valid_acc: 0.8002, valid_loss_norm: 0.0397\n",
      " epoch: 136, train accuracy: 0.8221, train_loss_norm:0.0386, valid_acc: 0.8008, valid_loss_norm: 0.0396\n",
      " epoch: 137, train accuracy: 0.8222, train_loss_norm:0.0384, valid_acc: 0.8017, valid_loss_norm: 0.0395\n",
      " epoch: 138, train accuracy: 0.8225, train_loss_norm:0.0383, valid_acc: 0.8020, valid_loss_norm: 0.0393\n",
      " epoch: 139, train accuracy: 0.8226, train_loss_norm:0.0382, valid_acc: 0.8020, valid_loss_norm: 0.0392\n",
      " epoch: 140, train accuracy: 0.8228, train_loss_norm:0.0381, valid_acc: 0.8020, valid_loss_norm: 0.0391\n",
      " epoch: 141, train accuracy: 0.8230, train_loss_norm:0.0380, valid_acc: 0.8020, valid_loss_norm: 0.0390\n",
      " epoch: 142, train accuracy: 0.8231, train_loss_norm:0.0378, valid_acc: 0.8022, valid_loss_norm: 0.0389\n",
      " epoch: 143, train accuracy: 0.8233, train_loss_norm:0.0377, valid_acc: 0.8022, valid_loss_norm: 0.0388\n",
      " epoch: 144, train accuracy: 0.8235, train_loss_norm:0.0376, valid_acc: 0.8022, valid_loss_norm: 0.0387\n",
      " epoch: 145, train accuracy: 0.8237, train_loss_norm:0.0375, valid_acc: 0.8025, valid_loss_norm: 0.0386\n",
      " epoch: 146, train accuracy: 0.8239, train_loss_norm:0.0374, valid_acc: 0.8025, valid_loss_norm: 0.0385\n",
      " epoch: 147, train accuracy: 0.8242, train_loss_norm:0.0373, valid_acc: 0.8028, valid_loss_norm: 0.0384\n",
      " epoch: 148, train accuracy: 0.8242, train_loss_norm:0.0372, valid_acc: 0.8031, valid_loss_norm: 0.0383\n",
      " epoch: 149, train accuracy: 0.8243, train_loss_norm:0.0371, valid_acc: 0.8034, valid_loss_norm: 0.0381\n",
      " epoch: 150, train accuracy: 0.8245, train_loss_norm:0.0370, valid_acc: 0.8031, valid_loss_norm: 0.0380\n",
      " epoch: 151, train accuracy: 0.8246, train_loss_norm:0.0369, valid_acc: 0.8031, valid_loss_norm: 0.0379\n",
      " epoch: 152, train accuracy: 0.8248, train_loss_norm:0.0368, valid_acc: 0.8031, valid_loss_norm: 0.0378\n",
      " epoch: 153, train accuracy: 0.8250, train_loss_norm:0.0366, valid_acc: 0.8031, valid_loss_norm: 0.0377\n",
      " epoch: 154, train accuracy: 0.8250, train_loss_norm:0.0365, valid_acc: 0.8034, valid_loss_norm: 0.0376\n",
      " epoch: 155, train accuracy: 0.8255, train_loss_norm:0.0364, valid_acc: 0.8037, valid_loss_norm: 0.0375\n",
      " epoch: 156, train accuracy: 0.8256, train_loss_norm:0.0363, valid_acc: 0.8045, valid_loss_norm: 0.0374\n",
      " epoch: 157, train accuracy: 0.8258, train_loss_norm:0.0362, valid_acc: 0.8045, valid_loss_norm: 0.0374\n",
      " epoch: 158, train accuracy: 0.8261, train_loss_norm:0.0361, valid_acc: 0.8040, valid_loss_norm: 0.0373\n",
      " epoch: 159, train accuracy: 0.8263, train_loss_norm:0.0360, valid_acc: 0.8043, valid_loss_norm: 0.0372\n",
      " epoch: 160, train accuracy: 0.8264, train_loss_norm:0.0359, valid_acc: 0.8045, valid_loss_norm: 0.0371\n",
      " epoch: 161, train accuracy: 0.8266, train_loss_norm:0.0358, valid_acc: 0.8048, valid_loss_norm: 0.0370\n",
      " epoch: 162, train accuracy: 0.8270, train_loss_norm:0.0358, valid_acc: 0.8048, valid_loss_norm: 0.0369\n",
      " epoch: 163, train accuracy: 0.8272, train_loss_norm:0.0357, valid_acc: 0.8048, valid_loss_norm: 0.0368\n",
      " epoch: 164, train accuracy: 0.8276, train_loss_norm:0.0356, valid_acc: 0.8051, valid_loss_norm: 0.0367\n",
      " epoch: 165, train accuracy: 0.8277, train_loss_norm:0.0355, valid_acc: 0.8048, valid_loss_norm: 0.0366\n",
      " epoch: 166, train accuracy: 0.8282, train_loss_norm:0.0354, valid_acc: 0.8051, valid_loss_norm: 0.0365\n",
      " epoch: 167, train accuracy: 0.8285, train_loss_norm:0.0353, valid_acc: 0.8054, valid_loss_norm: 0.0364\n",
      " epoch: 168, train accuracy: 0.8287, train_loss_norm:0.0352, valid_acc: 0.8057, valid_loss_norm: 0.0363\n",
      " epoch: 169, train accuracy: 0.8287, train_loss_norm:0.0351, valid_acc: 0.8057, valid_loss_norm: 0.0363\n",
      " epoch: 170, train accuracy: 0.8289, train_loss_norm:0.0350, valid_acc: 0.8057, valid_loss_norm: 0.0362\n",
      " epoch: 171, train accuracy: 0.8292, train_loss_norm:0.0349, valid_acc: 0.8060, valid_loss_norm: 0.0361\n",
      " epoch: 172, train accuracy: 0.8294, train_loss_norm:0.0348, valid_acc: 0.8057, valid_loss_norm: 0.0360\n",
      " epoch: 173, train accuracy: 0.8298, train_loss_norm:0.0347, valid_acc: 0.8060, valid_loss_norm: 0.0359\n",
      " epoch: 174, train accuracy: 0.8299, train_loss_norm:0.0347, valid_acc: 0.8063, valid_loss_norm: 0.0358\n",
      " epoch: 175, train accuracy: 0.8300, train_loss_norm:0.0346, valid_acc: 0.8063, valid_loss_norm: 0.0357\n",
      " epoch: 176, train accuracy: 0.8301, train_loss_norm:0.0345, valid_acc: 0.8063, valid_loss_norm: 0.0357\n",
      " epoch: 177, train accuracy: 0.8303, train_loss_norm:0.0344, valid_acc: 0.8063, valid_loss_norm: 0.0356\n",
      " epoch: 178, train accuracy: 0.8308, train_loss_norm:0.0343, valid_acc: 0.8066, valid_loss_norm: 0.0355\n",
      " epoch: 179, train accuracy: 0.8309, train_loss_norm:0.0342, valid_acc: 0.8071, valid_loss_norm: 0.0354\n",
      " epoch: 180, train accuracy: 0.8309, train_loss_norm:0.0341, valid_acc: 0.8074, valid_loss_norm: 0.0353\n",
      " epoch: 181, train accuracy: 0.8310, train_loss_norm:0.0341, valid_acc: 0.8071, valid_loss_norm: 0.0353\n",
      " epoch: 182, train accuracy: 0.8313, train_loss_norm:0.0340, valid_acc: 0.8071, valid_loss_norm: 0.0352\n",
      " epoch: 183, train accuracy: 0.8314, train_loss_norm:0.0339, valid_acc: 0.8074, valid_loss_norm: 0.0351\n",
      " epoch: 184, train accuracy: 0.8316, train_loss_norm:0.0338, valid_acc: 0.8071, valid_loss_norm: 0.0350\n",
      " epoch: 185, train accuracy: 0.8319, train_loss_norm:0.0337, valid_acc: 0.8068, valid_loss_norm: 0.0349\n",
      " epoch: 186, train accuracy: 0.8320, train_loss_norm:0.0337, valid_acc: 0.8066, valid_loss_norm: 0.0349\n",
      " epoch: 187, train accuracy: 0.8323, train_loss_norm:0.0336, valid_acc: 0.8066, valid_loss_norm: 0.0348\n",
      " epoch: 188, train accuracy: 0.8325, train_loss_norm:0.0335, valid_acc: 0.8068, valid_loss_norm: 0.0347\n",
      " epoch: 189, train accuracy: 0.8327, train_loss_norm:0.0334, valid_acc: 0.8068, valid_loss_norm: 0.0346\n",
      " epoch: 190, train accuracy: 0.8328, train_loss_norm:0.0333, valid_acc: 0.8068, valid_loss_norm: 0.0346\n",
      " epoch: 191, train accuracy: 0.8330, train_loss_norm:0.0333, valid_acc: 0.8068, valid_loss_norm: 0.0345\n",
      " epoch: 192, train accuracy: 0.8331, train_loss_norm:0.0332, valid_acc: 0.8068, valid_loss_norm: 0.0344\n",
      " epoch: 193, train accuracy: 0.8336, train_loss_norm:0.0331, valid_acc: 0.8074, valid_loss_norm: 0.0343\n",
      " epoch: 194, train accuracy: 0.8337, train_loss_norm:0.0330, valid_acc: 0.8074, valid_loss_norm: 0.0343\n",
      " epoch: 195, train accuracy: 0.8338, train_loss_norm:0.0330, valid_acc: 0.8077, valid_loss_norm: 0.0342\n",
      " epoch: 196, train accuracy: 0.8339, train_loss_norm:0.0329, valid_acc: 0.8083, valid_loss_norm: 0.0341\n",
      " epoch: 197, train accuracy: 0.8342, train_loss_norm:0.0328, valid_acc: 0.8086, valid_loss_norm: 0.0341\n",
      " epoch: 198, train accuracy: 0.8343, train_loss_norm:0.0327, valid_acc: 0.8086, valid_loss_norm: 0.0340\n",
      " epoch: 199, train accuracy: 0.8345, train_loss_norm:0.0327, valid_acc: 0.8086, valid_loss_norm: 0.0339\n",
      " epoch: 200, train accuracy: 0.8347, train_loss_norm:0.0326, valid_acc: 0.8091, valid_loss_norm: 0.0339\n",
      " epoch: 201, train accuracy: 0.8348, train_loss_norm:0.0325, valid_acc: 0.8094, valid_loss_norm: 0.0338\n",
      " epoch: 202, train accuracy: 0.8349, train_loss_norm:0.0325, valid_acc: 0.8097, valid_loss_norm: 0.0337\n",
      " epoch: 203, train accuracy: 0.8350, train_loss_norm:0.0324, valid_acc: 0.8100, valid_loss_norm: 0.0336\n",
      " epoch: 204, train accuracy: 0.8351, train_loss_norm:0.0323, valid_acc: 0.8100, valid_loss_norm: 0.0336\n",
      " epoch: 205, train accuracy: 0.8351, train_loss_norm:0.0322, valid_acc: 0.8100, valid_loss_norm: 0.0335\n",
      " epoch: 206, train accuracy: 0.8355, train_loss_norm:0.0322, valid_acc: 0.8103, valid_loss_norm: 0.0334\n",
      " epoch: 207, train accuracy: 0.8356, train_loss_norm:0.0321, valid_acc: 0.8109, valid_loss_norm: 0.0334\n",
      " epoch: 208, train accuracy: 0.8357, train_loss_norm:0.0320, valid_acc: 0.8112, valid_loss_norm: 0.0333\n",
      " epoch: 209, train accuracy: 0.8357, train_loss_norm:0.0320, valid_acc: 0.8112, valid_loss_norm: 0.0333\n",
      " epoch: 210, train accuracy: 0.8358, train_loss_norm:0.0319, valid_acc: 0.8109, valid_loss_norm: 0.0332\n",
      " epoch: 211, train accuracy: 0.8359, train_loss_norm:0.0318, valid_acc: 0.8109, valid_loss_norm: 0.0331\n",
      " epoch: 212, train accuracy: 0.8359, train_loss_norm:0.0318, valid_acc: 0.8109, valid_loss_norm: 0.0331\n",
      " epoch: 213, train accuracy: 0.8359, train_loss_norm:0.0317, valid_acc: 0.8117, valid_loss_norm: 0.0330\n",
      " epoch: 214, train accuracy: 0.8361, train_loss_norm:0.0316, valid_acc: 0.8117, valid_loss_norm: 0.0329\n",
      " epoch: 215, train accuracy: 0.8364, train_loss_norm:0.0316, valid_acc: 0.8123, valid_loss_norm: 0.0329\n",
      " epoch: 216, train accuracy: 0.8365, train_loss_norm:0.0315, valid_acc: 0.8129, valid_loss_norm: 0.0328\n",
      " epoch: 217, train accuracy: 0.8365, train_loss_norm:0.0314, valid_acc: 0.8135, valid_loss_norm: 0.0327\n",
      " epoch: 218, train accuracy: 0.8368, train_loss_norm:0.0314, valid_acc: 0.8135, valid_loss_norm: 0.0327\n",
      " epoch: 219, train accuracy: 0.8369, train_loss_norm:0.0313, valid_acc: 0.8135, valid_loss_norm: 0.0326\n",
      " epoch: 220, train accuracy: 0.8370, train_loss_norm:0.0313, valid_acc: 0.8137, valid_loss_norm: 0.0326\n",
      " epoch: 221, train accuracy: 0.8371, train_loss_norm:0.0312, valid_acc: 0.8137, valid_loss_norm: 0.0325\n",
      " epoch: 222, train accuracy: 0.8372, train_loss_norm:0.0311, valid_acc: 0.8137, valid_loss_norm: 0.0324\n",
      " epoch: 223, train accuracy: 0.8373, train_loss_norm:0.0311, valid_acc: 0.8137, valid_loss_norm: 0.0324\n",
      " epoch: 224, train accuracy: 0.8375, train_loss_norm:0.0310, valid_acc: 0.8140, valid_loss_norm: 0.0323\n",
      " epoch: 225, train accuracy: 0.8376, train_loss_norm:0.0309, valid_acc: 0.8143, valid_loss_norm: 0.0323\n",
      " epoch: 226, train accuracy: 0.8378, train_loss_norm:0.0309, valid_acc: 0.8146, valid_loss_norm: 0.0322\n",
      " epoch: 227, train accuracy: 0.8380, train_loss_norm:0.0308, valid_acc: 0.8146, valid_loss_norm: 0.0322\n",
      " epoch: 228, train accuracy: 0.8381, train_loss_norm:0.0308, valid_acc: 0.8149, valid_loss_norm: 0.0321\n",
      " epoch: 229, train accuracy: 0.8383, train_loss_norm:0.0307, valid_acc: 0.8149, valid_loss_norm: 0.0320\n",
      " epoch: 230, train accuracy: 0.8383, train_loss_norm:0.0306, valid_acc: 0.8152, valid_loss_norm: 0.0320\n",
      " epoch: 231, train accuracy: 0.8385, train_loss_norm:0.0306, valid_acc: 0.8152, valid_loss_norm: 0.0319\n",
      " epoch: 232, train accuracy: 0.8387, train_loss_norm:0.0305, valid_acc: 0.8152, valid_loss_norm: 0.0319\n",
      " epoch: 233, train accuracy: 0.8388, train_loss_norm:0.0305, valid_acc: 0.8155, valid_loss_norm: 0.0318\n",
      " epoch: 234, train accuracy: 0.8389, train_loss_norm:0.0304, valid_acc: 0.8155, valid_loss_norm: 0.0318\n",
      " epoch: 235, train accuracy: 0.8391, train_loss_norm:0.0304, valid_acc: 0.8155, valid_loss_norm: 0.0317\n",
      " epoch: 236, train accuracy: 0.8392, train_loss_norm:0.0303, valid_acc: 0.8163, valid_loss_norm: 0.0316\n",
      " epoch: 237, train accuracy: 0.8393, train_loss_norm:0.0302, valid_acc: 0.8163, valid_loss_norm: 0.0316\n",
      " epoch: 238, train accuracy: 0.8393, train_loss_norm:0.0302, valid_acc: 0.8166, valid_loss_norm: 0.0315\n",
      " epoch: 239, train accuracy: 0.8395, train_loss_norm:0.0301, valid_acc: 0.8166, valid_loss_norm: 0.0315\n",
      " epoch: 240, train accuracy: 0.8397, train_loss_norm:0.0301, valid_acc: 0.8163, valid_loss_norm: 0.0314\n",
      " epoch: 241, train accuracy: 0.8397, train_loss_norm:0.0300, valid_acc: 0.8166, valid_loss_norm: 0.0314\n",
      " epoch: 242, train accuracy: 0.8398, train_loss_norm:0.0300, valid_acc: 0.8163, valid_loss_norm: 0.0313\n",
      " epoch: 243, train accuracy: 0.8399, train_loss_norm:0.0299, valid_acc: 0.8169, valid_loss_norm: 0.0313\n",
      " epoch: 244, train accuracy: 0.8398, train_loss_norm:0.0299, valid_acc: 0.8178, valid_loss_norm: 0.0312\n",
      " epoch: 245, train accuracy: 0.8399, train_loss_norm:0.0298, valid_acc: 0.8178, valid_loss_norm: 0.0312\n",
      " epoch: 246, train accuracy: 0.8401, train_loss_norm:0.0297, valid_acc: 0.8178, valid_loss_norm: 0.0311\n",
      " epoch: 247, train accuracy: 0.8402, train_loss_norm:0.0297, valid_acc: 0.8175, valid_loss_norm: 0.0311\n",
      " epoch: 248, train accuracy: 0.8405, train_loss_norm:0.0296, valid_acc: 0.8175, valid_loss_norm: 0.0310\n",
      " epoch: 249, train accuracy: 0.8406, train_loss_norm:0.0296, valid_acc: 0.8175, valid_loss_norm: 0.0310\n",
      " epoch: 250, train accuracy: 0.8407, train_loss_norm:0.0295, valid_acc: 0.8175, valid_loss_norm: 0.0309\n",
      " epoch: 251, train accuracy: 0.8409, train_loss_norm:0.0295, valid_acc: 0.8178, valid_loss_norm: 0.0309\n",
      " epoch: 252, train accuracy: 0.8409, train_loss_norm:0.0294, valid_acc: 0.8181, valid_loss_norm: 0.0308\n",
      " epoch: 253, train accuracy: 0.8410, train_loss_norm:0.0294, valid_acc: 0.8186, valid_loss_norm: 0.0308\n",
      " epoch: 254, train accuracy: 0.8411, train_loss_norm:0.0293, valid_acc: 0.8189, valid_loss_norm: 0.0307\n",
      " epoch: 255, train accuracy: 0.8411, train_loss_norm:0.0293, valid_acc: 0.8192, valid_loss_norm: 0.0307\n",
      " epoch: 256, train accuracy: 0.8412, train_loss_norm:0.0292, valid_acc: 0.8198, valid_loss_norm: 0.0306\n",
      " epoch: 257, train accuracy: 0.8412, train_loss_norm:0.0292, valid_acc: 0.8201, valid_loss_norm: 0.0306\n",
      " epoch: 258, train accuracy: 0.8413, train_loss_norm:0.0291, valid_acc: 0.8204, valid_loss_norm: 0.0305\n",
      " epoch: 259, train accuracy: 0.8414, train_loss_norm:0.0291, valid_acc: 0.8206, valid_loss_norm: 0.0305\n",
      " epoch: 260, train accuracy: 0.8414, train_loss_norm:0.0290, valid_acc: 0.8212, valid_loss_norm: 0.0304\n",
      " epoch: 261, train accuracy: 0.8417, train_loss_norm:0.0290, valid_acc: 0.8212, valid_loss_norm: 0.0304\n",
      " epoch: 262, train accuracy: 0.8417, train_loss_norm:0.0289, valid_acc: 0.8209, valid_loss_norm: 0.0303\n",
      " epoch: 263, train accuracy: 0.8418, train_loss_norm:0.0289, valid_acc: 0.8212, valid_loss_norm: 0.0303\n",
      " epoch: 264, train accuracy: 0.8418, train_loss_norm:0.0288, valid_acc: 0.8212, valid_loss_norm: 0.0302\n",
      " epoch: 265, train accuracy: 0.8419, train_loss_norm:0.0288, valid_acc: 0.8218, valid_loss_norm: 0.0302\n",
      " epoch: 266, train accuracy: 0.8418, train_loss_norm:0.0287, valid_acc: 0.8221, valid_loss_norm: 0.0302\n",
      " epoch: 267, train accuracy: 0.8420, train_loss_norm:0.0287, valid_acc: 0.8221, valid_loss_norm: 0.0301\n",
      " epoch: 268, train accuracy: 0.8421, train_loss_norm:0.0286, valid_acc: 0.8224, valid_loss_norm: 0.0301\n",
      " epoch: 269, train accuracy: 0.8422, train_loss_norm:0.0286, valid_acc: 0.8229, valid_loss_norm: 0.0300\n",
      " epoch: 270, train accuracy: 0.8425, train_loss_norm:0.0285, valid_acc: 0.8232, valid_loss_norm: 0.0300\n",
      " epoch: 271, train accuracy: 0.8426, train_loss_norm:0.0285, valid_acc: 0.8232, valid_loss_norm: 0.0299\n",
      " epoch: 272, train accuracy: 0.8427, train_loss_norm:0.0284, valid_acc: 0.8232, valid_loss_norm: 0.0299\n",
      " epoch: 273, train accuracy: 0.8427, train_loss_norm:0.0284, valid_acc: 0.8229, valid_loss_norm: 0.0298\n",
      " epoch: 274, train accuracy: 0.8430, train_loss_norm:0.0284, valid_acc: 0.8229, valid_loss_norm: 0.0298\n",
      " epoch: 275, train accuracy: 0.8431, train_loss_norm:0.0283, valid_acc: 0.8229, valid_loss_norm: 0.0297\n",
      " epoch: 276, train accuracy: 0.8433, train_loss_norm:0.0283, valid_acc: 0.8229, valid_loss_norm: 0.0297\n",
      " epoch: 277, train accuracy: 0.8433, train_loss_norm:0.0282, valid_acc: 0.8227, valid_loss_norm: 0.0297\n",
      " epoch: 278, train accuracy: 0.8434, train_loss_norm:0.0282, valid_acc: 0.8229, valid_loss_norm: 0.0296\n",
      " epoch: 279, train accuracy: 0.8436, train_loss_norm:0.0281, valid_acc: 0.8232, valid_loss_norm: 0.0296\n",
      " epoch: 280, train accuracy: 0.8437, train_loss_norm:0.0281, valid_acc: 0.8235, valid_loss_norm: 0.0295\n",
      " epoch: 281, train accuracy: 0.8437, train_loss_norm:0.0280, valid_acc: 0.8235, valid_loss_norm: 0.0295\n",
      " epoch: 282, train accuracy: 0.8438, train_loss_norm:0.0280, valid_acc: 0.8235, valid_loss_norm: 0.0294\n",
      " epoch: 283, train accuracy: 0.8439, train_loss_norm:0.0279, valid_acc: 0.8235, valid_loss_norm: 0.0294\n",
      " epoch: 284, train accuracy: 0.8440, train_loss_norm:0.0279, valid_acc: 0.8235, valid_loss_norm: 0.0294\n",
      " epoch: 285, train accuracy: 0.8441, train_loss_norm:0.0279, valid_acc: 0.8229, valid_loss_norm: 0.0293\n",
      " epoch: 286, train accuracy: 0.8443, train_loss_norm:0.0278, valid_acc: 0.8232, valid_loss_norm: 0.0293\n",
      " epoch: 287, train accuracy: 0.8444, train_loss_norm:0.0278, valid_acc: 0.8235, valid_loss_norm: 0.0292\n",
      " epoch: 288, train accuracy: 0.8444, train_loss_norm:0.0277, valid_acc: 0.8235, valid_loss_norm: 0.0292\n",
      " epoch: 289, train accuracy: 0.8446, train_loss_norm:0.0277, valid_acc: 0.8235, valid_loss_norm: 0.0292\n",
      " epoch: 290, train accuracy: 0.8447, train_loss_norm:0.0276, valid_acc: 0.8235, valid_loss_norm: 0.0291\n",
      " epoch: 291, train accuracy: 0.8448, train_loss_norm:0.0276, valid_acc: 0.8238, valid_loss_norm: 0.0291\n",
      " epoch: 292, train accuracy: 0.8448, train_loss_norm:0.0276, valid_acc: 0.8238, valid_loss_norm: 0.0290\n",
      " epoch: 293, train accuracy: 0.8449, train_loss_norm:0.0275, valid_acc: 0.8238, valid_loss_norm: 0.0290\n",
      " epoch: 294, train accuracy: 0.8450, train_loss_norm:0.0275, valid_acc: 0.8238, valid_loss_norm: 0.0290\n",
      " epoch: 295, train accuracy: 0.8450, train_loss_norm:0.0274, valid_acc: 0.8241, valid_loss_norm: 0.0289\n",
      " epoch: 296, train accuracy: 0.8449, train_loss_norm:0.0274, valid_acc: 0.8241, valid_loss_norm: 0.0289\n",
      " epoch: 297, train accuracy: 0.8451, train_loss_norm:0.0274, valid_acc: 0.8241, valid_loss_norm: 0.0288\n",
      " epoch: 298, train accuracy: 0.8453, train_loss_norm:0.0273, valid_acc: 0.8241, valid_loss_norm: 0.0288\n",
      " epoch: 299, train accuracy: 0.8455, train_loss_norm:0.0273, valid_acc: 0.8241, valid_loss_norm: 0.0288\n",
      " epoch: 300, train accuracy: 0.8457, train_loss_norm:0.0272, valid_acc: 0.8241, valid_loss_norm: 0.0287\n",
      "Test accuracy: 0.8356\n",
      "Test loss norm: 0.0284\n",
      "Cur fold: 8\n",
      "(27841, 300)\n",
      "(3479, 300)\n",
      "(3479, 300)\n",
      " epoch: 1, train accuracy: 0.7908, train_loss_norm:0.0867, valid_acc: 0.7864, valid_loss_norm: 0.0867\n",
      " epoch: 2, train accuracy: 0.7908, train_loss_norm:0.0859, valid_acc: 0.7864, valid_loss_norm: 0.0860\n",
      " epoch: 3, train accuracy: 0.7908, train_loss_norm:0.0852, valid_acc: 0.7864, valid_loss_norm: 0.0852\n",
      " epoch: 4, train accuracy: 0.7908, train_loss_norm:0.0844, valid_acc: 0.7864, valid_loss_norm: 0.0845\n",
      " epoch: 5, train accuracy: 0.7908, train_loss_norm:0.0836, valid_acc: 0.7864, valid_loss_norm: 0.0837\n",
      " epoch: 6, train accuracy: 0.7909, train_loss_norm:0.0829, valid_acc: 0.7864, valid_loss_norm: 0.0830\n",
      " epoch: 7, train accuracy: 0.7910, train_loss_norm:0.0821, valid_acc: 0.7864, valid_loss_norm: 0.0822\n",
      " epoch: 8, train accuracy: 0.7910, train_loss_norm:0.0814, valid_acc: 0.7864, valid_loss_norm: 0.0815\n",
      " epoch: 9, train accuracy: 0.7910, train_loss_norm:0.0807, valid_acc: 0.7864, valid_loss_norm: 0.0808\n",
      " epoch: 10, train accuracy: 0.7911, train_loss_norm:0.0799, valid_acc: 0.7864, valid_loss_norm: 0.0801\n",
      " epoch: 11, train accuracy: 0.7912, train_loss_norm:0.0792, valid_acc: 0.7864, valid_loss_norm: 0.0794\n",
      " epoch: 12, train accuracy: 0.7912, train_loss_norm:0.0785, valid_acc: 0.7864, valid_loss_norm: 0.0787\n",
      " epoch: 13, train accuracy: 0.7912, train_loss_norm:0.0778, valid_acc: 0.7864, valid_loss_norm: 0.0780\n",
      " epoch: 14, train accuracy: 0.7913, train_loss_norm:0.0770, valid_acc: 0.7870, valid_loss_norm: 0.0773\n",
      " epoch: 15, train accuracy: 0.7915, train_loss_norm:0.0763, valid_acc: 0.7873, valid_loss_norm: 0.0766\n",
      " epoch: 16, train accuracy: 0.7916, train_loss_norm:0.0757, valid_acc: 0.7873, valid_loss_norm: 0.0759\n",
      " epoch: 17, train accuracy: 0.7918, train_loss_norm:0.0750, valid_acc: 0.7873, valid_loss_norm: 0.0752\n",
      " epoch: 18, train accuracy: 0.7920, train_loss_norm:0.0743, valid_acc: 0.7873, valid_loss_norm: 0.0746\n",
      " epoch: 19, train accuracy: 0.7920, train_loss_norm:0.0736, valid_acc: 0.7873, valid_loss_norm: 0.0739\n",
      " epoch: 20, train accuracy: 0.7920, train_loss_norm:0.0729, valid_acc: 0.7876, valid_loss_norm: 0.0732\n",
      " epoch: 21, train accuracy: 0.7921, train_loss_norm:0.0723, valid_acc: 0.7876, valid_loss_norm: 0.0726\n",
      " epoch: 22, train accuracy: 0.7921, train_loss_norm:0.0716, valid_acc: 0.7876, valid_loss_norm: 0.0720\n",
      " epoch: 23, train accuracy: 0.7922, train_loss_norm:0.0710, valid_acc: 0.7879, valid_loss_norm: 0.0713\n",
      " epoch: 24, train accuracy: 0.7923, train_loss_norm:0.0704, valid_acc: 0.7882, valid_loss_norm: 0.0707\n",
      " epoch: 25, train accuracy: 0.7924, train_loss_norm:0.0697, valid_acc: 0.7884, valid_loss_norm: 0.0701\n",
      " epoch: 26, train accuracy: 0.7924, train_loss_norm:0.0691, valid_acc: 0.7884, valid_loss_norm: 0.0695\n",
      " epoch: 27, train accuracy: 0.7926, train_loss_norm:0.0685, valid_acc: 0.7887, valid_loss_norm: 0.0689\n",
      " epoch: 28, train accuracy: 0.7928, train_loss_norm:0.0679, valid_acc: 0.7887, valid_loss_norm: 0.0683\n",
      " epoch: 29, train accuracy: 0.7929, train_loss_norm:0.0673, valid_acc: 0.7890, valid_loss_norm: 0.0677\n",
      " epoch: 30, train accuracy: 0.7930, train_loss_norm:0.0668, valid_acc: 0.7890, valid_loss_norm: 0.0672\n",
      " epoch: 31, train accuracy: 0.7932, train_loss_norm:0.0662, valid_acc: 0.7887, valid_loss_norm: 0.0666\n",
      " epoch: 32, train accuracy: 0.7934, train_loss_norm:0.0656, valid_acc: 0.7893, valid_loss_norm: 0.0661\n",
      " epoch: 33, train accuracy: 0.7937, train_loss_norm:0.0651, valid_acc: 0.7896, valid_loss_norm: 0.0655\n",
      " epoch: 34, train accuracy: 0.7940, train_loss_norm:0.0645, valid_acc: 0.7899, valid_loss_norm: 0.0650\n",
      " epoch: 35, train accuracy: 0.7944, train_loss_norm:0.0640, valid_acc: 0.7905, valid_loss_norm: 0.0645\n",
      " epoch: 36, train accuracy: 0.7948, train_loss_norm:0.0635, valid_acc: 0.7905, valid_loss_norm: 0.0640\n",
      " epoch: 37, train accuracy: 0.7951, train_loss_norm:0.0630, valid_acc: 0.7922, valid_loss_norm: 0.0635\n",
      " epoch: 38, train accuracy: 0.7954, train_loss_norm:0.0625, valid_acc: 0.7922, valid_loss_norm: 0.0630\n",
      " epoch: 39, train accuracy: 0.7957, train_loss_norm:0.0620, valid_acc: 0.7925, valid_loss_norm: 0.0625\n",
      " epoch: 40, train accuracy: 0.7959, train_loss_norm:0.0615, valid_acc: 0.7928, valid_loss_norm: 0.0620\n",
      " epoch: 41, train accuracy: 0.7962, train_loss_norm:0.0610, valid_acc: 0.7928, valid_loss_norm: 0.0616\n",
      " epoch: 42, train accuracy: 0.7964, train_loss_norm:0.0606, valid_acc: 0.7930, valid_loss_norm: 0.0611\n",
      " epoch: 43, train accuracy: 0.7967, train_loss_norm:0.0601, valid_acc: 0.7928, valid_loss_norm: 0.0606\n",
      " epoch: 44, train accuracy: 0.7969, train_loss_norm:0.0597, valid_acc: 0.7928, valid_loss_norm: 0.0602\n",
      " epoch: 45, train accuracy: 0.7972, train_loss_norm:0.0592, valid_acc: 0.7930, valid_loss_norm: 0.0598\n",
      " epoch: 46, train accuracy: 0.7976, train_loss_norm:0.0588, valid_acc: 0.7928, valid_loss_norm: 0.0594\n",
      " epoch: 47, train accuracy: 0.7979, train_loss_norm:0.0584, valid_acc: 0.7930, valid_loss_norm: 0.0589\n",
      " epoch: 48, train accuracy: 0.7981, train_loss_norm:0.0580, valid_acc: 0.7933, valid_loss_norm: 0.0585\n",
      " epoch: 49, train accuracy: 0.7984, train_loss_norm:0.0575, valid_acc: 0.7936, valid_loss_norm: 0.0581\n",
      " epoch: 50, train accuracy: 0.7986, train_loss_norm:0.0571, valid_acc: 0.7936, valid_loss_norm: 0.0577\n",
      " epoch: 51, train accuracy: 0.7990, train_loss_norm:0.0568, valid_acc: 0.7945, valid_loss_norm: 0.0573\n",
      " epoch: 52, train accuracy: 0.7993, train_loss_norm:0.0564, valid_acc: 0.7948, valid_loss_norm: 0.0570\n",
      " epoch: 53, train accuracy: 0.7995, train_loss_norm:0.0560, valid_acc: 0.7953, valid_loss_norm: 0.0566\n",
      " epoch: 54, train accuracy: 0.7997, train_loss_norm:0.0556, valid_acc: 0.7956, valid_loss_norm: 0.0562\n",
      " epoch: 55, train accuracy: 0.8001, train_loss_norm:0.0553, valid_acc: 0.7959, valid_loss_norm: 0.0559\n",
      " epoch: 56, train accuracy: 0.8005, train_loss_norm:0.0549, valid_acc: 0.7962, valid_loss_norm: 0.0555\n",
      " epoch: 57, train accuracy: 0.8008, train_loss_norm:0.0545, valid_acc: 0.7976, valid_loss_norm: 0.0552\n",
      " epoch: 58, train accuracy: 0.8012, train_loss_norm:0.0542, valid_acc: 0.7982, valid_loss_norm: 0.0548\n",
      " epoch: 59, train accuracy: 0.8015, train_loss_norm:0.0539, valid_acc: 0.7985, valid_loss_norm: 0.0545\n",
      " epoch: 60, train accuracy: 0.8019, train_loss_norm:0.0535, valid_acc: 0.7988, valid_loss_norm: 0.0542\n",
      " epoch: 61, train accuracy: 0.8022, train_loss_norm:0.0532, valid_acc: 0.7994, valid_loss_norm: 0.0539\n",
      " epoch: 62, train accuracy: 0.8024, train_loss_norm:0.0529, valid_acc: 0.7994, valid_loss_norm: 0.0535\n",
      " epoch: 63, train accuracy: 0.8027, train_loss_norm:0.0526, valid_acc: 0.8002, valid_loss_norm: 0.0532\n",
      " epoch: 64, train accuracy: 0.8029, train_loss_norm:0.0523, valid_acc: 0.8005, valid_loss_norm: 0.0529\n",
      " epoch: 65, train accuracy: 0.8032, train_loss_norm:0.0520, valid_acc: 0.8005, valid_loss_norm: 0.0526\n",
      " epoch: 66, train accuracy: 0.8037, train_loss_norm:0.0517, valid_acc: 0.8008, valid_loss_norm: 0.0523\n",
      " epoch: 67, train accuracy: 0.8040, train_loss_norm:0.0514, valid_acc: 0.8011, valid_loss_norm: 0.0520\n",
      " epoch: 68, train accuracy: 0.8042, train_loss_norm:0.0511, valid_acc: 0.8017, valid_loss_norm: 0.0518\n",
      " epoch: 69, train accuracy: 0.8044, train_loss_norm:0.0508, valid_acc: 0.8011, valid_loss_norm: 0.0515\n",
      " epoch: 70, train accuracy: 0.8047, train_loss_norm:0.0505, valid_acc: 0.8017, valid_loss_norm: 0.0512\n",
      " epoch: 71, train accuracy: 0.8052, train_loss_norm:0.0502, valid_acc: 0.8022, valid_loss_norm: 0.0509\n",
      " epoch: 72, train accuracy: 0.8055, train_loss_norm:0.0500, valid_acc: 0.8028, valid_loss_norm: 0.0507\n",
      " epoch: 73, train accuracy: 0.8063, train_loss_norm:0.0497, valid_acc: 0.8025, valid_loss_norm: 0.0504\n",
      " epoch: 74, train accuracy: 0.8067, train_loss_norm:0.0494, valid_acc: 0.8028, valid_loss_norm: 0.0501\n",
      " epoch: 75, train accuracy: 0.8070, train_loss_norm:0.0492, valid_acc: 0.8028, valid_loss_norm: 0.0499\n",
      " epoch: 76, train accuracy: 0.8074, train_loss_norm:0.0489, valid_acc: 0.8028, valid_loss_norm: 0.0496\n",
      " epoch: 77, train accuracy: 0.8079, train_loss_norm:0.0487, valid_acc: 0.8031, valid_loss_norm: 0.0494\n",
      " epoch: 78, train accuracy: 0.8082, train_loss_norm:0.0484, valid_acc: 0.8031, valid_loss_norm: 0.0492\n",
      " epoch: 79, train accuracy: 0.8084, train_loss_norm:0.0482, valid_acc: 0.8037, valid_loss_norm: 0.0489\n",
      " epoch: 80, train accuracy: 0.8086, train_loss_norm:0.0479, valid_acc: 0.8037, valid_loss_norm: 0.0487\n",
      " epoch: 81, train accuracy: 0.8089, train_loss_norm:0.0477, valid_acc: 0.8045, valid_loss_norm: 0.0484\n",
      " epoch: 82, train accuracy: 0.8092, train_loss_norm:0.0475, valid_acc: 0.8048, valid_loss_norm: 0.0482\n",
      " epoch: 83, train accuracy: 0.8096, train_loss_norm:0.0472, valid_acc: 0.8051, valid_loss_norm: 0.0480\n",
      " epoch: 84, train accuracy: 0.8101, train_loss_norm:0.0470, valid_acc: 0.8057, valid_loss_norm: 0.0478\n",
      " epoch: 85, train accuracy: 0.8104, train_loss_norm:0.0468, valid_acc: 0.8057, valid_loss_norm: 0.0476\n",
      " epoch: 86, train accuracy: 0.8105, train_loss_norm:0.0466, valid_acc: 0.8057, valid_loss_norm: 0.0473\n",
      " epoch: 87, train accuracy: 0.8109, train_loss_norm:0.0464, valid_acc: 0.8063, valid_loss_norm: 0.0471\n",
      " epoch: 88, train accuracy: 0.8112, train_loss_norm:0.0461, valid_acc: 0.8066, valid_loss_norm: 0.0469\n",
      " epoch: 89, train accuracy: 0.8118, train_loss_norm:0.0459, valid_acc: 0.8068, valid_loss_norm: 0.0467\n",
      " epoch: 90, train accuracy: 0.8121, train_loss_norm:0.0457, valid_acc: 0.8077, valid_loss_norm: 0.0465\n",
      " epoch: 91, train accuracy: 0.8124, train_loss_norm:0.0455, valid_acc: 0.8083, valid_loss_norm: 0.0463\n",
      " epoch: 92, train accuracy: 0.8128, train_loss_norm:0.0453, valid_acc: 0.8089, valid_loss_norm: 0.0461\n",
      " epoch: 93, train accuracy: 0.8131, train_loss_norm:0.0451, valid_acc: 0.8089, valid_loss_norm: 0.0459\n",
      " epoch: 94, train accuracy: 0.8136, train_loss_norm:0.0449, valid_acc: 0.8089, valid_loss_norm: 0.0457\n",
      " epoch: 95, train accuracy: 0.8140, train_loss_norm:0.0447, valid_acc: 0.8086, valid_loss_norm: 0.0455\n",
      " epoch: 96, train accuracy: 0.8143, train_loss_norm:0.0445, valid_acc: 0.8089, valid_loss_norm: 0.0453\n",
      " epoch: 97, train accuracy: 0.8148, train_loss_norm:0.0443, valid_acc: 0.8086, valid_loss_norm: 0.0452\n",
      " epoch: 98, train accuracy: 0.8150, train_loss_norm:0.0442, valid_acc: 0.8086, valid_loss_norm: 0.0450\n",
      " epoch: 99, train accuracy: 0.8152, train_loss_norm:0.0440, valid_acc: 0.8089, valid_loss_norm: 0.0448\n",
      " epoch: 100, train accuracy: 0.8155, train_loss_norm:0.0438, valid_acc: 0.8094, valid_loss_norm: 0.0446\n",
      " epoch: 101, train accuracy: 0.8157, train_loss_norm:0.0436, valid_acc: 0.8094, valid_loss_norm: 0.0444\n",
      " epoch: 102, train accuracy: 0.8161, train_loss_norm:0.0434, valid_acc: 0.8097, valid_loss_norm: 0.0443\n",
      " epoch: 103, train accuracy: 0.8165, train_loss_norm:0.0433, valid_acc: 0.8097, valid_loss_norm: 0.0441\n",
      " epoch: 104, train accuracy: 0.8166, train_loss_norm:0.0431, valid_acc: 0.8097, valid_loss_norm: 0.0439\n",
      " epoch: 105, train accuracy: 0.8170, train_loss_norm:0.0429, valid_acc: 0.8100, valid_loss_norm: 0.0438\n",
      " epoch: 106, train accuracy: 0.8172, train_loss_norm:0.0427, valid_acc: 0.8103, valid_loss_norm: 0.0436\n",
      " epoch: 107, train accuracy: 0.8177, train_loss_norm:0.0426, valid_acc: 0.8103, valid_loss_norm: 0.0434\n",
      " epoch: 108, train accuracy: 0.8178, train_loss_norm:0.0424, valid_acc: 0.8106, valid_loss_norm: 0.0433\n",
      " epoch: 109, train accuracy: 0.8179, train_loss_norm:0.0423, valid_acc: 0.8112, valid_loss_norm: 0.0431\n",
      " epoch: 110, train accuracy: 0.8181, train_loss_norm:0.0421, valid_acc: 0.8109, valid_loss_norm: 0.0429\n",
      " epoch: 111, train accuracy: 0.8184, train_loss_norm:0.0419, valid_acc: 0.8112, valid_loss_norm: 0.0428\n",
      " epoch: 112, train accuracy: 0.8186, train_loss_norm:0.0418, valid_acc: 0.8117, valid_loss_norm: 0.0426\n",
      " epoch: 113, train accuracy: 0.8189, train_loss_norm:0.0416, valid_acc: 0.8117, valid_loss_norm: 0.0425\n",
      " epoch: 114, train accuracy: 0.8192, train_loss_norm:0.0415, valid_acc: 0.8117, valid_loss_norm: 0.0423\n",
      " epoch: 115, train accuracy: 0.8195, train_loss_norm:0.0413, valid_acc: 0.8123, valid_loss_norm: 0.0422\n",
      " epoch: 116, train accuracy: 0.8196, train_loss_norm:0.0412, valid_acc: 0.8126, valid_loss_norm: 0.0420\n",
      " epoch: 117, train accuracy: 0.8199, train_loss_norm:0.0410, valid_acc: 0.8137, valid_loss_norm: 0.0419\n",
      " epoch: 118, train accuracy: 0.8202, train_loss_norm:0.0409, valid_acc: 0.8140, valid_loss_norm: 0.0418\n",
      " epoch: 119, train accuracy: 0.8203, train_loss_norm:0.0407, valid_acc: 0.8143, valid_loss_norm: 0.0416\n",
      " epoch: 120, train accuracy: 0.8207, train_loss_norm:0.0406, valid_acc: 0.8146, valid_loss_norm: 0.0415\n",
      " epoch: 121, train accuracy: 0.8207, train_loss_norm:0.0404, valid_acc: 0.8146, valid_loss_norm: 0.0413\n",
      " epoch: 122, train accuracy: 0.8210, train_loss_norm:0.0403, valid_acc: 0.8146, valid_loss_norm: 0.0412\n",
      " epoch: 123, train accuracy: 0.8211, train_loss_norm:0.0402, valid_acc: 0.8149, valid_loss_norm: 0.0411\n",
      " epoch: 124, train accuracy: 0.8213, train_loss_norm:0.0400, valid_acc: 0.8152, valid_loss_norm: 0.0409\n",
      " epoch: 125, train accuracy: 0.8215, train_loss_norm:0.0399, valid_acc: 0.8155, valid_loss_norm: 0.0408\n",
      " epoch: 126, train accuracy: 0.8218, train_loss_norm:0.0397, valid_acc: 0.8158, valid_loss_norm: 0.0407\n",
      " epoch: 127, train accuracy: 0.8222, train_loss_norm:0.0396, valid_acc: 0.8158, valid_loss_norm: 0.0405\n",
      " epoch: 128, train accuracy: 0.8225, train_loss_norm:0.0395, valid_acc: 0.8158, valid_loss_norm: 0.0404\n",
      " epoch: 129, train accuracy: 0.8226, train_loss_norm:0.0393, valid_acc: 0.8169, valid_loss_norm: 0.0403\n",
      " epoch: 130, train accuracy: 0.8227, train_loss_norm:0.0392, valid_acc: 0.8169, valid_loss_norm: 0.0401\n",
      " epoch: 131, train accuracy: 0.8229, train_loss_norm:0.0391, valid_acc: 0.8169, valid_loss_norm: 0.0400\n",
      " epoch: 132, train accuracy: 0.8232, train_loss_norm:0.0390, valid_acc: 0.8172, valid_loss_norm: 0.0399\n",
      " epoch: 133, train accuracy: 0.8234, train_loss_norm:0.0388, valid_acc: 0.8178, valid_loss_norm: 0.0398\n",
      " epoch: 134, train accuracy: 0.8235, train_loss_norm:0.0387, valid_acc: 0.8178, valid_loss_norm: 0.0397\n",
      " epoch: 135, train accuracy: 0.8235, train_loss_norm:0.0386, valid_acc: 0.8181, valid_loss_norm: 0.0395\n",
      " epoch: 136, train accuracy: 0.8236, train_loss_norm:0.0385, valid_acc: 0.8178, valid_loss_norm: 0.0394\n",
      " epoch: 137, train accuracy: 0.8237, train_loss_norm:0.0383, valid_acc: 0.8178, valid_loss_norm: 0.0393\n",
      " epoch: 138, train accuracy: 0.8237, train_loss_norm:0.0382, valid_acc: 0.8178, valid_loss_norm: 0.0392\n",
      " epoch: 139, train accuracy: 0.8239, train_loss_norm:0.0381, valid_acc: 0.8181, valid_loss_norm: 0.0391\n",
      " epoch: 140, train accuracy: 0.8239, train_loss_norm:0.0380, valid_acc: 0.8186, valid_loss_norm: 0.0389\n",
      " epoch: 141, train accuracy: 0.8240, train_loss_norm:0.0379, valid_acc: 0.8181, valid_loss_norm: 0.0388\n",
      " epoch: 142, train accuracy: 0.8241, train_loss_norm:0.0378, valid_acc: 0.8181, valid_loss_norm: 0.0387\n",
      " epoch: 143, train accuracy: 0.8240, train_loss_norm:0.0376, valid_acc: 0.8183, valid_loss_norm: 0.0386\n",
      " epoch: 144, train accuracy: 0.8242, train_loss_norm:0.0375, valid_acc: 0.8186, valid_loss_norm: 0.0385\n",
      " epoch: 145, train accuracy: 0.8244, train_loss_norm:0.0374, valid_acc: 0.8192, valid_loss_norm: 0.0384\n",
      " epoch: 146, train accuracy: 0.8248, train_loss_norm:0.0373, valid_acc: 0.8198, valid_loss_norm: 0.0383\n",
      " epoch: 147, train accuracy: 0.8251, train_loss_norm:0.0372, valid_acc: 0.8201, valid_loss_norm: 0.0382\n",
      " epoch: 148, train accuracy: 0.8252, train_loss_norm:0.0371, valid_acc: 0.8204, valid_loss_norm: 0.0381\n",
      " epoch: 149, train accuracy: 0.8255, train_loss_norm:0.0370, valid_acc: 0.8204, valid_loss_norm: 0.0380\n",
      " epoch: 150, train accuracy: 0.8258, train_loss_norm:0.0369, valid_acc: 0.8206, valid_loss_norm: 0.0379\n",
      " epoch: 151, train accuracy: 0.8259, train_loss_norm:0.0368, valid_acc: 0.8209, valid_loss_norm: 0.0378\n",
      " epoch: 152, train accuracy: 0.8261, train_loss_norm:0.0367, valid_acc: 0.8209, valid_loss_norm: 0.0377\n",
      " epoch: 153, train accuracy: 0.8262, train_loss_norm:0.0366, valid_acc: 0.8209, valid_loss_norm: 0.0376\n",
      " epoch: 154, train accuracy: 0.8264, train_loss_norm:0.0365, valid_acc: 0.8218, valid_loss_norm: 0.0375\n",
      " epoch: 155, train accuracy: 0.8268, train_loss_norm:0.0364, valid_acc: 0.8221, valid_loss_norm: 0.0374\n",
      " epoch: 156, train accuracy: 0.8269, train_loss_norm:0.0363, valid_acc: 0.8221, valid_loss_norm: 0.0373\n",
      " epoch: 157, train accuracy: 0.8273, train_loss_norm:0.0362, valid_acc: 0.8224, valid_loss_norm: 0.0372\n",
      " epoch: 158, train accuracy: 0.8274, train_loss_norm:0.0361, valid_acc: 0.8224, valid_loss_norm: 0.0371\n",
      " epoch: 159, train accuracy: 0.8275, train_loss_norm:0.0360, valid_acc: 0.8232, valid_loss_norm: 0.0370\n",
      " epoch: 160, train accuracy: 0.8277, train_loss_norm:0.0359, valid_acc: 0.8235, valid_loss_norm: 0.0369\n",
      " epoch: 161, train accuracy: 0.8281, train_loss_norm:0.0358, valid_acc: 0.8244, valid_loss_norm: 0.0368\n",
      " epoch: 162, train accuracy: 0.8283, train_loss_norm:0.0357, valid_acc: 0.8252, valid_loss_norm: 0.0367\n",
      " epoch: 163, train accuracy: 0.8284, train_loss_norm:0.0356, valid_acc: 0.8252, valid_loss_norm: 0.0366\n",
      " epoch: 164, train accuracy: 0.8285, train_loss_norm:0.0355, valid_acc: 0.8252, valid_loss_norm: 0.0365\n",
      " epoch: 165, train accuracy: 0.8287, train_loss_norm:0.0354, valid_acc: 0.8264, valid_loss_norm: 0.0364\n",
      " epoch: 166, train accuracy: 0.8288, train_loss_norm:0.0353, valid_acc: 0.8264, valid_loss_norm: 0.0363\n",
      " epoch: 167, train accuracy: 0.8290, train_loss_norm:0.0352, valid_acc: 0.8264, valid_loss_norm: 0.0362\n",
      " epoch: 168, train accuracy: 0.8294, train_loss_norm:0.0351, valid_acc: 0.8264, valid_loss_norm: 0.0361\n",
      " epoch: 169, train accuracy: 0.8296, train_loss_norm:0.0350, valid_acc: 0.8264, valid_loss_norm: 0.0360\n",
      " epoch: 170, train accuracy: 0.8297, train_loss_norm:0.0349, valid_acc: 0.8272, valid_loss_norm: 0.0360\n",
      " epoch: 171, train accuracy: 0.8299, train_loss_norm:0.0348, valid_acc: 0.8272, valid_loss_norm: 0.0359\n",
      " epoch: 172, train accuracy: 0.8301, train_loss_norm:0.0347, valid_acc: 0.8275, valid_loss_norm: 0.0358\n",
      " epoch: 173, train accuracy: 0.8302, train_loss_norm:0.0347, valid_acc: 0.8278, valid_loss_norm: 0.0357\n",
      " epoch: 174, train accuracy: 0.8305, train_loss_norm:0.0346, valid_acc: 0.8278, valid_loss_norm: 0.0356\n",
      " epoch: 175, train accuracy: 0.8305, train_loss_norm:0.0345, valid_acc: 0.8281, valid_loss_norm: 0.0355\n",
      " epoch: 176, train accuracy: 0.8306, train_loss_norm:0.0344, valid_acc: 0.8284, valid_loss_norm: 0.0355\n",
      " epoch: 177, train accuracy: 0.8310, train_loss_norm:0.0343, valid_acc: 0.8287, valid_loss_norm: 0.0354\n",
      " epoch: 178, train accuracy: 0.8311, train_loss_norm:0.0342, valid_acc: 0.8284, valid_loss_norm: 0.0353\n",
      " epoch: 179, train accuracy: 0.8315, train_loss_norm:0.0341, valid_acc: 0.8284, valid_loss_norm: 0.0352\n",
      " epoch: 180, train accuracy: 0.8316, train_loss_norm:0.0341, valid_acc: 0.8281, valid_loss_norm: 0.0351\n",
      " epoch: 181, train accuracy: 0.8317, train_loss_norm:0.0340, valid_acc: 0.8284, valid_loss_norm: 0.0350\n",
      " epoch: 182, train accuracy: 0.8318, train_loss_norm:0.0339, valid_acc: 0.8287, valid_loss_norm: 0.0350\n",
      " epoch: 183, train accuracy: 0.8318, train_loss_norm:0.0338, valid_acc: 0.8287, valid_loss_norm: 0.0349\n",
      " epoch: 184, train accuracy: 0.8319, train_loss_norm:0.0337, valid_acc: 0.8287, valid_loss_norm: 0.0348\n",
      " epoch: 185, train accuracy: 0.8321, train_loss_norm:0.0336, valid_acc: 0.8290, valid_loss_norm: 0.0347\n",
      " epoch: 186, train accuracy: 0.8323, train_loss_norm:0.0336, valid_acc: 0.8293, valid_loss_norm: 0.0347\n",
      " epoch: 187, train accuracy: 0.8328, train_loss_norm:0.0335, valid_acc: 0.8295, valid_loss_norm: 0.0346\n",
      " epoch: 188, train accuracy: 0.8331, train_loss_norm:0.0334, valid_acc: 0.8295, valid_loss_norm: 0.0345\n",
      " epoch: 189, train accuracy: 0.8334, train_loss_norm:0.0333, valid_acc: 0.8290, valid_loss_norm: 0.0344\n",
      " epoch: 190, train accuracy: 0.8334, train_loss_norm:0.0333, valid_acc: 0.8290, valid_loss_norm: 0.0343\n",
      " epoch: 191, train accuracy: 0.8336, train_loss_norm:0.0332, valid_acc: 0.8290, valid_loss_norm: 0.0343\n",
      " epoch: 192, train accuracy: 0.8338, train_loss_norm:0.0331, valid_acc: 0.8290, valid_loss_norm: 0.0342\n",
      " epoch: 193, train accuracy: 0.8338, train_loss_norm:0.0330, valid_acc: 0.8293, valid_loss_norm: 0.0341\n",
      " epoch: 194, train accuracy: 0.8339, train_loss_norm:0.0329, valid_acc: 0.8290, valid_loss_norm: 0.0341\n",
      " epoch: 195, train accuracy: 0.8342, train_loss_norm:0.0329, valid_acc: 0.8293, valid_loss_norm: 0.0340\n",
      " epoch: 196, train accuracy: 0.8342, train_loss_norm:0.0328, valid_acc: 0.8295, valid_loss_norm: 0.0339\n",
      " epoch: 197, train accuracy: 0.8342, train_loss_norm:0.0327, valid_acc: 0.8298, valid_loss_norm: 0.0338\n",
      " epoch: 198, train accuracy: 0.8344, train_loss_norm:0.0326, valid_acc: 0.8298, valid_loss_norm: 0.0338\n",
      " epoch: 199, train accuracy: 0.8346, train_loss_norm:0.0326, valid_acc: 0.8304, valid_loss_norm: 0.0337\n",
      " epoch: 200, train accuracy: 0.8347, train_loss_norm:0.0325, valid_acc: 0.8307, valid_loss_norm: 0.0336\n",
      " epoch: 201, train accuracy: 0.8348, train_loss_norm:0.0324, valid_acc: 0.8307, valid_loss_norm: 0.0336\n",
      " epoch: 202, train accuracy: 0.8349, train_loss_norm:0.0324, valid_acc: 0.8310, valid_loss_norm: 0.0335\n",
      " epoch: 203, train accuracy: 0.8350, train_loss_norm:0.0323, valid_acc: 0.8313, valid_loss_norm: 0.0334\n",
      " epoch: 204, train accuracy: 0.8350, train_loss_norm:0.0322, valid_acc: 0.8310, valid_loss_norm: 0.0334\n",
      " epoch: 205, train accuracy: 0.8354, train_loss_norm:0.0322, valid_acc: 0.8313, valid_loss_norm: 0.0333\n",
      " epoch: 206, train accuracy: 0.8356, train_loss_norm:0.0321, valid_acc: 0.8310, valid_loss_norm: 0.0332\n",
      " epoch: 207, train accuracy: 0.8359, train_loss_norm:0.0320, valid_acc: 0.8313, valid_loss_norm: 0.0332\n",
      " epoch: 208, train accuracy: 0.8360, train_loss_norm:0.0319, valid_acc: 0.8313, valid_loss_norm: 0.0331\n",
      " epoch: 209, train accuracy: 0.8361, train_loss_norm:0.0319, valid_acc: 0.8313, valid_loss_norm: 0.0330\n",
      " epoch: 210, train accuracy: 0.8363, train_loss_norm:0.0318, valid_acc: 0.8316, valid_loss_norm: 0.0330\n",
      " epoch: 211, train accuracy: 0.8364, train_loss_norm:0.0317, valid_acc: 0.8313, valid_loss_norm: 0.0329\n",
      " epoch: 212, train accuracy: 0.8367, train_loss_norm:0.0317, valid_acc: 0.8316, valid_loss_norm: 0.0328\n",
      " epoch: 213, train accuracy: 0.8369, train_loss_norm:0.0316, valid_acc: 0.8316, valid_loss_norm: 0.0328\n",
      " epoch: 214, train accuracy: 0.8370, train_loss_norm:0.0315, valid_acc: 0.8318, valid_loss_norm: 0.0327\n",
      " epoch: 215, train accuracy: 0.8371, train_loss_norm:0.0315, valid_acc: 0.8318, valid_loss_norm: 0.0326\n",
      " epoch: 216, train accuracy: 0.8374, train_loss_norm:0.0314, valid_acc: 0.8321, valid_loss_norm: 0.0326\n",
      " epoch: 217, train accuracy: 0.8375, train_loss_norm:0.0313, valid_acc: 0.8318, valid_loss_norm: 0.0325\n",
      " epoch: 218, train accuracy: 0.8375, train_loss_norm:0.0313, valid_acc: 0.8327, valid_loss_norm: 0.0325\n",
      " epoch: 219, train accuracy: 0.8377, train_loss_norm:0.0312, valid_acc: 0.8333, valid_loss_norm: 0.0324\n",
      " epoch: 220, train accuracy: 0.8378, train_loss_norm:0.0312, valid_acc: 0.8333, valid_loss_norm: 0.0323\n",
      " epoch: 221, train accuracy: 0.8380, train_loss_norm:0.0311, valid_acc: 0.8330, valid_loss_norm: 0.0323\n",
      " epoch: 222, train accuracy: 0.8380, train_loss_norm:0.0310, valid_acc: 0.8330, valid_loss_norm: 0.0322\n",
      " epoch: 223, train accuracy: 0.8380, train_loss_norm:0.0310, valid_acc: 0.8330, valid_loss_norm: 0.0322\n",
      " epoch: 224, train accuracy: 0.8380, train_loss_norm:0.0309, valid_acc: 0.8336, valid_loss_norm: 0.0321\n",
      " epoch: 225, train accuracy: 0.8383, train_loss_norm:0.0308, valid_acc: 0.8339, valid_loss_norm: 0.0320\n",
      " epoch: 226, train accuracy: 0.8384, train_loss_norm:0.0308, valid_acc: 0.8339, valid_loss_norm: 0.0320\n",
      " epoch: 227, train accuracy: 0.8385, train_loss_norm:0.0307, valid_acc: 0.8344, valid_loss_norm: 0.0319\n",
      " epoch: 228, train accuracy: 0.8388, train_loss_norm:0.0307, valid_acc: 0.8344, valid_loss_norm: 0.0319\n",
      " epoch: 229, train accuracy: 0.8392, train_loss_norm:0.0306, valid_acc: 0.8344, valid_loss_norm: 0.0318\n",
      " epoch: 230, train accuracy: 0.8393, train_loss_norm:0.0305, valid_acc: 0.8344, valid_loss_norm: 0.0317\n",
      " epoch: 231, train accuracy: 0.8394, train_loss_norm:0.0305, valid_acc: 0.8347, valid_loss_norm: 0.0317\n",
      " epoch: 232, train accuracy: 0.8396, train_loss_norm:0.0304, valid_acc: 0.8347, valid_loss_norm: 0.0316\n",
      " epoch: 233, train accuracy: 0.8397, train_loss_norm:0.0304, valid_acc: 0.8344, valid_loss_norm: 0.0316\n",
      " epoch: 234, train accuracy: 0.8398, train_loss_norm:0.0303, valid_acc: 0.8344, valid_loss_norm: 0.0315\n",
      " epoch: 235, train accuracy: 0.8400, train_loss_norm:0.0303, valid_acc: 0.8344, valid_loss_norm: 0.0315\n",
      " epoch: 236, train accuracy: 0.8400, train_loss_norm:0.0302, valid_acc: 0.8341, valid_loss_norm: 0.0314\n",
      " epoch: 237, train accuracy: 0.8401, train_loss_norm:0.0301, valid_acc: 0.8341, valid_loss_norm: 0.0314\n",
      " epoch: 238, train accuracy: 0.8402, train_loss_norm:0.0301, valid_acc: 0.8344, valid_loss_norm: 0.0313\n",
      " epoch: 239, train accuracy: 0.8403, train_loss_norm:0.0300, valid_acc: 0.8344, valid_loss_norm: 0.0313\n",
      " epoch: 240, train accuracy: 0.8403, train_loss_norm:0.0300, valid_acc: 0.8344, valid_loss_norm: 0.0312\n",
      " epoch: 241, train accuracy: 0.8405, train_loss_norm:0.0299, valid_acc: 0.8347, valid_loss_norm: 0.0311\n",
      " epoch: 242, train accuracy: 0.8405, train_loss_norm:0.0299, valid_acc: 0.8350, valid_loss_norm: 0.0311\n",
      " epoch: 243, train accuracy: 0.8405, train_loss_norm:0.0298, valid_acc: 0.8350, valid_loss_norm: 0.0310\n",
      " epoch: 244, train accuracy: 0.8407, train_loss_norm:0.0298, valid_acc: 0.8350, valid_loss_norm: 0.0310\n",
      " epoch: 245, train accuracy: 0.8407, train_loss_norm:0.0297, valid_acc: 0.8350, valid_loss_norm: 0.0309\n",
      " epoch: 246, train accuracy: 0.8410, train_loss_norm:0.0296, valid_acc: 0.8350, valid_loss_norm: 0.0309\n",
      " epoch: 247, train accuracy: 0.8410, train_loss_norm:0.0296, valid_acc: 0.8350, valid_loss_norm: 0.0308\n",
      " epoch: 248, train accuracy: 0.8411, train_loss_norm:0.0295, valid_acc: 0.8350, valid_loss_norm: 0.0308\n",
      " epoch: 249, train accuracy: 0.8411, train_loss_norm:0.0295, valid_acc: 0.8350, valid_loss_norm: 0.0307\n",
      " epoch: 250, train accuracy: 0.8412, train_loss_norm:0.0294, valid_acc: 0.8350, valid_loss_norm: 0.0307\n",
      " epoch: 251, train accuracy: 0.8413, train_loss_norm:0.0294, valid_acc: 0.8347, valid_loss_norm: 0.0306\n",
      " epoch: 252, train accuracy: 0.8414, train_loss_norm:0.0293, valid_acc: 0.8350, valid_loss_norm: 0.0306\n",
      " epoch: 253, train accuracy: 0.8414, train_loss_norm:0.0293, valid_acc: 0.8350, valid_loss_norm: 0.0305\n",
      " epoch: 254, train accuracy: 0.8416, train_loss_norm:0.0292, valid_acc: 0.8350, valid_loss_norm: 0.0305\n",
      " epoch: 255, train accuracy: 0.8418, train_loss_norm:0.0292, valid_acc: 0.8350, valid_loss_norm: 0.0304\n",
      " epoch: 256, train accuracy: 0.8416, train_loss_norm:0.0291, valid_acc: 0.8350, valid_loss_norm: 0.0304\n",
      " epoch: 257, train accuracy: 0.8417, train_loss_norm:0.0291, valid_acc: 0.8353, valid_loss_norm: 0.0303\n",
      " epoch: 258, train accuracy: 0.8417, train_loss_norm:0.0290, valid_acc: 0.8350, valid_loss_norm: 0.0303\n",
      " epoch: 259, train accuracy: 0.8418, train_loss_norm:0.0290, valid_acc: 0.8347, valid_loss_norm: 0.0302\n",
      " epoch: 260, train accuracy: 0.8419, train_loss_norm:0.0289, valid_acc: 0.8347, valid_loss_norm: 0.0302\n",
      " epoch: 261, train accuracy: 0.8421, train_loss_norm:0.0289, valid_acc: 0.8353, valid_loss_norm: 0.0301\n",
      " epoch: 262, train accuracy: 0.8422, train_loss_norm:0.0288, valid_acc: 0.8353, valid_loss_norm: 0.0301\n",
      " epoch: 263, train accuracy: 0.8424, train_loss_norm:0.0288, valid_acc: 0.8353, valid_loss_norm: 0.0301\n",
      " epoch: 264, train accuracy: 0.8425, train_loss_norm:0.0287, valid_acc: 0.8353, valid_loss_norm: 0.0300\n",
      " epoch: 265, train accuracy: 0.8426, train_loss_norm:0.0287, valid_acc: 0.8353, valid_loss_norm: 0.0300\n",
      " epoch: 266, train accuracy: 0.8428, train_loss_norm:0.0286, valid_acc: 0.8359, valid_loss_norm: 0.0299\n",
      " epoch: 267, train accuracy: 0.8428, train_loss_norm:0.0286, valid_acc: 0.8359, valid_loss_norm: 0.0299\n",
      " epoch: 268, train accuracy: 0.8428, train_loss_norm:0.0285, valid_acc: 0.8356, valid_loss_norm: 0.0298\n",
      " epoch: 269, train accuracy: 0.8429, train_loss_norm:0.0285, valid_acc: 0.8359, valid_loss_norm: 0.0298\n",
      " epoch: 270, train accuracy: 0.8430, train_loss_norm:0.0284, valid_acc: 0.8362, valid_loss_norm: 0.0297\n",
      " epoch: 271, train accuracy: 0.8433, train_loss_norm:0.0284, valid_acc: 0.8362, valid_loss_norm: 0.0297\n",
      " epoch: 272, train accuracy: 0.8434, train_loss_norm:0.0283, valid_acc: 0.8362, valid_loss_norm: 0.0296\n",
      " epoch: 273, train accuracy: 0.8435, train_loss_norm:0.0283, valid_acc: 0.8364, valid_loss_norm: 0.0296\n",
      " epoch: 274, train accuracy: 0.8436, train_loss_norm:0.0283, valid_acc: 0.8364, valid_loss_norm: 0.0296\n",
      " epoch: 275, train accuracy: 0.8437, train_loss_norm:0.0282, valid_acc: 0.8364, valid_loss_norm: 0.0295\n",
      " epoch: 276, train accuracy: 0.8439, train_loss_norm:0.0282, valid_acc: 0.8364, valid_loss_norm: 0.0295\n",
      " epoch: 277, train accuracy: 0.8439, train_loss_norm:0.0281, valid_acc: 0.8364, valid_loss_norm: 0.0294\n",
      " epoch: 278, train accuracy: 0.8440, train_loss_norm:0.0281, valid_acc: 0.8364, valid_loss_norm: 0.0294\n",
      " epoch: 279, train accuracy: 0.8441, train_loss_norm:0.0280, valid_acc: 0.8367, valid_loss_norm: 0.0293\n",
      " epoch: 280, train accuracy: 0.8442, train_loss_norm:0.0280, valid_acc: 0.8373, valid_loss_norm: 0.0293\n",
      " epoch: 281, train accuracy: 0.8443, train_loss_norm:0.0279, valid_acc: 0.8373, valid_loss_norm: 0.0293\n",
      " epoch: 282, train accuracy: 0.8443, train_loss_norm:0.0279, valid_acc: 0.8373, valid_loss_norm: 0.0292\n",
      " epoch: 283, train accuracy: 0.8446, train_loss_norm:0.0278, valid_acc: 0.8370, valid_loss_norm: 0.0292\n",
      " epoch: 284, train accuracy: 0.8447, train_loss_norm:0.0278, valid_acc: 0.8370, valid_loss_norm: 0.0291\n",
      " epoch: 285, train accuracy: 0.8447, train_loss_norm:0.0278, valid_acc: 0.8370, valid_loss_norm: 0.0291\n",
      " epoch: 286, train accuracy: 0.8447, train_loss_norm:0.0277, valid_acc: 0.8373, valid_loss_norm: 0.0290\n",
      " epoch: 287, train accuracy: 0.8447, train_loss_norm:0.0277, valid_acc: 0.8370, valid_loss_norm: 0.0290\n",
      " epoch: 288, train accuracy: 0.8447, train_loss_norm:0.0276, valid_acc: 0.8370, valid_loss_norm: 0.0290\n",
      " epoch: 289, train accuracy: 0.8449, train_loss_norm:0.0276, valid_acc: 0.8370, valid_loss_norm: 0.0289\n",
      " epoch: 290, train accuracy: 0.8452, train_loss_norm:0.0275, valid_acc: 0.8373, valid_loss_norm: 0.0289\n",
      " epoch: 291, train accuracy: 0.8453, train_loss_norm:0.0275, valid_acc: 0.8376, valid_loss_norm: 0.0288\n",
      " epoch: 292, train accuracy: 0.8453, train_loss_norm:0.0275, valid_acc: 0.8382, valid_loss_norm: 0.0288\n",
      " epoch: 293, train accuracy: 0.8453, train_loss_norm:0.0274, valid_acc: 0.8382, valid_loss_norm: 0.0288\n",
      " epoch: 294, train accuracy: 0.8455, train_loss_norm:0.0274, valid_acc: 0.8382, valid_loss_norm: 0.0287\n",
      " epoch: 295, train accuracy: 0.8457, train_loss_norm:0.0273, valid_acc: 0.8382, valid_loss_norm: 0.0287\n",
      " epoch: 296, train accuracy: 0.8458, train_loss_norm:0.0273, valid_acc: 0.8379, valid_loss_norm: 0.0286\n",
      " epoch: 297, train accuracy: 0.8458, train_loss_norm:0.0273, valid_acc: 0.8385, valid_loss_norm: 0.0286\n",
      " epoch: 298, train accuracy: 0.8460, train_loss_norm:0.0272, valid_acc: 0.8385, valid_loss_norm: 0.0286\n",
      " epoch: 299, train accuracy: 0.8461, train_loss_norm:0.0272, valid_acc: 0.8387, valid_loss_norm: 0.0285\n",
      " epoch: 300, train accuracy: 0.8462, train_loss_norm:0.0271, valid_acc: 0.8387, valid_loss_norm: 0.0285\n",
      "Test accuracy: 0.8181\n",
      "Test loss norm: 0.0291\n",
      "1\n",
      "Cur fold: 9\n",
      "(27841, 300)\n",
      "(3479, 300)\n",
      "(3479, 300)\n",
      " epoch: 1, train accuracy: 0.7933, train_loss_norm:0.0867, valid_acc: 0.7692, valid_loss_norm: 0.0867\n",
      " epoch: 2, train accuracy: 0.7933, train_loss_norm:0.0859, valid_acc: 0.7692, valid_loss_norm: 0.0859\n",
      " epoch: 3, train accuracy: 0.7933, train_loss_norm:0.0852, valid_acc: 0.7692, valid_loss_norm: 0.0852\n",
      " epoch: 4, train accuracy: 0.7933, train_loss_norm:0.0844, valid_acc: 0.7692, valid_loss_norm: 0.0844\n",
      " epoch: 5, train accuracy: 0.7934, train_loss_norm:0.0836, valid_acc: 0.7695, valid_loss_norm: 0.0837\n",
      " epoch: 6, train accuracy: 0.7934, train_loss_norm:0.0829, valid_acc: 0.7695, valid_loss_norm: 0.0829\n",
      " epoch: 7, train accuracy: 0.7934, train_loss_norm:0.0821, valid_acc: 0.7698, valid_loss_norm: 0.0822\n",
      " epoch: 8, train accuracy: 0.7935, train_loss_norm:0.0814, valid_acc: 0.7698, valid_loss_norm: 0.0814\n",
      " epoch: 9, train accuracy: 0.7935, train_loss_norm:0.0807, valid_acc: 0.7698, valid_loss_norm: 0.0807\n",
      " epoch: 10, train accuracy: 0.7935, train_loss_norm:0.0799, valid_acc: 0.7698, valid_loss_norm: 0.0800\n",
      " epoch: 11, train accuracy: 0.7936, train_loss_norm:0.0792, valid_acc: 0.7698, valid_loss_norm: 0.0793\n",
      " epoch: 12, train accuracy: 0.7936, train_loss_norm:0.0785, valid_acc: 0.7698, valid_loss_norm: 0.0785\n",
      " epoch: 13, train accuracy: 0.7937, train_loss_norm:0.0778, valid_acc: 0.7698, valid_loss_norm: 0.0778\n",
      " epoch: 14, train accuracy: 0.7937, train_loss_norm:0.0770, valid_acc: 0.7700, valid_loss_norm: 0.0771\n",
      " epoch: 15, train accuracy: 0.7939, train_loss_norm:0.0763, valid_acc: 0.7700, valid_loss_norm: 0.0764\n",
      " epoch: 16, train accuracy: 0.7940, train_loss_norm:0.0756, valid_acc: 0.7700, valid_loss_norm: 0.0757\n",
      " epoch: 17, train accuracy: 0.7942, train_loss_norm:0.0750, valid_acc: 0.7698, valid_loss_norm: 0.0751\n",
      " epoch: 18, train accuracy: 0.7942, train_loss_norm:0.0743, valid_acc: 0.7698, valid_loss_norm: 0.0744\n",
      " epoch: 19, train accuracy: 0.7943, train_loss_norm:0.0736, valid_acc: 0.7698, valid_loss_norm: 0.0737\n",
      " epoch: 20, train accuracy: 0.7944, train_loss_norm:0.0729, valid_acc: 0.7698, valid_loss_norm: 0.0731\n",
      " epoch: 21, train accuracy: 0.7946, train_loss_norm:0.0723, valid_acc: 0.7695, valid_loss_norm: 0.0724\n",
      " epoch: 22, train accuracy: 0.7947, train_loss_norm:0.0716, valid_acc: 0.7695, valid_loss_norm: 0.0718\n",
      " epoch: 23, train accuracy: 0.7946, train_loss_norm:0.0710, valid_acc: 0.7695, valid_loss_norm: 0.0711\n",
      " epoch: 24, train accuracy: 0.7948, train_loss_norm:0.0703, valid_acc: 0.7698, valid_loss_norm: 0.0705\n",
      " epoch: 25, train accuracy: 0.7947, train_loss_norm:0.0697, valid_acc: 0.7698, valid_loss_norm: 0.0699\n",
      " epoch: 26, train accuracy: 0.7949, train_loss_norm:0.0691, valid_acc: 0.7700, valid_loss_norm: 0.0693\n",
      " epoch: 27, train accuracy: 0.7951, train_loss_norm:0.0685, valid_acc: 0.7703, valid_loss_norm: 0.0687\n",
      " epoch: 28, train accuracy: 0.7953, train_loss_norm:0.0679, valid_acc: 0.7703, valid_loss_norm: 0.0681\n",
      " epoch: 29, train accuracy: 0.7956, train_loss_norm:0.0673, valid_acc: 0.7703, valid_loss_norm: 0.0675\n",
      " epoch: 30, train accuracy: 0.7958, train_loss_norm:0.0667, valid_acc: 0.7706, valid_loss_norm: 0.0670\n",
      " epoch: 31, train accuracy: 0.7961, train_loss_norm:0.0662, valid_acc: 0.7706, valid_loss_norm: 0.0664\n",
      " epoch: 32, train accuracy: 0.7964, train_loss_norm:0.0656, valid_acc: 0.7709, valid_loss_norm: 0.0658\n",
      " epoch: 33, train accuracy: 0.7967, train_loss_norm:0.0651, valid_acc: 0.7709, valid_loss_norm: 0.0653\n",
      " epoch: 34, train accuracy: 0.7971, train_loss_norm:0.0645, valid_acc: 0.7709, valid_loss_norm: 0.0648\n",
      " epoch: 35, train accuracy: 0.7975, train_loss_norm:0.0640, valid_acc: 0.7718, valid_loss_norm: 0.0643\n",
      " epoch: 36, train accuracy: 0.7975, train_loss_norm:0.0635, valid_acc: 0.7721, valid_loss_norm: 0.0638\n",
      " epoch: 37, train accuracy: 0.7980, train_loss_norm:0.0630, valid_acc: 0.7723, valid_loss_norm: 0.0633\n",
      " epoch: 38, train accuracy: 0.7981, train_loss_norm:0.0625, valid_acc: 0.7726, valid_loss_norm: 0.0628\n",
      " epoch: 39, train accuracy: 0.7983, train_loss_norm:0.0620, valid_acc: 0.7723, valid_loss_norm: 0.0623\n",
      " epoch: 40, train accuracy: 0.7986, train_loss_norm:0.0615, valid_acc: 0.7735, valid_loss_norm: 0.0618\n",
      " epoch: 41, train accuracy: 0.7988, train_loss_norm:0.0610, valid_acc: 0.7741, valid_loss_norm: 0.0614\n",
      " epoch: 42, train accuracy: 0.7989, train_loss_norm:0.0605, valid_acc: 0.7741, valid_loss_norm: 0.0609\n",
      " epoch: 43, train accuracy: 0.7991, train_loss_norm:0.0601, valid_acc: 0.7744, valid_loss_norm: 0.0605\n",
      " epoch: 44, train accuracy: 0.7995, train_loss_norm:0.0596, valid_acc: 0.7749, valid_loss_norm: 0.0600\n",
      " epoch: 45, train accuracy: 0.8002, train_loss_norm:0.0592, valid_acc: 0.7752, valid_loss_norm: 0.0596\n",
      " epoch: 46, train accuracy: 0.8005, train_loss_norm:0.0588, valid_acc: 0.7752, valid_loss_norm: 0.0592\n",
      " epoch: 47, train accuracy: 0.8007, train_loss_norm:0.0584, valid_acc: 0.7764, valid_loss_norm: 0.0588\n",
      " epoch: 48, train accuracy: 0.8010, train_loss_norm:0.0579, valid_acc: 0.7769, valid_loss_norm: 0.0584\n",
      " epoch: 49, train accuracy: 0.8012, train_loss_norm:0.0575, valid_acc: 0.7775, valid_loss_norm: 0.0580\n",
      " epoch: 50, train accuracy: 0.8016, train_loss_norm:0.0571, valid_acc: 0.7787, valid_loss_norm: 0.0576\n",
      " epoch: 51, train accuracy: 0.8021, train_loss_norm:0.0567, valid_acc: 0.7790, valid_loss_norm: 0.0572\n",
      " epoch: 52, train accuracy: 0.8023, train_loss_norm:0.0563, valid_acc: 0.7790, valid_loss_norm: 0.0568\n",
      " epoch: 53, train accuracy: 0.8028, train_loss_norm:0.0560, valid_acc: 0.7795, valid_loss_norm: 0.0565\n",
      " epoch: 54, train accuracy: 0.8033, train_loss_norm:0.0556, valid_acc: 0.7801, valid_loss_norm: 0.0561\n",
      " epoch: 55, train accuracy: 0.8034, train_loss_norm:0.0552, valid_acc: 0.7810, valid_loss_norm: 0.0557\n",
      " epoch: 56, train accuracy: 0.8036, train_loss_norm:0.0549, valid_acc: 0.7815, valid_loss_norm: 0.0554\n",
      " epoch: 57, train accuracy: 0.8036, train_loss_norm:0.0545, valid_acc: 0.7821, valid_loss_norm: 0.0551\n",
      " epoch: 58, train accuracy: 0.8039, train_loss_norm:0.0542, valid_acc: 0.7827, valid_loss_norm: 0.0547\n",
      " epoch: 59, train accuracy: 0.8042, train_loss_norm:0.0538, valid_acc: 0.7827, valid_loss_norm: 0.0544\n",
      " epoch: 60, train accuracy: 0.8047, train_loss_norm:0.0535, valid_acc: 0.7827, valid_loss_norm: 0.0541\n",
      " epoch: 61, train accuracy: 0.8050, train_loss_norm:0.0532, valid_acc: 0.7830, valid_loss_norm: 0.0538\n",
      " epoch: 62, train accuracy: 0.8054, train_loss_norm:0.0529, valid_acc: 0.7830, valid_loss_norm: 0.0535\n",
      " epoch: 63, train accuracy: 0.8056, train_loss_norm:0.0525, valid_acc: 0.7830, valid_loss_norm: 0.0531\n",
      " epoch: 64, train accuracy: 0.8060, train_loss_norm:0.0522, valid_acc: 0.7833, valid_loss_norm: 0.0528\n",
      " epoch: 65, train accuracy: 0.8064, train_loss_norm:0.0519, valid_acc: 0.7838, valid_loss_norm: 0.0526\n",
      " epoch: 66, train accuracy: 0.8065, train_loss_norm:0.0516, valid_acc: 0.7841, valid_loss_norm: 0.0523\n",
      " epoch: 67, train accuracy: 0.8066, train_loss_norm:0.0513, valid_acc: 0.7850, valid_loss_norm: 0.0520\n",
      " epoch: 68, train accuracy: 0.8069, train_loss_norm:0.0510, valid_acc: 0.7850, valid_loss_norm: 0.0517\n",
      " epoch: 69, train accuracy: 0.8075, train_loss_norm:0.0508, valid_acc: 0.7850, valid_loss_norm: 0.0514\n",
      " epoch: 70, train accuracy: 0.8077, train_loss_norm:0.0505, valid_acc: 0.7853, valid_loss_norm: 0.0512\n",
      " epoch: 71, train accuracy: 0.8080, train_loss_norm:0.0502, valid_acc: 0.7867, valid_loss_norm: 0.0509\n",
      " epoch: 72, train accuracy: 0.8082, train_loss_norm:0.0499, valid_acc: 0.7870, valid_loss_norm: 0.0506\n",
      " epoch: 73, train accuracy: 0.8084, train_loss_norm:0.0497, valid_acc: 0.7873, valid_loss_norm: 0.0504\n",
      " epoch: 74, train accuracy: 0.8088, train_loss_norm:0.0494, valid_acc: 0.7876, valid_loss_norm: 0.0501\n",
      " epoch: 75, train accuracy: 0.8090, train_loss_norm:0.0491, valid_acc: 0.7882, valid_loss_norm: 0.0499\n",
      " epoch: 76, train accuracy: 0.8092, train_loss_norm:0.0489, valid_acc: 0.7884, valid_loss_norm: 0.0496\n",
      " epoch: 77, train accuracy: 0.8096, train_loss_norm:0.0486, valid_acc: 0.7890, valid_loss_norm: 0.0494\n",
      " epoch: 78, train accuracy: 0.8096, train_loss_norm:0.0484, valid_acc: 0.7893, valid_loss_norm: 0.0491\n",
      " epoch: 79, train accuracy: 0.8099, train_loss_norm:0.0481, valid_acc: 0.7893, valid_loss_norm: 0.0489\n",
      " epoch: 80, train accuracy: 0.8102, train_loss_norm:0.0479, valid_acc: 0.7896, valid_loss_norm: 0.0487\n",
      " epoch: 81, train accuracy: 0.8104, train_loss_norm:0.0477, valid_acc: 0.7907, valid_loss_norm: 0.0485\n",
      " epoch: 82, train accuracy: 0.8108, train_loss_norm:0.0474, valid_acc: 0.7913, valid_loss_norm: 0.0482\n",
      " epoch: 83, train accuracy: 0.8113, train_loss_norm:0.0472, valid_acc: 0.7913, valid_loss_norm: 0.0480\n",
      " epoch: 84, train accuracy: 0.8117, train_loss_norm:0.0470, valid_acc: 0.7913, valid_loss_norm: 0.0478\n",
      " epoch: 85, train accuracy: 0.8121, train_loss_norm:0.0467, valid_acc: 0.7916, valid_loss_norm: 0.0476\n",
      " epoch: 86, train accuracy: 0.8124, train_loss_norm:0.0465, valid_acc: 0.7922, valid_loss_norm: 0.0474\n",
      " epoch: 87, train accuracy: 0.8127, train_loss_norm:0.0463, valid_acc: 0.7930, valid_loss_norm: 0.0472\n",
      " epoch: 88, train accuracy: 0.8130, train_loss_norm:0.0461, valid_acc: 0.7933, valid_loss_norm: 0.0470\n",
      " epoch: 89, train accuracy: 0.8136, train_loss_norm:0.0459, valid_acc: 0.7933, valid_loss_norm: 0.0468\n",
      " epoch: 90, train accuracy: 0.8140, train_loss_norm:0.0457, valid_acc: 0.7933, valid_loss_norm: 0.0466\n",
      " epoch: 91, train accuracy: 0.8144, train_loss_norm:0.0455, valid_acc: 0.7936, valid_loss_norm: 0.0464\n",
      " epoch: 92, train accuracy: 0.8148, train_loss_norm:0.0453, valid_acc: 0.7939, valid_loss_norm: 0.0462\n",
      " epoch: 93, train accuracy: 0.8150, train_loss_norm:0.0451, valid_acc: 0.7945, valid_loss_norm: 0.0460\n",
      " epoch: 94, train accuracy: 0.8153, train_loss_norm:0.0449, valid_acc: 0.7945, valid_loss_norm: 0.0458\n",
      " epoch: 95, train accuracy: 0.8156, train_loss_norm:0.0447, valid_acc: 0.7951, valid_loss_norm: 0.0456\n",
      " epoch: 96, train accuracy: 0.8157, train_loss_norm:0.0445, valid_acc: 0.7956, valid_loss_norm: 0.0454\n",
      " epoch: 97, train accuracy: 0.8160, train_loss_norm:0.0443, valid_acc: 0.7956, valid_loss_norm: 0.0452\n",
      " epoch: 98, train accuracy: 0.8163, train_loss_norm:0.0441, valid_acc: 0.7959, valid_loss_norm: 0.0451\n",
      " epoch: 99, train accuracy: 0.8164, train_loss_norm:0.0439, valid_acc: 0.7971, valid_loss_norm: 0.0449\n",
      " epoch: 100, train accuracy: 0.8167, train_loss_norm:0.0437, valid_acc: 0.7974, valid_loss_norm: 0.0447\n",
      " epoch: 101, train accuracy: 0.8170, train_loss_norm:0.0436, valid_acc: 0.7976, valid_loss_norm: 0.0445\n",
      " epoch: 102, train accuracy: 0.8172, train_loss_norm:0.0434, valid_acc: 0.7976, valid_loss_norm: 0.0444\n",
      " epoch: 103, train accuracy: 0.8175, train_loss_norm:0.0432, valid_acc: 0.7982, valid_loss_norm: 0.0442\n",
      " epoch: 104, train accuracy: 0.8178, train_loss_norm:0.0430, valid_acc: 0.7982, valid_loss_norm: 0.0440\n",
      " epoch: 105, train accuracy: 0.8184, train_loss_norm:0.0429, valid_acc: 0.7979, valid_loss_norm: 0.0439\n",
      " epoch: 106, train accuracy: 0.8188, train_loss_norm:0.0427, valid_acc: 0.7979, valid_loss_norm: 0.0437\n",
      " epoch: 107, train accuracy: 0.8190, train_loss_norm:0.0425, valid_acc: 0.7991, valid_loss_norm: 0.0436\n",
      " epoch: 108, train accuracy: 0.8193, train_loss_norm:0.0424, valid_acc: 0.7991, valid_loss_norm: 0.0434\n",
      " epoch: 109, train accuracy: 0.8196, train_loss_norm:0.0422, valid_acc: 0.7994, valid_loss_norm: 0.0432\n",
      " epoch: 110, train accuracy: 0.8198, train_loss_norm:0.0420, valid_acc: 0.7991, valid_loss_norm: 0.0431\n",
      " epoch: 111, train accuracy: 0.8200, train_loss_norm:0.0419, valid_acc: 0.7997, valid_loss_norm: 0.0429\n",
      " epoch: 112, train accuracy: 0.8203, train_loss_norm:0.0417, valid_acc: 0.7997, valid_loss_norm: 0.0428\n",
      " epoch: 113, train accuracy: 0.8203, train_loss_norm:0.0416, valid_acc: 0.7994, valid_loss_norm: 0.0426\n",
      " epoch: 114, train accuracy: 0.8206, train_loss_norm:0.0414, valid_acc: 0.7997, valid_loss_norm: 0.0425\n",
      " epoch: 115, train accuracy: 0.8208, train_loss_norm:0.0412, valid_acc: 0.7997, valid_loss_norm: 0.0423\n",
      " epoch: 116, train accuracy: 0.8209, train_loss_norm:0.0411, valid_acc: 0.7997, valid_loss_norm: 0.0422\n",
      " epoch: 117, train accuracy: 0.8211, train_loss_norm:0.0409, valid_acc: 0.7997, valid_loss_norm: 0.0421\n",
      " epoch: 118, train accuracy: 0.8213, train_loss_norm:0.0408, valid_acc: 0.7997, valid_loss_norm: 0.0419\n",
      " epoch: 119, train accuracy: 0.8213, train_loss_norm:0.0407, valid_acc: 0.7997, valid_loss_norm: 0.0418\n",
      " epoch: 120, train accuracy: 0.8215, train_loss_norm:0.0405, valid_acc: 0.7994, valid_loss_norm: 0.0416\n",
      " epoch: 121, train accuracy: 0.8217, train_loss_norm:0.0404, valid_acc: 0.7994, valid_loss_norm: 0.0415\n",
      " epoch: 122, train accuracy: 0.8219, train_loss_norm:0.0402, valid_acc: 0.7994, valid_loss_norm: 0.0414\n",
      " epoch: 123, train accuracy: 0.8221, train_loss_norm:0.0401, valid_acc: 0.7994, valid_loss_norm: 0.0412\n",
      " epoch: 124, train accuracy: 0.8223, train_loss_norm:0.0399, valid_acc: 0.7999, valid_loss_norm: 0.0411\n",
      " epoch: 125, train accuracy: 0.8226, train_loss_norm:0.0398, valid_acc: 0.8002, valid_loss_norm: 0.0410\n",
      " epoch: 126, train accuracy: 0.8227, train_loss_norm:0.0397, valid_acc: 0.7999, valid_loss_norm: 0.0408\n",
      " epoch: 127, train accuracy: 0.8229, train_loss_norm:0.0395, valid_acc: 0.8005, valid_loss_norm: 0.0407\n",
      " epoch: 128, train accuracy: 0.8230, train_loss_norm:0.0394, valid_acc: 0.8005, valid_loss_norm: 0.0406\n",
      " epoch: 129, train accuracy: 0.8231, train_loss_norm:0.0393, valid_acc: 0.8002, valid_loss_norm: 0.0405\n",
      " epoch: 130, train accuracy: 0.8233, train_loss_norm:0.0391, valid_acc: 0.8002, valid_loss_norm: 0.0403\n",
      " epoch: 131, train accuracy: 0.8235, train_loss_norm:0.0390, valid_acc: 0.8002, valid_loss_norm: 0.0402\n",
      " epoch: 132, train accuracy: 0.8239, train_loss_norm:0.0389, valid_acc: 0.8002, valid_loss_norm: 0.0401\n",
      " epoch: 133, train accuracy: 0.8241, train_loss_norm:0.0388, valid_acc: 0.8002, valid_loss_norm: 0.0400\n",
      " epoch: 134, train accuracy: 0.8246, train_loss_norm:0.0386, valid_acc: 0.8005, valid_loss_norm: 0.0399\n",
      " epoch: 135, train accuracy: 0.8248, train_loss_norm:0.0385, valid_acc: 0.8005, valid_loss_norm: 0.0397\n",
      " epoch: 136, train accuracy: 0.8249, train_loss_norm:0.0384, valid_acc: 0.8005, valid_loss_norm: 0.0396\n",
      " epoch: 137, train accuracy: 0.8249, train_loss_norm:0.0383, valid_acc: 0.8005, valid_loss_norm: 0.0395\n",
      " epoch: 138, train accuracy: 0.8253, train_loss_norm:0.0382, valid_acc: 0.8008, valid_loss_norm: 0.0394\n",
      " epoch: 139, train accuracy: 0.8254, train_loss_norm:0.0380, valid_acc: 0.8008, valid_loss_norm: 0.0393\n",
      " epoch: 140, train accuracy: 0.8257, train_loss_norm:0.0379, valid_acc: 0.8011, valid_loss_norm: 0.0392\n",
      " epoch: 141, train accuracy: 0.8257, train_loss_norm:0.0378, valid_acc: 0.8011, valid_loss_norm: 0.0391\n",
      " epoch: 142, train accuracy: 0.8259, train_loss_norm:0.0377, valid_acc: 0.8014, valid_loss_norm: 0.0390\n",
      " epoch: 143, train accuracy: 0.8260, train_loss_norm:0.0376, valid_acc: 0.8014, valid_loss_norm: 0.0388\n",
      " epoch: 144, train accuracy: 0.8265, train_loss_norm:0.0375, valid_acc: 0.8022, valid_loss_norm: 0.0387\n",
      " epoch: 145, train accuracy: 0.8265, train_loss_norm:0.0373, valid_acc: 0.8020, valid_loss_norm: 0.0386\n",
      " epoch: 146, train accuracy: 0.8267, train_loss_norm:0.0372, valid_acc: 0.8028, valid_loss_norm: 0.0385\n",
      " epoch: 147, train accuracy: 0.8268, train_loss_norm:0.0371, valid_acc: 0.8031, valid_loss_norm: 0.0384\n",
      " epoch: 148, train accuracy: 0.8271, train_loss_norm:0.0370, valid_acc: 0.8037, valid_loss_norm: 0.0383\n",
      " epoch: 149, train accuracy: 0.8274, train_loss_norm:0.0369, valid_acc: 0.8040, valid_loss_norm: 0.0382\n",
      " epoch: 150, train accuracy: 0.8278, train_loss_norm:0.0368, valid_acc: 0.8040, valid_loss_norm: 0.0381\n",
      " epoch: 151, train accuracy: 0.8279, train_loss_norm:0.0367, valid_acc: 0.8037, valid_loss_norm: 0.0380\n",
      " epoch: 152, train accuracy: 0.8282, train_loss_norm:0.0366, valid_acc: 0.8037, valid_loss_norm: 0.0379\n",
      " epoch: 153, train accuracy: 0.8285, train_loss_norm:0.0365, valid_acc: 0.8043, valid_loss_norm: 0.0378\n",
      " epoch: 154, train accuracy: 0.8286, train_loss_norm:0.0364, valid_acc: 0.8045, valid_loss_norm: 0.0377\n",
      " epoch: 155, train accuracy: 0.8288, train_loss_norm:0.0363, valid_acc: 0.8045, valid_loss_norm: 0.0376\n",
      " epoch: 156, train accuracy: 0.8290, train_loss_norm:0.0362, valid_acc: 0.8048, valid_loss_norm: 0.0375\n",
      " epoch: 157, train accuracy: 0.8290, train_loss_norm:0.0361, valid_acc: 0.8051, valid_loss_norm: 0.0374\n",
      " epoch: 158, train accuracy: 0.8294, train_loss_norm:0.0360, valid_acc: 0.8057, valid_loss_norm: 0.0373\n",
      " epoch: 159, train accuracy: 0.8295, train_loss_norm:0.0359, valid_acc: 0.8054, valid_loss_norm: 0.0372\n",
      " epoch: 160, train accuracy: 0.8297, train_loss_norm:0.0358, valid_acc: 0.8057, valid_loss_norm: 0.0371\n",
      " epoch: 161, train accuracy: 0.8300, train_loss_norm:0.0357, valid_acc: 0.8063, valid_loss_norm: 0.0371\n",
      " epoch: 162, train accuracy: 0.8302, train_loss_norm:0.0356, valid_acc: 0.8063, valid_loss_norm: 0.0370\n",
      " epoch: 163, train accuracy: 0.8303, train_loss_norm:0.0355, valid_acc: 0.8066, valid_loss_norm: 0.0369\n",
      " epoch: 164, train accuracy: 0.8307, train_loss_norm:0.0354, valid_acc: 0.8063, valid_loss_norm: 0.0368\n",
      " epoch: 165, train accuracy: 0.8308, train_loss_norm:0.0353, valid_acc: 0.8066, valid_loss_norm: 0.0367\n",
      " epoch: 166, train accuracy: 0.8308, train_loss_norm:0.0352, valid_acc: 0.8068, valid_loss_norm: 0.0366\n",
      " epoch: 167, train accuracy: 0.8308, train_loss_norm:0.0351, valid_acc: 0.8063, valid_loss_norm: 0.0365\n",
      " epoch: 168, train accuracy: 0.8310, train_loss_norm:0.0350, valid_acc: 0.8068, valid_loss_norm: 0.0364\n",
      " epoch: 169, train accuracy: 0.8311, train_loss_norm:0.0349, valid_acc: 0.8066, valid_loss_norm: 0.0363\n",
      " epoch: 170, train accuracy: 0.8312, train_loss_norm:0.0348, valid_acc: 0.8068, valid_loss_norm: 0.0363\n",
      " epoch: 171, train accuracy: 0.8316, train_loss_norm:0.0347, valid_acc: 0.8068, valid_loss_norm: 0.0362\n",
      " epoch: 172, train accuracy: 0.8318, train_loss_norm:0.0347, valid_acc: 0.8066, valid_loss_norm: 0.0361\n",
      " epoch: 173, train accuracy: 0.8319, train_loss_norm:0.0346, valid_acc: 0.8066, valid_loss_norm: 0.0360\n",
      " epoch: 174, train accuracy: 0.8322, train_loss_norm:0.0345, valid_acc: 0.8068, valid_loss_norm: 0.0359\n",
      " epoch: 175, train accuracy: 0.8322, train_loss_norm:0.0344, valid_acc: 0.8068, valid_loss_norm: 0.0358\n",
      " epoch: 176, train accuracy: 0.8325, train_loss_norm:0.0343, valid_acc: 0.8071, valid_loss_norm: 0.0358\n",
      " epoch: 177, train accuracy: 0.8327, train_loss_norm:0.0342, valid_acc: 0.8068, valid_loss_norm: 0.0357\n",
      " epoch: 178, train accuracy: 0.8328, train_loss_norm:0.0341, valid_acc: 0.8068, valid_loss_norm: 0.0356\n",
      " epoch: 179, train accuracy: 0.8330, train_loss_norm:0.0340, valid_acc: 0.8071, valid_loss_norm: 0.0355\n",
      " epoch: 180, train accuracy: 0.8333, train_loss_norm:0.0340, valid_acc: 0.8071, valid_loss_norm: 0.0354\n",
      " epoch: 181, train accuracy: 0.8336, train_loss_norm:0.0339, valid_acc: 0.8071, valid_loss_norm: 0.0354\n",
      " epoch: 182, train accuracy: 0.8337, train_loss_norm:0.0338, valid_acc: 0.8071, valid_loss_norm: 0.0353\n",
      " epoch: 183, train accuracy: 0.8337, train_loss_norm:0.0337, valid_acc: 0.8071, valid_loss_norm: 0.0352\n",
      " epoch: 184, train accuracy: 0.8337, train_loss_norm:0.0336, valid_acc: 0.8071, valid_loss_norm: 0.0351\n",
      " epoch: 185, train accuracy: 0.8341, train_loss_norm:0.0336, valid_acc: 0.8077, valid_loss_norm: 0.0350\n",
      " epoch: 186, train accuracy: 0.8342, train_loss_norm:0.0335, valid_acc: 0.8074, valid_loss_norm: 0.0350\n",
      " epoch: 187, train accuracy: 0.8343, train_loss_norm:0.0334, valid_acc: 0.8080, valid_loss_norm: 0.0349\n",
      " epoch: 188, train accuracy: 0.8346, train_loss_norm:0.0333, valid_acc: 0.8080, valid_loss_norm: 0.0348\n",
      " epoch: 189, train accuracy: 0.8349, train_loss_norm:0.0332, valid_acc: 0.8080, valid_loss_norm: 0.0347\n",
      " epoch: 190, train accuracy: 0.8350, train_loss_norm:0.0332, valid_acc: 0.8080, valid_loss_norm: 0.0347\n",
      " epoch: 191, train accuracy: 0.8350, train_loss_norm:0.0331, valid_acc: 0.8083, valid_loss_norm: 0.0346\n",
      " epoch: 192, train accuracy: 0.8351, train_loss_norm:0.0330, valid_acc: 0.8089, valid_loss_norm: 0.0345\n",
      " epoch: 193, train accuracy: 0.8353, train_loss_norm:0.0329, valid_acc: 0.8089, valid_loss_norm: 0.0345\n",
      " epoch: 194, train accuracy: 0.8354, train_loss_norm:0.0329, valid_acc: 0.8097, valid_loss_norm: 0.0344\n",
      " epoch: 195, train accuracy: 0.8356, train_loss_norm:0.0328, valid_acc: 0.8097, valid_loss_norm: 0.0343\n",
      " epoch: 196, train accuracy: 0.8360, train_loss_norm:0.0327, valid_acc: 0.8100, valid_loss_norm: 0.0342\n",
      " epoch: 197, train accuracy: 0.8361, train_loss_norm:0.0326, valid_acc: 0.8097, valid_loss_norm: 0.0342\n",
      " epoch: 198, train accuracy: 0.8363, train_loss_norm:0.0326, valid_acc: 0.8097, valid_loss_norm: 0.0341\n",
      " epoch: 199, train accuracy: 0.8367, train_loss_norm:0.0325, valid_acc: 0.8100, valid_loss_norm: 0.0340\n",
      " epoch: 200, train accuracy: 0.8368, train_loss_norm:0.0324, valid_acc: 0.8103, valid_loss_norm: 0.0340\n",
      " epoch: 201, train accuracy: 0.8369, train_loss_norm:0.0323, valid_acc: 0.8103, valid_loss_norm: 0.0339\n",
      " epoch: 202, train accuracy: 0.8371, train_loss_norm:0.0323, valid_acc: 0.8106, valid_loss_norm: 0.0338\n",
      " epoch: 203, train accuracy: 0.8374, train_loss_norm:0.0322, valid_acc: 0.8109, valid_loss_norm: 0.0338\n",
      " epoch: 204, train accuracy: 0.8376, train_loss_norm:0.0321, valid_acc: 0.8114, valid_loss_norm: 0.0337\n",
      " epoch: 205, train accuracy: 0.8378, train_loss_norm:0.0321, valid_acc: 0.8123, valid_loss_norm: 0.0336\n",
      " epoch: 206, train accuracy: 0.8379, train_loss_norm:0.0320, valid_acc: 0.8120, valid_loss_norm: 0.0336\n",
      " epoch: 207, train accuracy: 0.8380, train_loss_norm:0.0319, valid_acc: 0.8126, valid_loss_norm: 0.0335\n",
      " epoch: 208, train accuracy: 0.8382, train_loss_norm:0.0318, valid_acc: 0.8126, valid_loss_norm: 0.0334\n",
      " epoch: 209, train accuracy: 0.8384, train_loss_norm:0.0318, valid_acc: 0.8132, valid_loss_norm: 0.0334\n",
      " epoch: 210, train accuracy: 0.8385, train_loss_norm:0.0317, valid_acc: 0.8132, valid_loss_norm: 0.0333\n",
      " epoch: 211, train accuracy: 0.8385, train_loss_norm:0.0316, valid_acc: 0.8132, valid_loss_norm: 0.0333\n",
      " epoch: 212, train accuracy: 0.8385, train_loss_norm:0.0316, valid_acc: 0.8129, valid_loss_norm: 0.0332\n",
      " epoch: 213, train accuracy: 0.8388, train_loss_norm:0.0315, valid_acc: 0.8129, valid_loss_norm: 0.0331\n",
      " epoch: 214, train accuracy: 0.8388, train_loss_norm:0.0314, valid_acc: 0.8132, valid_loss_norm: 0.0331\n",
      " epoch: 215, train accuracy: 0.8389, train_loss_norm:0.0314, valid_acc: 0.8135, valid_loss_norm: 0.0330\n",
      " epoch: 216, train accuracy: 0.8391, train_loss_norm:0.0313, valid_acc: 0.8137, valid_loss_norm: 0.0329\n",
      " epoch: 217, train accuracy: 0.8393, train_loss_norm:0.0313, valid_acc: 0.8135, valid_loss_norm: 0.0329\n",
      " epoch: 218, train accuracy: 0.8394, train_loss_norm:0.0312, valid_acc: 0.8135, valid_loss_norm: 0.0328\n",
      " epoch: 219, train accuracy: 0.8395, train_loss_norm:0.0311, valid_acc: 0.8132, valid_loss_norm: 0.0328\n",
      " epoch: 220, train accuracy: 0.8395, train_loss_norm:0.0311, valid_acc: 0.8132, valid_loss_norm: 0.0327\n",
      " epoch: 221, train accuracy: 0.8396, train_loss_norm:0.0310, valid_acc: 0.8132, valid_loss_norm: 0.0326\n",
      " epoch: 222, train accuracy: 0.8399, train_loss_norm:0.0309, valid_acc: 0.8132, valid_loss_norm: 0.0326\n",
      " epoch: 223, train accuracy: 0.8401, train_loss_norm:0.0309, valid_acc: 0.8135, valid_loss_norm: 0.0325\n",
      " epoch: 224, train accuracy: 0.8402, train_loss_norm:0.0308, valid_acc: 0.8135, valid_loss_norm: 0.0325\n",
      " epoch: 225, train accuracy: 0.8403, train_loss_norm:0.0307, valid_acc: 0.8132, valid_loss_norm: 0.0324\n",
      " epoch: 226, train accuracy: 0.8405, train_loss_norm:0.0307, valid_acc: 0.8135, valid_loss_norm: 0.0324\n",
      " epoch: 227, train accuracy: 0.8407, train_loss_norm:0.0306, valid_acc: 0.8135, valid_loss_norm: 0.0323\n",
      " epoch: 228, train accuracy: 0.8407, train_loss_norm:0.0306, valid_acc: 0.8140, valid_loss_norm: 0.0322\n",
      " epoch: 229, train accuracy: 0.8408, train_loss_norm:0.0305, valid_acc: 0.8140, valid_loss_norm: 0.0322\n",
      " epoch: 230, train accuracy: 0.8408, train_loss_norm:0.0304, valid_acc: 0.8140, valid_loss_norm: 0.0321\n",
      " epoch: 231, train accuracy: 0.8410, train_loss_norm:0.0304, valid_acc: 0.8140, valid_loss_norm: 0.0321\n",
      " epoch: 232, train accuracy: 0.8410, train_loss_norm:0.0303, valid_acc: 0.8140, valid_loss_norm: 0.0320\n",
      " epoch: 233, train accuracy: 0.8411, train_loss_norm:0.0303, valid_acc: 0.8143, valid_loss_norm: 0.0320\n",
      " epoch: 234, train accuracy: 0.8411, train_loss_norm:0.0302, valid_acc: 0.8143, valid_loss_norm: 0.0319\n",
      " epoch: 235, train accuracy: 0.8413, train_loss_norm:0.0302, valid_acc: 0.8146, valid_loss_norm: 0.0319\n",
      " epoch: 236, train accuracy: 0.8413, train_loss_norm:0.0301, valid_acc: 0.8149, valid_loss_norm: 0.0318\n",
      " epoch: 237, train accuracy: 0.8416, train_loss_norm:0.0300, valid_acc: 0.8149, valid_loss_norm: 0.0317\n",
      " epoch: 238, train accuracy: 0.8417, train_loss_norm:0.0300, valid_acc: 0.8149, valid_loss_norm: 0.0317\n",
      " epoch: 239, train accuracy: 0.8419, train_loss_norm:0.0299, valid_acc: 0.8149, valid_loss_norm: 0.0316\n",
      " epoch: 240, train accuracy: 0.8420, train_loss_norm:0.0299, valid_acc: 0.8152, valid_loss_norm: 0.0316\n",
      " epoch: 241, train accuracy: 0.8421, train_loss_norm:0.0298, valid_acc: 0.8158, valid_loss_norm: 0.0315\n",
      " epoch: 242, train accuracy: 0.8422, train_loss_norm:0.0298, valid_acc: 0.8158, valid_loss_norm: 0.0315\n",
      " epoch: 243, train accuracy: 0.8423, train_loss_norm:0.0297, valid_acc: 0.8160, valid_loss_norm: 0.0314\n",
      " epoch: 244, train accuracy: 0.8424, train_loss_norm:0.0297, valid_acc: 0.8163, valid_loss_norm: 0.0314\n",
      " epoch: 245, train accuracy: 0.8425, train_loss_norm:0.0296, valid_acc: 0.8160, valid_loss_norm: 0.0313\n",
      " epoch: 246, train accuracy: 0.8426, train_loss_norm:0.0295, valid_acc: 0.8163, valid_loss_norm: 0.0313\n",
      " epoch: 247, train accuracy: 0.8428, train_loss_norm:0.0295, valid_acc: 0.8163, valid_loss_norm: 0.0312\n",
      " epoch: 248, train accuracy: 0.8432, train_loss_norm:0.0294, valid_acc: 0.8163, valid_loss_norm: 0.0312\n",
      " epoch: 249, train accuracy: 0.8432, train_loss_norm:0.0294, valid_acc: 0.8163, valid_loss_norm: 0.0311\n",
      " epoch: 250, train accuracy: 0.8433, train_loss_norm:0.0293, valid_acc: 0.8166, valid_loss_norm: 0.0311\n",
      " epoch: 251, train accuracy: 0.8433, train_loss_norm:0.0293, valid_acc: 0.8175, valid_loss_norm: 0.0310\n",
      " epoch: 252, train accuracy: 0.8434, train_loss_norm:0.0292, valid_acc: 0.8175, valid_loss_norm: 0.0310\n",
      " epoch: 253, train accuracy: 0.8435, train_loss_norm:0.0292, valid_acc: 0.8178, valid_loss_norm: 0.0309\n",
      " epoch: 254, train accuracy: 0.8435, train_loss_norm:0.0291, valid_acc: 0.8178, valid_loss_norm: 0.0309\n",
      " epoch: 255, train accuracy: 0.8435, train_loss_norm:0.0291, valid_acc: 0.8178, valid_loss_norm: 0.0308\n",
      " epoch: 256, train accuracy: 0.8437, train_loss_norm:0.0290, valid_acc: 0.8178, valid_loss_norm: 0.0308\n",
      " epoch: 257, train accuracy: 0.8438, train_loss_norm:0.0290, valid_acc: 0.8181, valid_loss_norm: 0.0307\n",
      " epoch: 258, train accuracy: 0.8440, train_loss_norm:0.0289, valid_acc: 0.8183, valid_loss_norm: 0.0307\n",
      " epoch: 259, train accuracy: 0.8442, train_loss_norm:0.0289, valid_acc: 0.8183, valid_loss_norm: 0.0306\n",
      " epoch: 260, train accuracy: 0.8443, train_loss_norm:0.0288, valid_acc: 0.8183, valid_loss_norm: 0.0306\n",
      " epoch: 261, train accuracy: 0.8445, train_loss_norm:0.0288, valid_acc: 0.8183, valid_loss_norm: 0.0306\n",
      " epoch: 262, train accuracy: 0.8447, train_loss_norm:0.0287, valid_acc: 0.8186, valid_loss_norm: 0.0305\n",
      " epoch: 263, train accuracy: 0.8447, train_loss_norm:0.0287, valid_acc: 0.8186, valid_loss_norm: 0.0305\n",
      " epoch: 264, train accuracy: 0.8447, train_loss_norm:0.0286, valid_acc: 0.8189, valid_loss_norm: 0.0304\n",
      " epoch: 265, train accuracy: 0.8449, train_loss_norm:0.0286, valid_acc: 0.8189, valid_loss_norm: 0.0304\n",
      " epoch: 266, train accuracy: 0.8449, train_loss_norm:0.0285, valid_acc: 0.8189, valid_loss_norm: 0.0303\n",
      " epoch: 267, train accuracy: 0.8450, train_loss_norm:0.0285, valid_acc: 0.8195, valid_loss_norm: 0.0303\n",
      " epoch: 268, train accuracy: 0.8451, train_loss_norm:0.0284, valid_acc: 0.8195, valid_loss_norm: 0.0302\n",
      " epoch: 269, train accuracy: 0.8452, train_loss_norm:0.0284, valid_acc: 0.8195, valid_loss_norm: 0.0302\n",
      " epoch: 270, train accuracy: 0.8453, train_loss_norm:0.0283, valid_acc: 0.8195, valid_loss_norm: 0.0301\n",
      " epoch: 271, train accuracy: 0.8454, train_loss_norm:0.0283, valid_acc: 0.8195, valid_loss_norm: 0.0301\n",
      " epoch: 272, train accuracy: 0.8454, train_loss_norm:0.0282, valid_acc: 0.8195, valid_loss_norm: 0.0301\n",
      " epoch: 273, train accuracy: 0.8454, train_loss_norm:0.0282, valid_acc: 0.8198, valid_loss_norm: 0.0300\n",
      " epoch: 274, train accuracy: 0.8455, train_loss_norm:0.0282, valid_acc: 0.8198, valid_loss_norm: 0.0300\n",
      " epoch: 275, train accuracy: 0.8456, train_loss_norm:0.0281, valid_acc: 0.8198, valid_loss_norm: 0.0299\n",
      " epoch: 276, train accuracy: 0.8456, train_loss_norm:0.0281, valid_acc: 0.8198, valid_loss_norm: 0.0299\n",
      " epoch: 277, train accuracy: 0.8457, train_loss_norm:0.0280, valid_acc: 0.8198, valid_loss_norm: 0.0298\n",
      " epoch: 278, train accuracy: 0.8459, train_loss_norm:0.0280, valid_acc: 0.8198, valid_loss_norm: 0.0298\n",
      " epoch: 279, train accuracy: 0.8461, train_loss_norm:0.0279, valid_acc: 0.8198, valid_loss_norm: 0.0298\n",
      " epoch: 280, train accuracy: 0.8463, train_loss_norm:0.0279, valid_acc: 0.8198, valid_loss_norm: 0.0297\n",
      " epoch: 281, train accuracy: 0.8464, train_loss_norm:0.0278, valid_acc: 0.8198, valid_loss_norm: 0.0297\n",
      " epoch: 282, train accuracy: 0.8464, train_loss_norm:0.0278, valid_acc: 0.8201, valid_loss_norm: 0.0296\n",
      " epoch: 283, train accuracy: 0.8465, train_loss_norm:0.0277, valid_acc: 0.8201, valid_loss_norm: 0.0296\n",
      " epoch: 284, train accuracy: 0.8466, train_loss_norm:0.0277, valid_acc: 0.8204, valid_loss_norm: 0.0296\n",
      " epoch: 285, train accuracy: 0.8467, train_loss_norm:0.0277, valid_acc: 0.8198, valid_loss_norm: 0.0295\n",
      " epoch: 286, train accuracy: 0.8469, train_loss_norm:0.0276, valid_acc: 0.8198, valid_loss_norm: 0.0295\n",
      " epoch: 287, train accuracy: 0.8468, train_loss_norm:0.0276, valid_acc: 0.8195, valid_loss_norm: 0.0294\n",
      " epoch: 288, train accuracy: 0.8469, train_loss_norm:0.0275, valid_acc: 0.8198, valid_loss_norm: 0.0294\n",
      " epoch: 289, train accuracy: 0.8470, train_loss_norm:0.0275, valid_acc: 0.8198, valid_loss_norm: 0.0294\n",
      " epoch: 290, train accuracy: 0.8471, train_loss_norm:0.0274, valid_acc: 0.8198, valid_loss_norm: 0.0293\n",
      " epoch: 291, train accuracy: 0.8472, train_loss_norm:0.0274, valid_acc: 0.8192, valid_loss_norm: 0.0293\n",
      " epoch: 292, train accuracy: 0.8473, train_loss_norm:0.0274, valid_acc: 0.8189, valid_loss_norm: 0.0292\n",
      " epoch: 293, train accuracy: 0.8474, train_loss_norm:0.0273, valid_acc: 0.8189, valid_loss_norm: 0.0292\n",
      " epoch: 294, train accuracy: 0.8475, train_loss_norm:0.0273, valid_acc: 0.8186, valid_loss_norm: 0.0292\n",
      " epoch: 295, train accuracy: 0.8475, train_loss_norm:0.0272, valid_acc: 0.8189, valid_loss_norm: 0.0291\n",
      " epoch: 296, train accuracy: 0.8477, train_loss_norm:0.0272, valid_acc: 0.8189, valid_loss_norm: 0.0291\n",
      " epoch: 297, train accuracy: 0.8477, train_loss_norm:0.0272, valid_acc: 0.8186, valid_loss_norm: 0.0290\n",
      " epoch: 298, train accuracy: 0.8477, train_loss_norm:0.0271, valid_acc: 0.8186, valid_loss_norm: 0.0290\n",
      " epoch: 299, train accuracy: 0.8479, train_loss_norm:0.0271, valid_acc: 0.8186, valid_loss_norm: 0.0290\n",
      " epoch: 300, train accuracy: 0.8480, train_loss_norm:0.0270, valid_acc: 0.8189, valid_loss_norm: 0.0289\n",
      "Test accuracy: 0.8181\n",
      "Test loss norm: 0.0291\n",
      "Average test accuracy over 10 folds: 0.8267 (+/- 0.0062)\n",
      "Average test loss per example and class over 10 folds: 0.028714254004416646\n"
     ]
    }
   ],
   "source": [
    "### Q6(b) - Stochastic Gradient Descent\n",
    "\n",
    "print(\"Q6(b) - Stochastic Gradient Descent\")\n",
    "\n",
    "# (i)\n",
    "# Load aligned data\n",
    "X, y = traffic_sign(True)\n",
    "X = X.astype(np.float32) # cast to float32 as float64 running out of memory\n",
    "X = z_score_normalize(X) \n",
    "\n",
    "# Softmax Regression Parameters\n",
    "lr = 0.1\n",
    "num_features = X.shape[1]\n",
    "num_classes = y.max() + 1\n",
    "\n",
    "train_loss_record = []\n",
    "train_accuracy_record = []\n",
    "holdout_loss_record = []\n",
    "holdout_accuracy_record = []\n",
    "test_accuracy_record = []\n",
    "\n",
    "\n",
    "# PCA number of principal components\n",
    "n_components = 300\n",
    "\n",
    "first_plot = True\n",
    "\n",
    "num_epochs = 300\n",
    "epochs_print = [50, 100, 150, 200, 250, 300]\n",
    "\n",
    "cur_fold = 0\n",
    "\n",
    "total_test_loss = 0\n",
    "\n",
    "for train, valid, test in generate_k_fold_set((X, y), k = 10):\n",
    "    print(\"Cur fold:\", cur_fold)\n",
    "    train_data, train_label = train\n",
    "    valid_data, valid_label = valid\n",
    "    test_data, test_label = test\n",
    "    \n",
    "    # Project data onto principal components\n",
    "    pca = PCA(n_components)\n",
    "    projected = pca.fit_transform(train_data)\n",
    "    \n",
    "    # Plot principal components\n",
    "    if first_plot == True : \n",
    "        pca.plot_PC()\n",
    "        first_plot = False\n",
    "    train_d = append_bias(projected)     \n",
    "    valid_d = append_bias(pca.PCA_generate(valid_data))\n",
    "    test_d = append_bias(pca.PCA_generate(test_data))\n",
    "\n",
    "    softmax_model = SoftmaxRegression(lr, n_components, num_classes)\n",
    "\n",
    "    valid_label_onehot = onehot_encode(valid_label)\n",
    "    test_label_onehot = onehot_encode(test_label)\n",
    "\n",
    "    # SGD\n",
    "    for epoch in range(num_epochs):\n",
    "        # Shuffle indices\n",
    "        indices = np.arange(len(train_d))\n",
    "        indices = np.random.shuffle(indices)\n",
    "\n",
    "        train_d = train_d[indices].squeeze(0)\n",
    "        train_label = train_label[indices].squeeze(0)\n",
    "        \n",
    "        # Onehot encode labels\n",
    "        y_true = onehot_encode(train_label)\n",
    "            \n",
    "        # Iterate over each example\n",
    "        for i in range(len(train_d)):\n",
    "            cur_ex = train_d[i][np.newaxis, :]\n",
    "            cur_label = y_true[i][np.newaxis, :]\n",
    "            y_hat = softmax_model.model(cur_ex)\n",
    "\n",
    "            # Update Weights\n",
    "            softmax_model.update_weights(cur_ex, cur_label, y_hat)\n",
    "\n",
    "        # Training Loss\n",
    "        y_hat = softmax_model.model(train_d)\n",
    "\n",
    "        raw_train_loss = softmax_model.cross_entropy(y_true, y_hat)\n",
    "        train_loss_norm = raw_train_loss / len(train_d) / num_classes\n",
    "\n",
    "        train_loss_record.append(train_loss_norm)\n",
    "\n",
    "        train_accuracy = softmax_model.accuracy(y_true, y_hat)\n",
    "        train_accuracy_record.append(train_accuracy)\n",
    "\n",
    "        # Validation Loss\n",
    "        holdout_y = softmax_model.model(valid_d)\n",
    "\n",
    "        holdout_loss = softmax_model.cross_entropy(valid_label_onehot, holdout_y)\n",
    "        holdout_loss_norm = holdout_loss / len(valid_d) / num_classes # holdout loss normalized by # examples and classes\n",
    "        holdout_loss_record.append(holdout_loss_norm)\n",
    "\n",
    "        holdout_accuracy = softmax_model.accuracy(holdout_y, valid_label_onehot)\n",
    "        holdout_accuracy_record.append(holdout_accuracy)\n",
    "\n",
    "        if holdout_accuracy >= max(holdout_accuracy_record[cur_fold * num_epochs:]):\n",
    "            best_w = softmax_model.W\n",
    "\n",
    "        \n",
    "        # if (epoch + 1) in epochs_print:\n",
    "        print(f' epoch: {epoch + 1}, train accuracy: {train_accuracy:.4f}, train_loss_norm:{train_loss_norm:.4f}, '\\\n",
    "            f'valid_acc: {holdout_accuracy:.4f}, valid_loss_norm: {holdout_loss_norm:.4f}')\n",
    "\n",
    "    # Run on Test Dataset\n",
    "    test_y = softmax_model.model_w(test_d, best_w)\n",
    "\n",
    "    test_accuracy = softmax_model.accuracy(test_y, test_label_onehot)\n",
    "\n",
    "    print(f'Test accuracy: {test_accuracy:.4f}')\n",
    "\n",
    "    test_accuracy_record.append(test_accuracy)\n",
    "\n",
    "    raw_test_loss = softmax_model.cross_entropy(test_label_onehot, test_y)\n",
    "    test_loss_norm = raw_test_loss / len(test_d) / num_classes\n",
    "    total_test_loss += test_loss_norm\n",
    "    print(f\"Test loss norm: {test_loss_norm:.4f}\")\n",
    "\n",
    "    cur_fold += 1\n",
    "\n",
    "print(f'Average test accuracy over {k} folds: {np.mean(test_accuracy_record):.4f} (+/- {np.std(test_accuracy_record):.4f})')\n",
    "print(f'Average test loss per example and class over {k} folds: {total_test_loss / k}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Victor\\AppData\\Local\\Temp/ipykernel_5488/1869973321.py:20: UserWarning: linestyle is redundantly defined by the 'linestyle' keyword argument and the fmt string \"-b\" (-> linestyle='-'). The keyword argument will take precedence.\n",
      "  axs[0].errorbar(x=epochs_error_bar_0, y=train_loss_error_bar_y, yerr=train_loss_error_bar_yerr, label='Training loss error', fmt='-b', linestyle='')\n",
      "C:\\Users\\Victor\\AppData\\Local\\Temp/ipykernel_5488/1869973321.py:23: UserWarning: linestyle is redundantly defined by the 'linestyle' keyword argument and the fmt string \"--r\" (-> linestyle='--'). The keyword argument will take precedence.\n",
      "  axs[0].errorbar(x=epochs_error_bar_0, y=valid_loss_error_bar_y, yerr=valid_loss_error_bar_yerr, label='Validation loss error', fmt='--r', linestyle='')\n",
      "C:\\Users\\Victor\\AppData\\Local\\Temp/ipykernel_5488/1869973321.py:40: UserWarning: linestyle is redundantly defined by the 'linestyle' keyword argument and the fmt string \"-b\" (-> linestyle='-'). The keyword argument will take precedence.\n",
      "  axs[1].errorbar(x=epochs_error_bar_0, y=train_acc_error_bar_y, yerr=train_acc_error_bar_yerr, label='Training accuracy error', fmt='-b', linestyle='')\n",
      "C:\\Users\\Victor\\AppData\\Local\\Temp/ipykernel_5488/1869973321.py:43: UserWarning: linestyle is redundantly defined by the 'linestyle' keyword argument and the fmt string \"--r\" (-> linestyle='--'). The keyword argument will take precedence.\n",
      "  axs[1].errorbar(x=epochs_error_bar_0, y=valid_acc_error_bar_y, yerr=valid_acc_error_bar_yerr, label='Validation accuracy error', fmt='--r', linestyle='')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()\n",
    "\n",
    "fig, axs = plt.subplots(2, 1, constrained_layout=True)\n",
    "fig.set_size_inches(12, 8)\n",
    "\n",
    "epochs_error_bar = [50, 100, 150, 200, 250, 300] # 1-indexed\n",
    "epochs_error_bar_0 = [epoch - 1 for epoch in epochs_error_bar] # 0-indexed\n",
    "\n",
    "# Plot Loss\n",
    "average_train_loss = average_out_data_k(train_loss_record)\n",
    "train_loss_error_bar_y = [average_train_loss[epoch] for epoch in epochs_error_bar_0]\n",
    "train_loss_error_bar_yerr = [np.std(get_data_at_epoch_fold(train_loss_record, epoch)) for epoch in epochs_error_bar_0]\n",
    "\n",
    "\n",
    "average_valid_loss = average_out_data_k(holdout_loss_record)\n",
    "valid_loss_error_bar_y = [average_valid_loss[epoch] for epoch in epochs_error_bar_0]\n",
    "valid_loss_error_bar_yerr = [np.std(get_data_at_epoch_fold(holdout_loss_record, epoch)) for epoch in epochs_error_bar_0]\n",
    "\n",
    "axs[0].plot(average_train_loss, '-b', label='Training loss')\n",
    "axs[0].errorbar(x=epochs_error_bar_0, y=train_loss_error_bar_y, yerr=train_loss_error_bar_yerr, label='Training loss error', fmt='-b', linestyle='')\n",
    "\n",
    "axs[0].plot(average_valid_loss, '--r', label='Validation loss')\n",
    "axs[0].errorbar(x=epochs_error_bar_0, y=valid_loss_error_bar_y, yerr=valid_loss_error_bar_yerr, label='Validation loss error', fmt='--r', linestyle='')\n",
    "\n",
    "axs[0].legend()\n",
    "axs[0].set_xlabel('Epochs')\n",
    "axs[0].set_ylabel('Normalized Loss')\n",
    "axs[0].set_title('Loss normalized per example and class vs. Epochs')\n",
    "\n",
    "# Plot Accuracy\n",
    "average_train_acc = average_out_data_k(train_accuracy_record)\n",
    "train_acc_error_bar_y = [average_train_acc[epoch] for epoch in epochs_error_bar_0]\n",
    "train_acc_error_bar_yerr = [np.std(get_data_at_epoch_fold(train_accuracy_record, epoch)) for epoch in epochs_error_bar_0]\n",
    "\n",
    "average_valid_acc = average_out_data_k(holdout_accuracy_record)\n",
    "valid_acc_error_bar_y = [average_valid_acc[epoch] for epoch in epochs_error_bar_0]\n",
    "valid_acc_error_bar_yerr = [np.std(get_data_at_epoch_fold(holdout_accuracy_record, epoch)) for epoch in epochs_error_bar_0]\n",
    "\n",
    "axs[1].plot(average_train_acc, '-b', label='Training accuracy')\n",
    "axs[1].errorbar(x=epochs_error_bar_0, y=train_acc_error_bar_y, yerr=train_acc_error_bar_yerr, label='Training accuracy error', fmt='-b', linestyle='')\n",
    "\n",
    "axs[1].plot(average_valid_acc, '--r', label='Validation accuracy')\n",
    "axs[1].errorbar(x=epochs_error_bar_0, y=valid_acc_error_bar_y, yerr=valid_acc_error_bar_yerr, label='Validation accuracy error', fmt='--r', linestyle='')\n",
    "\n",
    "axs[1].legend()\n",
    "axs[1].set_xlabel('Epochs')\n",
    "axs[1].set_ylabel('Accuracy')\n",
    "axs[1].set_title('Accuracy vs. Epochs')\n",
    "\n",
    "plt.savefig(\"plots/Q6b_i.png\")\n",
    "plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NO RUN\n",
    "sgd_train_loss = average_train_loss\n",
    "sgd_train_loss_error_bar_y = train_loss_error_bar_y\n",
    "sgd_train_loss_error_bar_yerr = train_loss_error_bar_yerr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_error_bar = [50, 100, 150, 200, 250, 300] # 1-indexed\n",
    "epochs_error_bar_0 = [epoch - 1 for epoch in epochs_error_bar] # 0-indexed\n",
    "\n",
    "# Plot Loss\n",
    "# For Q6b_ii comparison\n",
    "batch_average_train_loss = average_out_data_k(train_loss_record)\n",
    "batch_average_train_loss_error_bar_y = [average_train_loss[epoch] for epoch in epochs_error_bar_0]\n",
    "batch_average_train_loss_error_bar_yerr = [np.std(get_data_at_epoch_fold(train_loss_record, epoch)) for epoch in epochs_error_bar_0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Victor\\AppData\\Local\\Temp/ipykernel_5488/103520165.py:14: UserWarning: linestyle is redundantly defined by the 'linestyle' keyword argument and the fmt string \"-b\" (-> linestyle='-'). The keyword argument will take precedence.\n",
      "  plt.errorbar(x=epochs_error_bar_0, y=sgd_train_loss_error_bar_y, yerr=sgd_train_loss_error_bar_yerr, label='Stochastic error', fmt='-b', linestyle='')\n",
      "C:\\Users\\Victor\\AppData\\Local\\Temp/ipykernel_5488/103520165.py:17: UserWarning: linestyle is redundantly defined by the 'linestyle' keyword argument and the fmt string \"--r\" (-> linestyle='--'). The keyword argument will take precedence.\n",
      "  plt.errorbar(x=epochs_error_bar_0, y=batch_average_train_loss_error_bar_y, yerr=batch_average_train_loss_error_bar_yerr, label='Batch error', fmt='--r', linestyle='')\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAABMwElEQVR4nO2deXwURfbAvy/hDDfhkEsOuSEQICKICoggh4KiKyqKsLouuOqqqwv621VEXUVRFI9FVC4PPHBVVARFOURRAeU+BLkvSZBTQQl5vz+qJ5kMk2RyTCbH+34+/ZnuququV9Mz/brqVb0nqophGIZhBBIVaQEMwzCMgokpCMMwDCMopiAMwzCMoJiCMAzDMIJiCsIwDMMIiikIwzAMIyimIAoZIrJNRC6KtBzhRkS6iciufKrrmIg0yo+68gsRaSAiKiIlvONPROSGPK5jtIi8lpfXDFLHmd79ic7LskZomILIA7yH9nHvx3lQRD4WkXohnpvuj1wYEJH7RGSr195dIvKWX94CEbkpkvJlRjD5VLW8qm7J5nW6effthYD0xSIyNA9EzVNUtY+qTsuPukRksPfbOOb9L1L8jo9l51qqusO7P6fysmx2EZGpIvJwXl+3oGMKIu+4VFXLA7WAn4FnIyxPWPDeQq8HLvLamwB8HlmpIsavwPUi0iC3FypMLwhZoaqvew/q8kAfYI/v2EtLxd72CzamIPIYVT0BzARa+tJEpJ+I/CAiR0Rkp4iM9jtlkfd5yHvD6uyd8xcRWS8iR0VknYi09zsnXkRWichhEXlLRMoEyiEipUXkkIi09kur7r3R1RCRaiLykVfmFxH5UkRC+T2cDcxV1Z+89u5T1Une9R8Bzgee89rynJd+rogs9eRdKiLn+slUVUSmiMger/f1fkA7/iEi+0Vkr4gMC+U7FZEyIvKaiBzw2rdURGpmIp+KSGNvv6yIPCki2z15F4tI2Qy+i0PAVOCBYJkiEiUi//KutV9EpotIJS/P13O8UUR2AF+IyFAR+UpExntyb/G+u6FeG/eL3zBRFr+rQFlSe04istL/jd6To5uX10lEvvbqX+lL9/IaishC7zf5GVAto/oykWOqiPxXRGaLyK9A9yzuZeBQ2QIRecj7no6KyKciUi27Zb38Id69OSAi/5YcDt+K+69uFvc/miUitb108e7lfq9tq8X7P4pIX3H/66MisltE7s5uvfmCqtqWyw3YhnujBogBpgHT/fK7AXE4hdwG18O4zMtrAChQwq/8n4DduIexAI2B+n51fQfUBqoC64HhGcg1GXjE7/hvwBxv/1FgIlDS284HJIS2Xgf8AtyD6z1EB+QvAG7yO64KHMT1OkoA13jHsV7+x8BbQBVPjq5+31kyMMZL7wv8BlQJ4Tv9K/Chdy+igQ5AxWDyeWkKNPb2n/fK1PHOPRcoHeR76AbsAs4AjgDNvPTFwFBv/8/AZqARUB74H/BqwH2fDpQDygJDvTYP8+p+GNjhyVQa6AUcBcpn93cVrN1e+s3ABqCi1+YD3ncdBfT0jqt7ZZcAT3myXODJ8loWv5duwC6/46nAYaCLV0eZHLTjJ6Cp950tAB7LQdmWwDHgPKAUMA44ifc/DtKOqcDDQdIvBJKA9t738iywyMu7GFgOVMb9j1sAtby8vcD53n4VoH2kn2NB2x1pAYrChntoH8O9UZ4E9gBxmZR/Ghjv7af7UXtpc4G/Z1LXdX7HjwMTMyh7EfCT3/FXwBBvfwzwAd6DMZvtHQzMww2xHABG+uUtIL2CuB74LuD8JbiHYS0gBe+hH1CmG3A84HvZD3QK4Tv9M/A10CZIuXTyeWmKU8JRXp1tQ/gOuuE9+Lx78Ja3768gPgdu8Tunmff7KOF33xv55Q8FNvkdx3llavqlHQDis/u7yqDd53nfaVPveCSeAgv4Ld4AnIlTXuX88t4gZwpiehbnZNWOf/mVvYW0l57slL0fmOGXFwP8QfYVxCvA437H5b173ACnPH4EOgFRAeftwL3IVMzu/y8/NxtiyjsuU9XKuDeiW4GFInIGgIicIyLzRSRRRA4Dw8m8e14P9+aTEfv89n/D/SiDMR+I8epvAMQD73l5T+Debj/1hjJGZdY4f9SNMV+EezMaDjwkIhdnULw2sD0gbTvubbUe8IuqHszg3AOqmux3nNrWLL7TV3EPtjfFDV09LiIlQ2haNdz9y+y7D8ZY4GIRaRuQHtj27TjlUNMvbWfAOT/77R8HUNXAtFC+g0wRN4nibeAGVf3RS64P/MkbXjokIodwSqSW15aDqvprQHtyQro256Adof7+Mytb218OVf0Np3yzS7p7rKrHvOvUUdUvgOdwPcD9IjJJRCp6Ra/A9dS2e8N2nXNQd9gxBZHHqOopVf0fcAr35wL3pjULqKeqlXBDO+I7JchldgJn5YUsuIfANd72kaoe9fKOquo/VLUR0B+4S0R6ZPP6J1X1HWAV4LN1BLZnD+7B48+ZuCG0nUBVEamcnXo9MvxOPbkeVNWWuCGiS4AhGcjnTxJwgmx+96p6APfW+1BAVmDbfW/h/g/83LhTzux3lSHibCrvA0+r6id+WTtxPYjKfls5VX0MNyRSRUTKBbQnJwS2OUftyCV7gbq+A+87ic3BddLdY+/7icX9vlHVCaraATek1RQ3NIuqLlXVAUAN3L14O0etCDOmIPIYzzA1ADeuuN5LroB7Uz4hIh2Ba/1OScQNs/jPw38ZuFtEOnjXaywigQ/ZUHkDGIQbFnrDT85LvOsKbkz4lCdHVu0b6hkVK4gzwvYBWgHfekV+DmjLbKCpiFwrIiVEZBDuz/KRqu4FPgFeEJEqIlJSRC4IsV0Zfqci0l1E4sTNkDmC6/L72hYoXyqqmoKz2zwlIrVFJFpEOotI6RDkeQqnjFr4pc0A7hRn3C0P/Ac3FJUc7AI5ILPfVWZMBjao6uMB6a8Bl4rIxV7by4ibzltXVbcDy4AHRaSUiJwHXBrhduSGmbi2nisipYDRZK2UfN+JbyuFu8fDRCTe+538B/hWVbeJyNle76gkbjj2BJDifX+DRaSSqp7E/Uaz/O9FAlMQeceH4uZ4HwEewXXd13p5twBjROQobuwz9W3B69o+Anzldes7eW/lj+Ae6EdxbxhVcyKUqn6L+3HWxj2MfTTB2RGO4WwCL6jqfEhdVHVfBpc8AtyHG0M9hBt/H6Gqi738Z4Arxc1ImuC9XV8C/APX9f4ncImqJnnlr8c9wDfgxsPvCLFpGX6nOMPxTE/W9cBC3LDTafIFue7dwGpgKc4YP5YQ/ieqegT3Xfjfp8levYuArbgHxG0hti8UMvsOMuNq4HJJP5PpfFXdCQzA3d9EXI/iHtLafy1wDu57eQBnYI9kO3KM99+8DXgT15s4hvv9/Z7JaaNwQ3y+7QtVnQf8G3jXu85ZuO8XnOH/JdykjO243/8TXt71wDYROYIbUhucV23LS8QzmBiGYRRbvB7eIaCJqm6NsDgFButBGIZRLBGRS0UkxrMbjMP1HLdFVqqChSkIwzCKKwNwRuY9uCHXq9WGVNJhQ0yGYRhGUKwHYRiGYQQlrA7CRKQ3btZINPCyN5/aP780biZEB5yFf5A3PawU8CLOlUMKblXxgszqqlatmjZo0CDP22AYhlGUWb58eZKqVg+WFzYF4c1Bfx7nz2UXsFREZqnqOr9iN+JWZzYWkatxUwoHAX8BUNU4EakBfCIiZ3vz1IPSoEEDli1bFq7mGIZhFElEJMMV8eEcYuoIbFbVLar6B26+8YCAMgNwju3AzVvv4S3cagl8AaCq+3HTzxLCKKthGIYRQDgVRB3S+1zZ5aUFLeOtLj2MW6a+EujvrbxtiBuCOi0Aj4jcLCLLRGRZYmJiGJpgGIZRfCmoRurJOIWyDOfj5mucK4h0qOokVU1Q1YTq1YMOoRmGYRg5JJxG6t2kf+uv66UFK7NLXJCPSjgPngrc6SskIl/j3OYahhEGTp48ya5duzhx4kSkRTHCRJkyZahbty4lS4bi2NgRTgWxFGjiDRHtxvknCXTCNQvna34JcCXOt4mKSAxujcavItITSA4wbhuGkYfs2rWLChUq0KBBA5wZ0ChKqCoHDhxg165dNGzYMOTzwqYgVDVZRG7F+eWPBiar6loRGQMsU9VZuGAbr4rIZpwDMJ+TqxrAXBFJwSmX68Mlp2EYcOLECVMORRgRITY2luzaasO6DkJVZ+PcPfun3e+3fwIXXjPwvG246FuGYeQTphyKNjm5vwXVSG0YhmFEGFMQ27dD167w6aeRlsQwijWPPPIIrVq1ok2bNsTHx/Ptty4G1dNPP81vv/2Wo2uOHj2acePG5Vq2qVOnsmfPntTjm266iXXrQjOLLliwgEsuuSTHdS9fvpy4uDgaN27M7bffTjD/eRs2bKBz586ULl06T9rro9griEO/l4VFizixyiZJGUakWLJkCR999BHff/89q1atYt68edSr5yZB5kZB5BWBCuLll1+mZcuWubpmcnJogQVHjBjBSy+9xKZNm9i0aRNz5sw5rUzVqlWZMGECd999d65kCqTYK4gff6nGSUrw/Ud7si5sGEZY2Lt3L9WqVaN0aRfdtVq1atSuXZsJEyawZ88eunfvTvfu3QGYMWMGcXFxtG7dmpEjR6ZeY86cObRv3562bdvSo0daePV169bRrVs3GjVqxIQJaUEEL7vsMjp06ECrVq2YNGkSAKdOnWLo0KG0bt2auLg4xo8fz8yZM1m2bBmDBw8mPj6e48eP061bt1TXPhnVG4zRo0dz/fXX06VLF66/Puu5N3v37uXIkSN06tQJEWHIkCG8//77p5WrUaMGZ599dramsIZCWI3UhYGOnaLYX6YW25fsofURqFgx0hIZRmS54w5YsSJvrxkfD08/nXF+r169GDNmDE2bNuWiiy5i0KBBdO3aldtvv52nnnqK+fPnU61aNfbs2cPIkSNZvnw5VapUoVevXrz//vt06dKFv/zlLyxatIiGDRvyyy+/pF57w4YNzJ8/n6NHj9KsWTNGjBhByZIlmTx5MlWrVuX48eOcffbZXHHFFWzbto3du3ezZs0aAA4dOkTlypV57rnnGDduHAkJ6T3+JCYmZlhvRqxbt47FixdTtmxZNm7cyKBBg4KWW7BgAbt376Zu3bqpaXXr1mX37sDlZOGj2CsIgJjGdai2ZjfPPQf3ZRSJ2TCMsFG+fHmWL1/Ol19+yfz58xk0aBCPPfYYQ4cOTVdu6dKldOvWDZ/nhMGDB7No0SKio6O54IILUuf4V62aFhq8X79+lC5dmtKlS1OjRg1+/vln6taty4QJE3jvvfcA2LlzJ5s2baJZs2Zs2bKF2267jX79+tGrV69M5f7mm28yrDcj+vfvT9myZQFo1qwZK/JaG+chpiCA8j07c+rIMcaNg1tvtV6EUbzJ7E0/nERHR9OtWze6detGXFwc06ZNO01B5ATfsJWvjuTkZBYsWMC8efNYsmQJMTExdOvWjRMnTlClShVWrlzJ3LlzmThxIm+//TaTJ0/OtQz+lCtXLnU/qx5EnTp12LVrV2rarl27qFMn0KVd+Cj2NggAnnqKau9O4uBBePbZSAtjGMWPjRs3smnTptTjFStWUL9+fQAqVKjA0aNHAejYsSMLFy4kKSmJU6dOMWPGDLp27UqnTp1YtGgRW7duBchyqOfw4cNUqVKFmJgYNmzYwDfffANAUlISKSkpXHHFFTz88MN8//33p8ngT3brDcTXgwi2Va5cmVq1alGxYkW++eYbVJXp06czYECgU+zwYT0Ij4QEuPRSePJJ14uoVCnSEhlG8eHYsWPcdtttHDp0iBIlStC4ceNUw/HNN99M7969qV27NvPnz+exxx6je/fuqCr9+vVLfWBOmjSJgQMHkpKSQo0aNfjss88yrK93795MnDiRFi1a0KxZMzp16gTA7t27GTZsGCkpLvTMo48+CsDQoUMZPnw4ZcuWZcmSJanXqV69erbqzQkvvPACQ4cO5fjx4/Tp04c+ffoAMHHiRACGDx/Ovn37SEhI4MiRI0RFRfH000+zbt06KuZyOKTIxKROSEjQHAcM+uQTuPVWVj/1GW0ua8SYMfDvf+etfIZRkFm/fj0tWrSItBhGmAl2n0VkuaoGjbdjQ0wAJUrAli3EVd1N//7w1FNw+HCkhTIMw4gspiAAatd2n3v2MHo0HDoEzzwTSYEMwzAijykISKcg2rWDAQNg/HinKAzDMIorpiAAKleGMmXAW0r/wAPWizAMwzAFASACV18NTZoA0K4dXHaZ9SIMwyjemILwMWUK3Hxz6uEDDzhDdaQWDRmGYUQaUxD++E35jY+Hyy93vYiDByMnkmEUF6Kjo4mPj6dt27a0b9+er7/+OtPyhw4d4oUXXsjyuv6O9TJi27ZttG7dOlvy+rN161bOOeccGjduzKBBg/jjjz+C1lG2bFni4+OJj49n+PDhOa4vvzAF4ePBB8Hz7+Jj9Gg4csQtnjMMI7yULVuWFStWsHLlSh599FHuvffeTMuHqiByQ6guuUeOHMmdd97J5s2bqVKlCq+88krQcmeddVbqSmnfQreCTFgVhIj0FpGNIrJZREYFyS8tIm95+d+KSAMvvaSITBOR1SKyXkQy/6XkBTExcOAA+C2nb9MGrrrKDTP9/HPYJTAMw+PIkSNUqVIFcKuse/ToQfv27YmLi+ODDz4AYNSoUfz000/Ex8dzzz33ADB27Fji4uJo27Yto0alPXLeeecdOnbsSNOmTfnyyy8zrXvq1Kn079+fCy+8MEv33QCqyhdffMGVV14JwA033BDUJXdhJGyuNkQkGnge6AnsApaKyCxV9Q/DdCNwUFUbi8jVwFhgEC5OdWlVjRORGGCdiMzwYlWHB7+prjRLC4f90EPw7rvw6KNmjzCKEd26nZ521VVwyy3w22/Qt+/p+UOHui0pCbyHZSoLFmRZ5fHjx4mPj+fEiRPs3buXL774AoAyZcrw3nvvUbFiRZKSkujUqRP9+/fnscceY82aNaneUD/55BM++OADvv32W2JiYtL5RUpOTua7775j9uzZPPjgg8ybNy9TWXyBi6pWrcrRo0c5//zzg5Z74403qFGjBpUrV6ZECfc4zcwl99atW2nXrh0VK1bk4YcfzvC6BYVw+mLqCGxW1S0AIvImMADwVxADgNHe/kzgOXGRtRUoJyIlgLLAH8CRMMqaoYJo2tT95v/7X7jrLjjzzLBKYRjFFt8QE7gIc0OGDGHNmjWoKvfddx+LFi0iKiqK3bt383OQLv28efMYNmwYMTExQHrX2wMHDgSgQ4cObNu2LUtZevbsmXp+hQoVMnXJnZSUFFL7atWqxY4dO4iNjWX58uVcdtllrF27Ntf+ksJJOBVEHWCn3/Eu4JyMyqhqsogcBmJxymIAsBeIAe5U1dPcJIrIzcDNAGfm9sntryACeOABePVVGDMGXn45d9UYRqEgszf+mJjM86tVC6nHkBmdO3cmKSmJxMREZs+eTWJiIsuXL6dkyZI0aNCAEydOZOt6PpffPnffWeHvkjurHkSLFi04dOgQycnJlChRIkOX3L6YFOAU1VlnncWPP/54WhCigkRBNVJ3BE4BtYGGwD9EpFFgIVWdpKoJqppQPcDAnG3q1IGbbgLPxbA/9eq5nvWUKbBxY+6qMQwjazZs2MCpU6eIjY3l8OHD1KhRg5IlSzJ//ny2b98OnO6Cu2fPnkyZMiU1fnV2XW9nhK8HEWxr2bIlIkL37t2ZOXMmANOmTQvqkjsxMZFTp04BsGXLFjZt2kSjRqc91goU4VQQu4F6fsd1vbSgZbzhpErAAeBaYI6qnlTV/cBXQHjVbPny8NJLcN55QbPvvRfKloX77w+rFIZRbPHZIOLj4xk0aBDTpk0jOjqawYMHs2zZMuLi4pg+fTrNmzcHIDY2li5dutC6dWvuueceevfuTf/+/UlISCA+Pp5x48blm+xjx47lqaeeonHjxhw4cIAbb7wRgFmzZnG/99BYtGgRbdq0IT4+niuvvJKJEyeGFIEukoTN3bf3wP8R6IFTBEuBa1V1rV+ZvwFxqjrcM1IPVNWrRGQk0FxVh4lIOe/cq1V1VUb15crdt4+UFPj1V6hQIWj2/fc7o/X337vV1oZRVDB338WDAuPuW1WTgVuBucB64G1VXSsiY0Skv1fsFSBWRDYDdwG+eWnPA+VFZC1OOUzJTDnkGb16BZ+d4fGPf0CVKvCvf4VdEsMwjIgT1ohyqjobmB2Qdr/f/gnclNbA844FSw87NWuCF3owGJUqwahRMHIkLF6c4WiUYRhGkaCgGqkjQ+3abhZTJsNut94KtWo5m0QRCcZnGIYRFFMQ/tSuDSdOZOp8KSbGhSNdvBjmzMlH2QzDMPIZUxD++OYuB1kL4c+NN0KjRm6oyZu1ZhiGUeQwBeFPu3bOQ5/nAyYjSpVyrjdWr4bp0/NHNMMoaHTrFtwjh1F0MAXhT5Mmbtl0kFWQgfzpT3DOOW5Gk7cuxzCMXPDII4/QqlWr1LUC3377LQBPP/106uK37DJ69Og8WQ8xdepU9viNLNx0002sW7cukzOKBqYgAtm3D/buzbKYCIwb50ajxo/PB7kMowizZMkSPvroo1QnefPmzaNePbfONjcKIq8IVBAvv/wyLVu2zLPrB7r/CNXNeKjlcoopiEDi450VOgTOO8+FJn3sMXMHbhi5Ye/evVSrVi3VV1G1atWoXbs2EyZMYM+ePXTv3p3u3bsDMGPGDOLi4mjdujUjR45MvcacOXNo3749bdu2Teeme926dXTr1o1GjRoxYcKE1PTLLruMDh060KpVKyZNmgTAqVOnGDp0KK1btyYuLo7x48czc+ZMli1bxuDBg4mPj+f48ePpghBlVK+PU6dOcc8993D22WfTpk0bXnzxRQAWLFjA+eefT//+/WnZsuVpxydOnGDYsGHExcXRrl075s+fD2TfHXmuUNUisXXo0EHzhIQE1V69Qi6+YYNqdLTqiBF5U71hRIJ169Zl+5yuXd2WFxw9elTbtm2rTZo00REjRuiCBQtS8+rXr6+JiYmqqrp7926tV6+e7t+/X0+ePKndu3fX9957T/fv369169bVLVu2qKrqgQMHVFX1gQce0M6dO+uJEyc0MTFRq1atqn/88Ue6Mr/99pu2atVKk5KSdNmyZXrRRRel1n3w4EGvrV116dKlfm13xxnV68+LL76oDz30kKqqnjhxQjt06KBbtmzR+fPna0xMTOq5gcfjxo3TYcOGqarq+vXrtV69enr8+HGdMmWK1qlTJ2hdWRHsPgPLNIPnqvUgAqlXD3buzLqcR7NmMHw4TJoEGzaEUS7DKMKUL1+e5cuXM2nSJKpXr86gQYOYOnXqaeWWLl1Kt27dqF69OiVKlGDw4MEsWrSIb775hgsuuICGDRsC6V199+vXj9KlS1OtWjVq1KiR6ip8woQJtG3blk6dOrFz585U53lbtmzhtttuY86cOVm64s6sXh+ffvop06dPJz4+nnPOOYcDBw6wadMmADp27Jh6buDx4sWLue666wBo3rw59evX58cffwTSuyMPJ6YgAvEpiGysgnvgAbc+YtRpMfMMwwiV6OhounXrxoMPPshzzz3Hu+++myfX9Q1b+epITk5mwYIFzJs3jyVLlrBy5UratWvHiRMnqFKlCitXrqRbt25MnDiRm266Kdf1qyrPPvtsqgfYrVu30qtXLyC9W/FgxxkRarncYgoikHr14NgxOHw45FOqV3fK4YMPIItohoZhBGHjxo2pb9UAK1asoL7net/frXfHjh1ZuHAhSUlJnDp1ihkzZtC1a1c6derEokWL2Lp1K5C1q+/Dhw9TpUoVYmJi2LBhA994LnaSkpJISUnhiiuu4OGHH+b7778/TQZ/Qqn34osv5r///S8nT54E4Mcff+TXX3/N8js5//zzef3111PP2bFjB838gpnlB2H1xVQo6d0bqlaFkiWzddodd7ioc3fcAd99B9HRYZHOMIokx44d47bbbuPQoUOUKFGCxo0bpxqOb775Znr37k3t2rWZP38+jz32GN27d0dV6devX2rshUmTJjFw4EBSUlKoUaMGn332WYb19e7dm4kTJ9KiRQuaNWtGp06dANi9ezfDhg0jJSUFgEcffRSAoUOHMnz4cMqWLcuSJUtSr1O9evUs673pppvYtm0b7du3R1WpXr16SDGrb7nlFkaMGEFcXBwlSpRg6tSp6XpD+UHY3H3nN3ni7juXvPEGDB7swkrkQc/UMPKNnLj79i2Sy2XwOCMfKTDuvgstp07B0qXgdRmzwzXXQJcucN99cOhQ3otmGAWJBQtMORR1TEEEogqdOsHkydk+VQSefRaSkuDBB8Mgm2EYRj5iCiKQEiWcV9dsTHX1p107+Mtf4LnnoBisxDcMowhjCiIY2VwLEcjDD7sQ13fcYTEjDMMovJiCCEYuFUT16m6I6bPPYNasPJTLMAwjHwmrghCR3iKyUUQ2i8hpy8hEpLSIvOXlfysiDbz0wSKywm9LEZH4cMqajjPPzPZiuUBGjIBWreDOO10MIsMocpi/7yJP2BSEiEQDzwN9gJbANSIS6P7wRuCgqjYGxgNjAVT1dVWNV9V44Hpgq6quCJespzFsmHv1z4WCKFkSnnnGTYZ68sk8lM0wiijR0dHEx8fTtm1b2rdvz9dff51p+UOHDvHCCy9keV1/x3pG9ghnD6IjsFlVt6jqH8CbwICAMgOAad7+TKCHiEhAmWu8c/OPli2hZ0+Iyt3X06MHXHGFs0ls2ZJHshlGEaVs2bKsWLGClStX8uijj3LvvfdmWj5UBZFXqGrqArpgxxkRbpfc4SScCqIO4D+Qv8tLC1pGVZOBw0BsQJlBwIxgFYjIzSKyTESWJSYm5onQAPz6K7z3Xp481Z9+2k2MuuUWM1gbRqgcOXKEKl5kx2PHjtGjRw/at29PXFwcH3zwAQCjRo3ip59+Ij4+nnvuuQeAsWPHEhcXR9u2bRnl5xztnXfeoWPHjjRt2pQvM/CH88QTT6S65H7ggQcA2LZtG82aNWPIkCG0bt2aL7/8Mt3xzp07ueeee1Ldg7/11lvA6a68Cy0ZuXnN7QZcCbzsd3w98FxAmTVAXb/jn4BqfsfnAKtDqS/P3H2rqu7bpwqqzzyTJ5d75hl3uTffzJPLGUaekxN333nq71tVo6KitG3bttqsWTOtWLGiLlu2TFVVT548qYcPH1ZV1cTERD3rrLM0JSVFt27dqq1atUo9f/bs2dq5c2f99ddfVTXN9XbXrl31rrvuUlXVjz/+WHv06HFa3XPnztW//OUvmpKSoqdOndJ+/frpwoULdevWrSoiumTJElXV045nzpypF110kSYnJ+u+ffu0Xr16umfPntNcdxcUsuvuO5y+mHYD9fyO63ppwcrsEpESQCXggF/+1WTQewgrNWo496w5WE0djL/9zcWuvuMOuPhiqFw5Ty5rGEUK3xATuAhzQ4YMYc2aNagq9913H4sWLSIqKordu3enuuz2Z968eQwbNoyYmBggvevtgQMHAtChQwe2bdt22rmffvopn376Ke3atQNcr2XTpk2ceeaZ1K9fP9VXE5DuePHixVxzzTVER0dTs2ZNunbtytKlS6lYseJprrwLI+FUEEuBJiLSEKcIrgauDSgzC7gBWILrcXzhaTREJAq4Cjg/jDIGRwQaNswzBREdDS++CB07Ojcc+ThsahiFks6dO5OUlERiYiKzZ88mMTGR5cuXU7JkSRo0aMCJbE4N9Dm587n7DkRVuffee/nrX/+aLn3btm0F3iV3OAmbDUKdTeFWYC6wHnhbVdeKyBgR6e8VewWIFZHNwF2A/1TYC4CdqhoZ826jRnlqWe7QAW67DSZOBC8Wu2EYGbBhwwZOnTpFbGwshw8fpkaNGpQsWZL58+ezfft24HQX3D179mTKlCmp8auzcvntz8UXX8zkyZM5duwY4Ly67t+/P8vzzj//fN566y1OnTpFYmIiixYtomPHjtlpaoEmrO6+VXU2MDsg7X6//RPAnzI4dwHQKVhevtCwIcyf7yzLp02syhkPPQQzZzpXHMuWQalSeXJZwygSHD9+nPj4eMC90U+bNo3o6GgGDx7MpZdeSlxcHAkJCTRv3hyA2NhYunTpQuvWrenTpw9PPPEEK1asICEhgVKlStG3b1/+85//hFR3r169WL9+PZ07dwZchLvXXnuN6Cz89l9++eUsWbKEtm3bIiI8/vjjnHHGGWwoIuElzd13RmzfDr//Dk2a5JmCAPjoI7j0Urj/fnPoZxQccuLu2/x9Fz6y6+7bAgZlhBfNKq+55BK47jr4z3/g8svBe2EyjMKHKYYij/liyohjx5zvbi/kYF7yzDMQGwtDh4IXhdAwDKPAYQoiI0Tg9tth7tw8v3TVqm5W08qV4EU0NIyIU1SGm43g5OT+moLIiHLl3HqIMPnIGDAArr3WGa5XrQpLFYYRMmXKlOHAgQOmJIooqsqBAwcoU6ZMts4zG0RmNGqUZ2shgjFhAsybBzfc4Ka+2qwmI1LUrVuXXbt2kacua4wCRZkyZahbt262zjEFkRkNG8I334Tt8rGx8NJLrjfx73/D2LFhq8owMqVkyZKFftWvkfdka4hJRKJEpGK4hClwNGrk4kKE0Rtj//7w17/CE0/AF1+ErRrDMIxsk6WCEJE3RKSiiJTDOddbJyL3hF+0AsA998ChQ84daxh58klo2hSGDIFsLP40DMMIK6H0IFqq6hHgMuAToCHOM2vRp1IlZ6wOM+XKwRtvwP79cPPN5hbcMIyCQSgKoqSIlMQpiFmqehIoHo+wX391vYh588JeVfv2LrDQu+/C1Klhr84wDCNLQlEQLwLbgHLAIhGpDxwJp1AFhjJl3GK5MKyFCMbdd0P37nDrrbBuXb5UaRiGkSFZKghVnaCqdVS1rxdfYjvQPR9kizzR0c44kE+Ot6Ki4LXXoHx5uPJKt5jbMAwjUoRipP67Z6QWEXlFRL4HLswH2QoGzZvnm4IAqF3b2SM2bjR7hGEYkSWUIaY/e0bqXkAVnIH6sbBKVZBo3tytps5mgJLc0KMHjBkDM2a4+BGGYRiRIBQF4fN13Rd4VVXX+qUVfVq0cDFC9+zJ12rvvRf69HFhSpcuzdeqDcMwgNAUxHIR+RSnIOaKSAUgJbxiFSAGDYIDB9yiuXwkKgpefRXOOAP+9CcwDwiGYeQ3oSiIG3GhQM9W1d+AUsCwsEpVkIiKnD/D2Fg37fXnn53R+o8/IiaKYRjFkFBmMaUAdYF/icg44FxVDcn/qIj0FpGNIrJZREYFyS8tIm95+d+KSAO/vDYiskRE1orIahHJnhvCvOTOO52zpAiQkACvvAKLFrmY1ma0NgwjvwhlFtNjwN+Bdd52u4hkGehVRKKB54E+QEvgGhFpGVDsRuCgqjYGxgNjvXNLAK8Bw1W1FdANiFxonfXrYfbsrMuFiWuvdTaJSZPg+ecjJoZhGMWMUMZP+gI9VXWyqk4GegOXhHBeR2Czqm5R1T+AN4EBAWUGANO8/ZlADxER3IypVaq6EkBVD6jqqRDqDA++qa4pkTO9PPywc+x3xx3w+ecRE8MwjGJEqAPslf32K4V4Th1gp9/xLi8taBlVTQYOA7FAU0BFZK6IfC8i/wxWgYjcLCLLRGRZWP3YN28Ov/0Gu3eHr44s8C2ia9HCGa3Xr4+YKIZhFBNCURCPAj+IyFQRmQYsBx4Jr1iUAM4DBnufl4tIj8BCqjpJVRNUNaF69erhk6Z5c/cZ4adyhQrw4YcusFDv3vk+89YwjGJGKEbqGUAn4H/Au0BnnG+mrNgN1PM7ruulBS3j2R0qAQdwvY1FqprkzZyaDbQPoc7w0KIFtG5dICzEDRo4c8gvv0DfvnCkeHjFMgwjAoQ0xKSqe1V1lrftA94J4bSlQBMRaSgipYCrgVkBZWYBN3j7VwJfqAuKOxeIE5EYT3F0xRnII0PNmrB6NVx8ccRE8Kd9ezf9de1aGDjQpr8ahhEecjrJP8uV1J5N4Vbcw3498LaqrhWRMSLS3yv2ChArIpuBu3DrLVDVg8BTOCWzAvheVT/Ooax5RwHoQfjo1ctNf/38c/jznyNqPzcMo4iS01BpIT0pVXU2bnjIP+1+v/0TwJ8yOPc13FTXgsFLL8H998P27c4IUAAYMsTZze+7z8U2eu45kOLjBMUwjDCToYIQkQ8JrggEN9OoeFGxIuzb5wI1xMdHWppURo2CgwddTOuYGHj8cVMShmHkDZn1IMblMK9o0q6d+/zhhwKlIERg7FjY8cx7jBt3OeXKwejRkZbKMIyiQIYKQlUX5qcgBZ7GjV3w6B9+gGEFyxWVCLxx/HJiboIHH3Q9iX8GXTliGIYROjm1QRQ/oqKgbVunIAogUVHOTHL8OIwc6ZTGPfdEWirDMAozpiCyw+DBzvV3ASU6GqZPd5Ot/vlPF+MoQj4GDcMoApiCyA633BJpCbKkZEl4/XUoXdpNujpxwvlxMsO1YRjZJSezmABQ1f4Z5RVpfvsNfv8dqlSJtCQZEh0NU6ZAmTLwn/+4YacnnzQlYRhG9ghlFtNA4AzS1iRcA/wcTqEKLCdPQrVqLjDD2LGRliZToqJcPOsyZWD8eDh8GF58EUpYn9EwjBDJchaTiDypqgl+WR+KyLKwS1YQKVnSGaq//jrSkoSECDz9tOvsPPigi0z39ttulpNhGEZWhOJqo5yIpAZkFpGGQLnwiVTAOfdcWLrUDTMVAkTcuoj//hc++QR69ICkpEhLZRhGYSAUBXEnsEBEFojIQmA+cEdYpSrIdOnilMP330dakmwxfDjMnOlm6Z53HmzdGmmJDMMo6ITi7nsO0AQXdvR2oJmqzg23YAWWLl3c51dfRVaOHHD55fDZZ26oqWNHWLw40hIZhlGQCSUmdQxwD3CrFwL0TBEJJeRo0aRmTWftvaRwfgXnnw/ffuvsEj16uHUThmEYwQhliGkK8AcuUBC4ID8Ph02iwsDNN6dFmSuENG0K33zjhppuuAHuvdfchRuGcTqhKIizVPVx4CSAF+GteM+oP3LERezZty/SkuSYqlVhzhz461/hscfg0ktdlDrDMAwfoSiIP0SkLN6iORE5CygcU3jCxY4dcOWVMLdwm2JKlnSzm154wdkmOnQodLZ3wzDCSCgKYjQwB6gnIq8DnwPF21doy5buFXzBgkhLkmtEYMQI+PJLSE52s3hfeSXSUhmGURAIZRbTp7jV1EOBGUCCqi4Ir1gFnKgoZ+H97LMCFYY0N5xzjus9nH8+3HST206ciLRUhmFEklBmMX0OnKOqH6vqR6qaJCKTQrm4iPQWkY0isllERgXJLy0ib3n534pIAy+9gYgcF5EV3jYxuw0LO716uXif69dHWpI8o3p1Z5f4v/9zvYiOHWHNmkhLZRhGpAhliKkhMFJEHvBLS8iosA8RiQaeB/oALYFrRKRlQLEbgYOq2hgYD/g7OPpJVeO9bXgIcuYvPXu6z4VFK65SdLTz/jp7tlsvcfbZLtZ1EekoGYaRDUJREIeAHkBNEflQRCqFeO2OwGZV3aKqfwBvAgMCygwApnn7M4EeIoXE52j9+rBpk1uiXATp0wdWrYLu3Z1vwv79ITEx0lIZhpGfhKIgRFWTVfUW4F1gMVAjhPPqADv9jnd5aUHLqGoycBiI9fIaisgPIrJQRM4PKpjIzSKyTESWJUbi6dW4cZH2oV2zJnz8MUyY4MwtcXGuZ2EYRvEgFAWROv6vqlNxxupPwySPj73AmaraDrgLeENEKgYWUtVJqpqgqgnVq1cPs0hB2LMHhgwplG43QkXE9SCWLnU2in79YOhQOHgw0pIZhhFuMlQQfg/kd0Skqm8DtgJ3h3Dt3UA9v+O6XlrQMiJSAqgEHFDV31X1AICqLgd+ApqGUGf+UrEivPkmvP9+pCUJO3FxsGyZM2C/9hq0agUffhhpqQzDCCeZ9SDe8D6XA8u8z+V+x1mxFGgiIg1FpBRwNTAroMws4AZv/0rgC1VVEanuGbnxXI03AbaEUGf+Ur48XHihUxDFwIpburQzYH/3netN9O9f4MN0G4aRCzJUEKp6iffZUFUbeZ++rVFG5/mdnwzcCswF1gNvq+paERkjIr5wpa8AsSKyGTeU5JsKewGwSkRW4IzXw1W1YDqCGDgQNm8uVvNB27d3Q06jR7sARM2bw9SpxUJHGkaxQjSDf7WItM/sRFUtUE4ZEhISdNmyCAS6+/lnqFULHnjAbcWM1avdRK6vv3bO//77X2jdOtJSGYYRKiKyPCBqaCqZRSh+MpM8BS7MlVRFhZo14ZproFKos3+LFnFxzk3HlCnwz39Cu3Zw551w//1uBM4wjMJLhj2IwkbEehBGKklJMHIkTJ4MderAo486G0VUKHPlDMOICJn1IEL664pIaxG5SkSG+La8FbEIkJzsXG8UY6pVcy46vvrKjboNGeJ8PBXhWcCGUaQJxRfTA8Cz3tYdeBzon+lJxZFLLnGLBAzOPddFrZs+HfbudbaJq66yONiGUdgIpQdxJc7Vxj5VHQa0xa1XMPy59FJYudJtBlFRcP31sHGjm+308cfQooUbgrLARIZROAhFQRxX1RQg2Vs8t5/0C+AMgKuvdhF4pk3Lumwxolw5N7nrxx9h0CB44glo2NCtpzh6NNLSGYaRGaEoiGUiUhl4CbdI7ntgSTiFKpTExrphptdfh5MnIy1NgaNOHac7V650awv//W9o1AjGj7e4E4ZRUAklYNAtqnpIVScCPYEbvKEmI5AbboD9+2HevEhLUmCJi4P33nM2inbt4K67nM/DiRPh9+IdyNYwChyhzmJq461+bg80FpGB4RWrkNK3r3N72qtXpCUp8HTsCJ9+CvPnO8/pI0bAWWfBM8/Ab79FWjrDMCC0WUyTgcnAFcCl3nZJmOUqnJQsCRdd5KLuGCHRrRssXuyURePGcMcd0KABPPYYHDkSYeEMo5iT5UI5EVmnqoGR4AocBWahnCrcdx9Uruym7BjZYvFieOQRF/q0cmW4/Xb429+gRigRSAzDyDa5XSi3JEioUCMjRFyc6nHjzPqaA847Dz75xDkD7N4dxoyBM8+Ev/wF1q2LtHSGUbwIRUFMxymJjSKySkRWi8iqcAtWqLntNud34q23Ii1JoSUhAf73P6drhw1Li0HRp48z8xQRDzGGUaAJZYjJ54p7NZDiS1fV7eEVLXsUmCEmcE+vVq2cTWLFiiIdljS/SEqCF1+E556Dffucx9g773R+EsuWjbR0hlF4ye0QU6KqzlLVraq63bflsYxFCxFnf1i1yoI45xHVqrlodtu2udgTUVFw441ufcU//uEW4hmGkbeEoiB+EJE3ROQaERno28IuWWHn2mvd3M2GDSMtSZGidGm33GTFCvjiCzdpbMIEaNbM7b/7rq1TNIy8IpQhpilBklVV/xwekXJGgRpiMvKVvXudi/FJk2DHDqhdG266Cf78Z7fGwjCMjMnxEJMXF/qAqg4L2EJSDiLS2zNubxaRUUHyS4vIW17+tyLSICD/TBE5JiJ3h1JfgeTHH91UHLOqho1atdzw05YtMGsWtG0LDz3kOm8XXeQM3Lb4zjCyT6YKQlVPAV1ycmFPuTwP9AFaAtcEmS57I3BQVRsD44GxAflPAZ/kpP4Cw5w5zlvdp59GWpIiT3S0c6o7e7ZzLT56tFMa118PZ5zhpsp+/bXpasMIlVCGmP4L1AHeAX71pavq/7I4rzMwWlUv9o7v9c571K/MXK/MEhEpAewDqquqishlOOX0K3BMVcdlVl+BHWL6/Xdo3tyt+lq+3MKr5TMpKS4k6tSp8M478Ouv0LQpDB3qot2deWakJTSMyJLbWUxlgAO4GNTZcbVRB9jpd7zLSwtaRlWTgcNArIiUB0YCD4ZQT8GmdGk33rFiBbz9dqSlKXZERUHXri5m9r597vOMM9xi9/r13cK855+Hn3+OtKSGUfAIxZtroP0hZBtELhgNjFfVY5kVEpGbRWSZiCxLTEwMs0i54Npr3cD4qFFw/HikpSm2lC/veg4LF8JPPzmXHocPw623OsN2r15OgRw6FGlJDaNgEIqzvroi8p6I7Pe2d0WkbgjX3k36wEJ1vbSgZbwhpkq43so5wOMisg24A7hPRG4NrEBVJ6lqgqomVK9ePQSRIkRUlHNTOmCAi11tRJxGjVwvYvVqt40a5ZTGn/8MNWvC5ZfDjBlOgRhGcSUUG8RnwBvAq17SdcBgVe2ZxXklgB9x4Up3A0uBa1V1rV+ZvwFxqjpcRK4GBqrqVQHXGU1htkEYhQZV5wNqxgznJWXv3jQHvQMHQv/+5jTQKHrk1gZRXVWnqGqyt00Fsnxd92wKtwJzgfXA26q6VkTGeLElAF7B2Rx87jxOmwpb5PjyS7f016bSFDhEXJyK8eNh507nWfb222HDBjcDqlYtZ894+mnYbr4EjGJAKD2Iz4EpwAwv6RpgmKr2CLNs2aLQ9CCeesopiDfecI6EjAKPqvOa8r//uWh4q1e79Pbt4bLLoF8/Fx3PXG4ZhZHMehChKIj6wLNAZ0CBr4HbVXVHXguaGwqNgjh1Cs491w14r1tnYxaFkM2bnaL43/9c6FRV17vo29dtPXtChQqRltIwQiNXCqKwUGgUBMDate7189JL3eR8e/UstOzf7+JXfPwxzJ3rouCVLAkXXOB6Fv36uXUXhlFQyZGCEJH7M7mmqupDeSFcXlGoFATA2LFu6sz777vZTUah5+RJt1L744/d5gtwdNZZrldx0UVw4YVQpUpk5TQMf3KqIP4RJLkczj1GrKqWzzsRc0+hUxApKc5J0ODBFsO6iLJtm1MUc+bAggVw7Jib8ZyQ4BRGz57QuTOUKhVpSY3iTK6HmESkAvB3nHJ4G3hSVffnqZS5pNApCH/27YOKFSEmJtKSGGHi5Elnr/jsM7d9950zR8XEuJlRvh5Gq1bmjcXIX3KsIESkKm766WBgGvCMqh4Mi5S5pNAqiMOHXTCDSy+Fl16KtDRGPnH4sOtV+BSGL+BRbKxTGL4tLs4UhhFeMlMQJTI56QlgIDAJt5gtU7cXRg6pVMkt3330UYiPh7/9LdISGflApUrO9OQzP+3YAZ9/7tyALFzoZkiBs1dccEGawmjb1kYkjfwjMxtECvA7kIyb3pqahTNSVwy/eKFTaHsQ4MYaLr/c+an+5BM33mAUa7ZvT1MWPt9R4BTLeee57dxz4eyzLSa3kTtsmmth4OhR6NLFvUp+953NjTTSsWtXmrJYtAg2bnTpJUq4GdPnnpu21Qn0mWwYmWAKorCwfbsLLvTss7bSysiUpCT45hv46is3tfa77+DECZd35pnpFUabNm5thmEEwxREYeTIEef5tWrVSEtiFAL++ANWrnTK4uuvneLY7flOLlPGuQI5+2y3dewIjRub8dtwmIIobKg6y+TJkzBvngtkYBjZZOfOtN7F0qUuoKEvNnelSm49RseOaYqjTh1b1F8cMQVRGHnvPfjTn9zUlQ8/tDUSRq5JTob1652yWLrUKY5Vq9JClJxxhlMUCQmuxxEfD3XrmtIo6piCKKy89hrccIMzXn/0kVtMZxh5yIkTbmjKpzCWLnUGcN9jITY2TVm0a+e2pk1tqm1RIkfrIIwCwHXXOeviddfBTTdZTGsjzylTBs45x20+jh1zPYsffnCh1H/4ASZMcHYOcNNq27RJrzRat7ZOblHEehCFgdmzoUULaNgw0pIYxZSTJ13gpB9+SK84fCFZo6KcU8K4OKcsfJ+NG7upuEbBxYaYigqqcPfdcP317vXNMCKIqnNIuGKF29ascdvmzc4XJUDp0u7dxl9pxMWZbaMgYQqiqLB3r5t2cvCgG27q2zfSEhnGaRw/7ozhq1enKY3Vq9Om3YKbRdW6tdtatIDmzd1n3bo2/Ta/iZiCEJHewDNANPCyqj4WkF8amA50AA4Ag1R1m4h0xPmAAufaY7SqvpdZXcVCQQDs2QOXXOIsi488AiNH2quYUSg4eDC9wvDtH/Rz/1munPNd6VMYvs8mTcwteriIiIIQkWjgR6AnsAtYClyjquv8ytwCtFHV4SJyNXC5qg4SkRjgD1VNFpFawEqgtqomZ1RfsVEQ4KyIN90Eb73lPs0LrFFIUXVR+TZscL0O/88dfkGNo6OhUaP0SqN5czejytaS5o5IzWLqCGxW1S2eEG8CA4B1fmUGAKO9/ZnAcyIiqvqbX5kypHcWaJQvDzNmuKknrVpFWhrDyDEiULOm27p2TZ937Jhzgx6oOD75xBnNfVSt6noYgVvjxlC5cr42p8gRTgVRB9jpd7wLOCejMl5v4TAQCySJyDnAZKA+cH2w3oOI3AzcDHDmmWfmeQMKNCJw551px48+6gZv777bJqkbRYLy5Z0jwvbt06cnJ8PWrU5hbNqUti1c6JYO+VOtWnDl0aSJuTsLhQI7AU1VvwVaiUgLYJqIfKKqJwLKTMKzVSQkJBTfXoaqs0m89ZZ7vZo+3XlsM4wiSIkSaQ/5QI4fd67RN29Orzw+/9z9LfypWdP1Mho2dMNX/p916pixHMKrIHYD9fyO63ppwcrsEpESQCWcsToVVV0vIseA1kAxMTJkExE35NS7N9x2m1vFNG6cC0Rkv3KjGFG2bNrsqEB++80pDn/l8dNPzn36G2+kTc0FZxBv0CC48mjUqPgMXYXTSF0CZ6TugVMES4FrVXWtX5m/4aLV+YzUA1X1KhFpCOz0hp3qA0twxuykjOorVkbqzNiyxSmGr75yU0SaNYu0RIZR4PnjD2cU37rV/YV8n779X35JX75y5TSF0bAh1K/vOu2+z8qVC8/kwogYqb2H+63AXNw018mqulZExgDLVHUW8ArwqohsBn4BrvZOPw8YJSIngRTglsyUg+FHo0Ywf75z3elTDu++69ZMWOgxwwhKqVJuuKlx4+D5hw+frjy2bnXvYB99BL//nr58hQrpFUbgZ+3ahcNUaAvlijqrV7shp/r1YexYuOqqwvNqYxiFgJQUSEx08b527Aj+GdgDiY52iwJ9CsNfedSr5/IqVcof+W0ldXFnwQI342nFChdibPx4tyLbMIx84dgxpywyUiC7d7vQ9P5UqOAURUZbvXp5M5RlCsJwv76pU+H//s9NIt+1y4acDKOAkJzsnCTs2OH+msG2vXvTG9LBedCtWxeuuAL+85+c1W3uvg3Xp73xRjfE9MMPTjmkpDhXHTfe6JalGoYREUqUSBtqyojkZNi373TFsXNn+GZVWQ+iOLNmDXTq5CaPX3MN3HcftGwZaakMw8hHMutB2CT54kzr1m4qxt13uxCnrVpBv37OOY5hGMUeUxDFnerV3eym7dthzBg33cLn/Wzt2vRObwzDKFaYgjAc1arBv/8NX3/tBkRPnIALL3Rz7+6/3w10GoZRrDAFYaTHN2euVCmYPNl5Snv4Yed3oH9/twDPMIxigSkIIzhRUc4e8dFHbtnovffCd9+5Cd3ghqTWrImsjIZhhBVTEEbWNGjgehE7dsAFF7i08eNdcOH27d3+vn0RFdEwjLzHFIQROqVKpQ1B3XcfPPOMW19x113OP/KgQZGVzzCMPMUUhJEzatSA22+HpUth3ToYNSrN05kqDBkCzz2XPlK9YRiFClsoZ+Q9v/wC55/vFAe40Kj9+sG118JZZ0VWNsMw0mEL5Yz8pWpVt4Zi3Tp46CHXo3jggbQZUDt2OBfkR45EVk7DMDLFehBG/rB/vwsyHBMDTz0F//iHW29x3nnQo4dbc3HOOYXDSb5hFCHMm6tRsDh5EpYsgdmzYe5cF087OhoOHnRK5JtvoEwZF8fCQqYaRlgxBWEUbA4ccEriwgvdcdeuLlBw1arQpYvbune3GBaGEQbM3bdRsImNTVMOAK+/7sKmzp/vYmt/+CFcfDHMmePyn3wSmjRxwY+qVYuMzIZRDAhrD0JEegPP4GJSv6yqjwXklwamAx2AA8AgVd0mIj2Bx4BSwB/APar6RWZ1WQ+iCJOY6IafmjaFX391SuHECZd31lmQkAA33AB9+kRWTsMohESkByEi0cDzQE9gF7BURGap6jq/YjcCB1W1sYhcDYwFBgFJwKWqukdEWgNzgTrhktUo4FSv7jaAcuXcNNply5xjwaVLnc3ivPNc/tatcMklTmmcfbbb2rSx6HmGkQPCOcTUEdisqlsARORNYADgryAGAKO9/ZnAcyIiqvqDX5m1QFkRKa2qv4dRXqOwULasW2dx/vlpab5YjMePQ6NGzvg9fbpLi4qCjz+G3r2dD6nVq6FtWxerMbcBfQ2jCBNOBVEH8PcRvQs4J6MyqposIoeBWFwPwscVwPfBlIOI3AzcDHBmZrH6jKKPb7ZTy5bOZqHq4jEuW+YM4K1bu/wPP4TbbnP7Vaq43kXbts7VebVqTtHYzCnDAAq4kVpEWuGGnXoFy1fVScAkcDaIfBTNKOiIQL16brv88rT0G26Adu2c0li1yn1OmQKPPOLy//Uv1/No0SL9dsEFpjiMYkc4FcRuoJ7fcV0vLViZXSJSAqiEM1YjInWB94AhqvpTGOU0ihMVKqRNnfXh32tISHD+o9avd4rj2DEXEf6XX1z+ww+7YarmzZ3vqcaN3ZCW2TiMIkg4FcRSoImINMQpgquBawPKzAJuAJYAVwJfqKqKSGXgY2CUqn4VRhkNI33PYOBAt0HaMNWePWm2ih074P33IclvFLRNG9cTAXjiCffZpIlTHmedZcrDKLSEe5prX+Bp3DTXyar6iIiMAZap6iwRKQO8CrQDfgGuVtUtIvIv4F5gk9/leqnq/ozqsmmuRr7yyy+webPboqPTXJ3HxZ0eSOn669MM5k8+6WwdDRq4rU4d53LEMCKEraQ2jPzk0KE05bFpkxuCGjzYuRiJiYHk5LSy0dEwcqSzgSQnu0+f8mjQAGrXhpIlI9MOo1hgK6kNIz+pXNnZMhIC/nMlSzqbxs6dsG1b2tapk8vftw8efNANbfkQgaefdrE3fv7ZKZB69dwU3bp13X6dOqZEjLBgCsIw8pPSpdOM24HUrevWcfgrkJ073WI/cMbzadNOd5P+2muuh7JypXOr7lMctWq57eyzndIyjGxiCsIwChKZKZD27eHwYacgdu1K28491+UfOgQ//QQLF7p9HwsXumm677zj3KzXqgVnnJH2OWIE1KzpnCb+9pvbL1UqP1prFHBMQRhGYaNiRbcgsGXL9Oldu7pV4uCGsvbudcNWbdu6tFq1nFPEvXudS5Kvv3azsYYMcfmTJ8M//+n2Y2PTFMhbbznPul995YJA1ajhXJ/4PitWtBXpRRRTEIZRFClf3k21bdIkLe2889J8Vvn444+0WVR9+kClSk6B+Lb9+51hHeDtt2HChNPrOnnSXWPsWOeB11+B1KqVpoCSkpytxBRKocEUhGEUZ/yHklq3TnNJEoyxY90QVWKiUxyJiW7Iy6dgUlKc192NG13er7+6HohPQfz5z87VSXS065HExrppwW+/7fJfeskpkdhYt1Wt6mZxNWsWnrYbWWLTXA3DCA+//eZsIbVru+PZs90K9QMH3DqSAwecIpg40eV36eKGvfzp3Dkt7Zxz3KJFnwKJjXX2lzvucPlvvumUT+XKaVv16magzwKb5moYRv4TE5M2PAXQt6/bMuKrr9wsLn8F4t/DufRSZ4Q/cMBtq1e74Soft97q0v257jp49VW336yZmwTgr0D69oWrr3a9n2nTnAPHQAVTrlxuvoVCjSkIwzAKDmXLpq3xCORf/8r83JUr3RDXoUNpnz4vzykprofiy9u50ymYhg1d/rFjbggskH//G8aMcUNqHTo4G03FimnbsGHOdvPLLzB1alq6r1yTJmleglVdD6cQYQrCMIyiQZ06bgtGVJSbpZUR5cq5mV2BCsY3AywqCnr2dFOMjxxxeTt2pPnk2rnT2WcCmTIFhg6Fb791w2EVKqRXMGPHutln69bBpEkurUKFtO2ii9y040OH3Iy08uVdevny+aJsTEEYhmFER6e5NwlGtWqZK5i4OPcQ9ykQ33oVn9G/Vi23iNE/78iRtCG07dvd9Y8eTX/dBQucgvj4Yzdc5k9MDCxe7NzXhwkzUhuGYRQUUlLc7K9jx5yyqFvXKYLt252x/ujRtLyjR9MWPuYCM1IbhmEUBqKi0oaX/B/89eu7Lb/FyfcaDcMwjEKBKQjDMAwjKKYgDMMwjKCYgjAMwzCCYgrCMAzDCIopCMMwDCMopiAMwzCMoJiCMAzDMIJSZFZSi0gisD0Xl6gGJOWROJGkqLQDrC0FFWtLwSSnbamvqtWDZRQZBZFbRGRZRsvNCxNFpR1gbSmoWFsKJuFoiw0xGYZhGEExBWEYhmEExRREGpMiLUAeUVTaAdaWgoq1pWCS520xG4RhGIYRFOtBGIZhGEExBWEYhmEEpdgrCBHpLSIbRWSziIyKtDzZRUS2ichqEVkhIsu8tKoi8pmIbPI+q0RazmCIyGQR2S8ia/zSgsoujgnefVolIu0jJ/npZNCW0SKy27s3K0Skr1/evV5bNorIxZGR+nREpJ6IzBeRdSKyVkT+7qUXuvuSSVsK430pIyLfichKry0PeukNReRbT+a3RKSUl17aO97s5TfIUcWqWmw3IBr4CWgElAJWAi0jLVc227ANqBaQ9jgwytsfBYyNtJwZyH4B0B5Yk5XsQF/gE0CATsC3kZY/hLaMBu4OUral91srDTT0foPRkW6DJ1stoL23XwH40ZO30N2XTNpSGO+LAOW9/ZLAt973/TZwtZc+ERjh7d8CTPT2rwbeykm9xb0H0RHYrKpbVPUP4E1gQIRlygsGANO8/WnAZZETJWNUdRHwS0ByRrIPAKar4xugsojkLhhvHpJBWzJiAPCmqv6uqluBzbjfYsRR1b2q+r23fxRYD9ShEN6XTNqSEQX5vqiqHvMOS3qbAhcCM730wPviu18zgR4iItmtt7griDrATr/jXWT+AyqIKPCpiCwXkZu9tJqqutfb3wfUjIxoOSIj2QvrvbrVG3qZ7DfUVyja4g1LtMO9rRbq+xLQFiiE90VEokVkBbAf+AzXwzmkqsleEX95U9vi5R8GYrNbZ3FXEEWB81S1PdAH+JuIXOCfqa6PWSjnMhdm2T3+C5wFxAN7gScjKk02EJHywLvAHap6xD+vsN2XIG0plPdFVU+pajxQF9ezaR7uOou7gtgN1PM7ruulFRpUdbf3uR94D/fD+dnXzfc+90dOwmyTkeyF7l6p6s/enzoFeIm04YoC3RYRKYl7oL6uqv/zkgvlfQnWlsJ6X3yo6iFgPtAZN6RXwsvylze1LV5+JeBAdusq7gpiKdDEmwlQCmfMmRVhmUJGRMqJSAXfPtALWINrww1esRuADyIjYY7ISPZZwBBv1kwn4LDfkEeBJGAs/nLcvQHXlqu9mSYNgSbAd/ktXzC8cepXgPWq+pRfVqG7Lxm1pZDel+oiUtnbLwv0xNlU5gNXesUC74vvfl0JfOH1/LJHpK3zkd5wszB+xI3n/V+k5cmm7I1wsy5WAmt98uPGGj8HNgHzgKqRljUD+WfguvgnceOnN2YkO24Wx/PefVoNJERa/hDa8qon6yrvD1vLr/z/eW3ZCPSJtPx+cp2HGz5aBazwtr6F8b5k0pbCeF/aAD94Mq8B7vfSG+GU2GbgHaC0l17GO97s5TfKSb3masMwDMMISnEfYjIMwzAywBSEYRiGERRTEIZhGEZQTEEYhmEYQTEFYRiGYQTFFIRhZIGInPLz/LlC8tDrr4g08PcAaxgFiRJZFzGMYs9xdS4ODKNYYT0Iw8gh4mJxPC4uHsd3ItLYS28gIl94zuA+F5EzvfSaIvKe59N/pYic610qWkRe8vz8f+qtlEVEbvdiGawSkTcj1EyjGGMKwjCypmzAENMgv7zDqhoHPAc87aU9C0xT1TbA68AEL30CsFBV2+JiR6z10psAz6tqK+AQcIWXPgpo511neHiaZhgZYyupDSMLROSYqpYPkr4NuFBVt3hO4fapaqyIJOHcN5z00veqajURSQTqqurvftdoAHymqk2845FASVV9WETmAMeA94H3NS0egGHkC9aDMIzcoRnsZ4ff/fZPkWYb7Ifzc9QeWOrntdMw8gVTEIaROwb5fS7x9r/GeQYGGAx86e1/DoyA1OAvlTK6qIhEAfVUdT4wEueu+bRejGGEE3sjMYysKetF8vIxR1V9U12riMgqXC/gGi/tNmCKiNwDJALDvPS/A5NE5EZcT2EEzgNsMKKB1zwlIsAEdXEADCPfMBuEYeQQzwaRoKpJkZbFMMKBDTEZhmEYQbEehGEYhhEU60EYhmEYQTEFYRiGYQTFFIRhGIYRFFMQhmEYRlBMQRiGYRhB+X+Qs89xvcsWQAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# (ii) Plot Batch vs. Stochastic Gradient Descent\n",
    "plt.clf()\n",
    "# plt.set_size_inches(18.5, 10.5)\n",
    "\n",
    "epochs_error_bar = [50, 100, 150, 200, 250, 300] # 1-indexed\n",
    "epochs_error_bar_0 = [epoch - 1 for epoch in epochs_error_bar] # 0-indexed\n",
    "\n",
    "# Plot Loss\n",
    "average_train_loss = average_out_data_k(train_loss_record)\n",
    "train_loss_error_bar_y = [average_train_loss[epoch] for epoch in epochs_error_bar_0]\n",
    "train_loss_error_bar_yerr = [np.std(get_data_at_epoch_fold(train_loss_record, epoch)) for epoch in epochs_error_bar_0]\n",
    "\n",
    "plt.plot(sgd_train_loss, '-b', label='Stochastic lr=0.1')\n",
    "plt.errorbar(x=epochs_error_bar_0, y=sgd_train_loss_error_bar_y, yerr=sgd_train_loss_error_bar_yerr, label='Stochastic error', fmt='-b', linestyle='')\n",
    "\n",
    "plt.plot(batch_average_train_loss, '--r', label='Batch lr=0.5')\n",
    "plt.errorbar(x=epochs_error_bar_0, y=batch_average_train_loss_error_bar_y, yerr=batch_average_train_loss_error_bar_yerr, label='Batch error', fmt='--r', linestyle='')\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Normalized Loss')\n",
    "plt.title('Batch vs. Stochastic Normalized Training Loss')\n",
    "\n",
    "plt.savefig(\"plots/Q6b_ii_new2.png\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### (c) Visualize the weights\n",
    "\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "def weights2range(w, min=0, max=256):\n",
    "    # Scales weights to be between min and max\n",
    "    w /= np.max(w)\n",
    "    w *= (max)\n",
    "    w += min\n",
    "    return w\n",
    "\n",
    "# Plot image\n",
    "\n",
    "weight_visualization_weights = best_w[:-1]\n",
    "\n",
    "# Traffic sign classes to be plotted\n",
    "ts_classes = [7, 11, 21, 25]\n",
    "\n",
    "fig, axs = plt.subplots(4,1) \n",
    "fig.set_size_inches(10, 6)\n",
    "\n",
    "for i, ts_class in enumerate(ts_classes):\n",
    "    # Get weights for each class\n",
    "    class_weights = weight_visualization_weights[:,ts_class].reshape((32, 32))\n",
    "    # Scale to [0, 256]\n",
    "    img_weights = weights2range(class_weights)\n",
    "    # Plot image\n",
    "    axs[i].set_title(f'Class {ts_class}')\n",
    "    axs[i].imshow(img_weights)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/Q6c_weights.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "005f4ed24810181fa8b2266ec303702d6575bedfaa41c7848d327e7f780b3129"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
