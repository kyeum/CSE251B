{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification (PA3.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Victor\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torchvision\\io\\image.py:11: UserWarning: Failed to load image Python extension: [WinError 127] The specified procedure could not be found\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in starter_4\n",
      "GPU_STATUS: False\n",
      "creating model...\n",
      "GPU: False\n",
      "Training...\n",
      "in val\n",
      "x1bnd1:  torch.Size([8, 32, 192, 384])\n",
      "x1maxpool: torch.Size([8, 32, 192, 384])\n",
      "x2.shape torch.Size([8, 64, 96, 192])\n",
      "x3: torch.Size([8, 128, 48, 96])\n",
      "x3pool: torch.Size([8, 128, 48, 96])\n",
      "out_encoder:  torch.Size([8, 512, 12, 24])\n",
      "y1 torch.Size([8, 512, 24, 48])\n",
      "y4.shape torch.Size([8, 64, 192, 384])\n",
      "out_decoder.shape torch.Size([8, 32, 384, 768])\n",
      "x1bnd1:  torch.Size([8, 32, 192, 384])\n",
      "x1maxpool: torch.Size([8, 32, 192, 384])\n",
      "x2.shape torch.Size([8, 64, 96, 192])\n",
      "x3: torch.Size([8, 128, 48, 96])\n",
      "x3pool: torch.Size([8, 128, 48, 96])\n",
      "out_encoder:  torch.Size([8, 512, 12, 24])\n",
      "y1 torch.Size([8, 512, 24, 48])\n",
      "y4.shape torch.Size([8, 64, 192, 384])\n",
      "out_decoder.shape torch.Size([8, 32, 384, 768])\n",
      "x1bnd1:  torch.Size([8, 32, 192, 384])\n",
      "x1maxpool: torch.Size([8, 32, 192, 384])\n",
      "x2.shape torch.Size([8, 64, 96, 192])\n",
      "x3: torch.Size([8, 128, 48, 96])\n",
      "x3pool: torch.Size([8, 128, 48, 96])\n",
      "out_encoder:  torch.Size([8, 512, 12, 24])\n",
      "y1 torch.Size([8, 512, 24, 48])\n",
      "y4.shape torch.Size([8, 64, 192, 384])\n",
      "out_decoder.shape torch.Size([8, 32, 384, 768])\n",
      "x1bnd1:  torch.Size([8, 32, 192, 384])\n",
      "x1maxpool: torch.Size([8, 32, 192, 384])\n",
      "x2.shape torch.Size([8, 64, 96, 192])\n",
      "x3: torch.Size([8, 128, 48, 96])\n",
      "x3pool: torch.Size([8, 128, 48, 96])\n",
      "out_encoder:  torch.Size([8, 512, 12, 24])\n",
      "y1 torch.Size([8, 512, 24, 48])\n",
      "y4.shape torch.Size([8, 64, 192, 384])\n",
      "out_decoder.shape torch.Size([8, 32, 384, 768])\n",
      "x1bnd1:  torch.Size([8, 32, 192, 384])\n",
      "x1maxpool: torch.Size([8, 32, 192, 384])\n",
      "x2.shape torch.Size([8, 64, 96, 192])\n",
      "x3: torch.Size([8, 128, 48, 96])\n",
      "x3pool: torch.Size([8, 128, 48, 96])\n",
      "out_encoder:  torch.Size([8, 512, 12, 24])\n",
      "y1 torch.Size([8, 512, 24, 48])\n",
      "y4.shape torch.Size([8, 64, 192, 384])\n",
      "out_decoder.shape torch.Size([8, 32, 384, 768])\n",
      "x1bnd1:  torch.Size([8, 32, 192, 384])\n",
      "x1maxpool: torch.Size([8, 32, 192, 384])\n",
      "x2.shape torch.Size([8, 64, 96, 192])\n",
      "x3: torch.Size([8, 128, 48, 96])\n",
      "x3pool: torch.Size([8, 128, 48, 96])\n",
      "out_encoder:  torch.Size([8, 512, 12, 24])\n",
      "y1 torch.Size([8, 512, 24, 48])\n",
      "y4.shape torch.Size([8, 64, 192, 384])\n",
      "out_decoder.shape torch.Size([8, 32, 384, 768])\n",
      "x1bnd1:  torch.Size([2, 32, 192, 384])\n",
      "x1maxpool: torch.Size([2, 32, 192, 384])\n",
      "x2.shape torch.Size([2, 64, 96, 192])\n",
      "x3: torch.Size([2, 128, 48, 96])\n",
      "x3pool: torch.Size([2, 128, 48, 96])\n",
      "out_encoder:  torch.Size([2, 512, 12, 24])\n",
      "y1 torch.Size([2, 512, 24, 48])\n",
      "y4.shape torch.Size([2, 64, 192, 384])\n",
      "out_decoder.shape torch.Size([2, 32, 384, 768])\n",
      "Loss at epoch: 0 is 4.384551593235561\n",
      "IoU at epoch: 0 is 0.0007994328251308096\n",
      "Pixel acc at epoch: 0 is 0.0023055336725000025\n",
      "in train\n",
      "x1bnd1:  torch.Size([8, 32, 192, 384])\n",
      "x1maxpool: torch.Size([8, 32, 192, 384])\n",
      "x2.shape torch.Size([8, 64, 96, 192])\n",
      "x3: torch.Size([8, 128, 48, 96])\n",
      "x3pool: torch.Size([8, 128, 48, 96])\n",
      "out_encoder:  torch.Size([8, 512, 12, 24])\n",
      "y1 torch.Size([8, 512, 24, 48])\n",
      "y4.shape torch.Size([8, 64, 192, 384])\n",
      "out_decoder.shape torch.Size([8, 32, 384, 768])\n",
      "epoch0, iter0, loss: 4.204311370849609\n",
      "x1bnd1:  torch.Size([8, 32, 192, 384])\n",
      "x1maxpool: torch.Size([8, 32, 192, 384])\n",
      "x2.shape torch.Size([8, 64, 96, 192])\n",
      "x3: torch.Size([8, 128, 48, 96])\n",
      "x3pool: torch.Size([8, 128, 48, 96])\n",
      "out_encoder:  torch.Size([8, 512, 12, 24])\n",
      "y1 torch.Size([8, 512, 24, 48])\n",
      "y4.shape torch.Size([8, 64, 192, 384])\n",
      "out_decoder.shape torch.Size([8, 32, 384, 768])\n",
      "x1bnd1:  torch.Size([8, 32, 192, 384])\n",
      "x1maxpool: torch.Size([8, 32, 192, 384])\n",
      "x2.shape torch.Size([8, 64, 96, 192])\n",
      "x3: torch.Size([8, 128, 48, 96])\n",
      "x3pool: torch.Size([8, 128, 48, 96])\n",
      "out_encoder:  torch.Size([8, 512, 12, 24])\n",
      "y1 torch.Size([8, 512, 24, 48])\n",
      "y4.shape torch.Size([8, 64, 192, 384])\n",
      "out_decoder.shape torch.Size([8, 32, 384, 768])\n",
      "x1bnd1:  torch.Size([8, 32, 192, 384])\n",
      "x1maxpool: torch.Size([8, 32, 192, 384])\n",
      "x2.shape torch.Size([8, 64, 96, 192])\n",
      "x3: torch.Size([8, 128, 48, 96])\n",
      "x3pool: torch.Size([8, 128, 48, 96])\n",
      "out_encoder:  torch.Size([8, 512, 12, 24])\n",
      "y1 torch.Size([8, 512, 24, 48])\n",
      "y4.shape torch.Size([8, 64, 192, 384])\n",
      "out_decoder.shape torch.Size([8, 32, 384, 768])\n",
      "x1bnd1:  torch.Size([8, 32, 192, 384])\n",
      "x1maxpool: torch.Size([8, 32, 192, 384])\n",
      "x2.shape torch.Size([8, 64, 96, 192])\n",
      "x3: torch.Size([8, 128, 48, 96])\n",
      "x3pool: torch.Size([8, 128, 48, 96])\n",
      "out_encoder:  torch.Size([8, 512, 12, 24])\n",
      "y1 torch.Size([8, 512, 24, 48])\n",
      "y4.shape torch.Size([8, 64, 192, 384])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2248/2947660278.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[0mval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfcn_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# show the accuracy before training\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"latest_model_5a\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m \u001b[0mtrain_loss_record\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_loss_record\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfcn_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_fp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\Victor\\OneDrive\\Documents\\UCSD\\0CSE251B\\CSE251B\\PA3_starter\\starter_4.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(fcn_model, epochs, learning_rate, save_fp)\u001b[0m\n\u001b[0;32m     74\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#transfer the labels to the same device as the model's\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfcn_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#we will not need to transfer the output, it will be automatically in the same device as the model's!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#calculate loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Victor\\OneDrive\\Documents\\UCSD\\0CSE251B\\CSE251B\\PA3_starter\\custom_fcn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, output_size)\u001b[0m\n\u001b[0;32m    914\u001b[0m             input, output_size, self.stride, self.padding, self.kernel_size, self.dilation)  # type: ignore[arg-type]\n\u001b[0;32m    915\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 916\u001b[1;33m         return F.conv_transpose2d(\n\u001b[0m\u001b[0;32m    917\u001b[0m             \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    918\u001b[0m             output_padding, self.groups, self.dilation)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from custom_fcn import *\n",
    "from utils import *\n",
    "import torch.optim as optim\n",
    "import time\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import gc\n",
    "import copy\n",
    "from dataloader_4 import *\n",
    "from starter_4 import *\n",
    "\n",
    "\n",
    "#hyper param\n",
    "epochs = 30   \n",
    "lr = 0.0004\n",
    "criterion = nn.CrossEntropyLoss()# Choose an appropriate loss function from https://pytorch.org/docs/stable/_modules/torch/nn/modules/loss.html\n",
    "n_class = 10\n",
    "\n",
    "print(\"creating model...\")\n",
    "fcn_model = Custom(n_class=n_class)\n",
    "fcn_model.apply(init_weights)\n",
    "\n",
    "# gpu\n",
    "gpu_status = torch.cuda.is_available()\n",
    "print(\"GPU:\", gpu_status)\n",
    "\n",
    "if gpu_status : \n",
    "    device = torch.device('cuda') # determine which device to use (gpu or cpu)\n",
    "else : \n",
    "    device = torch.device('cpu')\n",
    "\n",
    "fcn_model.to(device)\n",
    "    \n",
    "print(\"Training...\")\n",
    "val(fcn_model, 0)  # show the accuracy before training\n",
    "model_name=\"latest_model_5a\"\n",
    "train_loss_record, valid_loss_record = train(fcn_model, epochs,lr, save_fp=model_name) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_fcn_model = torch.load(model_name)\n",
    "latest_fcn_model.to(device)\n",
    "test(latest_fcn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Continue training\n",
    "# model_name = \"latest_model_4_50e\"\n",
    "# # Train for 10 more epochs\n",
    "# train_loss_record, valid_loss_record = train(fcn_model, 20,lr, save_fp=model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# latest_fcn_model = torch.load(model_name)\n",
    "# latest_fcn_model.to(device)\n",
    "# test(latest_fcn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "005f4ed24810181fa8b2266ec303702d6575bedfaa41c7848d327e7f780b3129"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
