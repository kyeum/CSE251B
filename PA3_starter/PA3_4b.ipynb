{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification (PA3.4b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in starter_4\n",
      "GPU_STATUS: True\n"
     ]
    }
   ],
   "source": [
    "from basic_fcn import *\n",
    "from utils import *\n",
    "import torch.optim as optim\n",
    "import time\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import gc\n",
    "import copy\n",
    "from dataloader_4 import *\n",
    "from starter_4 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = torch.FloatTensor([1.7796e-01, 6.1295e-01, 4.1182e-02, 8.9837e-03, 1.0163e-01, 6.8722e-03,\n",
    "        1.4485e-03, 1.5937e-04, 4.7746e-02, 1.0698e-03])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_class_weights(dataloader):\n",
    "#     # Labels: batch_size x height x width\n",
    "#     total_num_pixels = 0\n",
    "#     n_class = 10\n",
    "#     class_weights = torch.zeros(n_class)\n",
    "#     for i, (inputs, labels) in enumerate(dataloader):\n",
    "#         total_num_pixels += labels.shape[0] * labels.shape[1] * labels.shape[2]\n",
    "#         for cur_class in range(n_class):\n",
    "#             class_weights[cur_class] += torch.sum(labels == cur_class)\n",
    "#         print(\"SANITY CHECK:\", total_num_pixels, class_weights.sum())\n",
    "#         print(\"class_weights:\", class_weights)\n",
    "        \n",
    "#     return class_weights / total_num_pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset_original_1 = TASDataset('tas500v1.1') \n",
    "# train_loader_1 = DataLoader(dataset=train_dataset_original_1, batch_size= 16, shuffle=False)\n",
    "\n",
    "# class_weights = compute_class_weights(train_loader_1)\n",
    "# print(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyper param\n",
    "epochs = 30   \n",
    "lr = 0.0004\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights, reduction=\"mean\")# Choose an appropriate loss function from https://pytorch.org/docs/stable/_modules/torch/nn/modules/loss.html\n",
    "n_class = 10\n",
    "\n",
    "print(\"creating model...\")\n",
    "fcn_model = FCN(n_class=n_class)\n",
    "fcn_model.apply(init_weights)\n",
    "\n",
    "# gpu\n",
    "gpu_status = torch.cuda.is_available()\n",
    "print(\"GPU:\", gpu_status)\n",
    "\n",
    "if gpu_status : \n",
    "    device = torch.device('cuda') # determine which device to use (gpu or cpu)\n",
    "else : \n",
    "    device = torch.device('cpu')\n",
    "\n",
    "fcn_model.to(device)\n",
    "    \n",
    "print(\"Training...\")\n",
    "val(fcn_model, 0)  # show the accuracy before training\n",
    "model_name=\"latest_model_4b\"\n",
    "train_loss_record, valid_loss_record = train(fcn_model, epochs,lr, save_fp=model_name) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'basic_fcn.FCN'>\n",
      "in test\n",
      "Loss :is 0.39947217064244406\n",
      "IoU is 0.45482963506531504\n",
      "Pixel is 0.866791810308184\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name=\"latest_model_4b\"\n",
    "latest_fcn_model = torch.load(model_name)\n",
    "print(type(latest_fcn_model))\n",
    "latest_fcn_model.to(device)\n",
    "test(latest_fcn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "plt.plot(np.arange(epochs), train_loss_record, label= \"Training Loss\")\n",
    "plt.plot(np.arange(epochs), valid_loss_record, label=\"Validation Loss\")\n",
    "plt.xlabel(\"Epoches\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.title(\"4(b) Weighted loss with data augmentation\")\n",
    "plt.savefig(\"plots/Q4_b\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1910/3421290243.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtest_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTASDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tas500v1.1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtest_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mvisualize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"latest_model_4b\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/CSE251B/PA3_starter/utils.py\u001b[0m in \u001b[0;36mvisualize\u001b[0;34m(model_name, test_loader)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0mclass2color\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolor2class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m         \u001b[0mclass2color\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "test_dataset = TASDataset('tas500v1.1', eval_mode=True, mode='test')\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size= batch_size, shuffle=False)\n",
    "visualize(\"latest_model_4b\", test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "005f4ed24810181fa8b2266ec303702d6575bedfaa41c7848d327e7f780b3129"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
